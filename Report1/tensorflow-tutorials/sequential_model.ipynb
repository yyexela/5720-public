{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b518b04cbfe0"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:54.509789Z",
     "iopub.status.busy": "2021-08-25T17:49:54.509134Z",
     "iopub.status.idle": "2021-08-25T17:49:54.511940Z",
     "shell.execute_reply": "2021-08-25T17:49:54.512333Z"
    },
    "id": "906e07f6e562"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Start Alexey Note:\n",
    "- Running the notebook gave me a GPU related error (sorry, forgot to copy the error message `sad face`). Some quick [internet searching](https://www.tensorflow.org/guide/gpu) led me to the following code snippet which resolved my problem:\n",
    "```python\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "```\n",
    " - I also had to `restart` another notebook's kernel which was using a lot of my GPU's memory. Though I can see this setting is limited my GPU usage, it isn't precise... The notebook uses 1439 MiB whereas the limit is 1024 MB (~977 MiB).\n",
    " \n",
    " ## End Alexey Note\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e19705694d6"
   },
   "source": [
    "# The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "defbb10e8ae3"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/sequential_model\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/snapshot-keras/site/en/guide/keras/sequential_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/keras-team/keras-io/blob/master/guides/sequential_model.py\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/keras/sequential_model.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d4ac441b1fc"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:54.519766Z",
     "iopub.status.busy": "2021-08-25T17:49:54.518858Z",
     "iopub.status.idle": "2021-08-25T17:49:56.141321Z",
     "shell.execute_reply": "2021-08-25T17:49:56.140744Z"
    },
    "id": "0472bf67b2bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024*4)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80f7713c6b92"
   },
   "source": [
    "## When to use a Sequential model\n",
    "\n",
    "A `Sequential` model is appropriate for **a plain stack of layers**\n",
    "where each layer has **exactly one input tensor and one output tensor**.\n",
    "\n",
    "Schematically, the following `Sequential` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:56.146198Z",
     "iopub.status.busy": "2021-08-25T17:49:56.145601Z",
     "iopub.status.idle": "2021-08-25T17:49:58.150793Z",
     "shell.execute_reply": "2021-08-25T17:49:58.150218Z"
    },
    "id": "f536515be229"
   },
   "outputs": [],
   "source": [
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(4, name=\"layer3\"),\n",
    "    ]\n",
    ")\n",
    "# Call model on a test input\n",
    "x = tf.ones((3, 3))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d81502d9753"
   },
   "source": [
    "is equivalent to this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.157662Z",
     "iopub.status.busy": "2021-08-25T17:49:58.153304Z",
     "iopub.status.idle": "2021-08-25T17:49:58.164952Z",
     "shell.execute_reply": "2021-08-25T17:49:58.164534Z"
    },
    "id": "7059a8890f72"
   },
   "outputs": [],
   "source": [
    "# Create 3 layers\n",
    "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "# Call layers on a test input\n",
    "x = tf.ones((3, 3))\n",
    "y = layer3(layer2(layer1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdf6d2932c31"
   },
   "source": [
    "A Sequential model is **not appropriate** when:\n",
    "\n",
    "- Your model has multiple inputs or multiple outputs\n",
    "- Any of your layers has multiple inputs or multiple outputs\n",
    "- You need to do layer sharing\n",
    "- You want non-linear topology (e.g. a residual connection, a multi-branch\n",
    "model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Start Alexey Note:\n",
    " - The first thing this notebook does is define a \"Sequential Model\", which looks something like this:\n",
    "\n",
    "<img src=\"../Images/SequentialModel.jpg\" alt=\"Diagram of a sequential model\" width=\"700\"/>\n",
    "\n",
    " - Where \"A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\" The image shows a \"dense\" neural network model, where each node in one layer is connected to every other node in neighboring layers. This is the kind of network that is created in this tutorial, implying there are non-dense and non-stack neural networks as well. Note that the exact network in the notebook is 3 layers of sizes 2, 3, and 4 respectively with the first 2 layers having the \"rectified linear unit activation function\" (\"relu\" for short).\n",
    " - An [activation function](https://deepai.org/machine-learning-glossary-and-terms/activation-function) is used to introduce nonlinearity to a neural network, giving them the ability to \"learn\" complex tasks that you wouldn't necessarily be able to learn without it. The link in the previous sentence claims that neural networks without activation functions can be decomposed into a single matrix acting on the input, which is really cool and I believe the proof is simple: every layer is effectively a matrix, so all layers can be matrix-multiplied together to get a single matrix acting on input and resulting in an output.\n",
    " - A diagram showing a \"feed-forward\" neural network is obtained from [here](https://deepai.org/machine-learning-glossary-and-terms/activation-function):\n",
    "\n",
    "<img src=\"../Images/FeedForward.svg\" alt=\"Diagram of a feed forward neural network\" width=\"700\"/>\n",
    "\n",
    " - The curvy line in a circle is the activation function. Take a look at layer 2. Each neuron is obtaining the values of the previous layer's neurons after being passed in the previous layer's activation function. Layer 2's neurons then take these values and compute their values with the following function:\n",
    "\n",
    "<img src=\"../Images/NeuronFunction.jpg\" alt=\"Formula for a neuron\" width=\"300\"/>\n",
    "\n",
    " - Where the function `f` is the activation function and `B` is some bias. So each successive neuron takes the values of the previous layer's neurons to dtermine it's own value. Though it looks like [Keras'](https://keras.io/api/layers/core_layers/dense/) `Dense` layer puts the bias inside the activation function:\n",
    "\n",
    "<img src=\"../Images/NeuronFunction2.jpg\" alt=\"Formula for a neuron\" width=\"300\"/>\n",
    "\n",
    "## End Alexey Note\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5706d9f8eb8"
   },
   "source": [
    "## Creating a Sequential model\n",
    "\n",
    "You can create a Sequential model by passing a list of layers to the Sequential\n",
    "constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.171521Z",
     "iopub.status.busy": "2021-08-25T17:49:58.170978Z",
     "iopub.status.idle": "2021-08-25T17:49:58.174668Z",
     "shell.execute_reply": "2021-08-25T17:49:58.174239Z"
    },
    "id": "8b3eee00f80d"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\"),\n",
    "        layers.Dense(3, activation=\"relu\"),\n",
    "        layers.Dense(4),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1939a7a4a66c"
   },
   "source": [
    "Its layers are accessible via the `layers` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.183445Z",
     "iopub.status.busy": "2021-08-25T17:49:58.182871Z",
     "iopub.status.idle": "2021-08-25T17:49:58.186043Z",
     "shell.execute_reply": "2021-08-25T17:49:58.186429Z"
    },
    "id": "49c0448b6da2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x7ffb5e4c99a0>,\n",
       " <keras.layers.core.dense.Dense at 0x7ffb5e4c9b80>,\n",
       " <keras.layers.core.dense.Dense at 0x7ffb5e4c9130>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4c7957e9913"
   },
   "source": [
    "You can also create a Sequential model incrementally via the `add()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.190977Z",
     "iopub.status.busy": "2021-08-25T17:49:58.190409Z",
     "iopub.status.idle": "2021-08-25T17:49:58.195751Z",
     "shell.execute_reply": "2021-08-25T17:49:58.195345Z"
    },
    "id": "d54fde401054"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x7ffb5e5027f0>,\n",
       " <keras.layers.core.dense.Dense at 0x7ffb5e4dea30>,\n",
       " <keras.layers.core.dense.Dense at 0x7ffba7fe24f0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, activation=\"relu\"))\n",
    "model.add(layers.Dense(3, activation=\"relu\"))\n",
    "model.add(layers.Dense(4))\n",
    "\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d16278f5a1dc"
   },
   "source": [
    "Note that there's also a corresponding `pop()` method to remove layers:\n",
    "a Sequential model behaves very much like a list of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.199624Z",
     "iopub.status.busy": "2021-08-25T17:49:58.199011Z",
     "iopub.status.idle": "2021-08-25T17:49:58.201650Z",
     "shell.execute_reply": "2021-08-25T17:49:58.201252Z"
    },
    "id": "e89f35b73979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "model.pop()\n",
    "print(len(model.layers))  # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99cb1c9a7c7a"
   },
   "source": [
    "Also note that the Sequential constructor accepts a `name` argument, just like\n",
    "any layer or model in Keras. This is useful to annotate TensorBoard graphs\n",
    "with semantically meaningful names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.206383Z",
     "iopub.status.busy": "2021-08-25T17:49:58.205813Z",
     "iopub.status.idle": "2021-08-25T17:49:58.210797Z",
     "shell.execute_reply": "2021-08-25T17:49:58.211153Z"
    },
    "id": "068c2f82e7cb"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential(name=\"my_sequential\")\n",
    "model.add(layers.Dense(2, activation=\"relu\", name=\"layer1\"))\n",
    "model.add(layers.Dense(3, activation=\"relu\", name=\"layer2\"))\n",
    "model.add(layers.Dense(4, name=\"layer3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6247ff17d3a"
   },
   "source": [
    "## Specifying the input shape in advance\n",
    "\n",
    "Generally, all layers in Keras need to know the shape of their inputs\n",
    "in order to be able to create their weights. So when you create a layer like\n",
    "this, initially, it has no weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.215631Z",
     "iopub.status.busy": "2021-08-25T17:49:58.215113Z",
     "iopub.status.idle": "2021-08-25T17:49:58.217620Z",
     "shell.execute_reply": "2021-08-25T17:49:58.217196Z"
    },
    "id": "373ecbb5c6bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.Dense(3)\n",
    "layer.weights  # Empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da150335961e"
   },
   "source": [
    "It creates its weights the first time it is called on an input, since the shape\n",
    "of the weights depends on the shape of the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.221940Z",
     "iopub.status.busy": "2021-08-25T17:49:58.221410Z",
     "iopub.status.idle": "2021-08-25T17:49:58.227263Z",
     "shell.execute_reply": "2021-08-25T17:49:58.227654Z"
    },
    "id": "bf28829ce193"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_6/kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
       " array([[ 0.03278744,  0.82709455,  0.50594497],\n",
       "        [-0.07007271,  0.85455394, -0.3165413 ],\n",
       "        [-0.6249998 , -0.16881174, -0.3493585 ],\n",
       "        [ 0.01035941, -0.5942502 , -0.5780734 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_6/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call layer on a test input\n",
    "x = tf.ones((1, 4))\n",
    "y = layer(x)\n",
    "layer.weights  # Now it has weights, of shape (4, 3) and (3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Start Alexey Note:\n",
    "  - The Keras API documentation can be found [here](https://keras.io/api/).\n",
    "  - Continuing through the tutorial was mostly straight forward, but I had trouble parsing the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_7/kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
       " array([[ 0.14241827,  0.8592663 , -0.57716835],\n",
       "        [ 0.16350663,  0.49261248,  0.870757  ],\n",
       "        [-0.01283383, -0.02807742,  0.3844235 ],\n",
       "        [ 0.75283515, -0.43364245, -0.7708735 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_7/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.Dense(3)\n",
    "layer.weights\n",
    "x = tf.ones((1, 4))\n",
    "y = layer(x)\n",
    "layer.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - What this code is doing is first making a `Dense` layer with `3` neurons. This layer initially has no weights associated with it, they are only defined after a tensor is passed into it. Then, a `(1,4)` sized-tensor is passed into the layer, resulting in the weights to be of size `(4,3)`, since the layer now knows the input size and output size, so by basic matrix multiplication we see that `(1,4)x(4,3)=(1,3)`, which is the number of neurons in the layer (and the number of generated weights).\n",
    " - If you were curious like me, you might wonder how the weights are randomized? It turns out that `kernel_initializer` value when creating the `Dense` layer controls that. By default, it is the `GlorotUniform` initializer (see [here for `GlorotUniform`](https://keras.io/api/layers/initializers/#glorotuniform-class) and [here for `Dense` layer initialization](https://keras.io/api/layers/core_layers/dense/)). Biases are randomly selected as well, and the way they are selected can be found by looking at `Dense` layer class as well. The weights can also be manually set with [the `set_weights` method](https://keras.io/api/layers/base_layer/#set_weights-method). The call to `layer(x)` produces random weights once and then the weights are the same from then on unless a new layer is created or the weights are manually changed.\n",
    " - The rest of the tutorial seemed much more technical that I'm comfortable with so far, so I wasn't able to follow along very well despite reading it all. I will revisit it later as I learn more about Tensorflow, but I left it included in here for the curious.\n",
    " \n",
    "## End Alexey Note\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e50f21c5f247"
   },
   "source": [
    "Naturally, this also applies to Sequential models. When you instantiate a\n",
    "Sequential model without an input shape, it isn't \"built\": it has no weights\n",
    "(and calling\n",
    "`model.weights` results in an error stating just this). The weights are created\n",
    "when the model first sees some input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.234176Z",
     "iopub.status.busy": "2021-08-25T17:49:58.233624Z",
     "iopub.status.idle": "2021-08-25T17:49:58.254343Z",
     "shell.execute_reply": "2021-08-25T17:49:58.253892Z"
    },
    "id": "04479960526c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weights after calling the model: 6\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (1, 2)                    10        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (1, 3)                    9         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (1, 4)                    16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\"),\n",
    "        layers.Dense(3, activation=\"relu\"),\n",
    "        layers.Dense(4),\n",
    "    ]\n",
    ")  # No weights at this stage!\n",
    "\n",
    "# At this point, you can't do this:\n",
    "# model.weights\n",
    "\n",
    "# You also can't do this:\n",
    "# model.summary()\n",
    "\n",
    "# Call the model on a test input\n",
    "x = tf.ones((1, 4))\n",
    "y = model(x)\n",
    "print(\"Number of weights after calling the model:\", len(model.weights))  # 6\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2837e3d2c798"
   },
   "source": [
    "Once a model is \"built\", you can call its `summary()` method to display its\n",
    "contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.258160Z",
     "iopub.status.busy": "2021-08-25T17:49:58.257363Z",
     "iopub.status.idle": "2021-08-25T17:49:58.260942Z",
     "shell.execute_reply": "2021-08-25T17:49:58.260539Z"
    },
    "id": "1368bd27f679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (1, 2)                    10        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (1, 3)                    9         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (1, 4)                    16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08cf1da27edb"
   },
   "source": [
    "However, it can be very useful when building a Sequential model incrementally\n",
    "to be able to display the summary of the model so far, including the current\n",
    "output shape. In this case, you should start your model by passing an `Input`\n",
    "object to your model, so that it knows its input shape from the start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.265148Z",
     "iopub.status.busy": "2021-08-25T17:49:58.264603Z",
     "iopub.status.idle": "2021-08-25T17:49:58.276182Z",
     "shell.execute_reply": "2021-08-25T17:49:58.275768Z"
    },
    "id": "e3d2024cfeeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(4,)))\n",
    "model.add(layers.Dense(2, activation=\"relu\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d965e3761a8"
   },
   "source": [
    "Note that the `Input` object is not displayed as part of `model.layers`, since\n",
    "it isn't a layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.280126Z",
     "iopub.status.busy": "2021-08-25T17:49:58.279482Z",
     "iopub.status.idle": "2021-08-25T17:49:58.282352Z",
     "shell.execute_reply": "2021-08-25T17:49:58.281827Z"
    },
    "id": "8e3b0d58e7ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.dense.Dense at 0x7ffb5e4f3610>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a057b1baf72"
   },
   "source": [
    "A simple alternative is to just pass an `input_shape` argument to your first\n",
    "layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.286863Z",
     "iopub.status.busy": "2021-08-25T17:49:58.286329Z",
     "iopub.status.idle": "2021-08-25T17:49:58.298341Z",
     "shell.execute_reply": "2021-08-25T17:49:58.297879Z"
    },
    "id": "1c6ab83d68ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, activation=\"relu\", input_shape=(4,)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40c14619d283"
   },
   "source": [
    "Models built with a predefined input shape like this always have weights (even\n",
    "before seeing any data) and always have a defined output shape.\n",
    "\n",
    "In general, it's a recommended best practice to always specify the input shape\n",
    "of a Sequential model in advance if you know what it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "843f6b6505b3"
   },
   "source": [
    "## A common debugging workflow: `add()` + `summary()`\n",
    "\n",
    "When building a new Sequential architecture, it's useful to incrementally stack\n",
    "layers with `add()` and frequently print model summaries. For instance, this\n",
    "enables you to monitor how a stack of `Conv2D` and `MaxPooling2D` layers is\n",
    "downsampling image feature maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.304957Z",
     "iopub.status.busy": "2021-08-25T17:49:58.302055Z",
     "iopub.status.idle": "2021-08-25T17:49:58.369226Z",
     "shell.execute_reply": "2021-08-25T17:49:58.369657Z"
    },
    "id": "46bfb8f7dc6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 123, 123, 32)      2432      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 121, 121, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 40, 40, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,680\n",
      "Trainable params: 11,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 123, 123, 32)      2432      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 121, 121, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 40, 40, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 38, 38, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 36, 36, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,672\n",
      "Trainable params: 48,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 123, 123, 32)      2432      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 121, 121, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 40, 40, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 38, 38, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 36, 36, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 10, 10, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 32)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,002\n",
      "Trainable params: 49,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(250, 250, 3)))  # 250x250 RGB images\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "# Can you guess what the current output shape is at this point? Probably not.\n",
    "# Let's just print it:\n",
    "model.summary()\n",
    "\n",
    "# The answer was: (40, 40, 32), so we can keep downsampling...\n",
    "\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "# And now?\n",
    "model.summary()\n",
    "\n",
    "# Now that we have 4x4 feature maps, time to apply global max pooling.\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "# And now?\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2d3335a90fa"
   },
   "source": [
    "Very practical, right?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46addede37f3"
   },
   "source": [
    "## What to do once you have a model\n",
    "\n",
    "Once your model architecture is ready, you will want to:\n",
    "\n",
    "- Train your model, evaluate it, and run inference. See our\n",
    "[guide to training & evaluation with the built-in loops](\n",
    "https://www.tensorflow.org/guide/keras/train_and_evaluate/)\n",
    "- Save your model to disk and restore it. See our\n",
    "[guide to serialization & saving](https://www.tensorflow.org/guide/keras/save_and_serialize/).\n",
    "- Speed up model training by leveraging multiple GPUs. See our\n",
    "[guide to multi-GPU and distributed training](https://keras.io/guides/distributed_training/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "608f3b03669c"
   },
   "source": [
    "## Feature extraction with a Sequential model\n",
    "\n",
    "Once a Sequential model has been built, it behaves like a [Functional API\n",
    "model](https://www.tensorflow.org/guide/keras/functional/). This means that every layer has an `input`\n",
    "and `output` attribute. These attributes can be used to do neat things, like\n",
    "quickly\n",
    "creating a model that extracts the outputs of all intermediate layers in a\n",
    "Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:58.378652Z",
     "iopub.status.busy": "2021-08-25T17:49:58.378074Z",
     "iopub.status.idle": "2021-08-25T17:49:59.438124Z",
     "shell.execute_reply": "2021-08-25T17:49:59.438548Z"
    },
    "id": "a5888d753301"
   },
   "outputs": [],
   "source": [
    "initial_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(250, 250, 3)),\n",
    "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "feature_extractor = keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=[layer.output for layer in initial_model.layers],\n",
    ")\n",
    "\n",
    "# Call feature extractor on test input.\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4abef35355d3"
   },
   "source": [
    "Here's a similar example that only extract features from one layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T17:49:59.450628Z",
     "iopub.status.busy": "2021-08-25T17:49:59.449945Z",
     "iopub.status.idle": "2021-08-25T17:49:59.473185Z",
     "shell.execute_reply": "2021-08-25T17:49:59.472746Z"
    },
    "id": "fc404c7ac90e"
   },
   "outputs": [],
   "source": [
    "initial_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(250, 250, 3)),\n",
    "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\", name=\"my_intermediate_layer\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "feature_extractor = keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=initial_model.get_layer(name=\"my_intermediate_layer\").output,\n",
    ")\n",
    "# Call feature extractor on test input.\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4e2fb64f0676"
   },
   "source": [
    "## Transfer learning with a Sequential model\n",
    "\n",
    "Transfer learning consists of freezing the bottom layers in a model and only training\n",
    "the top layers. If you aren't familiar with it, make sure to read our [guide\n",
    "to transfer learning](https://www.tensorflow.org/guide/keras/transfer_learning/).\n",
    "\n",
    "Here are two common transfer learning blueprint involving Sequential models.\n",
    "\n",
    "First, let's say that you have a Sequential model, and you want to freeze all\n",
    "layers except the last one. In this case, you would simply iterate over\n",
    "`model.layers` and set `layer.trainable = False` on each layer, except the\n",
    "last one. Like this:\n",
    "\n",
    "```python\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(784)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10),\n",
    "])\n",
    "\n",
    "# Presumably you would want to first load pre-trained weights.\n",
    "model.load_weights(...)\n",
    "\n",
    "# Freeze all layers except the last one.\n",
    "for layer in model.layers[:-1]:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Recompile and train (this will only update the weights of the last layer).\n",
    "model.compile(...)\n",
    "model.fit(...)\n",
    "```\n",
    "\n",
    "Another common blueprint is to use a Sequential model to stack a pre-trained\n",
    "model and some freshly initialized classification layers. Like this:\n",
    "\n",
    "```python\n",
    "# Load a convolutional base with pre-trained weights\n",
    "base_model = keras.applications.Xception(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    pooling='avg')\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Use a Sequential model to add a trainable classifier on top\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.Dense(1000),\n",
    "])\n",
    "\n",
    "# Compile & train\n",
    "model.compile(...)\n",
    "model.fit(...)\n",
    "```\n",
    "\n",
    "If you do transfer learning, you will probably find yourself frequently using\n",
    "these two patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcffc33b61e5"
   },
   "source": [
    "That's about all you need to know about Sequential models!\n",
    "\n",
    "To find out more about building models in Keras, see:\n",
    "\n",
    "- [Guide to the Functional API](https://www.tensorflow.org/guide/keras/functional/)\n",
    "- [Guide to making new Layers & Models via subclassing](\n",
    "https://www.tensorflow.org/guide/keras/custom_layers_and_models/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sequential_model.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
