initialize.py: running hydra_init
initialize.py: running hydra_init
[2023-03-31 16:36:07,105][HYDRA] Launching 1 jobs locally
[2023-03-31 16:36:07,105][HYDRA] 	#0 : task.data=/home/alexey/Desktop/fairseq/data-bin/wikitext-103/ checkpoint.restore_file=/home/alexey/Desktop/Roberta2/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 16:36:08,119][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': True, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 125000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [64], 'lr': [0.0007], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/home/alexey/Desktop/Roberta2/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'roberta', 'max_positions': 512, 'dropout': 0.1, 'attention_dropout': 0.1}, 'task': {'_name': 'masked_lm', 'data': '/home/alexey/Desktop/fairseq/data-bin/wikitext-103/', 'sample_break_mode': complete, 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': none, 'shorten_data_split_list': '', 'seed': 1, 'include_target_tokens': False, 'include_index': True, 'skip_masking': False, 'd2v2_multi': False}, 'criterion': {'_name': 'masked_lm', 'tpu': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 10000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 125000.0, 'lr': [0.0007]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2023-03-31 16:36:08,169][fairseq.tasks.masked_lm][INFO] - dictionary: 50264 types
[2023-03-31 16:36:08,853][fairseq_cli.train][INFO] - RobertaModel(
  (encoder): RobertaEncoder(
    (sentence_encoder): TransformerEncoder(
      (dropout_module): FairseqDropout()
      (embed_tokens): Embedding(50265, 768, padding_idx=1)
      (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)
      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=192, bias=True)
          (fc2): Linear(in_features=192, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (lm_head): RobertaLMHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classification_heads): ModuleDict()
)
[2023-03-31 16:36:08,854][fairseq_cli.train][INFO] - task: MaskedLMTask
[2023-03-31 16:36:08,854][fairseq_cli.train][INFO] - model: RobertaModel
[2023-03-31 16:36:08,854][fairseq_cli.train][INFO] - criterion: MaskedLmLoss
[2023-03-31 16:36:08,854][fairseq_cli.train][INFO] - num. shared model params: 42,303,513 (num. trained: 42,303,513)
[2023-03-31 16:36:08,854][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-03-31 16:36:08,855][fairseq.data.data_utils][INFO] - loaded 3,760 examples from: /home/alexey/Desktop/fairseq/data-bin/wikitext-103/valid
[2023-03-31 16:36:08,856][fairseq.tasks.masked_lm][INFO] - loaded 580 blocks from: /home/alexey/Desktop/fairseq/data-bin/wikitext-103/valid
[2023-03-31 16:36:09,749][fairseq.trainer][INFO] - detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight
[2023-03-31 16:36:09,750][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-03-31 16:36:09,750][fairseq.utils][INFO] - rank   0: capabilities =  6.1  ; total memory = 7.921 GB ; name = NVIDIA GeForce GTX 1070                 
[2023-03-31 16:36:09,750][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-03-31 16:36:09,750][fairseq_cli.train][INFO] - training on 1 devices (GPUs/TPUs)
[2023-03-31 16:36:09,750][fairseq_cli.train][INFO] - max tokens per device = None and max sentences per device = 4
[2023-03-31 16:36:09,751][fairseq.trainer][INFO] - Preparing to load checkpoint /home/alexey/Desktop/Roberta2/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 16:36:10,280][fairseq.trainer][INFO] - Loaded checkpoint /home/alexey/Desktop/Roberta2/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt (epoch 60 @ 64369 updates)
[2023-03-31 16:36:10,291][fairseq.trainer][INFO] - loading train data for epoch 60
[2023-03-31 16:36:10,370][fairseq.data.data_utils][INFO] - loaded 1,801,350 examples from: /home/alexey/Desktop/fairseq/data-bin/wikitext-103/train
[2023-03-31 16:36:10,433][fairseq.tasks.masked_lm][INFO] - loaded 280678 blocks from: /home/alexey/Desktop/fairseq/data-bin/wikitext-103/train
[2023-03-31 16:36:10,439][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 16:36:10,440][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2023-03-31 16:36:10,440][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2023-03-31 16:36:10,440][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 60
[2023-03-31 16:36:10,465][fairseq.tasks.fairseq_task][WARNING] - 1,414 samples have invalid sizes and will be skipped, max_positions=512, first few sample ids=[127070, 245388, 160963, 4508, 197654, 80339, 243532, 240011, 69697, 236498]
[2023-03-31 16:36:10,638][fairseq_cli.train][INFO] - begin dry-run validation on "valid" subset
[2023-03-31 16:36:10,639][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 16:36:10,639][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2023-03-31 16:36:10,639][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2023-03-31 16:36:10,639][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2023-03-31 16:36:11,359][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 16:36:11,362][fairseq.trainer][INFO] - begin training epoch 60
[2023-03-31 16:36:11,367][fairseq_cli.train][INFO] - Start iterating over samples
/home/alexey/Desktop/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2023-03-31 16:37:27,811][train_inner][INFO] - {"epoch": 60, "update": 59.028, "loss": "4.964", "ppl": "31.2", "wps": "43780", "ups": "0.41", "wpb": "107879", "bsz": "256", "num_updates": "64400", "lr": "0.00036887", "gnorm": "0.921", "train_wall": "68", "gb_free": "6.8", "wall": "78"}
[2023-03-31 16:46:51,162][train_inner][INFO] - {"epoch": 60, "update": 59.212, "loss": "4.756", "ppl": "27.03", "wps": "37985.4", "ups": "0.36", "wpb": "106995", "bsz": "256", "num_updates": "64600", "lr": "0.000367652", "gnorm": "0.652", "train_wall": "508", "gb_free": "6.8", "wall": "641"}
[2023-03-31 16:56:29,979][train_inner][INFO] - {"epoch": 60, "update": 59.395, "loss": "4.689", "ppl": "25.79", "wps": "36999.8", "ups": "0.35", "wpb": "107079", "bsz": "256", "num_updates": "64800", "lr": "0.000366435", "gnorm": "0.656", "train_wall": "522", "gb_free": "6.8", "wall": "1220"}
[2023-03-31 17:05:39,167][train_inner][INFO] - {"epoch": 60, "update": 59.578, "loss": "4.65", "ppl": "25.11", "wps": "39088.1", "ups": "0.36", "wpb": "107334", "bsz": "256", "num_updates": "65000", "lr": "0.000365217", "gnorm": "0.666", "train_wall": "494", "gb_free": "6.8", "wall": "1769"}
[2023-03-31 17:14:44,738][train_inner][INFO] - {"epoch": 60, "update": 59.762, "loss": "4.626", "ppl": "24.7", "wps": "39382.2", "ups": "0.37", "wpb": "107429", "bsz": "256", "num_updates": "65200", "lr": "0.000364", "gnorm": "0.664", "train_wall": "492", "gb_free": "6.8", "wall": "2315"}
[2023-03-31 17:23:55,591][train_inner][INFO] - {"epoch": 60, "update": 59.945, "loss": "4.609", "ppl": "24.41", "wps": "38901.3", "ups": "0.36", "wpb": "107144", "bsz": "256", "num_updates": "65400", "lr": "0.000362783", "gnorm": "0.675", "train_wall": "497", "gb_free": "6.8", "wall": "2866"}
[2023-03-31 17:26:40,725][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 17:26:40,726][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 17:26:42,931][valid][INFO] - {"epoch": 60, "valid_loss": "4.207", "valid_ppl": "18.47", "valid_wps": "112639", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "65460", "valid_best_loss": "4.207"}
[2023-03-31 17:26:42,932][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 65460 updates
[2023-03-31 17:26:42,933][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_best.pt
[2023-03-31 17:26:43,902][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_best.pt
[2023-03-31 17:26:44,471][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 60 @ 65460 updates, score 4.207) (writing took 1.5395153210001808 seconds)
[2023-03-31 17:26:44,472][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2023-03-31 17:26:44,472][train][INFO] - {"epoch": 60, "train_loss": "4.671", "train_ppl": "25.47", "train_wps": "38558.3", "train_ups": "0.36", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "65460", "train_lr": "0.000362417", "train_gnorm": "0.671", "train_train_wall": "2731", "train_gb_free": "6.8", "train_wall": "3035"}
[2023-03-31 17:26:44,474][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 17:26:44,515][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 17:26:44,519][fairseq.trainer][INFO] - begin training epoch 61
[2023-03-31 17:26:44,520][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 17:33:03,481][train_inner][INFO] - {"epoch": 61, "update": 60.128, "loss": "4.459", "ppl": "21.99", "wps": "39186.8", "ups": "0.37", "wpb": "107350", "bsz": "255.8", "num_updates": "65600", "lr": "0.000361565", "gnorm": "0.695", "train_wall": "490", "gb_free": "6.8", "wall": "3414"}
[2023-03-31 17:42:05,517][train_inner][INFO] - {"epoch": 61, "update": 60.312, "loss": "4.431", "ppl": "21.58", "wps": "39516.5", "ups": "0.37", "wpb": "107097", "bsz": "256", "num_updates": "65800", "lr": "0.000360348", "gnorm": "0.682", "train_wall": "488", "gb_free": "6.8", "wall": "3956"}
[2023-03-31 17:51:17,541][train_inner][INFO] - {"epoch": 61, "update": 60.495, "loss": "4.441", "ppl": "21.72", "wps": "38904.7", "ups": "0.36", "wpb": "107381", "bsz": "256", "num_updates": "66000", "lr": "0.00035913", "gnorm": "0.68", "train_wall": "497", "gb_free": "6.8", "wall": "4508"}
[2023-03-31 18:00:14,881][train_inner][INFO] - {"epoch": 61, "update": 60.678, "loss": "4.446", "ppl": "21.8", "wps": "39942", "ups": "0.37", "wpb": "107312", "bsz": "256", "num_updates": "66200", "lr": "0.000357913", "gnorm": "0.686", "train_wall": "482", "gb_free": "6.8", "wall": "5045"}
[2023-03-31 18:09:05,331][train_inner][INFO] - {"epoch": 61, "update": 60.862, "loss": "4.443", "ppl": "21.75", "wps": "40312.5", "ups": "0.38", "wpb": "106919", "bsz": "256", "num_updates": "66400", "lr": "0.000356696", "gnorm": "0.677", "train_wall": "478", "gb_free": "6.8", "wall": "5576"}
[2023-03-31 18:16:08,087][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 18:16:08,088][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 18:16:10,293][valid][INFO] - {"epoch": 61, "valid_loss": "4.161", "valid_ppl": "17.89", "valid_wps": "111917", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "66551", "valid_best_loss": "4.161"}
[2023-03-31 18:16:10,295][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 61 @ 66551 updates
[2023-03-31 18:16:10,296][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_best.pt
[2023-03-31 18:16:11,679][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_best.pt
[2023-03-31 18:16:12,319][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 61 @ 66551 updates, score 4.161) (writing took 2.0238352469996244 seconds)
[2023-03-31 18:16:12,319][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2023-03-31 18:16:12,320][train][INFO] - {"epoch": 61, "train_loss": "4.436", "train_ppl": "21.64", "train_wps": "39409.7", "train_ups": "0.37", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "66551", "train_lr": "0.000355777", "train_gnorm": "0.683", "train_train_wall": "2669", "train_gb_free": "6.8", "train_wall": "6003"}
[2023-03-31 18:16:12,322][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 18:16:12,356][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 18:16:12,358][fairseq.trainer][INFO] - begin training epoch 62
[2023-03-31 18:16:12,359][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 18:18:37,440][train_inner][INFO] - {"epoch": 62, "update": 61.045, "loss": "4.4", "ppl": "21.11", "wps": "37439.3", "ups": "0.35", "wpb": "107097", "bsz": "255.8", "num_updates": "66600", "lr": "0.000355478", "gnorm": "0.684", "train_wall": "511", "gb_free": "6.8", "wall": "6148"}
[2023-03-31 18:28:01,965][train_inner][INFO] - {"epoch": 62, "update": 61.228, "loss": "4.291", "ppl": "19.57", "wps": "38148", "ups": "0.35", "wpb": "107676", "bsz": "256", "num_updates": "66800", "lr": "0.000354261", "gnorm": "0.69", "train_wall": "509", "gb_free": "6.8", "wall": "6712"}
[2023-03-31 18:37:12,069][train_inner][INFO] - {"epoch": 62, "update": 61.412, "loss": "4.302", "ppl": "19.72", "wps": "38959.8", "ups": "0.36", "wpb": "107160", "bsz": "256", "num_updates": "67000", "lr": "0.000353043", "gnorm": "0.691", "train_wall": "497", "gb_free": "6.8", "wall": "7262"}
[2023-03-31 18:46:11,956][train_inner][INFO] - {"epoch": 62, "update": 61.595, "loss": "4.319", "ppl": "19.96", "wps": "39667.5", "ups": "0.37", "wpb": "107080", "bsz": "256", "num_updates": "67200", "lr": "0.000351826", "gnorm": "0.68", "train_wall": "488", "gb_free": "6.8", "wall": "7802"}
[2023-03-31 18:55:10,988][train_inner][INFO] - {"epoch": 62, "update": 61.778, "loss": "4.328", "ppl": "20.09", "wps": "39782.3", "ups": "0.37", "wpb": "107220", "bsz": "256", "num_updates": "67400", "lr": "0.000350609", "gnorm": "0.7", "train_wall": "487", "gb_free": "6.8", "wall": "8341"}
[2023-03-31 19:04:00,689][train_inner][INFO] - {"epoch": 62, "update": 61.962, "loss": "4.33", "ppl": "20.11", "wps": "40388.7", "ups": "0.38", "wpb": "106970", "bsz": "256", "num_updates": "67600", "lr": "0.000349391", "gnorm": "0.694", "train_wall": "478", "gb_free": "6.8", "wall": "8871"}
[2023-03-31 19:05:53,261][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 19:05:53,262][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 19:05:55,278][valid][INFO] - {"epoch": 62, "valid_loss": "4.146", "valid_ppl": "17.7", "valid_wps": "122583", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "67642", "valid_best_loss": "4.146"}
[2023-03-31 19:05:55,279][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 62 @ 67642 updates
[2023-03-31 19:05:55,286][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_best.pt
[2023-03-31 19:05:56,263][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_best.pt
[2023-03-31 19:05:56,787][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 62 @ 67642 updates, score 4.146) (writing took 1.5079876590007188 seconds)
[2023-03-31 19:05:56,788][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2023-03-31 19:05:56,788][train][INFO] - {"epoch": 62, "train_loss": "4.313", "train_ppl": "19.87", "train_wps": "39190.2", "train_ups": "0.37", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "67642", "train_lr": "0.000349136", "train_gnorm": "0.692", "train_train_wall": "2690", "train_gb_free": "6.8", "train_wall": "8987"}
[2023-03-31 19:05:56,791][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 19:05:56,829][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 19:05:56,832][fairseq.trainer][INFO] - begin training epoch 63
[2023-03-31 19:05:56,833][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 19:12:59,434][train_inner][INFO] - {"epoch": 63, "update": 62.145, "loss": "4.208", "ppl": "18.48", "wps": "39855.6", "ups": "0.37", "wpb": "107360", "bsz": "255.8", "num_updates": "67800", "lr": "0.000348174", "gnorm": "0.696", "train_wall": "482", "gb_free": "6.8", "wall": "9410"}
[2023-03-31 19:22:00,184][train_inner][INFO] - {"epoch": 63, "update": 62.328, "loss": "4.203", "ppl": "18.42", "wps": "39636.1", "ups": "0.37", "wpb": "107165", "bsz": "256", "num_updates": "68000", "lr": "0.000346957", "gnorm": "0.7", "train_wall": "488", "gb_free": "6.8", "wall": "9950"}
[2023-03-31 19:29:27,982][train_inner][INFO] - {"epoch": 63, "update": 62.511, "loss": "4.223", "ppl": "18.67", "wps": "47863.7", "ups": "0.45", "wpb": "107166", "bsz": "256", "num_updates": "68200", "lr": "0.000345739", "gnorm": "0.69", "train_wall": "402", "gb_free": "6.8", "wall": "10398"}
[2023-03-31 19:37:16,167][train_inner][INFO] - {"epoch": 63, "update": 62.695, "loss": "4.235", "ppl": "18.83", "wps": "45830.8", "ups": "0.43", "wpb": "107286", "bsz": "256", "num_updates": "68400", "lr": "0.000344522", "gnorm": "0.692", "train_wall": "420", "gb_free": "6.8", "wall": "10866"}
[2023-03-31 19:45:57,251][train_inner][INFO] - {"epoch": 63, "update": 62.878, "loss": "4.247", "ppl": "18.99", "wps": "41173", "ups": "0.38", "wpb": "107273", "bsz": "256", "num_updates": "68600", "lr": "0.000343304", "gnorm": "0.698", "train_wall": "470", "gb_free": "6.8", "wall": "11388"}
[2023-03-31 19:51:24,421][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 19:51:24,428][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 19:51:26,514][valid][INFO] - {"epoch": 63, "valid_loss": "4.132", "valid_ppl": "17.53", "valid_wps": "118521", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "68733", "valid_best_loss": "4.132"}
[2023-03-31 19:51:26,516][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 63 @ 68733 updates
[2023-03-31 19:51:26,517][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_best.pt
[2023-03-31 19:51:27,896][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_best.pt
[2023-03-31 19:51:28,639][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 63 @ 68733 updates, score 4.132) (writing took 2.1228063120015577 seconds)
[2023-03-31 19:51:28,639][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2023-03-31 19:51:28,640][train][INFO] - {"epoch": 63, "train_loss": "4.222", "train_ppl": "18.66", "train_wps": "42814.2", "train_ups": "0.4", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "68733", "train_lr": "0.000342495", "train_gnorm": "0.694", "train_train_wall": "2456", "train_gb_free": "6.8", "train_wall": "11719"}
[2023-03-31 19:51:28,642][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 19:51:28,687][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 19:51:28,690][fairseq.trainer][INFO] - begin training epoch 64
[2023-03-31 19:51:28,690][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 19:54:27,542][train_inner][INFO] - {"epoch": 64, "update": 63.061, "loss": "4.192", "ppl": "18.27", "wps": "41915.9", "ups": "0.39", "wpb": "106947", "bsz": "255.8", "num_updates": "68800", "lr": "0.000342087", "gnorm": "0.694", "train_wall": "456", "gb_free": "6.8", "wall": "11898"}
[2023-03-31 20:03:11,262][train_inner][INFO] - {"epoch": 64, "update": 63.245, "loss": "4.111", "ppl": "17.28", "wps": "40835.5", "ups": "0.38", "wpb": "106930", "bsz": "256", "num_updates": "69000", "lr": "0.00034087", "gnorm": "0.703", "train_wall": "473", "gb_free": "6.8", "wall": "12422"}
[2023-03-31 20:12:04,548][train_inner][INFO] - {"epoch": 64, "update": 63.428, "loss": "4.14", "ppl": "17.64", "wps": "40171.5", "ups": "0.38", "wpb": "107114", "bsz": "256", "num_updates": "69200", "lr": "0.000339652", "gnorm": "0.699", "train_wall": "482", "gb_free": "6.8", "wall": "12955"}
[2023-03-31 20:20:51,114][train_inner][INFO] - {"epoch": 64, "update": 63.611, "loss": "4.158", "ppl": "17.86", "wps": "40775.2", "ups": "0.38", "wpb": "107354", "bsz": "256", "num_updates": "69400", "lr": "0.000338435", "gnorm": "0.691", "train_wall": "476", "gb_free": "6.8", "wall": "13481"}
[2023-03-31 20:29:51,653][train_inner][INFO] - {"epoch": 64, "update": 63.795, "loss": "4.174", "ppl": "18.05", "wps": "39795.7", "ups": "0.37", "wpb": "107556", "bsz": "256", "num_updates": "69600", "lr": "0.000337217", "gnorm": "0.694", "train_wall": "487", "gb_free": "6.8", "wall": "14022"}
[2023-03-31 20:39:00,651][train_inner][INFO] - {"epoch": 64, "update": 63.978, "loss": "4.183", "ppl": "18.17", "wps": "39025.2", "ups": "0.36", "wpb": "107124", "bsz": "256", "num_updates": "69800", "lr": "0.000336", "gnorm": "0.69", "train_wall": "495", "gb_free": "6.8", "wall": "14571"}
[2023-03-31 20:40:06,624][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 20:40:06,625][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 20:40:08,735][valid][INFO] - {"epoch": 64, "valid_loss": "4.145", "valid_ppl": "17.7", "valid_wps": "117019", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "69824", "valid_best_loss": "4.132"}
[2023-03-31 20:40:08,736][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 64 @ 69824 updates
[2023-03-31 20:40:08,737][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-03-31 20:40:10,716][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-03-31 20:40:10,740][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 64 @ 69824 updates, score 4.145) (writing took 2.0033543789995747 seconds)
[2023-03-31 20:40:10,740][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2023-03-31 20:40:10,741][train][INFO] - {"epoch": 64, "train_loss": "4.149", "train_ppl": "17.74", "train_wps": "40026.7", "train_ups": "0.37", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "69824", "train_lr": "0.000335854", "train_gnorm": "0.696", "train_train_wall": "2634", "train_gb_free": "6.8", "train_wall": "14641"}
[2023-03-31 20:40:10,743][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 20:40:10,776][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 20:40:10,780][fairseq.trainer][INFO] - begin training epoch 65
[2023-03-31 20:40:10,780][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 20:48:05,974][train_inner][INFO] - {"epoch": 65, "update": 64.161, "loss": "4.046", "ppl": "16.52", "wps": "39352.5", "ups": "0.37", "wpb": "107299", "bsz": "255.8", "num_updates": "70000", "lr": "0.000334783", "gnorm": "0.712", "train_wall": "488", "gb_free": "6.8", "wall": "15116"}
[2023-03-31 20:57:06,429][train_inner][INFO] - {"epoch": 65, "update": 64.345, "loss": "4.067", "ppl": "16.75", "wps": "39712.4", "ups": "0.37", "wpb": "107314", "bsz": "256", "num_updates": "70200", "lr": "0.000333565", "gnorm": "0.704", "train_wall": "487", "gb_free": "6.8", "wall": "15657"}
[2023-03-31 21:06:15,335][train_inner][INFO] - {"epoch": 65, "update": 64.528, "loss": "4.088", "ppl": "17", "wps": "39064.8", "ups": "0.36", "wpb": "107214", "bsz": "256", "num_updates": "70400", "lr": "0.000332348", "gnorm": "0.702", "train_wall": "496", "gb_free": "6.8", "wall": "16206"}
[2023-03-31 21:15:18,121][train_inner][INFO] - {"epoch": 65, "update": 64.711, "loss": "4.103", "ppl": "17.18", "wps": "39410.1", "ups": "0.37", "wpb": "106956", "bsz": "256", "num_updates": "70600", "lr": "0.00033113", "gnorm": "0.714", "train_wall": "488", "gb_free": "6.8", "wall": "16748"}
[2023-03-31 21:24:19,155][train_inner][INFO] - {"epoch": 65, "update": 64.895, "loss": "4.117", "ppl": "17.35", "wps": "39656.4", "ups": "0.37", "wpb": "107277", "bsz": "256", "num_updates": "70800", "lr": "0.000329913", "gnorm": "0.705", "train_wall": "487", "gb_free": "6.8", "wall": "17289"}
[2023-03-31 21:29:38,615][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 21:29:38,616][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 21:29:40,766][valid][INFO] - {"epoch": 65, "valid_loss": "4.142", "valid_ppl": "17.65", "valid_wps": "115034", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "70915", "valid_best_loss": "4.132"}
[2023-03-31 21:29:40,768][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 65 @ 70915 updates
[2023-03-31 21:29:40,768][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-03-31 21:29:41,745][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-03-31 21:29:41,769][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 65 @ 70915 updates, score 4.142) (writing took 1.0017018990001816 seconds)
[2023-03-31 21:29:41,770][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2023-03-31 21:29:41,770][train][INFO] - {"epoch": 65, "train_loss": "4.087", "train_ppl": "16.99", "train_wps": "39367.5", "train_ups": "0.37", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "70915", "train_lr": "0.000329213", "train_gnorm": "0.708", "train_train_wall": "2674", "train_gb_free": "6.8", "train_wall": "17612"}
[2023-03-31 21:29:41,772][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 21:29:41,805][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 21:29:41,807][fairseq.trainer][INFO] - begin training epoch 66
[2023-03-31 21:29:41,808][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 21:33:34,558][train_inner][INFO] - {"epoch": 66, "update": 65.078, "loss": "4.055", "ppl": "16.63", "wps": "38586.4", "ups": "0.36", "wpb": "107155", "bsz": "255.8", "num_updates": "71000", "lr": "0.000328696", "gnorm": "0.716", "train_wall": "498", "gb_free": "6.8", "wall": "17845"}
[2023-03-31 21:42:43,038][train_inner][INFO] - {"epoch": 66, "update": 65.261, "loss": "3.993", "ppl": "15.92", "wps": "39110.2", "ups": "0.36", "wpb": "107256", "bsz": "256", "num_updates": "71200", "lr": "0.000327478", "gnorm": "0.708", "train_wall": "492", "gb_free": "6.8", "wall": "18393"}
[2023-03-31 21:52:04,153][train_inner][INFO] - {"epoch": 66, "update": 65.445, "loss": "4.018", "ppl": "16.21", "wps": "38172.3", "ups": "0.36", "wpb": "107095", "bsz": "256", "num_updates": "71400", "lr": "0.000326261", "gnorm": "0.713", "train_wall": "505", "gb_free": "6.8", "wall": "18954"}
[2023-03-31 22:01:32,519][train_inner][INFO] - {"epoch": 66, "update": 65.628, "loss": "4.047", "ppl": "16.53", "wps": "37764.1", "ups": "0.35", "wpb": "107319", "bsz": "256", "num_updates": "71600", "lr": "0.000325043", "gnorm": "0.711", "train_wall": "510", "gb_free": "6.8", "wall": "19523"}
[2023-03-31 22:10:49,927][train_inner][INFO] - {"epoch": 66, "update": 65.811, "loss": "4.058", "ppl": "16.65", "wps": "38466.4", "ups": "0.36", "wpb": "107207", "bsz": "256", "num_updates": "71800", "lr": "0.000323826", "gnorm": "0.71", "train_wall": "501", "gb_free": "6.8", "wall": "20080"}
[2023-03-31 22:20:01,350][train_inner][INFO] - {"epoch": 66, "update": 65.995, "loss": "4.076", "ppl": "16.86", "wps": "38890.9", "ups": "0.36", "wpb": "107225", "bsz": "256", "num_updates": "72000", "lr": "0.000322609", "gnorm": "0.711", "train_wall": "496", "gb_free": "6.8", "wall": "20632"}
[2023-03-31 22:20:16,976][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 22:20:16,977][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 22:20:18,970][valid][INFO] - {"epoch": 66, "valid_loss": "4.157", "valid_ppl": "17.84", "valid_wps": "123939", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "72006", "valid_best_loss": "4.132"}
[2023-03-31 22:20:18,971][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 66 @ 72006 updates
[2023-03-31 22:20:18,972][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-03-31 22:20:20,859][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-03-31 22:20:20,883][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 66 @ 72006 updates, score 4.157) (writing took 1.9121746819982945 seconds)
[2023-03-31 22:20:20,884][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2023-03-31 22:20:20,884][train][INFO] - {"epoch": 66, "train_loss": "4.032", "train_ppl": "16.36", "train_wps": "38485.6", "train_ups": "0.36", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "72006", "train_lr": "0.000322572", "train_gnorm": "0.711", "train_train_wall": "2729", "train_gb_free": "6.8", "train_wall": "20651"}
[2023-03-31 22:20:20,886][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 22:20:20,919][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 22:20:20,921][fairseq.trainer][INFO] - begin training epoch 67
[2023-03-31 22:20:20,922][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 22:28:41,797][train_inner][INFO] - {"epoch": 67, "update": 66.178, "loss": "3.92", "ppl": "15.14", "wps": "41066", "ups": "0.38", "wpb": "106862", "bsz": "255.8", "num_updates": "72200", "lr": "0.000321391", "gnorm": "0.72", "train_wall": "465", "gb_free": "6.8", "wall": "21152"}
[2023-03-31 22:37:33,515][train_inner][INFO] - {"epoch": 67, "update": 66.361, "loss": "3.962", "ppl": "15.59", "wps": "40362.4", "ups": "0.38", "wpb": "107307", "bsz": "256", "num_updates": "72400", "lr": "0.000320174", "gnorm": "0.715", "train_wall": "477", "gb_free": "6.8", "wall": "21684"}
[2023-03-31 22:45:17,125][train_inner][INFO] - {"epoch": 67, "update": 66.544, "loss": "3.986", "ppl": "15.85", "wps": "46322.6", "ups": "0.43", "wpb": "107378", "bsz": "256", "num_updates": "72600", "lr": "0.000318957", "gnorm": "0.715", "train_wall": "417", "gb_free": "6.8", "wall": "22147"}
[2023-03-31 22:52:39,628][train_inner][INFO] - {"epoch": 67, "update": 66.728, "loss": "4.005", "ppl": "16.05", "wps": "48406.8", "ups": "0.45", "wpb": "107101", "bsz": "256", "num_updates": "72800", "lr": "0.000317739", "gnorm": "0.712", "train_wall": "398", "gb_free": "6.8", "wall": "22590"}
[2023-03-31 23:00:02,242][train_inner][INFO] - {"epoch": 67, "update": 66.911, "loss": "4.019", "ppl": "16.22", "wps": "48401.5", "ups": "0.45", "wpb": "107116", "bsz": "256", "num_updates": "73000", "lr": "0.000316522", "gnorm": "0.711", "train_wall": "398", "gb_free": "6.8", "wall": "23032"}
[2023-03-31 23:03:37,211][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 23:03:37,212][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 23:03:38,937][valid][INFO] - {"epoch": 67, "valid_loss": "4.172", "valid_ppl": "18.03", "valid_wps": "143496", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "73097", "valid_best_loss": "4.132"}
[2023-03-31 23:03:38,938][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 67 @ 73097 updates
[2023-03-31 23:03:38,939][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-03-31 23:03:40,379][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-03-31 23:03:40,381][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 67 @ 73097 updates, score 4.172) (writing took 1.4424768119970395 seconds)
[2023-03-31 23:03:40,381][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2023-03-31 23:03:40,381][train][INFO] - {"epoch": 67, "train_loss": "3.983", "train_ppl": "15.82", "train_wps": "44994.1", "train_ups": "0.42", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "73097", "train_lr": "0.000315931", "train_gnorm": "0.716", "train_train_wall": "2334", "train_gb_free": "6.8", "train_wall": "23251"}
[2023-03-31 23:03:40,383][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 23:03:40,415][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 23:03:40,417][fairseq.trainer][INFO] - begin training epoch 68
[2023-03-31 23:03:40,417][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 23:07:28,840][train_inner][INFO] - {"epoch": 68, "update": 67.094, "loss": "3.946", "ppl": "15.41", "wps": "48148.8", "ups": "0.45", "wpb": "107516", "bsz": "255.8", "num_updates": "73200", "lr": "0.000315304", "gnorm": "0.727", "train_wall": "399", "gb_free": "6.8", "wall": "23479"}
[2023-03-31 23:14:52,031][train_inner][INFO] - {"epoch": 68, "update": 67.278, "loss": "3.899", "ppl": "14.92", "wps": "48487.3", "ups": "0.45", "wpb": "107446", "bsz": "256", "num_updates": "73400", "lr": "0.000314087", "gnorm": "0.723", "train_wall": "399", "gb_free": "6.8", "wall": "23922"}
[2023-03-31 23:22:13,871][train_inner][INFO] - {"epoch": 68, "update": 67.461, "loss": "3.931", "ppl": "15.25", "wps": "48439.3", "ups": "0.45", "wpb": "107012", "bsz": "256", "num_updates": "73600", "lr": "0.00031287", "gnorm": "0.718", "train_wall": "397", "gb_free": "6.8", "wall": "24364"}
[2023-03-31 23:29:36,660][train_inner][INFO] - {"epoch": 68, "update": 67.644, "loss": "3.955", "ppl": "15.51", "wps": "48455.6", "ups": "0.45", "wpb": "107278", "bsz": "256", "num_updates": "73800", "lr": "0.000311652", "gnorm": "0.724", "train_wall": "398", "gb_free": "6.8", "wall": "24807"}
[2023-03-31 23:36:58,913][train_inner][INFO] - {"epoch": 68, "update": 67.828, "loss": "3.973", "ppl": "15.7", "wps": "48460.7", "ups": "0.45", "wpb": "107159", "bsz": "256", "num_updates": "74000", "lr": "0.000310435", "gnorm": "0.719", "train_wall": "398", "gb_free": "6.8", "wall": "25249"}
[2023-03-31 23:43:53,991][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 23:43:53,992][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 23:43:55,706][valid][INFO] - {"epoch": 68, "valid_loss": "4.19", "valid_ppl": "18.26", "valid_wps": "144461", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "74188", "valid_best_loss": "4.132"}
[2023-03-31 23:43:55,707][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 68 @ 74188 updates
[2023-03-31 23:43:55,707][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-03-31 23:43:56,825][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-03-31 23:43:56,846][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 68 @ 74188 updates, score 4.19) (writing took 1.1391093009988253 seconds)
[2023-03-31 23:43:56,846][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2023-03-31 23:43:56,846][train][INFO] - {"epoch": 68, "train_loss": "3.94", "train_ppl": "15.35", "train_wps": "48402.1", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "74188", "train_lr": "0.00030929", "train_gnorm": "0.722", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "25667"}
[2023-03-31 23:43:56,848][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 23:43:56,882][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 23:43:56,884][fairseq.trainer][INFO] - begin training epoch 69
[2023-03-31 23:43:56,885][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 23:44:23,660][train_inner][INFO] - {"epoch": 69, "update": 68.011, "loss": "3.975", "ppl": "15.72", "wps": "48115.3", "ups": "0.45", "wpb": "106996", "bsz": "255.8", "num_updates": "74200", "lr": "0.000309217", "gnorm": "0.722", "train_wall": "397", "gb_free": "6.8", "wall": "25694"}
[2023-03-31 23:51:46,413][train_inner][INFO] - {"epoch": 69, "update": 68.194, "loss": "3.838", "ppl": "14.3", "wps": "48479", "ups": "0.45", "wpb": "107321", "bsz": "256", "num_updates": "74400", "lr": "0.000308", "gnorm": "0.732", "train_wall": "398", "gb_free": "6.8", "wall": "26137"}
[2023-03-31 23:59:09,545][train_inner][INFO] - {"epoch": 69, "update": 68.378, "loss": "3.875", "ppl": "14.68", "wps": "48492.3", "ups": "0.45", "wpb": "107442", "bsz": "256", "num_updates": "74600", "lr": "0.000306783", "gnorm": "0.722", "train_wall": "398", "gb_free": "6.8", "wall": "26580"}
[2023-04-01 00:06:30,847][train_inner][INFO] - {"epoch": 69, "update": 68.561, "loss": "3.9", "ppl": "14.93", "wps": "48410.9", "ups": "0.45", "wpb": "106819", "bsz": "256", "num_updates": "74800", "lr": "0.000305565", "gnorm": "0.725", "train_wall": "397", "gb_free": "6.8", "wall": "27021"}
[2023-04-01 00:13:54,292][train_inner][INFO] - {"epoch": 69, "update": 68.744, "loss": "3.926", "ppl": "15.2", "wps": "48489.9", "ups": "0.45", "wpb": "107513", "bsz": "256", "num_updates": "75000", "lr": "0.000304348", "gnorm": "0.725", "train_wall": "399", "gb_free": "6.8", "wall": "27465"}
[2023-04-01 00:21:16,380][train_inner][INFO] - {"epoch": 69, "update": 68.928, "loss": "3.947", "ppl": "15.42", "wps": "48441.4", "ups": "0.45", "wpb": "107075", "bsz": "256", "num_updates": "75200", "lr": "0.00030313", "gnorm": "0.73", "train_wall": "397", "gb_free": "6.8", "wall": "27907"}
[2023-04-01 00:24:10,662][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 00:24:10,663][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 00:24:12,396][valid][INFO] - {"epoch": 69, "valid_loss": "4.193", "valid_ppl": "18.29", "valid_wps": "142728", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "75279", "valid_best_loss": "4.132"}
[2023-04-01 00:24:12,397][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 69 @ 75279 updates
[2023-04-01 00:24:12,398][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 00:24:13,261][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 00:24:13,284][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 69 @ 75279 updates, score 4.193) (writing took 0.8869922060002864 seconds)
[2023-04-01 00:24:13,284][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2023-04-01 00:24:13,285][train][INFO] - {"epoch": 69, "train_loss": "3.899", "train_ppl": "14.92", "train_wps": "48402.6", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "75279", "train_lr": "0.00030265", "train_gnorm": "0.727", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "28084"}
[2023-04-01 00:24:13,286][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 00:24:13,319][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 00:24:13,321][fairseq.trainer][INFO] - begin training epoch 70
[2023-04-01 00:24:13,322][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 00:28:41,022][train_inner][INFO] - {"epoch": 70, "update": 69.111, "loss": "3.85", "ppl": "14.42", "wps": "48141.2", "ups": "0.45", "wpb": "107028", "bsz": "255.8", "num_updates": "75400", "lr": "0.000301913", "gnorm": "0.728", "train_wall": "397", "gb_free": "6.8", "wall": "28351"}
[2023-04-01 00:36:03,738][train_inner][INFO] - {"epoch": 70, "update": 69.294, "loss": "3.834", "ppl": "14.26", "wps": "48480.2", "ups": "0.45", "wpb": "107314", "bsz": "256", "num_updates": "75600", "lr": "0.000300696", "gnorm": "0.732", "train_wall": "398", "gb_free": "6.8", "wall": "28794"}
[2023-04-01 00:43:26,516][train_inner][INFO] - {"epoch": 70, "update": 69.478, "loss": "3.851", "ppl": "14.43", "wps": "48478.9", "ups": "0.45", "wpb": "107327", "bsz": "256", "num_updates": "75800", "lr": "0.000299478", "gnorm": "0.731", "train_wall": "398", "gb_free": "6.8", "wall": "29237"}
[2023-04-01 00:50:48,808][train_inner][INFO] - {"epoch": 70, "update": 69.661, "loss": "3.872", "ppl": "14.64", "wps": "48461.3", "ups": "0.45", "wpb": "107170", "bsz": "256", "num_updates": "76000", "lr": "0.000298261", "gnorm": "0.739", "train_wall": "398", "gb_free": "6.8", "wall": "29679"}
[2023-04-01 00:58:10,795][train_inner][INFO] - {"epoch": 70, "update": 69.844, "loss": "3.894", "ppl": "14.87", "wps": "48440.4", "ups": "0.45", "wpb": "107050", "bsz": "256", "num_updates": "76200", "lr": "0.000297043", "gnorm": "0.729", "train_wall": "397", "gb_free": "6.8", "wall": "30121"}
[2023-04-01 01:04:26,728][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 01:04:26,728][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 01:04:28,442][valid][INFO] - {"epoch": 70, "valid_loss": "4.205", "valid_ppl": "18.44", "valid_wps": "144440", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "76370", "valid_best_loss": "4.132"}
[2023-04-01 01:04:28,443][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 70 @ 76370 updates
[2023-04-01 01:04:28,444][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 01:04:29,786][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 01:04:29,808][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 70 @ 76370 updates, score 4.205) (writing took 1.3649889989974326 seconds)
[2023-04-01 01:04:29,808][fairseq_cli.train][INFO] - end of epoch 70 (average epoch stats below)
[2023-04-01 01:04:29,809][train][INFO] - {"epoch": 70, "train_loss": "3.863", "train_ppl": "14.55", "train_wps": "48400.9", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "76370", "train_lr": "0.000296009", "train_gnorm": "0.733", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "30500"}
[2023-04-01 01:04:29,810][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 01:04:29,843][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 01:04:29,846][fairseq.trainer][INFO] - begin training epoch 71
[2023-04-01 01:04:29,846][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 01:05:36,449][train_inner][INFO] - {"epoch": 71, "update": 70.027, "loss": "3.891", "ppl": "14.84", "wps": "48108.3", "ups": "0.45", "wpb": "107198", "bsz": "255.8", "num_updates": "76400", "lr": "0.000295826", "gnorm": "0.737", "train_wall": "398", "gb_free": "6.8", "wall": "30567"}
[2023-04-01 01:12:59,402][train_inner][INFO] - {"epoch": 71, "update": 70.211, "loss": "3.77", "ppl": "13.65", "wps": "48485.1", "ups": "0.45", "wpb": "107383", "bsz": "256", "num_updates": "76600", "lr": "0.000294609", "gnorm": "0.74", "train_wall": "398", "gb_free": "6.8", "wall": "31010"}
[2023-04-01 01:20:21,277][train_inner][INFO] - {"epoch": 71, "update": 70.394, "loss": "3.802", "ppl": "13.95", "wps": "48445", "ups": "0.45", "wpb": "107033", "bsz": "256", "num_updates": "76800", "lr": "0.000293391", "gnorm": "0.743", "train_wall": "397", "gb_free": "6.8", "wall": "31452"}
[2023-04-01 01:27:43,759][train_inner][INFO] - {"epoch": 71, "update": 70.577, "loss": "3.832", "ppl": "14.24", "wps": "48461.1", "ups": "0.45", "wpb": "107216", "bsz": "256", "num_updates": "77000", "lr": "0.000292174", "gnorm": "0.735", "train_wall": "398", "gb_free": "6.8", "wall": "31894"}
[2023-04-01 01:35:06,514][train_inner][INFO] - {"epoch": 71, "update": 70.761, "loss": "3.86", "ppl": "14.52", "wps": "48484.9", "ups": "0.45", "wpb": "107334", "bsz": "256", "num_updates": "77200", "lr": "0.000290957", "gnorm": "0.751", "train_wall": "398", "gb_free": "6.8", "wall": "32337"}
[2023-04-01 01:42:28,245][train_inner][INFO] - {"epoch": 71, "update": 70.944, "loss": "3.873", "ppl": "14.65", "wps": "48441.8", "ups": "0.45", "wpb": "106991", "bsz": "256", "num_updates": "77400", "lr": "0.000289739", "gnorm": "0.742", "train_wall": "397", "gb_free": "6.8", "wall": "32778"}
[2023-04-01 01:44:43,426][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 01:44:43,427][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 01:44:45,141][valid][INFO] - {"epoch": 71, "valid_loss": "4.22", "valid_ppl": "18.63", "valid_wps": "144392", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "77461", "valid_best_loss": "4.132"}
[2023-04-01 01:44:45,142][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 71 @ 77461 updates
[2023-04-01 01:44:45,143][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 01:44:46,061][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 01:44:46,085][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 71 @ 77461 updates, score 4.22) (writing took 0.9429433810000774 seconds)
[2023-04-01 01:44:46,085][fairseq_cli.train][INFO] - end of epoch 71 (average epoch stats below)
[2023-04-01 01:44:46,086][train][INFO] - {"epoch": 71, "train_loss": "3.829", "train_ppl": "14.21", "train_wps": "48405.9", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "77461", "train_lr": "0.000289368", "train_gnorm": "0.742", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "32916"}
[2023-04-01 01:44:46,087][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 01:44:46,120][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 01:44:46,122][fairseq.trainer][INFO] - begin training epoch 72
[2023-04-01 01:44:46,123][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 01:49:54,154][train_inner][INFO] - {"epoch": 72, "update": 71.127, "loss": "3.773", "ppl": "13.67", "wps": "48169.2", "ups": "0.45", "wpb": "107395", "bsz": "255.8", "num_updates": "77600", "lr": "0.000288522", "gnorm": "0.75", "train_wall": "398", "gb_free": "6.8", "wall": "33224"}
[2023-04-01 01:57:16,550][train_inner][INFO] - {"epoch": 72, "update": 71.311, "loss": "3.77", "ppl": "13.64", "wps": "48456", "ups": "0.45", "wpb": "107184", "bsz": "256", "num_updates": "77800", "lr": "0.000287304", "gnorm": "0.746", "train_wall": "398", "gb_free": "6.8", "wall": "33667"}
[2023-04-01 02:04:39,223][train_inner][INFO] - {"epoch": 72, "update": 71.494, "loss": "3.789", "ppl": "13.82", "wps": "48471.6", "ups": "0.45", "wpb": "107285", "bsz": "256", "num_updates": "78000", "lr": "0.000286087", "gnorm": "0.745", "train_wall": "398", "gb_free": "6.8", "wall": "34109"}
[2023-04-01 02:12:01,375][train_inner][INFO] - {"epoch": 72, "update": 71.677, "loss": "3.811", "ppl": "14.04", "wps": "48459.5", "ups": "0.45", "wpb": "107132", "bsz": "256", "num_updates": "78200", "lr": "0.00028487", "gnorm": "0.743", "train_wall": "397", "gb_free": "6.8", "wall": "34552"}
[2023-04-01 02:19:23,421][train_inner][INFO] - {"epoch": 72, "update": 71.861, "loss": "3.831", "ppl": "14.23", "wps": "48439.5", "ups": "0.45", "wpb": "107062", "bsz": "256", "num_updates": "78400", "lr": "0.000283652", "gnorm": "0.749", "train_wall": "397", "gb_free": "6.8", "wall": "34994"}
[2023-04-01 02:24:59,857][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 02:24:59,858][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 02:25:01,576][valid][INFO] - {"epoch": 72, "valid_loss": "4.237", "valid_ppl": "18.85", "valid_wps": "144020", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "78552", "valid_best_loss": "4.132"}
[2023-04-01 02:25:01,577][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 72 @ 78552 updates
[2023-04-01 02:25:01,578][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 02:25:02,491][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 02:25:02,515][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 72 @ 78552 updates, score 4.237) (writing took 0.9382671130006202 seconds)
[2023-04-01 02:25:02,516][fairseq_cli.train][INFO] - end of epoch 72 (average epoch stats below)
[2023-04-01 02:25:02,516][train][INFO] - {"epoch": 72, "train_loss": "3.798", "train_ppl": "13.91", "train_wps": "48402.8", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "78552", "train_lr": "0.000282727", "train_gnorm": "0.746", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "35333"}
[2023-04-01 02:25:02,518][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 02:25:02,548][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 02:25:02,551][fairseq.trainer][INFO] - begin training epoch 73
[2023-04-01 02:25:02,551][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 02:26:48,653][train_inner][INFO] - {"epoch": 73, "update": 72.044, "loss": "3.812", "ppl": "14.04", "wps": "48148.4", "ups": "0.45", "wpb": "107186", "bsz": "255.8", "num_updates": "78600", "lr": "0.000282435", "gnorm": "0.744", "train_wall": "398", "gb_free": "6.8", "wall": "35439"}
[2023-04-01 02:34:11,048][train_inner][INFO] - {"epoch": 73, "update": 72.227, "loss": "3.717", "ppl": "13.15", "wps": "48467.7", "ups": "0.45", "wpb": "107208", "bsz": "256", "num_updates": "78800", "lr": "0.000281217", "gnorm": "0.753", "train_wall": "398", "gb_free": "6.8", "wall": "35881"}
[2023-04-01 02:41:33,702][train_inner][INFO] - {"epoch": 73, "update": 72.411, "loss": "3.746", "ppl": "13.42", "wps": "48485", "ups": "0.45", "wpb": "107310", "bsz": "256", "num_updates": "79000", "lr": "0.00028", "gnorm": "0.747", "train_wall": "398", "gb_free": "6.8", "wall": "36324"}
[2023-04-01 02:48:56,295][train_inner][INFO] - {"epoch": 73, "update": 72.594, "loss": "3.78", "ppl": "13.74", "wps": "48481.8", "ups": "0.45", "wpb": "107288", "bsz": "256", "num_updates": "79200", "lr": "0.000278783", "gnorm": "0.754", "train_wall": "398", "gb_free": "6.8", "wall": "36767"}
[2023-04-01 02:56:18,263][train_inner][INFO] - {"epoch": 73, "update": 72.777, "loss": "3.793", "ppl": "13.86", "wps": "48433.4", "ups": "0.45", "wpb": "107030", "bsz": "256", "num_updates": "79400", "lr": "0.000277565", "gnorm": "0.746", "train_wall": "397", "gb_free": "6.8", "wall": "37209"}
[2023-04-01 03:03:41,155][train_inner][INFO] - {"epoch": 73, "update": 72.961, "loss": "3.815", "ppl": "14.08", "wps": "48482.3", "ups": "0.45", "wpb": "107362", "bsz": "256", "num_updates": "79600", "lr": "0.000276348", "gnorm": "0.735", "train_wall": "398", "gb_free": "6.8", "wall": "37651"}
[2023-04-01 03:05:15,935][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 03:05:15,936][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 03:05:17,607][valid][INFO] - {"epoch": 73, "valid_loss": "4.247", "valid_ppl": "18.99", "valid_wps": "147913", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "79643", "valid_best_loss": "4.132"}
[2023-04-01 03:05:17,608][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 73 @ 79643 updates
[2023-04-01 03:05:17,609][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 03:05:18,710][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 03:05:18,732][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 73 @ 79643 updates, score 4.247) (writing took 1.1235331450006925 seconds)
[2023-04-01 03:05:18,732][fairseq_cli.train][INFO] - end of epoch 73 (average epoch stats below)
[2023-04-01 03:05:18,733][train][INFO] - {"epoch": 73, "train_loss": "3.768", "train_ppl": "13.63", "train_wps": "48407.1", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "79643", "train_lr": "0.000276086", "train_gnorm": "0.747", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "37749"}
[2023-04-01 03:05:18,734][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 03:05:18,765][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 03:05:18,768][fairseq.trainer][INFO] - begin training epoch 74
[2023-04-01 03:05:18,768][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 03:11:06,075][train_inner][INFO] - {"epoch": 74, "update": 73.144, "loss": "3.7", "ppl": "12.99", "wps": "48134.9", "ups": "0.45", "wpb": "107081", "bsz": "255.8", "num_updates": "79800", "lr": "0.00027513", "gnorm": "0.746", "train_wall": "397", "gb_free": "6.8", "wall": "38096"}
[2023-04-01 03:18:27,776][train_inner][INFO] - {"epoch": 74, "update": 73.327, "loss": "3.712", "ppl": "13.1", "wps": "48452.1", "ups": "0.45", "wpb": "107006", "bsz": "256", "num_updates": "80000", "lr": "0.000273913", "gnorm": "0.751", "train_wall": "397", "gb_free": "6.8", "wall": "38538"}
[2023-04-01 03:25:51,085][train_inner][INFO] - {"epoch": 74, "update": 73.511, "loss": "3.735", "ppl": "13.32", "wps": "48486", "ups": "0.45", "wpb": "107470", "bsz": "256", "num_updates": "80200", "lr": "0.000272696", "gnorm": "0.756", "train_wall": "399", "gb_free": "6.8", "wall": "38981"}
[2023-04-01 03:33:14,111][train_inner][INFO] - {"epoch": 74, "update": 73.694, "loss": "3.762", "ppl": "13.56", "wps": "48487.1", "ups": "0.45", "wpb": "107405", "bsz": "256", "num_updates": "80400", "lr": "0.000271478", "gnorm": "0.749", "train_wall": "398", "gb_free": "6.8", "wall": "39424"}
[2023-04-01 03:40:35,944][train_inner][INFO] - {"epoch": 74, "update": 73.877, "loss": "3.781", "ppl": "13.75", "wps": "48453.4", "ups": "0.45", "wpb": "107042", "bsz": "256", "num_updates": "80600", "lr": "0.000270261", "gnorm": "0.758", "train_wall": "397", "gb_free": "6.8", "wall": "39866"}
[2023-04-01 03:45:32,069][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 03:45:32,070][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 03:45:33,784][valid][INFO] - {"epoch": 74, "valid_loss": "4.263", "valid_ppl": "19.2", "valid_wps": "144922", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "80734", "valid_best_loss": "4.132"}
[2023-04-01 03:45:33,785][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 74 @ 80734 updates
[2023-04-01 03:45:33,786][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 03:45:35,340][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 03:45:35,365][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 74 @ 80734 updates, score 4.263) (writing took 1.5798947790026432 seconds)
[2023-04-01 03:45:35,365][fairseq_cli.train][INFO] - end of epoch 74 (average epoch stats below)
[2023-04-01 03:45:35,366][train][INFO] - {"epoch": 74, "train_loss": "3.741", "train_ppl": "13.37", "train_wps": "48398.7", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "80734", "train_lr": "0.000269445", "train_gnorm": "0.752", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "40166"}
[2023-04-01 03:45:35,367][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 03:45:35,398][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 03:45:35,400][fairseq.trainer][INFO] - begin training epoch 75
[2023-04-01 03:45:35,401][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 03:48:01,336][train_inner][INFO] - {"epoch": 75, "update": 74.06, "loss": "3.737", "ppl": "13.34", "wps": "48074.4", "ups": "0.45", "wpb": "107060", "bsz": "255.8", "num_updates": "80800", "lr": "0.000269043", "gnorm": "0.746", "train_wall": "397", "gb_free": "6.8", "wall": "40312"}
[2023-04-01 03:55:23,954][train_inner][INFO] - {"epoch": 75, "update": 74.244, "loss": "3.662", "ppl": "12.65", "wps": "48459.2", "ups": "0.45", "wpb": "107243", "bsz": "256", "num_updates": "81000", "lr": "0.000267826", "gnorm": "0.752", "train_wall": "398", "gb_free": "6.8", "wall": "40754"}
[2023-04-01 04:02:46,254][train_inner][INFO] - {"epoch": 75, "update": 74.427, "loss": "3.697", "ppl": "12.97", "wps": "48475.3", "ups": "0.45", "wpb": "107203", "bsz": "256", "num_updates": "81200", "lr": "0.000266609", "gnorm": "0.755", "train_wall": "398", "gb_free": "6.8", "wall": "41197"}
[2023-04-01 04:10:08,932][train_inner][INFO] - {"epoch": 75, "update": 74.61, "loss": "3.727", "ppl": "13.24", "wps": "48468.7", "ups": "0.45", "wpb": "107280", "bsz": "256", "num_updates": "81400", "lr": "0.000265391", "gnorm": "0.751", "train_wall": "398", "gb_free": "6.8", "wall": "41639"}
[2023-04-01 04:17:31,107][train_inner][INFO] - {"epoch": 75, "update": 74.794, "loss": "3.749", "ppl": "13.45", "wps": "48458.2", "ups": "0.45", "wpb": "107135", "bsz": "256", "num_updates": "81600", "lr": "0.000264174", "gnorm": "0.751", "train_wall": "398", "gb_free": "6.8", "wall": "42081"}
[2023-04-01 04:24:53,637][train_inner][INFO] - {"epoch": 75, "update": 74.977, "loss": "3.762", "ppl": "13.57", "wps": "48480.8", "ups": "0.45", "wpb": "107271", "bsz": "256", "num_updates": "81800", "lr": "0.000262957", "gnorm": "0.753", "train_wall": "398", "gb_free": "6.8", "wall": "42524"}
[2023-04-01 04:25:48,861][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 04:25:48,862][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 04:25:50,534][valid][INFO] - {"epoch": 75, "valid_loss": "4.273", "valid_ppl": "19.34", "valid_wps": "147860", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "81825", "valid_best_loss": "4.132"}
[2023-04-01 04:25:50,535][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 75 @ 81825 updates
[2023-04-01 04:25:50,536][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 04:25:52,558][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 04:25:52,580][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 75 @ 81825 updates, score 4.273) (writing took 2.0449641890008934 seconds)
[2023-04-01 04:25:52,580][fairseq_cli.train][INFO] - end of epoch 75 (average epoch stats below)
[2023-04-01 04:25:52,581][train][INFO] - {"epoch": 75, "train_loss": "3.715", "train_ppl": "13.14", "train_wps": "48387.1", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "81825", "train_lr": "0.000262804", "train_gnorm": "0.752", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "42583"}
[2023-04-01 04:25:52,583][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 04:25:52,613][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 04:25:52,615][fairseq.trainer][INFO] - begin training epoch 76
[2023-04-01 04:25:52,616][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 04:32:20,204][train_inner][INFO] - {"epoch": 76, "update": 75.16, "loss": "3.641", "ppl": "12.48", "wps": "48071.3", "ups": "0.45", "wpb": "107335", "bsz": "255.8", "num_updates": "82000", "lr": "0.000261739", "gnorm": "0.757", "train_wall": "398", "gb_free": "6.8", "wall": "42970"}
[2023-04-01 04:39:43,145][train_inner][INFO] - {"epoch": 76, "update": 75.344, "loss": "3.665", "ppl": "12.68", "wps": "48502.3", "ups": "0.45", "wpb": "107417", "bsz": "256", "num_updates": "82200", "lr": "0.000260522", "gnorm": "0.767", "train_wall": "398", "gb_free": "6.8", "wall": "43413"}
[2023-04-01 04:47:05,074][train_inner][INFO] - {"epoch": 76, "update": 75.527, "loss": "3.691", "ppl": "12.92", "wps": "48445.8", "ups": "0.45", "wpb": "107048", "bsz": "256", "num_updates": "82400", "lr": "0.000259304", "gnorm": "0.759", "train_wall": "397", "gb_free": "6.8", "wall": "43855"}
[2023-04-01 04:54:27,156][train_inner][INFO] - {"epoch": 76, "update": 75.71, "loss": "3.708", "ppl": "13.07", "wps": "48438.9", "ups": "0.45", "wpb": "107070", "bsz": "256", "num_updates": "82600", "lr": "0.000258087", "gnorm": "0.758", "train_wall": "397", "gb_free": "6.8", "wall": "44297"}
[2023-04-01 05:01:49,501][train_inner][INFO] - {"epoch": 76, "update": 75.894, "loss": "3.732", "ppl": "13.29", "wps": "48459.2", "ups": "0.45", "wpb": "107178", "bsz": "256", "num_updates": "82800", "lr": "0.00025687", "gnorm": "0.753", "train_wall": "398", "gb_free": "6.8", "wall": "44740"}
[2023-04-01 05:06:05,956][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 05:06:05,957][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 05:06:07,672][valid][INFO] - {"epoch": 76, "valid_loss": "4.282", "valid_ppl": "19.46", "valid_wps": "144358", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "82916", "valid_best_loss": "4.132"}
[2023-04-01 05:06:07,673][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 76 @ 82916 updates
[2023-04-01 05:06:07,673][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 05:06:08,600][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 05:06:08,623][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 76 @ 82916 updates, score 4.282) (writing took 0.9507626319973497 seconds)
[2023-04-01 05:06:08,624][fairseq_cli.train][INFO] - end of epoch 76 (average epoch stats below)
[2023-04-01 05:06:08,624][train][INFO] - {"epoch": 76, "train_loss": "3.691", "train_ppl": "12.92", "train_wps": "48410.6", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "82916", "train_lr": "0.000256163", "train_gnorm": "0.758", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "44999"}
[2023-04-01 05:06:08,626][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 05:06:08,658][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 05:06:08,660][fairseq.trainer][INFO] - begin training epoch 77
[2023-04-01 05:06:08,661][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 05:09:14,616][train_inner][INFO] - {"epoch": 77, "update": 76.077, "loss": "3.679", "ppl": "12.81", "wps": "48136", "ups": "0.45", "wpb": "107130", "bsz": "255.8", "num_updates": "83000", "lr": "0.000255652", "gnorm": "0.758", "train_wall": "398", "gb_free": "6.8", "wall": "45185"}
[2023-04-01 05:16:37,468][train_inner][INFO] - {"epoch": 77, "update": 76.26, "loss": "3.626", "ppl": "12.34", "wps": "48503.7", "ups": "0.45", "wpb": "107400", "bsz": "256", "num_updates": "83200", "lr": "0.000254435", "gnorm": "0.766", "train_wall": "398", "gb_free": "6.8", "wall": "45628"}
[2023-04-01 05:23:59,822][train_inner][INFO] - {"epoch": 77, "update": 76.444, "loss": "3.654", "ppl": "12.59", "wps": "48448", "ups": "0.45", "wpb": "107156", "bsz": "256", "num_updates": "83400", "lr": "0.000253217", "gnorm": "0.76", "train_wall": "398", "gb_free": "6.8", "wall": "46070"}
[2023-04-01 05:31:21,987][train_inner][INFO] - {"epoch": 77, "update": 76.627, "loss": "3.678", "ppl": "12.8", "wps": "48449.9", "ups": "0.45", "wpb": "107114", "bsz": "256", "num_updates": "83600", "lr": "0.000252", "gnorm": "0.761", "train_wall": "398", "gb_free": "6.8", "wall": "46512"}
[2023-04-01 05:38:44,386][train_inner][INFO] - {"epoch": 77, "update": 76.81, "loss": "3.7", "ppl": "13", "wps": "48479.9", "ups": "0.45", "wpb": "107237", "bsz": "256", "num_updates": "83800", "lr": "0.000250783", "gnorm": "0.766", "train_wall": "398", "gb_free": "6.8", "wall": "46955"}
[2023-04-01 05:46:06,863][train_inner][INFO] - {"epoch": 77, "update": 76.994, "loss": "3.718", "ppl": "13.16", "wps": "48466.9", "ups": "0.45", "wpb": "107228", "bsz": "256", "num_updates": "84000", "lr": "0.000249565", "gnorm": "0.76", "train_wall": "398", "gb_free": "6.8", "wall": "47397"}
[2023-04-01 05:46:22,135][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 05:46:22,136][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 05:46:23,807][valid][INFO] - {"epoch": 77, "valid_loss": "4.296", "valid_ppl": "19.65", "valid_wps": "148001", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "84007", "valid_best_loss": "4.132"}
[2023-04-01 05:46:23,808][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 77 @ 84007 updates
[2023-04-01 05:46:23,809][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 05:46:25,176][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 05:46:25,197][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 77 @ 84007 updates, score 4.296) (writing took 1.3892325689957943 seconds)
[2023-04-01 05:46:25,198][fairseq_cli.train][INFO] - end of epoch 77 (average epoch stats below)
[2023-04-01 05:46:25,198][train][INFO] - {"epoch": 77, "train_loss": "3.669", "train_ppl": "12.72", "train_wps": "48399.9", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "84007", "train_lr": "0.000249523", "train_gnorm": "0.762", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "47415"}
[2023-04-01 05:46:25,200][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 05:46:25,231][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 05:46:25,233][fairseq.trainer][INFO] - begin training epoch 78
[2023-04-01 05:46:25,233][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 05:53:31,958][train_inner][INFO] - {"epoch": 78, "update": 77.177, "loss": "3.589", "ppl": "12.03", "wps": "48098.3", "ups": "0.45", "wpb": "107042", "bsz": "255.8", "num_updates": "84200", "lr": "0.000248348", "gnorm": "0.772", "train_wall": "397", "gb_free": "6.8", "wall": "47842"}
[2023-04-01 06:00:54,420][train_inner][INFO] - {"epoch": 78, "update": 77.36, "loss": "3.618", "ppl": "12.28", "wps": "48457.4", "ups": "0.45", "wpb": "107202", "bsz": "256", "num_updates": "84400", "lr": "0.00024713", "gnorm": "0.759", "train_wall": "398", "gb_free": "6.8", "wall": "48285"}
[2023-04-01 06:08:16,909][train_inner][INFO] - {"epoch": 78, "update": 77.544, "loss": "3.651", "ppl": "12.56", "wps": "48473.3", "ups": "0.45", "wpb": "107245", "bsz": "256", "num_updates": "84600", "lr": "0.000245913", "gnorm": "0.763", "train_wall": "398", "gb_free": "6.8", "wall": "48727"}
[2023-04-01 06:15:39,057][train_inner][INFO] - {"epoch": 78, "update": 77.727, "loss": "3.667", "ppl": "12.7", "wps": "48466", "ups": "0.45", "wpb": "107146", "bsz": "256", "num_updates": "84800", "lr": "0.000244696", "gnorm": "0.768", "train_wall": "397", "gb_free": "6.8", "wall": "49169"}
[2023-04-01 06:23:02,125][train_inner][INFO] - {"epoch": 78, "update": 77.91, "loss": "3.687", "ppl": "12.88", "wps": "48485.4", "ups": "0.45", "wpb": "107411", "bsz": "256", "num_updates": "85000", "lr": "0.000243478", "gnorm": "0.767", "train_wall": "398", "gb_free": "6.8", "wall": "49612"}
[2023-04-01 06:26:38,633][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 06:26:38,634][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 06:26:40,363][valid][INFO] - {"epoch": 78, "valid_loss": "4.31", "valid_ppl": "19.83", "valid_wps": "143089", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "85098", "valid_best_loss": "4.132"}
[2023-04-01 06:26:40,364][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 78 @ 85098 updates
[2023-04-01 06:26:40,365][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 06:26:41,444][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 06:26:41,467][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 78 @ 85098 updates, score 4.31) (writing took 1.1029192640053225 seconds)
[2023-04-01 06:26:41,468][fairseq_cli.train][INFO] - end of epoch 78 (average epoch stats below)
[2023-04-01 06:26:41,468][train][INFO] - {"epoch": 78, "train_loss": "3.647", "train_ppl": "12.52", "train_wps": "48406", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "85098", "train_lr": "0.000242882", "train_gnorm": "0.766", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "49832"}
[2023-04-01 06:26:41,470][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 06:26:41,502][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 06:26:41,504][fairseq.trainer][INFO] - begin training epoch 79
[2023-04-01 06:26:41,504][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 06:30:27,422][train_inner][INFO] - {"epoch": 79, "update": 78.093, "loss": "3.623", "ppl": "12.32", "wps": "48126.5", "ups": "0.45", "wpb": "107153", "bsz": "255.8", "num_updates": "85200", "lr": "0.000242261", "gnorm": "0.767", "train_wall": "398", "gb_free": "6.8", "wall": "50058"}
[2023-04-01 06:37:50,528][train_inner][INFO] - {"epoch": 79, "update": 78.277, "loss": "3.586", "ppl": "12.01", "wps": "48505.6", "ups": "0.45", "wpb": "107464", "bsz": "256", "num_updates": "85400", "lr": "0.000241043", "gnorm": "0.762", "train_wall": "398", "gb_free": "6.8", "wall": "50501"}
[2023-04-01 06:45:12,491][train_inner][INFO] - {"epoch": 79, "update": 78.46, "loss": "3.622", "ppl": "12.31", "wps": "48438.8", "ups": "0.45", "wpb": "107041", "bsz": "256", "num_updates": "85600", "lr": "0.000239826", "gnorm": "0.773", "train_wall": "397", "gb_free": "6.8", "wall": "50943"}
[2023-04-01 06:52:35,088][train_inner][INFO] - {"epoch": 79, "update": 78.643, "loss": "3.639", "ppl": "12.46", "wps": "48454.1", "ups": "0.45", "wpb": "107228", "bsz": "256", "num_updates": "85800", "lr": "0.000238609", "gnorm": "0.766", "train_wall": "398", "gb_free": "6.8", "wall": "51385"}
[2023-04-01 06:59:56,783][train_inner][INFO] - {"epoch": 79, "update": 78.827, "loss": "3.654", "ppl": "12.59", "wps": "48435.4", "ups": "0.45", "wpb": "106968", "bsz": "256", "num_updates": "86000", "lr": "0.000237391", "gnorm": "0.768", "train_wall": "397", "gb_free": "6.8", "wall": "51827"}
[2023-04-01 07:06:55,243][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 07:06:55,244][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 07:06:56,963][valid][INFO] - {"epoch": 79, "valid_loss": "4.32", "valid_ppl": "19.97", "valid_wps": "144230", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "86189", "valid_best_loss": "4.132"}
[2023-04-01 07:06:56,964][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 79 @ 86189 updates
[2023-04-01 07:06:56,965][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 07:06:58,215][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 07:06:58,239][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 79 @ 86189 updates, score 4.32) (writing took 1.2746308829955524 seconds)
[2023-04-01 07:06:58,239][fairseq_cli.train][INFO] - end of epoch 79 (average epoch stats below)
[2023-04-01 07:06:58,239][train][INFO] - {"epoch": 79, "train_loss": "3.627", "train_ppl": "12.36", "train_wps": "48396", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "86189", "train_lr": "0.000236241", "train_gnorm": "0.767", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "52248"}
[2023-04-01 07:06:58,241][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 07:06:58,273][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 07:06:58,275][fairseq.trainer][INFO] - begin training epoch 80
[2023-04-01 07:06:58,275][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 07:07:22,705][train_inner][INFO] - {"epoch": 80, "update": 79.01, "loss": "3.667", "ppl": "12.7", "wps": "48109.2", "ups": "0.45", "wpb": "107265", "bsz": "255.8", "num_updates": "86200", "lr": "0.000236174", "gnorm": "0.765", "train_wall": "398", "gb_free": "6.8", "wall": "52273"}
[2023-04-01 07:14:44,739][train_inner][INFO] - {"epoch": 80, "update": 79.193, "loss": "3.543", "ppl": "11.66", "wps": "48458.3", "ups": "0.45", "wpb": "107101", "bsz": "256", "num_updates": "86400", "lr": "0.000234957", "gnorm": "0.767", "train_wall": "397", "gb_free": "6.8", "wall": "52715"}
[2023-04-01 07:22:07,169][train_inner][INFO] - {"epoch": 80, "update": 79.377, "loss": "3.581", "ppl": "11.97", "wps": "48466.8", "ups": "0.45", "wpb": "107214", "bsz": "256", "num_updates": "86600", "lr": "0.000233739", "gnorm": "0.763", "train_wall": "398", "gb_free": "6.8", "wall": "53157"}
[2023-04-01 07:29:29,563][train_inner][INFO] - {"epoch": 80, "update": 79.56, "loss": "3.612", "ppl": "12.23", "wps": "48456.1", "ups": "0.45", "wpb": "107183", "bsz": "256", "num_updates": "86800", "lr": "0.000232522", "gnorm": "0.773", "train_wall": "398", "gb_free": "6.8", "wall": "53600"}
[2023-04-01 07:36:52,537][train_inner][INFO] - {"epoch": 80, "update": 79.743, "loss": "3.632", "ppl": "12.4", "wps": "48490.5", "ups": "0.45", "wpb": "107400", "bsz": "256", "num_updates": "87000", "lr": "0.000231304", "gnorm": "0.779", "train_wall": "398", "gb_free": "6.8", "wall": "54043"}
[2023-04-01 07:44:15,120][train_inner][INFO] - {"epoch": 80, "update": 79.927, "loss": "3.654", "ppl": "12.59", "wps": "48472.8", "ups": "0.45", "wpb": "107266", "bsz": "256", "num_updates": "87200", "lr": "0.000230087", "gnorm": "0.77", "train_wall": "398", "gb_free": "6.8", "wall": "54485"}
[2023-04-01 07:47:11,800][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 07:47:11,801][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 07:47:13,520][valid][INFO] - {"epoch": 80, "valid_loss": "4.324", "valid_ppl": "20.03", "valid_wps": "144062", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "87280", "valid_best_loss": "4.132"}
[2023-04-01 07:47:13,521][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 80 @ 87280 updates
[2023-04-01 07:47:13,522][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 07:47:15,299][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 07:47:15,320][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 80 @ 87280 updates, score 4.324) (writing took 1.7993509029984125 seconds)
[2023-04-01 07:47:15,321][fairseq_cli.train][INFO] - end of epoch 80 (average epoch stats below)
[2023-04-01 07:47:15,321][train][INFO] - {"epoch": 80, "train_loss": "3.608", "train_ppl": "12.19", "train_wps": "48389.8", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "87280", "train_lr": "0.0002296", "train_gnorm": "0.77", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "54666"}
[2023-04-01 07:47:15,323][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 07:47:15,355][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 07:47:15,357][fairseq.trainer][INFO] - begin training epoch 81
[2023-04-01 07:47:15,357][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 07:51:41,680][train_inner][INFO] - {"epoch": 81, "update": 80.11, "loss": "3.573", "ppl": "11.9", "wps": "48083.5", "ups": "0.45", "wpb": "107361", "bsz": "255.8", "num_updates": "87400", "lr": "0.00022887", "gnorm": "0.773", "train_wall": "398", "gb_free": "6.8", "wall": "54932"}
[2023-04-01 07:59:04,010][train_inner][INFO] - {"epoch": 81, "update": 80.293, "loss": "3.553", "ppl": "11.74", "wps": "48464.9", "ups": "0.45", "wpb": "107186", "bsz": "256", "num_updates": "87600", "lr": "0.000227652", "gnorm": "0.781", "train_wall": "398", "gb_free": "6.8", "wall": "55374"}
[2023-04-01 08:06:26,824][train_inner][INFO] - {"epoch": 81, "update": 80.477, "loss": "3.577", "ppl": "11.94", "wps": "48464.3", "ups": "0.45", "wpb": "107303", "bsz": "256", "num_updates": "87800", "lr": "0.000226435", "gnorm": "0.773", "train_wall": "398", "gb_free": "6.8", "wall": "55817"}
[2023-04-01 08:13:48,387][train_inner][INFO] - {"epoch": 81, "update": 80.66, "loss": "3.603", "ppl": "12.15", "wps": "48440.9", "ups": "0.45", "wpb": "106948", "bsz": "256", "num_updates": "88000", "lr": "0.000225217", "gnorm": "0.769", "train_wall": "397", "gb_free": "6.8", "wall": "56259"}
[2023-04-01 08:21:11,420][train_inner][INFO] - {"epoch": 81, "update": 80.843, "loss": "3.621", "ppl": "12.3", "wps": "48442.2", "ups": "0.45", "wpb": "107308", "bsz": "256", "num_updates": "88200", "lr": "0.000224", "gnorm": "0.781", "train_wall": "398", "gb_free": "6.8", "wall": "56702"}
[2023-04-01 08:27:29,144][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 08:27:29,145][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 08:27:30,896][valid][INFO] - {"epoch": 81, "valid_loss": "4.341", "valid_ppl": "20.26", "valid_wps": "141380", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "88371", "valid_best_loss": "4.132"}
[2023-04-01 08:27:30,897][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 81 @ 88371 updates
[2023-04-01 08:27:30,898][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 08:27:32,168][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 08:27:32,191][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 81 @ 88371 updates, score 4.341) (writing took 1.2939204789945506 seconds)
[2023-04-01 08:27:32,192][fairseq_cli.train][INFO] - end of epoch 81 (average epoch stats below)
[2023-04-01 08:27:32,192][train][INFO] - {"epoch": 81, "train_loss": "3.589", "train_ppl": "12.03", "train_wps": "48394", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "88371", "train_lr": "0.000222959", "train_gnorm": "0.775", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "57082"}
[2023-04-01 08:27:32,194][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 08:27:32,225][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 08:27:32,228][fairseq.trainer][INFO] - begin training epoch 82
[2023-04-01 08:27:32,228][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 08:28:36,519][train_inner][INFO] - {"epoch": 82, "update": 81.027, "loss": "3.621", "ppl": "12.31", "wps": "48093.1", "ups": "0.45", "wpb": "107031", "bsz": "255.8", "num_updates": "88400", "lr": "0.000222783", "gnorm": "0.776", "train_wall": "397", "gb_free": "6.8", "wall": "57147"}
[2023-04-01 08:35:59,315][train_inner][INFO] - {"epoch": 82, "update": 81.21, "loss": "3.512", "ppl": "11.41", "wps": "48458.4", "ups": "0.45", "wpb": "107286", "bsz": "256", "num_updates": "88600", "lr": "0.000221565", "gnorm": "0.773", "train_wall": "398", "gb_free": "6.8", "wall": "57590"}
[2023-04-01 08:43:22,451][train_inner][INFO] - {"epoch": 82, "update": 81.393, "loss": "3.548", "ppl": "11.7", "wps": "48491.4", "ups": "0.45", "wpb": "107441", "bsz": "256", "num_updates": "88800", "lr": "0.000220348", "gnorm": "0.773", "train_wall": "398", "gb_free": "6.8", "wall": "58033"}
[2023-04-01 08:50:44,960][train_inner][INFO] - {"epoch": 82, "update": 81.577, "loss": "3.581", "ppl": "11.97", "wps": "48466.2", "ups": "0.45", "wpb": "107234", "bsz": "256", "num_updates": "89000", "lr": "0.00021913", "gnorm": "0.774", "train_wall": "398", "gb_free": "6.8", "wall": "58475"}
[2023-04-01 08:58:06,428][train_inner][INFO] - {"epoch": 82, "update": 81.76, "loss": "3.597", "ppl": "12.1", "wps": "48420.4", "ups": "0.45", "wpb": "106880", "bsz": "256", "num_updates": "89200", "lr": "0.000217913", "gnorm": "0.782", "train_wall": "397", "gb_free": "6.8", "wall": "58917"}
[2023-04-01 09:05:28,590][train_inner][INFO] - {"epoch": 82, "update": 81.943, "loss": "3.616", "ppl": "12.26", "wps": "48453.9", "ups": "0.45", "wpb": "107122", "bsz": "256", "num_updates": "89400", "lr": "0.000216696", "gnorm": "0.776", "train_wall": "397", "gb_free": "6.8", "wall": "59359"}
[2023-04-01 09:07:45,977][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 09:07:45,977][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 09:07:47,716][valid][INFO] - {"epoch": 82, "valid_loss": "4.343", "valid_ppl": "20.29", "valid_wps": "142308", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "89462", "valid_best_loss": "4.132"}
[2023-04-01 09:07:47,717][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 82 @ 89462 updates
[2023-04-01 09:07:47,718][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 09:07:49,716][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 09:07:49,740][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 82 @ 89462 updates, score 4.343) (writing took 2.0231838620020426 seconds)
[2023-04-01 09:07:49,740][fairseq_cli.train][INFO] - end of epoch 82 (average epoch stats below)
[2023-04-01 09:07:49,741][train][INFO] - {"epoch": 82, "train_loss": "3.572", "train_ppl": "11.89", "train_wps": "48380.4", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "89462", "train_lr": "0.000216318", "train_gnorm": "0.776", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "59500"}
[2023-04-01 09:07:49,742][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 09:07:49,773][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 09:07:49,776][fairseq.trainer][INFO] - begin training epoch 83
[2023-04-01 09:07:49,776][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 09:12:55,174][train_inner][INFO] - {"epoch": 83, "update": 82.126, "loss": "3.527", "ppl": "11.53", "wps": "47987.4", "ups": "0.45", "wpb": "107152", "bsz": "255.8", "num_updates": "89600", "lr": "0.000215478", "gnorm": "0.777", "train_wall": "398", "gb_free": "6.8", "wall": "59805"}
[2023-04-01 09:20:17,571][train_inner][INFO] - {"epoch": 83, "update": 82.31, "loss": "3.524", "ppl": "11.51", "wps": "48485.2", "ups": "0.45", "wpb": "107248", "bsz": "256", "num_updates": "89800", "lr": "0.000214261", "gnorm": "0.78", "train_wall": "398", "gb_free": "6.8", "wall": "60248"}
[2023-04-01 09:27:40,420][train_inner][INFO] - {"epoch": 83, "update": 82.493, "loss": "3.543", "ppl": "11.66", "wps": "48481.4", "ups": "0.45", "wpb": "107350", "bsz": "256", "num_updates": "90000", "lr": "0.000213043", "gnorm": "0.78", "train_wall": "398", "gb_free": "6.8", "wall": "60691"}
[2023-04-01 09:35:02,939][train_inner][INFO] - {"epoch": 83, "update": 82.676, "loss": "3.569", "ppl": "11.87", "wps": "48461.8", "ups": "0.45", "wpb": "107226", "bsz": "256", "num_updates": "90200", "lr": "0.000211826", "gnorm": "0.777", "train_wall": "398", "gb_free": "6.8", "wall": "61133"}
[2023-04-01 09:42:25,480][train_inner][INFO] - {"epoch": 83, "update": 82.86, "loss": "3.588", "ppl": "12.03", "wps": "48498.3", "ups": "0.45", "wpb": "107312", "bsz": "256", "num_updates": "90400", "lr": "0.000210609", "gnorm": "0.78", "train_wall": "398", "gb_free": "6.8", "wall": "61576"}
[2023-04-01 09:48:03,253][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 09:48:03,253][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 09:48:04,975][valid][INFO] - {"epoch": 83, "valid_loss": "4.356", "valid_ppl": "20.48", "valid_wps": "143681", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "90553", "valid_best_loss": "4.132"}
[2023-04-01 09:48:04,976][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 83 @ 90553 updates
[2023-04-01 09:48:04,977][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 09:48:07,079][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 09:48:07,100][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 83 @ 90553 updates, score 4.356) (writing took 2.1231616549994214 seconds)
[2023-04-01 09:48:07,100][fairseq_cli.train][INFO] - end of epoch 83 (average epoch stats below)
[2023-04-01 09:48:07,100][train][INFO] - {"epoch": 83, "train_loss": "3.554", "train_ppl": "11.75", "train_wps": "48384.2", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "90553", "train_lr": "0.000209677", "train_gnorm": "0.778", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "61917"}
[2023-04-01 09:48:07,102][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 09:48:07,135][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 09:48:07,138][fairseq.trainer][INFO] - begin training epoch 84
[2023-04-01 09:48:07,138][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 09:49:51,073][train_inner][INFO] - {"epoch": 84, "update": 83.043, "loss": "3.568", "ppl": "11.86", "wps": "48005.7", "ups": "0.45", "wpb": "106955", "bsz": "255.8", "num_updates": "90600", "lr": "0.000209391", "gnorm": "0.775", "train_wall": "397", "gb_free": "6.8", "wall": "62021"}
[2023-04-01 09:58:24,253][train_inner][INFO] - {"epoch": 84, "update": 83.226, "loss": "3.489", "ppl": "11.23", "wps": "41835.5", "ups": "0.39", "wpb": "107346", "bsz": "256", "num_updates": "90800", "lr": "0.000208174", "gnorm": "0.773", "train_wall": "456", "gb_free": "6.8", "wall": "62535"}
[2023-04-01 10:08:39,692][train_inner][INFO] - {"epoch": 84, "update": 83.41, "loss": "3.523", "ppl": "11.5", "wps": "34857.8", "ups": "0.32", "wpb": "107264", "bsz": "256", "num_updates": "91000", "lr": "0.000206957", "gnorm": "0.779", "train_wall": "544", "gb_free": "6.8", "wall": "63150"}
[2023-04-01 10:18:47,566][train_inner][INFO] - {"epoch": 84, "update": 83.593, "loss": "3.541", "ppl": "11.64", "wps": "35295.8", "ups": "0.33", "wpb": "107277", "bsz": "256", "num_updates": "91200", "lr": "0.000205739", "gnorm": "0.783", "train_wall": "540", "gb_free": "6.8", "wall": "63758"}
[2023-04-01 10:28:49,604][train_inner][INFO] - {"epoch": 84, "update": 83.776, "loss": "3.563", "ppl": "11.82", "wps": "35616.5", "ups": "0.33", "wpb": "107212", "bsz": "256", "num_updates": "91400", "lr": "0.000204522", "gnorm": "0.779", "train_wall": "536", "gb_free": "6.8", "wall": "64360"}
[2023-04-01 10:38:44,129][train_inner][INFO] - {"epoch": 84, "update": 83.96, "loss": "3.583", "ppl": "11.98", "wps": "36020.2", "ups": "0.34", "wpb": "107074", "bsz": "256", "num_updates": "91600", "lr": "0.000203304", "gnorm": "0.777", "train_wall": "530", "gb_free": "6.8", "wall": "64954"}
[2023-04-01 10:40:56,980][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 10:40:56,981][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 10:40:59,351][valid][INFO] - {"epoch": 84, "valid_loss": "4.364", "valid_ppl": "20.6", "valid_wps": "105084", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "91644", "valid_best_loss": "4.132"}
[2023-04-01 10:40:59,352][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 84 @ 91644 updates
[2023-04-01 10:40:59,353][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 10:41:00,495][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 10:41:00,525][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 84 @ 91644 updates, score 4.364) (writing took 1.1730290559935383 seconds)
[2023-04-01 10:41:00,525][fairseq_cli.train][INFO] - end of epoch 84 (average epoch stats below)
[2023-04-01 10:41:00,526][train][INFO] - {"epoch": 84, "train_loss": "3.538", "train_ppl": "11.62", "train_wps": "36856.7", "train_ups": "0.34", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "91644", "train_lr": "0.000203037", "train_gnorm": "0.778", "train_train_wall": "2819", "train_gb_free": "6.8", "train_wall": "65091"}
[2023-04-01 10:41:00,527][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 10:41:00,565][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 10:41:00,568][fairseq.trainer][INFO] - begin training epoch 85
[2023-04-01 10:41:00,568][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 10:48:58,127][train_inner][INFO] - {"epoch": 85, "update": 84.143, "loss": "3.489", "ppl": "11.23", "wps": "34870.6", "ups": "0.33", "wpb": "107052", "bsz": "255.8", "num_updates": "91800", "lr": "0.000202087", "gnorm": "0.779", "train_wall": "549", "gb_free": "6.8", "wall": "65568"}
[2023-04-01 10:59:05,081][train_inner][INFO] - {"epoch": 85, "update": 84.326, "loss": "3.488", "ppl": "11.22", "wps": "35377.6", "ups": "0.33", "wpb": "107361", "bsz": "256", "num_updates": "92000", "lr": "0.00020087", "gnorm": "0.789", "train_wall": "539", "gb_free": "6.8", "wall": "66175"}
[2023-04-01 11:08:55,551][train_inner][INFO] - {"epoch": 85, "update": 84.51, "loss": "3.52", "ppl": "11.47", "wps": "36418.1", "ups": "0.34", "wpb": "107519", "bsz": "256", "num_updates": "92200", "lr": "0.000199652", "gnorm": "0.781", "train_wall": "530", "gb_free": "6.8", "wall": "66766"}
[2023-04-01 11:18:56,797][train_inner][INFO] - {"epoch": 85, "update": 84.693, "loss": "3.542", "ppl": "11.64", "wps": "35543.4", "ups": "0.33", "wpb": "106852", "bsz": "256", "num_updates": "92400", "lr": "0.000198435", "gnorm": "0.782", "train_wall": "536", "gb_free": "6.8", "wall": "67367"}
[2023-04-01 11:28:45,687][train_inner][INFO] - {"epoch": 85, "update": 84.876, "loss": "3.557", "ppl": "11.77", "wps": "36422.5", "ups": "0.34", "wpb": "107244", "bsz": "256", "num_updates": "92600", "lr": "0.000197217", "gnorm": "0.781", "train_wall": "526", "gb_free": "6.8", "wall": "67956"}
[2023-04-01 11:35:28,863][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 11:35:28,864][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 11:35:31,076][valid][INFO] - {"epoch": 85, "valid_loss": "4.377", "valid_ppl": "20.78", "valid_wps": "112024", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "92735", "valid_best_loss": "4.132"}
[2023-04-01 11:35:31,077][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 85 @ 92735 updates
[2023-04-01 11:35:31,078][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 11:35:32,047][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 11:35:32,077][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 85 @ 92735 updates, score 4.377) (writing took 1.0004319330037106 seconds)
[2023-04-01 11:35:32,078][fairseq_cli.train][INFO] - end of epoch 85 (average epoch stats below)
[2023-04-01 11:35:32,080][train][INFO] - {"epoch": 85, "train_loss": "3.524", "train_ppl": "11.5", "train_wps": "35751.2", "train_ups": "0.33", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "92735", "train_lr": "0.000196396", "train_gnorm": "0.782", "train_train_wall": "2919", "train_gb_free": "6.8", "train_wall": "68362"}
[2023-04-01 11:35:32,083][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 11:35:32,124][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 11:35:32,127][fairseq.trainer][INFO] - begin training epoch 86
[2023-04-01 11:35:32,129][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 11:38:41,322][train_inner][INFO] - {"epoch": 86, "update": 85.06, "loss": "3.533", "ppl": "11.57", "wps": "35957.8", "ups": "0.34", "wpb": "107088", "bsz": "255.8", "num_updates": "92800", "lr": "0.000196", "gnorm": "0.78", "train_wall": "529", "gb_free": "6.8", "wall": "68552"}
[2023-04-01 11:48:39,992][train_inner][INFO] - {"epoch": 86, "update": 85.243, "loss": "3.458", "ppl": "10.99", "wps": "35749.2", "ups": "0.33", "wpb": "107009", "bsz": "256", "num_updates": "93000", "lr": "0.000194783", "gnorm": "0.791", "train_wall": "540", "gb_free": "6.8", "wall": "69150"}
[2023-04-01 11:58:51,707][train_inner][INFO] - {"epoch": 86, "update": 85.426, "loss": "3.494", "ppl": "11.26", "wps": "34970.5", "ups": "0.33", "wpb": "106960", "bsz": "256", "num_updates": "93200", "lr": "0.000193565", "gnorm": "0.781", "train_wall": "542", "gb_free": "6.8", "wall": "69762"}
[2023-04-01 12:09:04,142][train_inner][INFO] - {"epoch": 86, "update": 85.61, "loss": "3.513", "ppl": "11.42", "wps": "35083.4", "ups": "0.33", "wpb": "107431", "bsz": "256", "num_updates": "93400", "lr": "0.000192348", "gnorm": "0.794", "train_wall": "541", "gb_free": "6.8", "wall": "70374"}
[2023-04-01 12:19:20,553][train_inner][INFO] - {"epoch": 86, "update": 85.793, "loss": "3.538", "ppl": "11.62", "wps": "34850.8", "ups": "0.32", "wpb": "107411", "bsz": "256", "num_updates": "93600", "lr": "0.00019113", "gnorm": "0.782", "train_wall": "554", "gb_free": "6.8", "wall": "70991"}
[2023-04-01 12:29:40,671][train_inner][INFO] - {"epoch": 86, "update": 85.976, "loss": "3.557", "ppl": "11.77", "wps": "34626.8", "ups": "0.32", "wpb": "107363", "bsz": "256", "num_updates": "93800", "lr": "0.000189913", "gnorm": "0.787", "train_wall": "545", "gb_free": "6.8", "wall": "71611"}
[2023-04-01 12:31:01,307][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 12:31:01,309][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 12:31:03,664][valid][INFO] - {"epoch": 86, "valid_loss": "4.37", "valid_ppl": "20.68", "valid_wps": "105194", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "93826", "valid_best_loss": "4.132"}
[2023-04-01 12:31:03,669][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 86 @ 93826 updates
[2023-04-01 12:31:03,670][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 12:31:05,072][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 12:31:05,109][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 86 @ 93826 updates, score 4.37) (writing took 1.4400553220039 seconds)
[2023-04-01 12:31:05,110][fairseq_cli.train][INFO] - end of epoch 86 (average epoch stats below)
[2023-04-01 12:31:05,112][train][INFO] - {"epoch": 86, "train_loss": "3.509", "train_ppl": "11.38", "train_wps": "35091.8", "train_ups": "0.33", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "93826", "train_lr": "0.000189755", "train_gnorm": "0.787", "train_train_wall": "2962", "train_gb_free": "6.8", "train_wall": "71695"}
[2023-04-01 12:31:05,115][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 12:31:05,164][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 12:31:05,167][fairseq.trainer][INFO] - begin training epoch 87
[2023-04-01 12:31:05,169][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 12:40:02,145][train_inner][INFO] - {"epoch": 87, "update": 86.159, "loss": "3.45", "ppl": "10.93", "wps": "34493.7", "ups": "0.32", "wpb": "107183", "bsz": "255.8", "num_updates": "94000", "lr": "0.000188696", "gnorm": "0.787", "train_wall": "537", "gb_free": "6.8", "wall": "72232"}
[2023-04-01 12:50:30,298][train_inner][INFO] - {"epoch": 87, "update": 86.343, "loss": "3.464", "ppl": "11.04", "wps": "34259.9", "ups": "0.32", "wpb": "107602", "bsz": "256", "num_updates": "94200", "lr": "0.000187478", "gnorm": "0.787", "train_wall": "552", "gb_free": "6.8", "wall": "72861"}
[2023-04-01 13:00:48,069][train_inner][INFO] - {"epoch": 87, "update": 86.526, "loss": "3.496", "ppl": "11.28", "wps": "34615.6", "ups": "0.32", "wpb": "106922", "bsz": "256", "num_updates": "94400", "lr": "0.000186261", "gnorm": "0.783", "train_wall": "542", "gb_free": "6.8", "wall": "73478"}
[2023-04-01 13:11:14,477][train_inner][INFO] - {"epoch": 87, "update": 86.709, "loss": "3.512", "ppl": "11.41", "wps": "34211.7", "ups": "0.32", "wpb": "107152", "bsz": "256", "num_updates": "94600", "lr": "0.000185043", "gnorm": "0.795", "train_wall": "556", "gb_free": "6.8", "wall": "74105"}
[2023-04-01 13:21:30,685][train_inner][INFO] - {"epoch": 87, "update": 86.893, "loss": "3.532", "ppl": "11.56", "wps": "34790.8", "ups": "0.32", "wpb": "107190", "bsz": "256", "num_updates": "94800", "lr": "0.000183826", "gnorm": "0.787", "train_wall": "552", "gb_free": "6.8", "wall": "74721"}
[2023-04-01 13:27:29,620][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 13:27:29,622][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 13:27:31,990][valid][INFO] - {"epoch": 87, "valid_loss": "4.386", "valid_ppl": "20.91", "valid_wps": "105157", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "94917", "valid_best_loss": "4.132"}
[2023-04-01 13:27:31,992][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 87 @ 94917 updates
[2023-04-01 13:27:31,993][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 13:27:33,252][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 13:27:33,280][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 87 @ 94917 updates, score 4.386) (writing took 1.2879509100021096 seconds)
[2023-04-01 13:27:33,280][fairseq_cli.train][INFO] - end of epoch 87 (average epoch stats below)
[2023-04-01 13:27:33,281][train][INFO] - {"epoch": 87, "train_loss": "3.494", "train_ppl": "11.27", "train_wps": "34520.7", "train_ups": "0.32", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "94917", "train_lr": "0.000183114", "train_gnorm": "0.788", "train_train_wall": "2992", "train_gb_free": "6.8", "train_wall": "75084"}
[2023-04-01 13:27:33,283][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 13:27:33,326][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 13:27:33,332][fairseq.trainer][INFO] - begin training epoch 88
[2023-04-01 13:27:33,333][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 13:31:51,041][train_inner][INFO] - {"epoch": 88, "update": 87.076, "loss": "3.486", "ppl": "11.21", "wps": "34523.6", "ups": "0.32", "wpb": "107083", "bsz": "255.8", "num_updates": "95000", "lr": "0.000182609", "gnorm": "0.79", "train_wall": "555", "gb_free": "6.8", "wall": "75341"}
[2023-04-01 13:41:40,489][train_inner][INFO] - {"epoch": 88, "update": 87.259, "loss": "3.441", "ppl": "10.86", "wps": "36346.4", "ups": "0.34", "wpb": "107122", "bsz": "256", "num_updates": "95200", "lr": "0.000181391", "gnorm": "0.787", "train_wall": "532", "gb_free": "6.8", "wall": "75931"}
[2023-04-01 13:49:12,783][train_inner][INFO] - {"epoch": 88, "update": 87.443, "loss": "3.468", "ppl": "11.07", "wps": "47392.7", "ups": "0.44", "wpb": "107176", "bsz": "256", "num_updates": "95400", "lr": "0.000180174", "gnorm": "0.794", "train_wall": "403", "gb_free": "6.8", "wall": "76383"}
[2023-04-01 13:59:20,651][train_inner][INFO] - {"epoch": 88, "update": 87.626, "loss": "3.491", "ppl": "11.25", "wps": "35306.2", "ups": "0.33", "wpb": "107307", "bsz": "256", "num_updates": "95600", "lr": "0.000178957", "gnorm": "0.796", "train_wall": "548", "gb_free": "6.8", "wall": "76991"}
[2023-04-01 14:08:36,265][train_inner][INFO] - {"epoch": 88, "update": 87.809, "loss": "3.51", "ppl": "11.39", "wps": "38579.3", "ups": "0.36", "wpb": "107175", "bsz": "256", "num_updates": "95800", "lr": "0.000177739", "gnorm": "0.789", "train_wall": "502", "gb_free": "6.8", "wall": "77547"}
[2023-04-01 14:17:51,054][train_inner][INFO] - {"epoch": 88, "update": 87.993, "loss": "3.522", "ppl": "11.48", "wps": "38691.9", "ups": "0.36", "wpb": "107329", "bsz": "256", "num_updates": "96000", "lr": "0.000176522", "gnorm": "0.789", "train_wall": "497", "gb_free": "6.8", "wall": "78101"}
[2023-04-01 14:18:15,245][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 14:18:15,253][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 14:18:17,679][valid][INFO] - {"epoch": 88, "valid_loss": "4.4", "valid_ppl": "21.12", "valid_wps": "102947", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "96008", "valid_best_loss": "4.132"}
[2023-04-01 14:18:17,683][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 88 @ 96008 updates
[2023-04-01 14:18:17,684][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 14:18:20,064][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 14:18:20,092][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 88 @ 96008 updates, score 4.4) (writing took 2.4092721959896153 seconds)
[2023-04-01 14:18:20,094][fairseq_cli.train][INFO] - end of epoch 88 (average epoch stats below)
[2023-04-01 14:18:20,095][train][INFO] - {"epoch": 88, "train_loss": "3.481", "train_ppl": "11.16", "train_wps": "38388.3", "train_ups": "0.36", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "96008", "train_lr": "0.000176473", "train_gnorm": "0.791", "train_train_wall": "2736", "train_gb_free": "6.8", "train_wall": "78130"}
[2023-04-01 14:18:20,099][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 14:18:20,151][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 14:18:20,155][fairseq.trainer][INFO] - begin training epoch 89
[2023-04-01 14:18:20,155][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 14:28:20,485][train_inner][INFO] - {"epoch": 89, "update": 88.176, "loss": "3.414", "ppl": "10.66", "wps": "33995.1", "ups": "0.32", "wpb": "106988", "bsz": "255.8", "num_updates": "96200", "lr": "0.000175304", "gnorm": "0.793", "train_wall": "552", "gb_free": "6.8", "wall": "78731"}
[2023-04-01 14:38:57,893][train_inner][INFO] - {"epoch": 89, "update": 88.359, "loss": "3.447", "ppl": "10.9", "wps": "33694.7", "ups": "0.31", "wpb": "107386", "bsz": "256", "num_updates": "96400", "lr": "0.000174087", "gnorm": "0.795", "train_wall": "567", "gb_free": "6.8", "wall": "79368"}
[2023-04-01 14:49:19,654][train_inner][INFO] - {"epoch": 89, "update": 88.543, "loss": "3.473", "ppl": "11.1", "wps": "34398.9", "ups": "0.32", "wpb": "106938", "bsz": "256", "num_updates": "96600", "lr": "0.00017287", "gnorm": "0.793", "train_wall": "545", "gb_free": "6.8", "wall": "79990"}
[2023-04-01 14:59:28,443][train_inner][INFO] - {"epoch": 89, "update": 88.726, "loss": "3.488", "ppl": "11.22", "wps": "35308.3", "ups": "0.33", "wpb": "107476", "bsz": "256", "num_updates": "96800", "lr": "0.000171652", "gnorm": "0.789", "train_wall": "544", "gb_free": "6.8", "wall": "80599"}
[2023-04-01 15:09:37,700][train_inner][INFO] - {"epoch": 89, "update": 88.909, "loss": "3.496", "ppl": "11.28", "wps": "35221.5", "ups": "0.33", "wpb": "107294", "bsz": "256", "num_updates": "97000", "lr": "0.000170435", "gnorm": "0.792", "train_wall": "541", "gb_free": "6.8", "wall": "81208"}
[2023-04-01 15:14:49,696][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 15:14:49,698][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 15:14:52,050][valid][INFO] - {"epoch": 89, "valid_loss": "4.403", "valid_ppl": "21.16", "valid_wps": "105445", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "97099", "valid_best_loss": "4.132"}
[2023-04-01 15:14:52,051][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 89 @ 97099 updates
[2023-04-01 15:14:52,052][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 15:14:54,201][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 15:14:54,233][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 89 @ 97099 updates, score 4.403) (writing took 2.181967620999785 seconds)
[2023-04-01 15:14:54,233][fairseq_cli.train][INFO] - end of epoch 89 (average epoch stats below)
[2023-04-01 15:14:54,234][train][INFO] - {"epoch": 89, "train_loss": "3.467", "train_ppl": "11.06", "train_wps": "34460", "train_ups": "0.32", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "97099", "train_lr": "0.000169832", "train_gnorm": "0.792", "train_train_wall": "3009", "train_gb_free": "6.8", "train_wall": "81524"}
[2023-04-01 15:14:54,236][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 15:14:54,270][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 15:14:54,273][fairseq.trainer][INFO] - begin training epoch 90
[2023-04-01 15:14:54,274][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 15:20:12,835][train_inner][INFO] - {"epoch": 90, "update": 89.093, "loss": "3.447", "ppl": "10.91", "wps": "33690.8", "ups": "0.31", "wpb": "106990", "bsz": "255.8", "num_updates": "97200", "lr": "0.000169217", "gnorm": "0.785", "train_wall": "566", "gb_free": "6.8", "wall": "81843"}
[2023-04-01 15:30:43,900][train_inner][INFO] - {"epoch": 90, "update": 89.276, "loss": "3.418", "ppl": "10.69", "wps": "33972.9", "ups": "0.32", "wpb": "107196", "bsz": "256", "num_updates": "97400", "lr": "0.000168", "gnorm": "0.792", "train_wall": "566", "gb_free": "6.8", "wall": "82474"}
[2023-04-01 15:41:09,193][train_inner][INFO] - {"epoch": 90, "update": 89.459, "loss": "3.443", "ppl": "10.88", "wps": "34333.8", "ups": "0.32", "wpb": "107343", "bsz": "256", "num_updates": "97600", "lr": "0.000166783", "gnorm": "0.79", "train_wall": "563", "gb_free": "6.8", "wall": "83099"}
[2023-04-01 15:51:46,433][train_inner][INFO] - {"epoch": 90, "update": 89.643, "loss": "3.465", "ppl": "11.04", "wps": "33623.5", "ups": "0.31", "wpb": "107131", "bsz": "256", "num_updates": "97800", "lr": "0.000165565", "gnorm": "0.793", "train_wall": "566", "gb_free": "6.8", "wall": "83737"}
[2023-04-01 16:02:24,651][train_inner][INFO] - {"epoch": 90, "update": 89.826, "loss": "3.484", "ppl": "11.19", "wps": "33591.6", "ups": "0.31", "wpb": "107194", "bsz": "256", "num_updates": "98000", "lr": "0.000164348", "gnorm": "0.798", "train_wall": "568", "gb_free": "6.8", "wall": "84375"}
[2023-04-01 16:12:11,919][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 16:12:11,920][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 16:12:14,436][valid][INFO] - {"epoch": 90, "valid_loss": "4.413", "valid_ppl": "21.3", "valid_wps": "98373", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "98190", "valid_best_loss": "4.132"}
[2023-04-01 16:12:14,444][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 90 @ 98190 updates
[2023-04-01 16:12:14,445][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 16:12:15,870][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 16:12:15,910][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 90 @ 98190 updates, score 4.413) (writing took 1.4654203440004494 seconds)
[2023-04-01 16:12:15,910][fairseq_cli.train][INFO] - end of epoch 90 (average epoch stats below)
[2023-04-01 16:12:15,912][train][INFO] - {"epoch": 90, "train_loss": "3.455", "train_ppl": "10.96", "train_wps": "33984", "train_ups": "0.32", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "98190", "train_lr": "0.000163191", "train_gnorm": "0.792", "train_train_wall": "3072", "train_gb_free": "6.8", "train_wall": "84966"}
[2023-04-01 16:12:15,915][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 16:12:15,963][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 16:12:15,968][fairseq.trainer][INFO] - begin training epoch 91
[2023-04-01 16:12:15,969][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 16:12:46,654][train_inner][INFO] - {"epoch": 91, "update": 90.009, "loss": "3.493", "ppl": "11.26", "wps": "34496.6", "ups": "0.32", "wpb": "107285", "bsz": "255.8", "num_updates": "98200", "lr": "0.00016313", "gnorm": "0.794", "train_wall": "552", "gb_free": "6.8", "wall": "84997"}
[2023-04-01 16:22:49,282][train_inner][INFO] - {"epoch": 91, "update": 90.192, "loss": "3.394", "ppl": "10.51", "wps": "35524.5", "ups": "0.33", "wpb": "107040", "bsz": "256", "num_updates": "98400", "lr": "0.000161913", "gnorm": "0.793", "train_wall": "535", "gb_free": "6.8", "wall": "85600"}
[2023-04-01 16:33:01,506][train_inner][INFO] - {"epoch": 91, "update": 90.376, "loss": "3.421", "ppl": "10.71", "wps": "35050", "ups": "0.33", "wpb": "107291", "bsz": "256", "num_updates": "98600", "lr": "0.000160696", "gnorm": "0.797", "train_wall": "547", "gb_free": "6.8", "wall": "86212"}
[2023-04-01 16:43:11,644][train_inner][INFO] - {"epoch": 91, "update": 90.559, "loss": "3.439", "ppl": "10.84", "wps": "35195.5", "ups": "0.33", "wpb": "107370", "bsz": "256", "num_updates": "98800", "lr": "0.000159478", "gnorm": "0.795", "train_wall": "546", "gb_free": "6.8", "wall": "86822"}
[2023-04-01 16:53:16,672][train_inner][INFO] - {"epoch": 91, "update": 90.742, "loss": "3.458", "ppl": "10.99", "wps": "35424.6", "ups": "0.33", "wpb": "107163", "bsz": "256", "num_updates": "99000", "lr": "0.000158261", "gnorm": "0.796", "train_wall": "541", "gb_free": "6.8", "wall": "87427"}
[2023-04-01 17:00:48,922][train_inner][INFO] - {"epoch": 91, "update": 90.926, "loss": "3.482", "ppl": "11.18", "wps": "47434.6", "ups": "0.44", "wpb": "107260", "bsz": "256", "num_updates": "99200", "lr": "0.000157043", "gnorm": "0.793", "train_wall": "406", "gb_free": "6.8", "wall": "87879"}
[2023-04-01 17:03:49,327][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 17:03:49,328][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 17:03:51,056][valid][INFO] - {"epoch": 91, "valid_loss": "4.414", "valid_ppl": "21.31", "valid_wps": "143289", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "99281", "valid_best_loss": "4.132"}
[2023-04-01 17:03:51,057][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 91 @ 99281 updates
[2023-04-01 17:03:51,058][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 17:03:51,897][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 17:03:51,907][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 91 @ 99281 updates, score 4.414) (writing took 0.8491862680093618 seconds)
[2023-04-01 17:03:51,907][fairseq_cli.train][INFO] - end of epoch 91 (average epoch stats below)
[2023-04-01 17:03:51,907][train][INFO] - {"epoch": 91, "train_loss": "3.442", "train_ppl": "10.87", "train_wps": "37778.5", "train_ups": "0.35", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "99281", "train_lr": "0.00015655", "train_gnorm": "0.795", "train_train_wall": "2763", "train_gb_free": "6.8", "train_wall": "88062"}
[2023-04-01 17:03:51,909][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 17:03:51,943][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 17:03:51,945][fairseq.trainer][INFO] - begin training epoch 92
[2023-04-01 17:03:51,945][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 17:08:17,701][train_inner][INFO] - {"epoch": 92, "update": 91.109, "loss": "3.42", "ppl": "10.71", "wps": "47719.8", "ups": "0.45", "wpb": "107078", "bsz": "255.8", "num_updates": "99400", "lr": "0.000155826", "gnorm": "0.797", "train_wall": "400", "gb_free": "6.8", "wall": "88328"}
[2023-04-01 17:15:43,349][train_inner][INFO] - {"epoch": 92, "update": 91.292, "loss": "3.398", "ppl": "10.54", "wps": "48026.3", "ups": "0.45", "wpb": "107014", "bsz": "256", "num_updates": "99600", "lr": "0.000154609", "gnorm": "0.791", "train_wall": "400", "gb_free": "6.8", "wall": "88774"}
[2023-04-01 17:23:09,458][train_inner][INFO] - {"epoch": 92, "update": 91.476, "loss": "3.427", "ppl": "10.76", "wps": "48047.2", "ups": "0.45", "wpb": "107171", "bsz": "256", "num_updates": "99800", "lr": "0.000153391", "gnorm": "0.807", "train_wall": "400", "gb_free": "6.8", "wall": "89220"}
[2023-04-01 17:30:36,394][train_inner][INFO] - {"epoch": 92, "update": 91.659, "loss": "3.44", "ppl": "10.86", "wps": "48073.1", "ups": "0.45", "wpb": "107428", "bsz": "256", "num_updates": "100000", "lr": "0.000152174", "gnorm": "0.8", "train_wall": "401", "gb_free": "6.8", "wall": "89667"}
[2023-04-01 17:38:02,665][train_inner][INFO] - {"epoch": 92, "update": 91.842, "loss": "3.46", "ppl": "11.01", "wps": "48045.3", "ups": "0.45", "wpb": "107206", "bsz": "256", "num_updates": "100200", "lr": "0.000150957", "gnorm": "0.795", "train_wall": "400", "gb_free": "6.8", "wall": "90113"}
[2023-04-01 17:44:26,251][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 17:44:26,252][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 17:44:28,001][valid][INFO] - {"epoch": 92, "valid_loss": "4.42", "valid_ppl": "21.41", "valid_wps": "141526", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "100372", "valid_best_loss": "4.132"}
[2023-04-01 17:44:28,002][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 92 @ 100372 updates
[2023-04-01 17:44:28,003][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 17:44:29,776][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 17:44:29,800][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 92 @ 100372 updates, score 4.42) (writing took 1.7983001499960665 seconds)
[2023-04-01 17:44:29,801][fairseq_cli.train][INFO] - end of epoch 92 (average epoch stats below)
[2023-04-01 17:44:29,801][train][INFO] - {"epoch": 92, "train_loss": "3.43", "train_ppl": "10.78", "train_wps": "47976.7", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "100372", "train_lr": "0.00014991", "train_gnorm": "0.797", "train_train_wall": "2184", "train_gb_free": "6.8", "train_wall": "90500"}
[2023-04-01 17:44:29,803][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 17:44:29,836][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 17:44:29,838][fairseq.trainer][INFO] - begin training epoch 93
[2023-04-01 17:44:29,839][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 17:45:32,577][train_inner][INFO] - {"epoch": 93, "update": 92.026, "loss": "3.451", "ppl": "10.94", "wps": "47676.1", "ups": "0.44", "wpb": "107250", "bsz": "255.8", "num_updates": "100400", "lr": "0.000149739", "gnorm": "0.798", "train_wall": "400", "gb_free": "6.8", "wall": "90563"}
[2023-04-01 17:52:58,303][train_inner][INFO] - {"epoch": 93, "update": 92.209, "loss": "3.377", "ppl": "10.39", "wps": "48020.3", "ups": "0.45", "wpb": "107019", "bsz": "256", "num_updates": "100600", "lr": "0.000148522", "gnorm": "0.798", "train_wall": "400", "gb_free": "6.8", "wall": "91009"}
[2023-04-01 18:00:24,914][train_inner][INFO] - {"epoch": 93, "update": 92.392, "loss": "3.398", "ppl": "10.54", "wps": "48055.3", "ups": "0.45", "wpb": "107310", "bsz": "256", "num_updates": "100800", "lr": "0.000147304", "gnorm": "0.798", "train_wall": "401", "gb_free": "6.8", "wall": "91455"}
[2023-04-01 18:07:51,027][train_inner][INFO] - {"epoch": 93, "update": 92.576, "loss": "3.417", "ppl": "10.68", "wps": "48069.5", "ups": "0.45", "wpb": "107222", "bsz": "256", "num_updates": "101000", "lr": "0.000146087", "gnorm": "0.798", "train_wall": "400", "gb_free": "6.8", "wall": "91901"}
[2023-04-01 18:15:17,084][train_inner][INFO] - {"epoch": 93, "update": 92.759, "loss": "3.436", "ppl": "10.82", "wps": "48058", "ups": "0.45", "wpb": "107183", "bsz": "256", "num_updates": "101200", "lr": "0.00014487", "gnorm": "0.799", "train_wall": "400", "gb_free": "6.8", "wall": "92347"}
[2023-04-01 18:22:43,770][train_inner][INFO] - {"epoch": 93, "update": 92.942, "loss": "3.457", "ppl": "10.98", "wps": "48113.7", "ups": "0.45", "wpb": "107458", "bsz": "256", "num_updates": "101400", "lr": "0.000143652", "gnorm": "0.799", "train_wall": "401", "gb_free": "6.8", "wall": "92794"}
[2023-04-01 18:25:03,717][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 18:25:03,717][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 18:25:05,447][valid][INFO] - {"epoch": 93, "valid_loss": "4.425", "valid_ppl": "21.48", "valid_wps": "142958", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "101463", "valid_best_loss": "4.132"}
[2023-04-01 18:25:05,455][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 93 @ 101463 updates
[2023-04-01 18:25:05,456][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 18:25:06,799][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 18:25:06,822][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 93 @ 101463 updates, score 4.425) (writing took 1.3667635830061045 seconds)
[2023-04-01 18:25:06,822][fairseq_cli.train][INFO] - end of epoch 93 (average epoch stats below)
[2023-04-01 18:25:06,823][train][INFO] - {"epoch": 93, "train_loss": "3.418", "train_ppl": "10.69", "train_wps": "47993.8", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "101463", "train_lr": "0.000143269", "train_gnorm": "0.799", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "92937"}
[2023-04-01 18:25:06,824][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 18:25:06,857][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 18:25:06,859][fairseq.trainer][INFO] - begin training epoch 94
[2023-04-01 18:25:06,859][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 18:30:13,092][train_inner][INFO] - {"epoch": 94, "update": 93.126, "loss": "3.387", "ppl": "10.46", "wps": "47709.9", "ups": "0.45", "wpb": "107186", "bsz": "255.8", "num_updates": "101600", "lr": "0.000142435", "gnorm": "0.799", "train_wall": "400", "gb_free": "6.8", "wall": "93243"}
[2023-04-01 18:37:40,227][train_inner][INFO] - {"epoch": 94, "update": 93.309, "loss": "3.378", "ppl": "10.4", "wps": "48115.9", "ups": "0.45", "wpb": "107571", "bsz": "256", "num_updates": "101800", "lr": "0.000141217", "gnorm": "0.797", "train_wall": "401", "gb_free": "6.8", "wall": "93690"}
[2023-04-01 18:45:06,256][train_inner][INFO] - {"epoch": 94, "update": 93.492, "loss": "3.402", "ppl": "10.57", "wps": "48041.9", "ups": "0.45", "wpb": "107140", "bsz": "256", "num_updates": "102000", "lr": "0.00014", "gnorm": "0.798", "train_wall": "400", "gb_free": "6.8", "wall": "94137"}
[2023-04-01 18:52:31,883][train_inner][INFO] - {"epoch": 94, "update": 93.676, "loss": "3.42", "ppl": "10.71", "wps": "48034", "ups": "0.45", "wpb": "107026", "bsz": "256", "num_updates": "102200", "lr": "0.000138783", "gnorm": "0.801", "train_wall": "400", "gb_free": "6.8", "wall": "94582"}
[2023-04-01 18:59:57,735][train_inner][INFO] - {"epoch": 94, "update": 93.859, "loss": "3.434", "ppl": "10.81", "wps": "48057.7", "ups": "0.45", "wpb": "107133", "bsz": "256", "num_updates": "102400", "lr": "0.000137565", "gnorm": "0.803", "train_wall": "400", "gb_free": "6.8", "wall": "95028"}
[2023-04-01 19:05:40,614][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 19:05:40,615][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 19:05:42,366][valid][INFO] - {"epoch": 94, "valid_loss": "4.435", "valid_ppl": "21.63", "valid_wps": "141516", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "102554", "valid_best_loss": "4.132"}
[2023-04-01 19:05:42,367][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 94 @ 102554 updates
[2023-04-01 19:05:42,368][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 19:05:43,286][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 19:05:43,310][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 94 @ 102554 updates, score 4.435) (writing took 0.9435769319970859 seconds)
[2023-04-01 19:05:43,311][fairseq_cli.train][INFO] - end of epoch 94 (average epoch stats below)
[2023-04-01 19:05:43,311][train][INFO] - {"epoch": 94, "train_loss": "3.407", "train_ppl": "10.61", "train_wps": "48004.3", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "102554", "train_lr": "0.000136628", "train_gnorm": "0.8", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "95374"}
[2023-04-01 19:05:43,313][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 19:05:43,346][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 19:05:43,349][fairseq.trainer][INFO] - begin training epoch 95
[2023-04-01 19:05:43,350][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 19:07:26,512][train_inner][INFO] - {"epoch": 95, "update": 94.042, "loss": "3.419", "ppl": "10.7", "wps": "47714.7", "ups": "0.45", "wpb": "107066", "bsz": "255.8", "num_updates": "102600", "lr": "0.000136348", "gnorm": "0.797", "train_wall": "400", "gb_free": "6.8", "wall": "95477"}
[2023-04-01 19:14:52,941][train_inner][INFO] - {"epoch": 95, "update": 94.225, "loss": "3.363", "ppl": "10.29", "wps": "48090", "ups": "0.45", "wpb": "107344", "bsz": "256", "num_updates": "102800", "lr": "0.00013513", "gnorm": "0.799", "train_wall": "401", "gb_free": "6.8", "wall": "95923"}
[2023-04-01 19:22:18,674][train_inner][INFO] - {"epoch": 95, "update": 94.409, "loss": "3.38", "ppl": "10.41", "wps": "48037.5", "ups": "0.45", "wpb": "107059", "bsz": "256", "num_updates": "103000", "lr": "0.000133913", "gnorm": "0.796", "train_wall": "400", "gb_free": "6.8", "wall": "96369"}
[2023-04-01 19:29:44,667][train_inner][INFO] - {"epoch": 95, "update": 94.592, "loss": "3.397", "ppl": "10.54", "wps": "48052.7", "ups": "0.45", "wpb": "107156", "bsz": "256", "num_updates": "103200", "lr": "0.000132696", "gnorm": "0.809", "train_wall": "400", "gb_free": "6.8", "wall": "96815"}
[2023-04-01 19:37:10,764][train_inner][INFO] - {"epoch": 95, "update": 94.775, "loss": "3.416", "ppl": "10.67", "wps": "48053.8", "ups": "0.45", "wpb": "107183", "bsz": "256", "num_updates": "103400", "lr": "0.000131478", "gnorm": "0.793", "train_wall": "400", "gb_free": "6.8", "wall": "97261"}
[2023-04-01 19:44:37,532][train_inner][INFO] - {"epoch": 95, "update": 94.959, "loss": "3.435", "ppl": "10.81", "wps": "48090.8", "ups": "0.45", "wpb": "107427", "bsz": "256", "num_updates": "103600", "lr": "0.000130261", "gnorm": "0.798", "train_wall": "401", "gb_free": "6.8", "wall": "97708"}
[2023-04-01 19:46:17,365][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 19:46:17,366][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 19:46:19,061][valid][INFO] - {"epoch": 95, "valid_loss": "4.435", "valid_ppl": "21.63", "valid_wps": "145806", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "103645", "valid_best_loss": "4.132"}
[2023-04-01 19:46:19,062][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 95 @ 103645 updates
[2023-04-01 19:46:19,063][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 19:46:20,511][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 19:46:20,536][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 95 @ 103645 updates, score 4.435) (writing took 1.4734262909914833 seconds)
[2023-04-01 19:46:20,536][fairseq_cli.train][INFO] - end of epoch 95 (average epoch stats below)
[2023-04-01 19:46:20,537][train][INFO] - {"epoch": 95, "train_loss": "3.397", "train_ppl": "10.53", "train_wps": "47989.8", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "103645", "train_lr": "0.000129987", "train_gnorm": "0.798", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "97811"}
[2023-04-01 19:46:20,538][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 19:46:20,571][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 19:46:20,573][fairseq.trainer][INFO] - begin training epoch 96
[2023-04-01 19:46:20,574][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 19:52:06,212][train_inner][INFO] - {"epoch": 96, "update": 95.142, "loss": "3.364", "ppl": "10.3", "wps": "47637", "ups": "0.45", "wpb": "106869", "bsz": "255.8", "num_updates": "103800", "lr": "0.000129043", "gnorm": "0.801", "train_wall": "399", "gb_free": "6.8", "wall": "98156"}
[2023-04-01 19:59:32,994][train_inner][INFO] - {"epoch": 96, "update": 95.325, "loss": "3.365", "ppl": "10.3", "wps": "48101", "ups": "0.45", "wpb": "107453", "bsz": "256", "num_updates": "104000", "lr": "0.000127826", "gnorm": "0.802", "train_wall": "401", "gb_free": "6.8", "wall": "98603"}
[2023-04-01 20:06:58,506][train_inner][INFO] - {"epoch": 96, "update": 95.509, "loss": "3.381", "ppl": "10.42", "wps": "48028.9", "ups": "0.45", "wpb": "106987", "bsz": "256", "num_updates": "104200", "lr": "0.000126609", "gnorm": "0.803", "train_wall": "400", "gb_free": "6.8", "wall": "99049"}
[2023-04-01 20:14:24,882][train_inner][INFO] - {"epoch": 96, "update": 95.692, "loss": "3.396", "ppl": "10.53", "wps": "48067.8", "ups": "0.45", "wpb": "107282", "bsz": "256", "num_updates": "104400", "lr": "0.000125391", "gnorm": "0.806", "train_wall": "400", "gb_free": "6.8", "wall": "99495"}
[2023-04-01 20:21:51,080][train_inner][INFO] - {"epoch": 96, "update": 95.875, "loss": "3.412", "ppl": "10.65", "wps": "48056.9", "ups": "0.45", "wpb": "107214", "bsz": "256", "num_updates": "104600", "lr": "0.000124174", "gnorm": "0.805", "train_wall": "400", "gb_free": "6.8", "wall": "99941"}
[2023-04-01 20:26:54,390][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 20:26:54,391][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 20:26:56,137][valid][INFO] - {"epoch": 96, "valid_loss": "4.45", "valid_ppl": "21.85", "valid_wps": "141737", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "104736", "valid_best_loss": "4.132"}
[2023-04-01 20:26:56,138][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 96 @ 104736 updates
[2023-04-01 20:26:56,139][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 20:26:58,465][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 20:26:58,494][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 96 @ 104736 updates, score 4.45) (writing took 2.355848134000553 seconds)
[2023-04-01 20:26:58,494][fairseq_cli.train][INFO] - end of epoch 96 (average epoch stats below)
[2023-04-01 20:26:58,494][train][INFO] - {"epoch": 96, "train_loss": "3.386", "train_ppl": "10.46", "train_wps": "47975.4", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "104736", "train_lr": "0.000123346", "train_gnorm": "0.803", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "100249"}
[2023-04-01 20:26:58,496][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 20:26:58,528][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 20:26:58,530][fairseq.trainer][INFO] - begin training epoch 97
[2023-04-01 20:26:58,531][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 20:29:21,499][train_inner][INFO] - {"epoch": 97, "update": 96.059, "loss": "3.388", "ppl": "10.47", "wps": "47594.4", "ups": "0.44", "wpb": "107187", "bsz": "255.8", "num_updates": "104800", "lr": "0.000122957", "gnorm": "0.8", "train_wall": "400", "gb_free": "6.8", "wall": "100392"}
[2023-04-01 20:36:47,691][train_inner][INFO] - {"epoch": 97, "update": 96.242, "loss": "3.344", "ppl": "10.15", "wps": "48062.1", "ups": "0.45", "wpb": "107223", "bsz": "256", "num_updates": "105000", "lr": "0.000121739", "gnorm": "0.801", "train_wall": "400", "gb_free": "6.8", "wall": "100838"}
[2023-04-01 20:44:13,839][train_inner][INFO] - {"epoch": 97, "update": 96.425, "loss": "3.366", "ppl": "10.31", "wps": "48065.8", "ups": "0.45", "wpb": "107222", "bsz": "256", "num_updates": "105200", "lr": "0.000120522", "gnorm": "0.808", "train_wall": "400", "gb_free": "6.8", "wall": "101284"}
[2023-04-01 20:51:40,207][train_inner][INFO] - {"epoch": 97, "update": 96.609, "loss": "3.384", "ppl": "10.44", "wps": "48069.2", "ups": "0.45", "wpb": "107283", "bsz": "256", "num_updates": "105400", "lr": "0.000119304", "gnorm": "0.8", "train_wall": "400", "gb_free": "6.8", "wall": "101730"}
[2023-04-01 20:59:06,059][train_inner][INFO] - {"epoch": 97, "update": 96.792, "loss": "3.396", "ppl": "10.52", "wps": "48053.9", "ups": "0.45", "wpb": "107125", "bsz": "256", "num_updates": "105600", "lr": "0.000118087", "gnorm": "0.804", "train_wall": "400", "gb_free": "6.8", "wall": "102176"}
[2023-04-01 21:06:32,367][train_inner][INFO] - {"epoch": 97, "update": 96.975, "loss": "3.406", "ppl": "10.6", "wps": "48075.5", "ups": "0.45", "wpb": "107282", "bsz": "256", "num_updates": "105800", "lr": "0.00011687", "gnorm": "0.811", "train_wall": "400", "gb_free": "6.8", "wall": "102623"}
[2023-04-01 21:07:32,406][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 21:07:32,407][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 21:07:34,101][valid][INFO] - {"epoch": 97, "valid_loss": "4.45", "valid_ppl": "21.86", "valid_wps": "145998", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "105827", "valid_best_loss": "4.132"}
[2023-04-01 21:07:34,102][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 97 @ 105827 updates
[2023-04-01 21:07:34,103][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 21:07:35,602][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 21:07:35,625][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 97 @ 105827 updates, score 4.45) (writing took 1.5230041920003714 seconds)
[2023-04-01 21:07:35,625][fairseq_cli.train][INFO] - end of epoch 97 (average epoch stats below)
[2023-04-01 21:07:35,626][train][INFO] - {"epoch": 97, "train_loss": "3.376", "train_ppl": "10.38", "train_wps": "47991.7", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "105827", "train_lr": "0.000116705", "train_gnorm": "0.804", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "102686"}
[2023-04-01 21:07:35,627][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 21:07:35,659][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 21:07:35,662][fairseq.trainer][INFO] - begin training epoch 98
[2023-04-01 21:07:35,662][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 21:14:01,791][train_inner][INFO] - {"epoch": 98, "update": 97.159, "loss": "3.337", "ppl": "10.11", "wps": "47702.6", "ups": "0.45", "wpb": "107193", "bsz": "255.8", "num_updates": "106000", "lr": "0.000115652", "gnorm": "0.804", "train_wall": "400", "gb_free": "6.8", "wall": "103072"}
[2023-04-01 21:21:27,834][train_inner][INFO] - {"epoch": 98, "update": 97.342, "loss": "3.345", "ppl": "10.16", "wps": "48061.7", "ups": "0.45", "wpb": "107188", "bsz": "256", "num_updates": "106200", "lr": "0.000114435", "gnorm": "0.805", "train_wall": "400", "gb_free": "6.8", "wall": "103518"}
[2023-04-01 21:28:54,301][train_inner][INFO] - {"epoch": 98, "update": 97.525, "loss": "3.362", "ppl": "10.28", "wps": "48067.4", "ups": "0.45", "wpb": "107302", "bsz": "256", "num_updates": "106400", "lr": "0.000113217", "gnorm": "0.802", "train_wall": "401", "gb_free": "6.8", "wall": "103965"}
[2023-04-01 21:36:20,452][train_inner][INFO] - {"epoch": 98, "update": 97.709, "loss": "3.38", "ppl": "10.41", "wps": "48069.1", "ups": "0.45", "wpb": "107230", "bsz": "256", "num_updates": "106600", "lr": "0.000112", "gnorm": "0.806", "train_wall": "400", "gb_free": "6.8", "wall": "104411"}
[2023-04-01 21:43:46,205][train_inner][INFO] - {"epoch": 98, "update": 97.892, "loss": "3.394", "ppl": "10.51", "wps": "48040.6", "ups": "0.45", "wpb": "107071", "bsz": "256", "num_updates": "106800", "lr": "0.000110783", "gnorm": "0.802", "train_wall": "400", "gb_free": "6.8", "wall": "104856"}
[2023-04-01 21:48:09,399][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 21:48:09,399][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 21:48:11,145][valid][INFO] - {"epoch": 98, "valid_loss": "4.455", "valid_ppl": "21.93", "valid_wps": "141834", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "106918", "valid_best_loss": "4.132"}
[2023-04-01 21:48:11,146][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 98 @ 106918 updates
[2023-04-01 21:48:11,147][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 21:48:12,515][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 21:48:12,540][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 98 @ 106918 updates, score 4.455) (writing took 1.3943338350072736 seconds)
[2023-04-01 21:48:12,541][fairseq_cli.train][INFO] - end of epoch 98 (average epoch stats below)
[2023-04-01 21:48:12,541][train][INFO] - {"epoch": 98, "train_loss": "3.366", "train_ppl": "10.31", "train_wps": "47995.9", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "106918", "train_lr": "0.000110064", "train_gnorm": "0.803", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "105123"}
[2023-04-01 21:48:12,543][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 21:48:12,575][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 21:48:12,577][fairseq.trainer][INFO] - begin training epoch 99
[2023-04-01 21:48:12,578][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 21:51:16,098][train_inner][INFO] - {"epoch": 99, "update": 98.075, "loss": "3.361", "ppl": "10.28", "wps": "47692.1", "ups": "0.44", "wpb": "107282", "bsz": "255.8", "num_updates": "107000", "lr": "0.000109565", "gnorm": "0.799", "train_wall": "401", "gb_free": "6.8", "wall": "105306"}
[2023-04-01 21:58:42,793][train_inner][INFO] - {"epoch": 99, "update": 98.258, "loss": "3.326", "ppl": "10.03", "wps": "48086.2", "ups": "0.45", "wpb": "107398", "bsz": "256", "num_updates": "107200", "lr": "0.000108348", "gnorm": "0.804", "train_wall": "401", "gb_free": "6.8", "wall": "105753"}
[2023-04-01 22:06:08,697][train_inner][INFO] - {"epoch": 99, "update": 98.442, "loss": "3.346", "ppl": "10.17", "wps": "48056.3", "ups": "0.45", "wpb": "107142", "bsz": "256", "num_updates": "107400", "lr": "0.00010713", "gnorm": "0.808", "train_wall": "400", "gb_free": "6.8", "wall": "106199"}
[2023-04-01 22:13:34,838][train_inner][INFO] - {"epoch": 99, "update": 98.625, "loss": "3.361", "ppl": "10.28", "wps": "48060.8", "ups": "0.45", "wpb": "107209", "bsz": "256", "num_updates": "107600", "lr": "0.000105913", "gnorm": "0.808", "train_wall": "400", "gb_free": "6.8", "wall": "106645"}
[2023-04-01 22:21:00,940][train_inner][INFO] - {"epoch": 99, "update": 98.808, "loss": "3.378", "ppl": "10.39", "wps": "48050.7", "ups": "0.45", "wpb": "107177", "bsz": "256", "num_updates": "107800", "lr": "0.000104696", "gnorm": "0.8", "train_wall": "400", "gb_free": "6.8", "wall": "107091"}
[2023-04-01 22:28:26,819][train_inner][INFO] - {"epoch": 99, "update": 98.992, "loss": "3.39", "ppl": "10.49", "wps": "48035.3", "ups": "0.45", "wpb": "107090", "bsz": "256", "num_updates": "108000", "lr": "0.000103478", "gnorm": "0.804", "train_wall": "400", "gb_free": "6.8", "wall": "107537"}
[2023-04-01 22:28:46,634][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 22:28:46,635][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 22:28:48,325][valid][INFO] - {"epoch": 99, "valid_loss": "4.456", "valid_ppl": "21.95", "valid_wps": "146261", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "108009", "valid_best_loss": "4.132"}
[2023-04-01 22:28:48,326][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 99 @ 108009 updates
[2023-04-01 22:28:48,327][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 22:28:50,197][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 22:28:50,222][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 99 @ 108009 updates, score 4.456) (writing took 1.895670786005212 seconds)
[2023-04-01 22:28:50,222][fairseq_cli.train][INFO] - end of epoch 99 (average epoch stats below)
[2023-04-01 22:28:50,223][train][INFO] - {"epoch": 99, "train_loss": "3.357", "train_ppl": "10.24", "train_wps": "47980.8", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "108009", "train_lr": "0.000103423", "train_gnorm": "0.804", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "107560"}
[2023-04-01 22:28:50,224][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 22:28:50,255][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 22:28:50,257][fairseq.trainer][INFO] - begin training epoch 100
[2023-04-01 22:28:50,258][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 22:35:56,694][train_inner][INFO] - {"epoch": 100, "update": 99.175, "loss": "3.313", "ppl": "9.94", "wps": "47673.7", "ups": "0.44", "wpb": "107236", "bsz": "255.8", "num_updates": "108200", "lr": "0.000102261", "gnorm": "0.809", "train_wall": "400", "gb_free": "6.8", "wall": "107987"}
[2023-04-01 22:43:22,349][train_inner][INFO] - {"epoch": 100, "update": 99.358, "loss": "3.327", "ppl": "10.03", "wps": "48019.3", "ups": "0.45", "wpb": "106999", "bsz": "256", "num_updates": "108400", "lr": "0.000101043", "gnorm": "0.808", "train_wall": "400", "gb_free": "6.8", "wall": "108433"}
[2023-04-01 22:50:48,605][train_inner][INFO] - {"epoch": 100, "update": 99.542, "loss": "3.346", "ppl": "10.17", "wps": "48067.7", "ups": "0.45", "wpb": "107251", "bsz": "256", "num_updates": "108600", "lr": "9.98261e-05", "gnorm": "0.809", "train_wall": "400", "gb_free": "6.8", "wall": "108879"}
[2023-04-01 22:58:14,910][train_inner][INFO] - {"epoch": 100, "update": 99.725, "loss": "3.36", "ppl": "10.27", "wps": "48076.8", "ups": "0.45", "wpb": "107285", "bsz": "256", "num_updates": "108800", "lr": "9.86087e-05", "gnorm": "0.808", "train_wall": "400", "gb_free": "6.8", "wall": "109325"}
[2023-04-01 23:05:41,438][train_inner][INFO] - {"epoch": 100, "update": 99.908, "loss": "3.376", "ppl": "10.38", "wps": "48050.5", "ups": "0.45", "wpb": "107279", "bsz": "256", "num_updates": "109000", "lr": "9.73913e-05", "gnorm": "0.802", "train_wall": "401", "gb_free": "6.8", "wall": "109772"}
[2023-04-01 23:09:24,165][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 23:09:24,166][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 23:09:25,913][valid][INFO] - {"epoch": 100, "valid_loss": "4.456", "valid_ppl": "21.95", "valid_wps": "141530", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "109100", "valid_best_loss": "4.132"}
[2023-04-01 23:09:25,914][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 100 @ 109100 updates
[2023-04-01 23:09:25,915][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 23:09:26,882][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 23:09:26,917][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 100 @ 109100 updates, score 4.456) (writing took 1.0033160239981953 seconds)
[2023-04-01 23:09:26,917][fairseq_cli.train][INFO] - end of epoch 100 (average epoch stats below)
[2023-04-01 23:09:26,918][train][INFO] - {"epoch": 100, "train_loss": "3.347", "train_ppl": "10.18", "train_wps": "48000.3", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "109100", "train_lr": "9.67826e-05", "train_gnorm": "0.807", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "109997"}
[2023-04-01 23:09:26,921][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 23:09:26,971][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 23:09:26,974][fairseq.trainer][INFO] - begin training epoch 101
[2023-04-01 23:09:26,975][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 23:13:11,056][train_inner][INFO] - {"epoch": 101, "update": 100.092, "loss": "3.337", "ppl": "10.1", "wps": "47754.4", "ups": "0.44", "wpb": "107356", "bsz": "255.8", "num_updates": "109200", "lr": "9.61739e-05", "gnorm": "0.805", "train_wall": "401", "gb_free": "6.8", "wall": "110221"}
[2023-04-01 23:20:36,677][train_inner][INFO] - {"epoch": 101, "update": 100.275, "loss": "3.311", "ppl": "9.92", "wps": "48021.5", "ups": "0.45", "wpb": "106997", "bsz": "256", "num_updates": "109400", "lr": "9.49565e-05", "gnorm": "0.807", "train_wall": "400", "gb_free": "6.8", "wall": "110667"}
[2023-04-01 23:28:02,291][train_inner][INFO] - {"epoch": 101, "update": 100.458, "loss": "3.33", "ppl": "10.06", "wps": "48037.7", "ups": "0.45", "wpb": "107031", "bsz": "256", "num_updates": "109600", "lr": "9.37391e-05", "gnorm": "0.805", "train_wall": "400", "gb_free": "6.8", "wall": "111113"}
[2023-04-01 23:35:29,230][train_inner][INFO] - {"epoch": 101, "update": 100.642, "loss": "3.348", "ppl": "10.18", "wps": "48080", "ups": "0.45", "wpb": "107444", "bsz": "256", "num_updates": "109800", "lr": "9.25217e-05", "gnorm": "0.809", "train_wall": "401", "gb_free": "6.8", "wall": "111559"}
[2023-04-01 23:42:54,483][train_inner][INFO] - {"epoch": 101, "update": 100.825, "loss": "3.357", "ppl": "10.24", "wps": "48035.4", "ups": "0.45", "wpb": "106940", "bsz": "256", "num_updates": "110000", "lr": "9.13043e-05", "gnorm": "0.803", "train_wall": "399", "gb_free": "6.8", "wall": "112005"}
[2023-04-01 23:50:00,967][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-01 23:50:00,968][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 23:50:02,721][valid][INFO] - {"epoch": 101, "valid_loss": "4.461", "valid_ppl": "22.03", "valid_wps": "141057", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "110191", "valid_best_loss": "4.132"}
[2023-04-01 23:50:02,722][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 101 @ 110191 updates
[2023-04-01 23:50:02,723][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 23:50:03,674][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-01 23:50:03,699][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 101 @ 110191 updates, score 4.461) (writing took 0.9768635140062543 seconds)
[2023-04-01 23:50:03,699][fairseq_cli.train][INFO] - end of epoch 101 (average epoch stats below)
[2023-04-01 23:50:03,699][train][INFO] - {"epoch": 101, "train_loss": "3.339", "train_ppl": "10.12", "train_wps": "47998.6", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "110191", "train_lr": "9.01417e-05", "train_gnorm": "0.805", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "112434"}
[2023-04-01 23:50:03,701][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-01 23:50:03,732][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-01 23:50:03,734][fairseq.trainer][INFO] - begin training epoch 102
[2023-04-01 23:50:03,735][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-01 23:50:24,035][train_inner][INFO] - {"epoch": 102, "update": 101.008, "loss": "3.366", "ppl": "10.31", "wps": "47757.1", "ups": "0.44", "wpb": "107346", "bsz": "255.8", "num_updates": "110200", "lr": "9.0087e-05", "gnorm": "0.799", "train_wall": "401", "gb_free": "6.8", "wall": "112454"}
[2023-04-01 23:57:51,096][train_inner][INFO] - {"epoch": 102, "update": 101.192, "loss": "3.289", "ppl": "9.78", "wps": "48095.7", "ups": "0.45", "wpb": "107509", "bsz": "256", "num_updates": "110400", "lr": "8.88696e-05", "gnorm": "0.804", "train_wall": "401", "gb_free": "6.8", "wall": "112901"}
[2023-04-02 00:05:16,288][train_inner][INFO] - {"epoch": 102, "update": 101.375, "loss": "3.314", "ppl": "9.94", "wps": "48021.3", "ups": "0.45", "wpb": "106894", "bsz": "256", "num_updates": "110600", "lr": "8.76522e-05", "gnorm": "0.81", "train_wall": "399", "gb_free": "6.8", "wall": "113347"}
[2023-04-02 00:12:42,281][train_inner][INFO] - {"epoch": 102, "update": 101.558, "loss": "3.332", "ppl": "10.07", "wps": "48036", "ups": "0.45", "wpb": "107118", "bsz": "256", "num_updates": "110800", "lr": "8.64348e-05", "gnorm": "0.806", "train_wall": "400", "gb_free": "6.8", "wall": "113793"}
[2023-04-02 00:20:08,799][train_inner][INFO] - {"epoch": 102, "update": 101.742, "loss": "3.343", "ppl": "10.15", "wps": "48069.2", "ups": "0.45", "wpb": "107319", "bsz": "256", "num_updates": "111000", "lr": "8.52174e-05", "gnorm": "0.805", "train_wall": "401", "gb_free": "6.8", "wall": "114239"}
[2023-04-02 00:27:34,828][train_inner][INFO] - {"epoch": 102, "update": 101.925, "loss": "3.358", "ppl": "10.25", "wps": "48043.5", "ups": "0.45", "wpb": "107144", "bsz": "256", "num_updates": "111200", "lr": "8.4e-05", "gnorm": "0.802", "train_wall": "400", "gb_free": "6.8", "wall": "114685"}
[2023-04-02 00:30:37,938][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 00:30:37,939][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 00:30:39,674][valid][INFO] - {"epoch": 102, "valid_loss": "4.466", "valid_ppl": "22.1", "valid_wps": "142764", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "111282", "valid_best_loss": "4.132"}
[2023-04-02 00:30:39,675][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 102 @ 111282 updates
[2023-04-02 00:30:39,676][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 00:30:40,609][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 00:30:40,634][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 102 @ 111282 updates, score 4.466) (writing took 0.9587903759966139 seconds)
[2023-04-02 00:30:40,634][fairseq_cli.train][INFO] - end of epoch 102 (average epoch stats below)
[2023-04-02 00:30:40,635][train][INFO] - {"epoch": 102, "train_loss": "3.329", "train_ppl": "10.05", "train_wps": "47995.5", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "111282", "train_lr": "8.35009e-05", "train_gnorm": "0.805", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "114871"}
[2023-04-02 00:30:40,637][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 00:30:40,676][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 00:30:40,679][fairseq.trainer][INFO] - begin training epoch 103
[2023-04-02 00:30:40,679][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 00:35:04,782][train_inner][INFO] - {"epoch": 103, "update": 102.108, "loss": "3.316", "ppl": "9.96", "wps": "47773.9", "ups": "0.44", "wpb": "107480", "bsz": "255.8", "num_updates": "111400", "lr": "8.27826e-05", "gnorm": "0.81", "train_wall": "401", "gb_free": "6.8", "wall": "115135"}
[2023-04-02 00:42:30,548][train_inner][INFO] - {"epoch": 103, "update": 102.291, "loss": "3.301", "ppl": "9.86", "wps": "48051.6", "ups": "0.45", "wpb": "107099", "bsz": "256", "num_updates": "111600", "lr": "8.15652e-05", "gnorm": "0.801", "train_wall": "400", "gb_free": "6.8", "wall": "115581"}
[2023-04-02 00:49:56,735][train_inner][INFO] - {"epoch": 103, "update": 102.475, "loss": "3.316", "ppl": "9.96", "wps": "48067.5", "ups": "0.45", "wpb": "107236", "bsz": "256", "num_updates": "111800", "lr": "8.03478e-05", "gnorm": "0.807", "train_wall": "400", "gb_free": "6.8", "wall": "116027"}
[2023-04-02 00:57:23,646][train_inner][INFO] - {"epoch": 103, "update": 102.658, "loss": "3.328", "ppl": "10.04", "wps": "48095", "ups": "0.45", "wpb": "107471", "bsz": "256", "num_updates": "112000", "lr": "7.91304e-05", "gnorm": "0.812", "train_wall": "401", "gb_free": "6.8", "wall": "116474"}
[2023-04-02 01:04:49,542][train_inner][INFO] - {"epoch": 103, "update": 102.841, "loss": "3.342", "ppl": "10.14", "wps": "48070.6", "ups": "0.45", "wpb": "107172", "bsz": "256", "num_updates": "112200", "lr": "7.7913e-05", "gnorm": "0.799", "train_wall": "400", "gb_free": "6.8", "wall": "116920"}
[2023-04-02 01:11:14,262][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 01:11:14,263][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 01:11:16,001][valid][INFO] - {"epoch": 103, "valid_loss": "4.473", "valid_ppl": "22.21", "valid_wps": "142450", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "112373", "valid_best_loss": "4.132"}
[2023-04-02 01:11:16,002][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 103 @ 112373 updates
[2023-04-02 01:11:16,003][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 01:11:17,974][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 01:11:17,999][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 103 @ 112373 updates, score 4.473) (writing took 1.9967729170020903 seconds)
[2023-04-02 01:11:17,999][fairseq_cli.train][INFO] - end of epoch 103 (average epoch stats below)
[2023-04-02 01:11:18,000][train][INFO] - {"epoch": 103, "train_loss": "3.321", "train_ppl": "10", "train_wps": "47987.1", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "112373", "train_lr": "7.686e-05", "train_gnorm": "0.806", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "117308"}
[2023-04-02 01:11:18,003][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 01:11:18,052][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 01:11:18,055][fairseq.trainer][INFO] - begin training epoch 104
[2023-04-02 01:11:18,056][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 01:12:18,316][train_inner][INFO] - {"epoch": 104, "update": 103.025, "loss": "3.332", "ppl": "10.07", "wps": "47597.6", "ups": "0.45", "wpb": "106803", "bsz": "255.8", "num_updates": "112400", "lr": "7.66957e-05", "gnorm": "0.81", "train_wall": "399", "gb_free": "6.8", "wall": "117369"}
[2023-04-02 01:19:44,087][train_inner][INFO] - {"epoch": 104, "update": 103.208, "loss": "3.288", "ppl": "9.77", "wps": "48063.5", "ups": "0.45", "wpb": "107126", "bsz": "256", "num_updates": "112600", "lr": "7.54783e-05", "gnorm": "0.805", "train_wall": "400", "gb_free": "6.8", "wall": "117814"}
[2023-04-02 01:27:09,980][train_inner][INFO] - {"epoch": 104, "update": 103.391, "loss": "3.297", "ppl": "9.83", "wps": "48030.5", "ups": "0.45", "wpb": "107082", "bsz": "256", "num_updates": "112800", "lr": "7.42609e-05", "gnorm": "0.807", "train_wall": "400", "gb_free": "6.8", "wall": "118260"}
[2023-04-02 01:34:37,025][train_inner][INFO] - {"epoch": 104, "update": 103.575, "loss": "3.316", "ppl": "9.96", "wps": "48094.9", "ups": "0.45", "wpb": "107503", "bsz": "256", "num_updates": "113000", "lr": "7.30435e-05", "gnorm": "0.807", "train_wall": "401", "gb_free": "6.8", "wall": "118707"}
[2023-04-02 01:42:03,652][train_inner][INFO] - {"epoch": 104, "update": 103.758, "loss": "3.323", "ppl": "10.01", "wps": "48069.3", "ups": "0.45", "wpb": "107345", "bsz": "256", "num_updates": "113200", "lr": "7.18261e-05", "gnorm": "0.804", "train_wall": "401", "gb_free": "6.8", "wall": "119154"}
[2023-04-02 01:49:29,478][train_inner][INFO] - {"epoch": 104, "update": 103.941, "loss": "3.339", "ppl": "10.12", "wps": "48044.1", "ups": "0.45", "wpb": "107096", "bsz": "256", "num_updates": "113400", "lr": "7.06087e-05", "gnorm": "0.809", "train_wall": "400", "gb_free": "6.8", "wall": "119600"}
[2023-04-02 01:51:51,929][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 01:51:51,930][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 01:51:53,675][valid][INFO] - {"epoch": 104, "valid_loss": "4.476", "valid_ppl": "22.25", "valid_wps": "141916", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "113464", "valid_best_loss": "4.132"}
[2023-04-02 01:51:53,676][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 104 @ 113464 updates
[2023-04-02 01:51:53,677][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 01:51:55,203][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 01:51:55,226][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 104 @ 113464 updates, score 4.476) (writing took 1.549966353995842 seconds)
[2023-04-02 01:51:55,226][fairseq_cli.train][INFO] - end of epoch 104 (average epoch stats below)
[2023-04-02 01:51:55,227][train][INFO] - {"epoch": 104, "train_loss": "3.313", "train_ppl": "9.94", "train_wps": "47989.8", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "113464", "train_lr": "7.02191e-05", "train_gnorm": "0.807", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "119745"}
[2023-04-02 01:51:55,228][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 01:51:55,261][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 01:51:55,263][fairseq.trainer][INFO] - begin training epoch 105
[2023-04-02 01:51:55,264][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 01:56:58,967][train_inner][INFO] - {"epoch": 105, "update": 104.125, "loss": "3.292", "ppl": "9.79", "wps": "47687.6", "ups": "0.44", "wpb": "107175", "bsz": "255.8", "num_updates": "113600", "lr": "6.93913e-05", "gnorm": "0.804", "train_wall": "400", "gb_free": "6.8", "wall": "120049"}
[2023-04-02 02:04:25,370][train_inner][INFO] - {"epoch": 105, "update": 104.308, "loss": "3.284", "ppl": "9.74", "wps": "48056.5", "ups": "0.45", "wpb": "107263", "bsz": "256", "num_updates": "113800", "lr": "6.81739e-05", "gnorm": "0.801", "train_wall": "400", "gb_free": "6.8", "wall": "120496"}
[2023-04-02 02:11:52,222][train_inner][INFO] - {"epoch": 105, "update": 104.491, "loss": "3.297", "ppl": "9.83", "wps": "48051.2", "ups": "0.45", "wpb": "107359", "bsz": "256", "num_updates": "114000", "lr": "6.69565e-05", "gnorm": "0.805", "train_wall": "401", "gb_free": "6.8", "wall": "120942"}
[2023-04-02 02:19:17,707][train_inner][INFO] - {"epoch": 105, "update": 104.675, "loss": "3.315", "ppl": "9.95", "wps": "48015.4", "ups": "0.45", "wpb": "106951", "bsz": "256", "num_updates": "114200", "lr": "6.57391e-05", "gnorm": "0.8", "train_wall": "400", "gb_free": "6.8", "wall": "121388"}
[2023-04-02 02:26:44,180][train_inner][INFO] - {"epoch": 105, "update": 104.858, "loss": "3.327", "ppl": "10.03", "wps": "48060", "ups": "0.45", "wpb": "107287", "bsz": "256", "num_updates": "114400", "lr": "6.45217e-05", "gnorm": "0.811", "train_wall": "401", "gb_free": "6.8", "wall": "121834"}
[2023-04-02 02:32:29,718][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 02:32:29,719][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 02:32:31,471][valid][INFO] - {"epoch": 105, "valid_loss": "4.475", "valid_ppl": "22.24", "valid_wps": "141009", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "114555", "valid_best_loss": "4.132"}
[2023-04-02 02:32:31,472][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 105 @ 114555 updates
[2023-04-02 02:32:31,473][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 02:32:32,418][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 02:32:32,440][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 105 @ 114555 updates, score 4.475) (writing took 0.9678846759925364 seconds)
[2023-04-02 02:32:32,440][fairseq_cli.train][INFO] - end of epoch 105 (average epoch stats below)
[2023-04-02 02:32:32,441][train][INFO] - {"epoch": 105, "train_loss": "3.305", "train_ppl": "9.88", "train_wps": "47990", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "114555", "train_lr": "6.35783e-05", "train_gnorm": "0.804", "train_train_wall": "2184", "train_gb_free": "6.8", "train_wall": "122183"}
[2023-04-02 02:32:32,442][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 02:32:32,474][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 02:32:32,476][fairseq.trainer][INFO] - begin training epoch 106
[2023-04-02 02:32:32,477][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 02:34:13,355][train_inner][INFO] - {"epoch": 106, "update": 105.041, "loss": "3.314", "ppl": "9.94", "wps": "47739.1", "ups": "0.45", "wpb": "107216", "bsz": "255.8", "num_updates": "114600", "lr": "6.33043e-05", "gnorm": "0.807", "train_wall": "400", "gb_free": "6.8", "wall": "122284"}
[2023-04-02 02:41:39,452][train_inner][INFO] - {"epoch": 106, "update": 105.225, "loss": "3.272", "ppl": "9.66", "wps": "48055.6", "ups": "0.45", "wpb": "107187", "bsz": "256", "num_updates": "114800", "lr": "6.2087e-05", "gnorm": "0.802", "train_wall": "400", "gb_free": "6.8", "wall": "122730"}
[2023-04-02 02:49:06,404][train_inner][INFO] - {"epoch": 106, "update": 105.408, "loss": "3.288", "ppl": "9.77", "wps": "48113.4", "ups": "0.45", "wpb": "107522", "bsz": "256", "num_updates": "115000", "lr": "6.08696e-05", "gnorm": "0.805", "train_wall": "401", "gb_free": "6.8", "wall": "123177"}
[2023-04-02 02:56:31,803][train_inner][INFO] - {"epoch": 106, "update": 105.591, "loss": "3.298", "ppl": "9.83", "wps": "48010.7", "ups": "0.45", "wpb": "106920", "bsz": "256", "num_updates": "115200", "lr": "5.96522e-05", "gnorm": "0.804", "train_wall": "399", "gb_free": "6.8", "wall": "123622"}
[2023-04-02 03:03:57,966][train_inner][INFO] - {"epoch": 106, "update": 105.775, "loss": "3.307", "ppl": "9.9", "wps": "48078", "ups": "0.45", "wpb": "107253", "bsz": "256", "num_updates": "115400", "lr": "5.84348e-05", "gnorm": "0.805", "train_wall": "400", "gb_free": "6.8", "wall": "124068"}
[2023-04-02 03:11:23,743][train_inner][INFO] - {"epoch": 106, "update": 105.958, "loss": "3.318", "ppl": "9.97", "wps": "48036.2", "ups": "0.45", "wpb": "107067", "bsz": "256", "num_updates": "115600", "lr": "5.72174e-05", "gnorm": "0.801", "train_wall": "400", "gb_free": "6.8", "wall": "124514"}
[2023-04-02 03:13:06,249][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 03:13:06,250][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 03:13:07,945][valid][INFO] - {"epoch": 106, "valid_loss": "4.481", "valid_ppl": "22.33", "valid_wps": "146000", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "115646", "valid_best_loss": "4.132"}
[2023-04-02 03:13:07,946][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 106 @ 115646 updates
[2023-04-02 03:13:07,947][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 03:13:08,863][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 03:13:08,885][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 106 @ 115646 updates, score 4.481) (writing took 0.9393339180096518 seconds)
[2023-04-02 03:13:08,886][fairseq_cli.train][INFO] - end of epoch 106 (average epoch stats below)
[2023-04-02 03:13:08,886][train][INFO] - {"epoch": 106, "train_loss": "3.297", "train_ppl": "9.83", "train_wps": "48005.2", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "115646", "train_lr": "5.69374e-05", "train_gnorm": "0.804", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "124619"}
[2023-04-02 03:13:08,888][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 03:13:08,919][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 03:13:08,922][fairseq.trainer][INFO] - begin training epoch 107
[2023-04-02 03:13:08,922][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 03:18:52,639][train_inner][INFO] - {"epoch": 107, "update": 106.141, "loss": "3.273", "ppl": "9.66", "wps": "47787.1", "ups": "0.45", "wpb": "107257", "bsz": "255.8", "num_updates": "115800", "lr": "5.6e-05", "gnorm": "0.799", "train_wall": "400", "gb_free": "6.8", "wall": "124963"}
[2023-04-02 03:26:18,479][train_inner][INFO] - {"epoch": 107, "update": 106.324, "loss": "3.273", "ppl": "9.66", "wps": "48046.7", "ups": "0.45", "wpb": "107104", "bsz": "256", "num_updates": "116000", "lr": "5.47826e-05", "gnorm": "0.798", "train_wall": "400", "gb_free": "6.8", "wall": "125409"}
[2023-04-02 03:33:44,364][train_inner][INFO] - {"epoch": 107, "update": 106.508, "loss": "3.289", "ppl": "9.77", "wps": "48065", "ups": "0.45", "wpb": "107157", "bsz": "256", "num_updates": "116200", "lr": "5.35652e-05", "gnorm": "0.806", "train_wall": "400", "gb_free": "6.8", "wall": "125855"}
[2023-04-02 03:41:10,529][train_inner][INFO] - {"epoch": 107, "update": 106.691, "loss": "3.297", "ppl": "9.83", "wps": "48056.3", "ups": "0.45", "wpb": "107205", "bsz": "256", "num_updates": "116400", "lr": "5.23478e-05", "gnorm": "0.804", "train_wall": "400", "gb_free": "6.8", "wall": "126301"}
[2023-04-02 03:48:36,887][train_inner][INFO] - {"epoch": 107, "update": 106.874, "loss": "3.307", "ppl": "9.9", "wps": "48064.4", "ups": "0.45", "wpb": "107270", "bsz": "256", "num_updates": "116600", "lr": "5.11304e-05", "gnorm": "0.801", "train_wall": "400", "gb_free": "6.8", "wall": "126747"}
[2023-04-02 03:53:42,501][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 03:53:42,501][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 03:53:44,244][valid][INFO] - {"epoch": 107, "valid_loss": "4.482", "valid_ppl": "22.35", "valid_wps": "141944", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "116737", "valid_best_loss": "4.132"}
[2023-04-02 03:53:44,245][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 107 @ 116737 updates
[2023-04-02 03:53:44,246][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 03:53:45,196][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 03:53:45,219][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 107 @ 116737 updates, score 4.482) (writing took 0.9731904680083971 seconds)
[2023-04-02 03:53:45,219][fairseq_cli.train][INFO] - end of epoch 107 (average epoch stats below)
[2023-04-02 03:53:45,219][train][INFO] - {"epoch": 107, "train_loss": "3.289", "train_ppl": "9.77", "train_wps": "48007.4", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "116737", "train_lr": "5.02965e-05", "train_gnorm": "0.802", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "127055"}
[2023-04-02 03:53:45,221][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 03:53:45,253][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 03:53:45,255][fairseq.trainer][INFO] - begin training epoch 108
[2023-04-02 03:53:45,256][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 03:56:06,277][train_inner][INFO] - {"epoch": 108, "update": 107.058, "loss": "3.291", "ppl": "9.79", "wps": "47753.2", "ups": "0.45", "wpb": "107299", "bsz": "255.8", "num_updates": "116800", "lr": "4.9913e-05", "gnorm": "0.801", "train_wall": "400", "gb_free": "6.8", "wall": "127197"}
[2023-04-02 04:03:32,672][train_inner][INFO] - {"epoch": 108, "update": 107.241, "loss": "3.265", "ppl": "9.61", "wps": "48053.9", "ups": "0.45", "wpb": "107255", "bsz": "256", "num_updates": "117000", "lr": "4.86957e-05", "gnorm": "0.802", "train_wall": "400", "gb_free": "6.8", "wall": "127643"}
[2023-04-02 04:10:59,424][train_inner][INFO] - {"epoch": 108, "update": 107.424, "loss": "3.272", "ppl": "9.66", "wps": "48066.2", "ups": "0.45", "wpb": "107368", "bsz": "256", "num_updates": "117200", "lr": "4.74783e-05", "gnorm": "0.801", "train_wall": "401", "gb_free": "6.8", "wall": "128090"}
[2023-04-02 04:18:26,040][train_inner][INFO] - {"epoch": 108, "update": 107.608, "loss": "3.281", "ppl": "9.72", "wps": "48096", "ups": "0.45", "wpb": "107402", "bsz": "256", "num_updates": "117400", "lr": "4.62609e-05", "gnorm": "0.804", "train_wall": "401", "gb_free": "6.8", "wall": "128536"}
[2023-04-02 04:25:51,903][train_inner][INFO] - {"epoch": 108, "update": 107.791, "loss": "3.298", "ppl": "9.83", "wps": "48067.7", "ups": "0.45", "wpb": "107158", "bsz": "256", "num_updates": "117600", "lr": "4.50435e-05", "gnorm": "0.807", "train_wall": "400", "gb_free": "6.8", "wall": "128982"}
[2023-04-02 04:33:17,405][train_inner][INFO] - {"epoch": 108, "update": 107.974, "loss": "3.301", "ppl": "9.86", "wps": "48019.2", "ups": "0.45", "wpb": "106963", "bsz": "256", "num_updates": "117800", "lr": "4.38261e-05", "gnorm": "0.808", "train_wall": "400", "gb_free": "6.8", "wall": "129428"}
[2023-04-02 04:34:19,386][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 04:34:19,386][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 04:34:21,077][valid][INFO] - {"epoch": 108, "valid_loss": "4.487", "valid_ppl": "22.43", "valid_wps": "146281", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "117828", "valid_best_loss": "4.132"}
[2023-04-02 04:34:21,078][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 108 @ 117828 updates
[2023-04-02 04:34:21,079][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 04:34:22,353][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 04:34:22,378][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 108 @ 117828 updates, score 4.487) (writing took 1.2996306669956539 seconds)
[2023-04-02 04:34:22,378][fairseq_cli.train][INFO] - end of epoch 108 (average epoch stats below)
[2023-04-02 04:34:22,378][train][INFO] - {"epoch": 108, "train_loss": "3.282", "train_ppl": "9.72", "train_wps": "47991.1", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "117828", "train_lr": "4.36557e-05", "train_gnorm": "0.804", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "129493"}
[2023-04-02 04:34:22,380][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 04:34:22,411][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 04:34:22,413][fairseq.trainer][INFO] - begin training epoch 109
[2023-04-02 04:34:22,413][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 04:40:45,358][train_inner][INFO] - {"epoch": 109, "update": 108.158, "loss": "3.259", "ppl": "9.57", "wps": "47666.8", "ups": "0.45", "wpb": "106762", "bsz": "255.8", "num_updates": "118000", "lr": "4.26087e-05", "gnorm": "0.807", "train_wall": "399", "gb_free": "6.8", "wall": "129876"}
[2023-04-02 04:48:11,679][train_inner][INFO] - {"epoch": 109, "update": 108.341, "loss": "3.27", "ppl": "9.65", "wps": "48073.2", "ups": "0.45", "wpb": "107280", "bsz": "256", "num_updates": "118200", "lr": "4.13913e-05", "gnorm": "0.801", "train_wall": "400", "gb_free": "6.8", "wall": "130322"}
[2023-04-02 04:55:38,459][train_inner][INFO] - {"epoch": 109, "update": 108.524, "loss": "3.273", "ppl": "9.66", "wps": "48086.5", "ups": "0.45", "wpb": "107421", "bsz": "256", "num_updates": "118400", "lr": "4.01739e-05", "gnorm": "0.795", "train_wall": "401", "gb_free": "6.8", "wall": "130769"}
[2023-04-02 05:03:04,666][train_inner][INFO] - {"epoch": 109, "update": 108.708, "loss": "3.28", "ppl": "9.71", "wps": "48057.7", "ups": "0.45", "wpb": "107218", "bsz": "256", "num_updates": "118600", "lr": "3.89565e-05", "gnorm": "0.801", "train_wall": "400", "gb_free": "6.8", "wall": "131215"}
[2023-04-02 05:10:31,009][train_inner][INFO] - {"epoch": 109, "update": 108.891, "loss": "3.282", "ppl": "9.73", "wps": "48077.7", "ups": "0.45", "wpb": "107296", "bsz": "256", "num_updates": "118800", "lr": "3.77391e-05", "gnorm": "0.805", "train_wall": "400", "gb_free": "6.8", "wall": "131661"}
[2023-04-02 05:14:56,016][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 05:14:56,017][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 05:14:57,742][valid][INFO] - {"epoch": 109, "valid_loss": "4.483", "valid_ppl": "22.36", "valid_wps": "143569", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "118919", "valid_best_loss": "4.132"}
[2023-04-02 05:14:57,743][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 109 @ 118919 updates
[2023-04-02 05:14:57,744][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 05:14:59,098][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 05:14:59,122][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 109 @ 118919 updates, score 4.483) (writing took 1.3791067769925576 seconds)
[2023-04-02 05:14:59,122][fairseq_cli.train][INFO] - end of epoch 109 (average epoch stats below)
[2023-04-02 05:14:59,123][train][INFO] - {"epoch": 109, "train_loss": "3.274", "train_ppl": "9.67", "train_wps": "47999.3", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "118919", "train_lr": "3.70148e-05", "train_gnorm": "0.802", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "131929"}
[2023-04-02 05:14:59,125][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 05:14:59,156][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 05:14:59,158][fairseq.trainer][INFO] - begin training epoch 110
[2023-04-02 05:14:59,158][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 05:18:00,586][train_inner][INFO] - {"epoch": 110, "update": 109.074, "loss": "3.267", "ppl": "9.63", "wps": "47715.9", "ups": "0.44", "wpb": "107260", "bsz": "255.8", "num_updates": "119000", "lr": "3.65217e-05", "gnorm": "0.802", "train_wall": "400", "gb_free": "6.8", "wall": "132111"}
[2023-04-02 05:25:25,631][train_inner][INFO] - {"epoch": 110, "update": 109.258, "loss": "3.253", "ppl": "9.53", "wps": "48002.1", "ups": "0.45", "wpb": "106815", "bsz": "256", "num_updates": "119200", "lr": "3.53043e-05", "gnorm": "0.808", "train_wall": "399", "gb_free": "6.8", "wall": "132556"}
[2023-04-02 05:32:51,649][train_inner][INFO] - {"epoch": 110, "update": 109.441, "loss": "3.258", "ppl": "9.57", "wps": "48055.2", "ups": "0.45", "wpb": "107168", "bsz": "256", "num_updates": "119400", "lr": "3.4087e-05", "gnorm": "0.801", "train_wall": "400", "gb_free": "6.8", "wall": "133002"}
[2023-04-02 05:40:17,841][train_inner][INFO] - {"epoch": 110, "update": 109.624, "loss": "3.271", "ppl": "9.66", "wps": "48070.9", "ups": "0.45", "wpb": "107244", "bsz": "256", "num_updates": "119600", "lr": "3.28696e-05", "gnorm": "0.801", "train_wall": "400", "gb_free": "6.8", "wall": "133448"}
[2023-04-02 05:47:44,785][train_inner][INFO] - {"epoch": 110, "update": 109.808, "loss": "3.281", "ppl": "9.72", "wps": "48101.3", "ups": "0.45", "wpb": "107493", "bsz": "256", "num_updates": "119800", "lr": "3.16522e-05", "gnorm": "0.802", "train_wall": "401", "gb_free": "6.8", "wall": "133895"}
[2023-04-02 05:55:10,763][train_inner][INFO] - {"epoch": 110, "update": 109.991, "loss": "3.283", "ppl": "9.73", "wps": "48058.9", "ups": "0.45", "wpb": "107166", "bsz": "256", "num_updates": "120000", "lr": "3.04348e-05", "gnorm": "0.801", "train_wall": "400", "gb_free": "6.8", "wall": "134341"}
[2023-04-02 05:55:32,959][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 05:55:32,959][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 05:55:34,648][valid][INFO] - {"epoch": 110, "valid_loss": "4.485", "valid_ppl": "22.4", "valid_wps": "146509", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "120010", "valid_best_loss": "4.132"}
[2023-04-02 05:55:34,649][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 110 @ 120010 updates
[2023-04-02 05:55:34,650][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 05:55:35,577][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 05:55:35,600][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 110 @ 120010 updates, score 4.485) (writing took 0.9503784470143728 seconds)
[2023-04-02 05:55:35,600][fairseq_cli.train][INFO] - end of epoch 110 (average epoch stats below)
[2023-04-02 05:55:35,600][train][INFO] - {"epoch": 110, "train_loss": "3.267", "train_ppl": "9.63", "train_wps": "48004.5", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "120010", "train_lr": "3.03739e-05", "train_gnorm": "0.803", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "134366"}
[2023-04-02 05:55:35,602][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 05:55:35,635][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 05:55:35,637][fairseq.trainer][INFO] - begin training epoch 111
[2023-04-02 05:55:35,637][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 06:02:40,647][train_inner][INFO] - {"epoch": 111, "update": 110.174, "loss": "3.249", "ppl": "9.51", "wps": "47788.4", "ups": "0.44", "wpb": "107496", "bsz": "255.8", "num_updates": "120200", "lr": "2.92174e-05", "gnorm": "0.81", "train_wall": "401", "gb_free": "6.8", "wall": "134791"}
[2023-04-02 06:10:06,035][train_inner][INFO] - {"epoch": 111, "update": 110.357, "loss": "3.252", "ppl": "9.53", "wps": "48046.8", "ups": "0.45", "wpb": "106997", "bsz": "256", "num_updates": "120400", "lr": "2.8e-05", "gnorm": "0.805", "train_wall": "400", "gb_free": "6.8", "wall": "135236"}
[2023-04-02 06:17:31,015][train_inner][INFO] - {"epoch": 111, "update": 110.541, "loss": "3.257", "ppl": "9.56", "wps": "48035.3", "ups": "0.45", "wpb": "106874", "bsz": "256", "num_updates": "120600", "lr": "2.67826e-05", "gnorm": "0.802", "train_wall": "399", "gb_free": "6.8", "wall": "135681"}
[2023-04-02 06:24:56,902][train_inner][INFO] - {"epoch": 111, "update": 110.724, "loss": "3.265", "ppl": "9.62", "wps": "48070.3", "ups": "0.45", "wpb": "107170", "bsz": "256", "num_updates": "120800", "lr": "2.55652e-05", "gnorm": "0.796", "train_wall": "400", "gb_free": "6.8", "wall": "136127"}
[2023-04-02 06:32:23,633][train_inner][INFO] - {"epoch": 111, "update": 110.907, "loss": "3.27", "ppl": "9.65", "wps": "48079.8", "ups": "0.45", "wpb": "107394", "bsz": "256", "num_updates": "121000", "lr": "2.43478e-05", "gnorm": "0.798", "train_wall": "401", "gb_free": "6.8", "wall": "136574"}
[2023-04-02 06:36:09,047][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 06:36:09,047][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 06:36:10,807][valid][INFO] - {"epoch": 111, "valid_loss": "4.487", "valid_ppl": "22.42", "valid_wps": "140733", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "121101", "valid_best_loss": "4.132"}
[2023-04-02 06:36:10,808][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 111 @ 121101 updates
[2023-04-02 06:36:10,809][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 06:36:12,559][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 06:36:12,586][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 111 @ 121101 updates, score 4.487) (writing took 1.7784380719822366 seconds)
[2023-04-02 06:36:12,587][fairseq_cli.train][INFO] - end of epoch 111 (average epoch stats below)
[2023-04-02 06:36:12,587][train][INFO] - {"epoch": 111, "train_loss": "3.26", "train_ppl": "9.58", "train_wps": "47994.5", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "121101", "train_lr": "2.3733e-05", "train_gnorm": "0.801", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "136803"}
[2023-04-02 06:36:12,589][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 06:36:12,619][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 06:36:12,621][fairseq.trainer][INFO] - begin training epoch 112
[2023-04-02 06:36:12,621][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 06:39:53,786][train_inner][INFO] - {"epoch": 112, "update": 111.091, "loss": "3.256", "ppl": "9.55", "wps": "47685.6", "ups": "0.44", "wpb": "107329", "bsz": "255.8", "num_updates": "121200", "lr": "2.31304e-05", "gnorm": "0.794", "train_wall": "401", "gb_free": "6.8", "wall": "137024"}
[2023-04-02 06:47:19,291][train_inner][INFO] - {"epoch": 112, "update": 111.274, "loss": "3.245", "ppl": "9.48", "wps": "48037.8", "ups": "0.45", "wpb": "107005", "bsz": "256", "num_updates": "121400", "lr": "2.1913e-05", "gnorm": "0.798", "train_wall": "400", "gb_free": "6.8", "wall": "137470"}
[2023-04-02 06:54:45,722][train_inner][INFO] - {"epoch": 112, "update": 111.457, "loss": "3.254", "ppl": "9.54", "wps": "48110.5", "ups": "0.45", "wpb": "107390", "bsz": "256", "num_updates": "121600", "lr": "2.06957e-05", "gnorm": "0.8", "train_wall": "401", "gb_free": "6.8", "wall": "137916"}
[2023-04-02 07:02:11,556][train_inner][INFO] - {"epoch": 112, "update": 111.641, "loss": "3.255", "ppl": "9.54", "wps": "48047.5", "ups": "0.45", "wpb": "107106", "bsz": "256", "num_updates": "121800", "lr": "1.94783e-05", "gnorm": "0.796", "train_wall": "400", "gb_free": "6.8", "wall": "138362"}
[2023-04-02 07:09:38,562][train_inner][INFO] - {"epoch": 112, "update": 111.824, "loss": "3.257", "ppl": "9.56", "wps": "48119.6", "ups": "0.45", "wpb": "107549", "bsz": "256", "num_updates": "122000", "lr": "1.82609e-05", "gnorm": "0.801", "train_wall": "401", "gb_free": "6.8", "wall": "138809"}
[2023-04-02 07:16:45,901][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 07:16:45,902][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 07:16:47,639][valid][INFO] - {"epoch": 112, "valid_loss": "4.489", "valid_ppl": "22.45", "valid_wps": "142470", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "122192", "valid_best_loss": "4.132"}
[2023-04-02 07:16:47,640][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 112 @ 122192 updates
[2023-04-02 07:16:47,641][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 07:16:48,571][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 07:16:48,598][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 112 @ 122192 updates, score 4.489) (writing took 0.9575965109979734 seconds)
[2023-04-02 07:16:48,598][fairseq_cli.train][INFO] - end of epoch 112 (average epoch stats below)
[2023-04-02 07:16:48,598][train][INFO] - {"epoch": 112, "train_loss": "3.253", "train_ppl": "9.54", "train_wps": "48013.7", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "122192", "train_lr": "1.70922e-05", "train_gnorm": "0.798", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "139239"}
[2023-04-02 07:16:48,600][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 07:16:48,631][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 07:16:48,633][fairseq.trainer][INFO] - begin training epoch 113
[2023-04-02 07:16:48,634][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 07:17:06,559][train_inner][INFO] - {"epoch": 113, "update": 112.007, "loss": "3.262", "ppl": "9.59", "wps": "47707.8", "ups": "0.45", "wpb": "106864", "bsz": "255.8", "num_updates": "122200", "lr": "1.70435e-05", "gnorm": "0.799", "train_wall": "399", "gb_free": "6.8", "wall": "139257"}
[2023-04-02 07:24:32,695][train_inner][INFO] - {"epoch": 113, "update": 112.191, "loss": "3.236", "ppl": "9.42", "wps": "48077.5", "ups": "0.45", "wpb": "107246", "bsz": "256", "num_updates": "122400", "lr": "1.58261e-05", "gnorm": "0.792", "train_wall": "400", "gb_free": "6.8", "wall": "139703"}
[2023-04-02 07:31:59,081][train_inner][INFO] - {"epoch": 113, "update": 112.374, "loss": "3.246", "ppl": "9.49", "wps": "48068.9", "ups": "0.45", "wpb": "107286", "bsz": "256", "num_updates": "122600", "lr": "1.46087e-05", "gnorm": "0.794", "train_wall": "401", "gb_free": "6.8", "wall": "140149"}
[2023-04-02 07:39:24,917][train_inner][INFO] - {"epoch": 113, "update": 112.557, "loss": "3.246", "ppl": "9.48", "wps": "48069.5", "ups": "0.45", "wpb": "107155", "bsz": "256", "num_updates": "122800", "lr": "1.33913e-05", "gnorm": "0.798", "train_wall": "400", "gb_free": "6.8", "wall": "140595"}
[2023-04-02 07:46:50,740][train_inner][INFO] - {"epoch": 113, "update": 112.741, "loss": "3.251", "ppl": "9.52", "wps": "48067.4", "ups": "0.45", "wpb": "107148", "bsz": "256", "num_updates": "123000", "lr": "1.21739e-05", "gnorm": "0.795", "train_wall": "400", "gb_free": "6.8", "wall": "141041"}
[2023-04-02 07:54:16,848][train_inner][INFO] - {"epoch": 113, "update": 112.924, "loss": "3.254", "ppl": "9.54", "wps": "48087.3", "ups": "0.45", "wpb": "107261", "bsz": "256", "num_updates": "123200", "lr": "1.09565e-05", "gnorm": "0.797", "train_wall": "400", "gb_free": "6.8", "wall": "141487"}
[2023-04-02 07:57:21,914][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 07:57:21,915][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 07:57:23,642][valid][INFO] - {"epoch": 113, "valid_loss": "4.489", "valid_ppl": "22.46", "valid_wps": "143284", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "123283", "valid_best_loss": "4.132"}
[2023-04-02 07:57:23,643][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 113 @ 123283 updates
[2023-04-02 07:57:23,644][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 07:57:25,050][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 07:57:25,076][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 113 @ 123283 updates, score 4.489) (writing took 1.4328927219903562 seconds)
[2023-04-02 07:57:25,076][fairseq_cli.train][INFO] - end of epoch 113 (average epoch stats below)
[2023-04-02 07:57:25,077][train][INFO] - {"epoch": 113, "train_loss": "3.247", "train_ppl": "9.49", "train_wps": "48004.5", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "123283", "train_lr": "1.04513e-05", "train_gnorm": "0.796", "train_train_wall": "2183", "train_gb_free": "6.8", "train_wall": "141675"}
[2023-04-02 07:57:25,078][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 07:57:25,111][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 07:57:25,113][fairseq.trainer][INFO] - begin training epoch 114
[2023-04-02 07:57:25,113][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 08:01:46,852][train_inner][INFO] - {"epoch": 114, "update": 113.107, "loss": "3.243", "ppl": "9.47", "wps": "47716.3", "ups": "0.44", "wpb": "107363", "bsz": "255.8", "num_updates": "123400", "lr": "9.73913e-06", "gnorm": "0.8", "train_wall": "401", "gb_free": "6.8", "wall": "141937"}
[2023-04-02 08:09:12,763][train_inner][INFO] - {"epoch": 114, "update": 113.291, "loss": "3.234", "ppl": "9.41", "wps": "48074", "ups": "0.45", "wpb": "107183", "bsz": "256", "num_updates": "123600", "lr": "8.52174e-06", "gnorm": "0.789", "train_wall": "400", "gb_free": "6.8", "wall": "142383"}
[2023-04-02 08:16:39,115][train_inner][INFO] - {"epoch": 114, "update": 113.474, "loss": "3.245", "ppl": "9.48", "wps": "48072.1", "ups": "0.45", "wpb": "107286", "bsz": "256", "num_updates": "123800", "lr": "7.30435e-06", "gnorm": "0.793", "train_wall": "400", "gb_free": "6.8", "wall": "142829"}
[2023-04-02 08:24:14,605][train_inner][INFO] - {"epoch": 114, "update": 113.657, "loss": "3.245", "ppl": "9.48", "wps": "47076.1", "ups": "0.44", "wpb": "107213", "bsz": "256", "num_updates": "124000", "lr": "6.08696e-06", "gnorm": "0.793", "train_wall": "409", "gb_free": "6.8", "wall": "143285"}
[2023-04-02 08:31:42,748][train_inner][INFO] - {"epoch": 114, "update": 113.841, "loss": "3.239", "ppl": "9.44", "wps": "47845.6", "ups": "0.45", "wpb": "107208", "bsz": "256", "num_updates": "124200", "lr": "4.86957e-06", "gnorm": "0.79", "train_wall": "402", "gb_free": "6.8", "wall": "143733"}
[2023-04-02 08:38:12,110][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 08:38:12,111][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 08:38:13,848][valid][INFO] - {"epoch": 114, "valid_loss": "4.49", "valid_ppl": "22.47", "valid_wps": "142673", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "124374", "valid_best_loss": "4.132"}
[2023-04-02 08:38:13,849][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 114 @ 124374 updates
[2023-04-02 08:38:13,849][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 08:38:15,263][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 08:38:15,296][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 114 @ 124374 updates, score 4.49) (writing took 1.447921381011838 seconds)
[2023-04-02 08:38:15,297][fairseq_cli.train][INFO] - end of epoch 114 (average epoch stats below)
[2023-04-02 08:38:15,297][train][INFO] - {"epoch": 114, "train_loss": "3.24", "train_ppl": "9.45", "train_wps": "47735.3", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "124374", "train_lr": "3.81043e-06", "train_gnorm": "0.793", "train_train_wall": "2195", "train_gb_free": "6.8", "train_wall": "144126"}
[2023-04-02 08:38:15,299][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 08:38:15,330][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-04-02 08:38:15,332][fairseq.trainer][INFO] - begin training epoch 115
[2023-04-02 08:38:15,333][fairseq_cli.train][INFO] - Start iterating over samples
[2023-04-02 08:39:13,620][train_inner][INFO] - {"epoch": 115, "update": 114.024, "loss": "3.241", "ppl": "9.45", "wps": "47413.5", "ups": "0.44", "wpb": "106887", "bsz": "255.8", "num_updates": "124400", "lr": "3.65217e-06", "gnorm": "0.793", "train_wall": "401", "gb_free": "6.8", "wall": "144184"}
[2023-04-02 08:46:43,912][train_inner][INFO] - {"epoch": 115, "update": 114.207, "loss": "3.236", "ppl": "9.42", "wps": "47684.1", "ups": "0.44", "wpb": "107359", "bsz": "256", "num_updates": "124600", "lr": "2.43478e-06", "gnorm": "0.79", "train_wall": "405", "gb_free": "6.8", "wall": "144634"}
[2023-04-02 08:54:12,840][train_inner][INFO] - {"epoch": 115, "update": 114.39, "loss": "3.235", "ppl": "9.41", "wps": "47654.7", "ups": "0.45", "wpb": "106968", "bsz": "256", "num_updates": "124800", "lr": "1.21739e-06", "gnorm": "0.791", "train_wall": "403", "gb_free": "6.8", "wall": "145083"}
[2023-04-02 09:01:42,417][train_inner][INFO] - {"epoch": 115, "update": 114.574, "loss": "3.233", "ppl": "9.4", "wps": "47685.4", "ups": "0.44", "wpb": "107191", "bsz": "256", "num_updates": "125000", "lr": "0", "gnorm": "0.794", "train_wall": "404", "gb_free": "6.8", "wall": "145533"}
[2023-04-02 09:01:42,417][fairseq_cli.train][INFO] - Stopping training due to num_updates: 125000 >= max_update: 125000
[2023-04-02 09:01:42,418][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-04-02 09:01:42,418][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-04-02 09:01:44,148][valid][INFO] - {"epoch": 115, "valid_loss": "4.492", "valid_ppl": "22.5", "valid_wps": "143112", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "125000", "valid_best_loss": "4.132"}
[2023-04-02 09:01:44,149][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 115 @ 125000 updates
[2023-04-02 09:01:44,149][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 09:01:45,066][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-31/16-36-06/0/checkpoints/checkpoint_last.pt
[2023-04-02 09:01:45,091][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 115 @ 125000 updates, score 4.492) (writing took 0.9427249000000302 seconds)
[2023-04-02 09:01:45,092][fairseq_cli.train][INFO] - end of epoch 115 (average epoch stats below)
[2023-04-02 09:01:45,092][train][INFO] - {"epoch": 115, "train_loss": "3.235", "train_ppl": "9.41", "train_wps": "47575.9", "train_ups": "0.44", "train_wpb": "107144", "train_bsz": "256", "train_num_updates": "125000", "train_lr": "0", "train_gnorm": "0.792", "train_train_wall": "1264", "train_gb_free": "6.8", "train_wall": "145535"}
[2023-04-02 09:01:45,093][fairseq_cli.train][INFO] - done training in 145533.8 seconds
