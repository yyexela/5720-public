initialize.py: running hydra_init
initialize.py: running hydra_init
[2023-03-27 22:24:17,841][HYDRA] Launching 1 jobs locally
[2023-03-27 22:24:17,841][HYDRA] 	#0 : task.data=/home/alexey/Desktop/fairseq/data-bin/wikitext-103/ checkpoint.restore_file=./roberta.base/model.pt
[2023-03-27 22:24:18,846][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': True, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 125000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [64], 'lr': [0.0007], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': './roberta.base/model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'roberta', 'max_positions': 512, 'dropout': 0.1, 'attention_dropout': 0.1}, 'task': {'_name': 'masked_lm', 'data': '/home/alexey/Desktop/fairseq/data-bin/wikitext-103/', 'sample_break_mode': complete, 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': none, 'shorten_data_split_list': '', 'seed': 1, 'include_target_tokens': False, 'include_index': True, 'skip_masking': False, 'd2v2_multi': False}, 'criterion': {'_name': 'masked_lm', 'tpu': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 10000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 125000.0, 'lr': [0.0007]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2023-03-27 22:24:18,890][fairseq.tasks.masked_lm][INFO] - dictionary: 50264 types
[2023-03-27 22:24:19,074][fairseq_cli.train][INFO] - RobertaModel(
  (encoder): RobertaEncoder(
    (sentence_encoder): TransformerEncoder(
      (dropout_module): FairseqDropout()
      (embed_tokens): Embedding(50265, 192, padding_idx=1)
      (embed_positions): LearnedPositionalEmbedding(514, 192, padding_idx=1)
      (layernorm_embedding): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=192, out_features=192, bias=True)
            (v_proj): Linear(in_features=192, out_features=192, bias=True)
            (q_proj): Linear(in_features=192, out_features=192, bias=True)
            (out_proj): Linear(in_features=192, out_features=192, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (fc2): Linear(in_features=768, out_features=192, bias=True)
          (final_layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (lm_head): RobertaLMHead(
      (dense): Linear(in_features=192, out_features=192, bias=True)
      (layer_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classification_heads): ModuleDict()
)
[2023-03-27 22:24:19,076][fairseq_cli.train][INFO] - task: MaskedLMTask
[2023-03-27 22:24:19,077][fairseq_cli.train][INFO] - model: RobertaModel
[2023-03-27 22:24:19,077][fairseq_cli.train][INFO] - criterion: MaskedLmLoss
[2023-03-27 22:24:19,078][fairseq_cli.train][INFO] - num. shared model params: 10,282,521 (num. trained: 10,282,521)
[2023-03-27 22:24:19,078][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-03-27 22:24:19,080][fairseq.data.data_utils][INFO] - loaded 3,760 examples from: /home/alexey/Desktop/fairseq/data-bin/wikitext-103/valid
[2023-03-27 22:24:19,081][fairseq.tasks.masked_lm][INFO] - loaded 580 blocks from: /home/alexey/Desktop/fairseq/data-bin/wikitext-103/valid
[2023-03-27 22:24:20,150][fairseq.trainer][INFO] - detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight
[2023-03-27 22:24:20,150][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-03-27 22:24:20,150][fairseq.utils][INFO] - rank   0: capabilities =  6.1  ; total memory = 7.921 GB ; name = NVIDIA GeForce GTX 1070                 
[2023-03-27 22:24:20,150][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-03-27 22:24:20,150][fairseq_cli.train][INFO] - training on 1 devices (GPUs/TPUs)
[2023-03-27 22:24:20,151][fairseq_cli.train][INFO] - max tokens per device = None and max sentences per device = 4
[2023-03-27 22:24:20,152][fairseq.trainer][INFO] - Preparing to load checkpoint ./roberta.base/model.pt
[2023-03-27 22:24:20,152][fairseq.trainer][INFO] - No existing checkpoint found ./roberta.base/model.pt
[2023-03-27 22:24:20,152][fairseq.trainer][INFO] - loading train data for epoch 1
[2023-03-27 22:24:20,320][fairseq.data.data_utils][INFO] - loaded 1,801,350 examples from: /home/alexey/Desktop/fairseq/data-bin/wikitext-103/train
[2023-03-27 22:24:20,388][fairseq.tasks.masked_lm][INFO] - loaded 280678 blocks from: /home/alexey/Desktop/fairseq/data-bin/wikitext-103/train
[2023-03-27 22:24:20,396][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-27 22:24:20,396][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2023-03-27 22:24:20,396][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2023-03-27 22:24:20,396][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2023-03-27 22:24:20,422][fairseq.tasks.fairseq_task][WARNING] - 1,414 samples have invalid sizes and will be skipped, max_positions=512, first few sample ids=[127070, 245388, 160963, 4508, 197654, 80339, 243532, 240011, 69697, 236498]
[2023-03-27 22:24:20,636][fairseq_cli.train][INFO] - begin dry-run validation on "valid" subset
[2023-03-27 22:24:20,638][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-27 22:24:20,640][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2023-03-27 22:24:20,641][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2023-03-27 22:24:20,642][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2023-03-27 22:24:21,846][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-27 22:24:21,849][fairseq.trainer][INFO] - begin training epoch 1
[2023-03-27 22:24:21,851][fairseq_cli.train][INFO] - Start iterating over samples
/home/alexey/Desktop/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2023-03-27 22:27:59,778][train_inner][INFO] - {"epoch": 1, "update": 0.183, "loss": "15.504", "ppl": "46472.1", "wps": "98991.7", "ups": "0.93", "wpb": "107015", "bsz": "256", "num_updates": "200", "lr": "1.4e-05", "gnorm": "1.117", "train_wall": "170", "gb_free": "7.5", "wall": "220"}
[2023-03-27 22:31:33,380][train_inner][INFO] - {"epoch": 1, "update": 0.367, "loss": "14.609", "ppl": "24989.1", "wps": "100359", "ups": "0.94", "wpb": "107181", "bsz": "256", "num_updates": "400", "lr": "2.8e-05", "gnorm": "1.151", "train_wall": "168", "gb_free": "7.5", "wall": "433"}
[2023-03-27 22:35:08,114][train_inner][INFO] - {"epoch": 1, "update": 0.55, "loss": "12.998", "ppl": "8180.93", "wps": "99893.5", "ups": "0.93", "wpb": "107252", "bsz": "256", "num_updates": "600", "lr": "4.2e-05", "gnorm": "1.249", "train_wall": "169", "gb_free": "7.5", "wall": "648"}
[2023-03-27 22:38:43,002][train_inner][INFO] - {"epoch": 1, "update": 0.733, "loss": "11.501", "ppl": "2898.21", "wps": "100012", "ups": "0.93", "wpb": "107457", "bsz": "256", "num_updates": "800", "lr": "5.6e-05", "gnorm": "1.061", "train_wall": "169", "gb_free": "7.5", "wall": "863"}
[2023-03-27 22:42:16,206][train_inner][INFO] - {"epoch": 1, "update": 0.917, "loss": "10.759", "ppl": "1732.4", "wps": "100460", "ups": "0.94", "wpb": "107092", "bsz": "256", "num_updates": "1000", "lr": "7e-05", "gnorm": "0.368", "train_wall": "168", "gb_free": "7.5", "wall": "1076"}
[2023-03-27 22:43:53,310][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-27 22:43:53,311][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-27 22:43:54,203][valid][INFO] - {"epoch": 1, "valid_loss": "10.537", "valid_ppl": "1485.29", "valid_wps": "278369", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "1091"}
[2023-03-27 22:43:54,204][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 1091 updates
[2023-03-27 22:43:54,205][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-27 22:43:54,360][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-27 22:43:54,436][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 1 @ 1091 updates, score 10.537) (writing took 0.23264935199949832 seconds)
[2023-03-27 22:43:54,437][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2023-03-27 22:43:54,437][train][INFO] - {"epoch": 1, "train_loss": "12.869", "train_ppl": "7479.53", "train_wps": "99894.2", "train_ups": "0.93", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "1091", "train_lr": "7.637e-05", "train_gnorm": "0.923", "train_train_wall": "919", "train_gb_free": "7.5", "train_wall": "1174"}
[2023-03-27 22:43:54,439][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-27 22:43:54,471][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-27 22:43:54,473][fairseq.trainer][INFO] - begin training epoch 2
[2023-03-27 22:43:54,474][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-27 22:45:50,410][train_inner][INFO] - {"epoch": 2, "update": 1.1, "loss": "10.584", "ppl": "1534.86", "wps": "100150", "ups": "0.93", "wpb": "107262", "bsz": "255.8", "num_updates": "1200", "lr": "8.4e-05", "gnorm": "0.202", "train_wall": "167", "gb_free": "7.5", "wall": "1290"}
[2023-03-27 22:49:22,100][train_inner][INFO] - {"epoch": 2, "update": 1.283, "loss": "10.447", "ppl": "1396.14", "wps": "101240", "ups": "0.94", "wpb": "107157", "bsz": "256", "num_updates": "1400", "lr": "9.8e-05", "gnorm": "0.223", "train_wall": "166", "gb_free": "7.5", "wall": "1502"}
[2023-03-27 22:52:53,960][train_inner][INFO] - {"epoch": 2, "update": 1.467, "loss": "10.337", "ppl": "1293.09", "wps": "101499", "ups": "0.94", "wpb": "107518", "bsz": "256", "num_updates": "1600", "lr": "0.000112", "gnorm": "0.237", "train_wall": "166", "gb_free": "7.5", "wall": "1714"}
[2023-03-27 22:56:25,424][train_inner][INFO] - {"epoch": 2, "update": 1.65, "loss": "10.254", "ppl": "1220.75", "wps": "101368", "ups": "0.95", "wpb": "107179", "bsz": "256", "num_updates": "1800", "lr": "0.000126", "gnorm": "0.248", "train_wall": "166", "gb_free": "7.5", "wall": "1925"}
[2023-03-27 22:59:57,082][train_inner][INFO] - {"epoch": 2, "update": 1.833, "loss": "10.169", "ppl": "1151.53", "wps": "101193", "ups": "0.94", "wpb": "107091", "bsz": "256", "num_updates": "2000", "lr": "0.00014", "gnorm": "0.262", "train_wall": "166", "gb_free": "7.5", "wall": "2137"}
[2023-03-27 23:03:09,275][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-27 23:03:09,276][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-27 23:03:10,206][valid][INFO] - {"epoch": 2, "valid_loss": "10", "valid_ppl": "1023.72", "valid_wps": "268082", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "2182", "valid_best_loss": "10"}
[2023-03-27 23:03:10,207][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 2182 updates
[2023-03-27 23:03:10,208][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-27 23:03:10,762][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-27 23:03:11,164][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 2 @ 2182 updates, score 10.0) (writing took 0.9573891509990062 seconds)
[2023-03-27 23:03:11,164][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2023-03-27 23:03:11,165][train][INFO] - {"epoch": 2, "train_loss": "10.294", "train_ppl": "1255.19", "train_wps": "101115", "train_ups": "0.94", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "2182", "train_lr": "0.00015274", "train_gnorm": "0.244", "train_train_wall": "906", "train_gb_free": "7.5", "train_wall": "2331"}
[2023-03-27 23:03:11,167][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-27 23:03:11,197][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-27 23:03:11,200][fairseq.trainer][INFO] - begin training epoch 3
[2023-03-27 23:03:11,200][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-27 23:03:30,582][train_inner][INFO] - {"epoch": 3, "update": 2.016, "loss": "10.1", "ppl": "1097.52", "wps": "100334", "ups": "0.94", "wpb": "107107", "bsz": "255.8", "num_updates": "2200", "lr": "0.000154", "gnorm": "0.273", "train_wall": "166", "gb_free": "7.5", "wall": "2350"}
[2023-03-27 23:07:01,886][train_inner][INFO] - {"epoch": 3, "update": 2.2, "loss": "10.015", "ppl": "1034.73", "wps": "101452", "ups": "0.95", "wpb": "107186", "bsz": "256", "num_updates": "2400", "lr": "0.000168", "gnorm": "0.312", "train_wall": "166", "gb_free": "7.5", "wall": "2562"}
[2023-03-27 23:10:33,118][train_inner][INFO] - {"epoch": 3, "update": 2.383, "loss": "9.932", "ppl": "976.69", "wps": "101462", "ups": "0.95", "wpb": "107160", "bsz": "256", "num_updates": "2600", "lr": "0.000182", "gnorm": "0.359", "train_wall": "166", "gb_free": "7.5", "wall": "2773"}
[2023-03-27 23:14:04,183][train_inner][INFO] - {"epoch": 3, "update": 2.566, "loss": "9.832", "ppl": "911.29", "wps": "101440", "ups": "0.95", "wpb": "107052", "bsz": "256", "num_updates": "2800", "lr": "0.000196", "gnorm": "0.392", "train_wall": "166", "gb_free": "7.5", "wall": "2984"}
[2023-03-27 23:17:35,695][train_inner][INFO] - {"epoch": 3, "update": 2.75, "loss": "9.733", "ppl": "851.24", "wps": "101553", "ups": "0.95", "wpb": "107398", "bsz": "256", "num_updates": "3000", "lr": "0.00021", "gnorm": "0.416", "train_wall": "166", "gb_free": "7.5", "wall": "3196"}
[2023-03-27 23:21:07,059][train_inner][INFO] - {"epoch": 3, "update": 2.933, "loss": "9.65", "ppl": "803.3", "wps": "101446", "ups": "0.95", "wpb": "107210", "bsz": "256", "num_updates": "3200", "lr": "0.000224", "gnorm": "0.442", "train_wall": "166", "gb_free": "7.5", "wall": "3407"}
[2023-03-27 23:22:24,120][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-27 23:22:24,121][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-27 23:22:25,012][valid][INFO] - {"epoch": 3, "valid_loss": "9.537", "valid_ppl": "742.96", "valid_wps": "279680", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "3273", "valid_best_loss": "9.537"}
[2023-03-27 23:22:25,013][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 3273 updates
[2023-03-27 23:22:25,014][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-27 23:22:25,714][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-27 23:22:26,053][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 3 @ 3273 updates, score 9.537) (writing took 1.0397878410003614 seconds)
[2023-03-27 23:22:26,053][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2023-03-27 23:22:26,054][train][INFO] - {"epoch": 3, "train_loss": "9.821", "train_ppl": "904.27", "train_wps": "101276", "train_ups": "0.94", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "3273", "train_lr": "0.00022911", "train_gnorm": "0.386", "train_train_wall": "906", "train_gb_free": "7.5", "train_wall": "3486"}
[2023-03-27 23:22:26,056][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-27 23:22:26,089][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-27 23:22:26,091][fairseq.trainer][INFO] - begin training epoch 4
[2023-03-27 23:22:26,092][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-27 23:24:40,487][train_inner][INFO] - {"epoch": 4, "update": 3.116, "loss": "9.562", "ppl": "755.92", "wps": "100539", "ups": "0.94", "wpb": "107289", "bsz": "255.8", "num_updates": "3400", "lr": "0.000238", "gnorm": "0.456", "train_wall": "166", "gb_free": "7.5", "wall": "3620"}
[2023-03-27 23:28:11,813][train_inner][INFO] - {"epoch": 4, "update": 3.3, "loss": "9.504", "ppl": "725.9", "wps": "101456", "ups": "0.95", "wpb": "107201", "bsz": "256", "num_updates": "3600", "lr": "0.000252", "gnorm": "0.471", "train_wall": "166", "gb_free": "7.5", "wall": "3832"}
[2023-03-27 23:31:42,793][train_inner][INFO] - {"epoch": 4, "update": 3.483, "loss": "9.442", "ppl": "695.4", "wps": "101527", "ups": "0.95", "wpb": "107101", "bsz": "256", "num_updates": "3800", "lr": "0.000266", "gnorm": "0.503", "train_wall": "166", "gb_free": "7.5", "wall": "4043"}
[2023-03-27 23:35:14,039][train_inner][INFO] - {"epoch": 4, "update": 3.666, "loss": "9.383", "ppl": "667.53", "wps": "101490", "ups": "0.95", "wpb": "107196", "bsz": "256", "num_updates": "4000", "lr": "0.00028", "gnorm": "0.539", "train_wall": "166", "gb_free": "7.5", "wall": "4254"}
[2023-03-27 23:38:45,194][train_inner][INFO] - {"epoch": 4, "update": 3.85, "loss": "9.318", "ppl": "638.36", "wps": "101455", "ups": "0.95", "wpb": "107113", "bsz": "256", "num_updates": "4200", "lr": "0.000294", "gnorm": "0.564", "train_wall": "166", "gb_free": "7.5", "wall": "4465"}
[2023-03-27 23:41:38,485][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-27 23:41:38,486][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-27 23:41:39,432][valid][INFO] - {"epoch": 4, "valid_loss": "9.192", "valid_ppl": "584.9", "valid_wps": "263762", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "4364", "valid_best_loss": "9.192"}
[2023-03-27 23:41:39,433][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 4364 updates
[2023-03-27 23:41:39,434][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-27 23:41:39,674][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-27 23:41:39,816][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 4 @ 4364 updates, score 9.192) (writing took 0.38245758499760996 seconds)
[2023-03-27 23:41:39,816][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2023-03-27 23:41:39,817][train][INFO] - {"epoch": 4, "train_loss": "9.404", "train_ppl": "677.69", "train_wps": "101374", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "4364", "train_lr": "0.00030548", "train_gnorm": "0.522", "train_train_wall": "906", "train_gb_free": "7.5", "train_wall": "4640"}
[2023-03-27 23:41:39,819][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-27 23:41:39,851][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-27 23:41:39,854][fairseq.trainer][INFO] - begin training epoch 5
[2023-03-27 23:41:39,854][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-27 23:42:18,243][train_inner][INFO] - {"epoch": 5, "update": 4.033, "loss": "9.251", "ppl": "609.37", "wps": "100716", "ups": "0.94", "wpb": "107288", "bsz": "255.8", "num_updates": "4400", "lr": "0.000308", "gnorm": "0.578", "train_wall": "166", "gb_free": "7.5", "wall": "4678"}
[2023-03-27 23:45:49,226][train_inner][INFO] - {"epoch": 5, "update": 4.216, "loss": "9.164", "ppl": "573.76", "wps": "101524", "ups": "0.95", "wpb": "107099", "bsz": "256", "num_updates": "4600", "lr": "0.000322", "gnorm": "0.604", "train_wall": "166", "gb_free": "7.5", "wall": "4889"}
[2023-03-27 23:49:20,520][train_inner][INFO] - {"epoch": 5, "update": 4.4, "loss": "9.133", "ppl": "561.37", "wps": "101585", "ups": "0.95", "wpb": "107321", "bsz": "256", "num_updates": "4800", "lr": "0.000336", "gnorm": "0.609", "train_wall": "166", "gb_free": "7.5", "wall": "5100"}
[2023-03-27 23:52:51,590][train_inner][INFO] - {"epoch": 5, "update": 4.583, "loss": "9.069", "ppl": "536.99", "wps": "101532", "ups": "0.95", "wpb": "107152", "bsz": "256", "num_updates": "5000", "lr": "0.00035", "gnorm": "0.615", "train_wall": "166", "gb_free": "7.5", "wall": "5311"}
[2023-03-27 23:56:22,763][train_inner][INFO] - {"epoch": 5, "update": 4.766, "loss": "8.926", "ppl": "486.29", "wps": "101507", "ups": "0.95", "wpb": "107178", "bsz": "256", "num_updates": "5200", "lr": "0.000364", "gnorm": "0.667", "train_wall": "166", "gb_free": "7.5", "wall": "5523"}
[2023-03-27 23:59:54,251][train_inner][INFO] - {"epoch": 5, "update": 4.95, "loss": "8.733", "ppl": "425.38", "wps": "101575", "ups": "0.95", "wpb": "107409", "bsz": "256", "num_updates": "5400", "lr": "0.000378", "gnorm": "0.732", "train_wall": "166", "gb_free": "7.5", "wall": "5734"}
[2023-03-28 00:00:52,240][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 00:00:52,241][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 00:00:53,136][valid][INFO] - {"epoch": 5, "valid_loss": "8.297", "valid_ppl": "314.54", "valid_wps": "278902", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "5455", "valid_best_loss": "8.297"}
[2023-03-28 00:00:53,137][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 5455 updates
[2023-03-28 00:00:53,138][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 00:00:53,372][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 00:00:53,518][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 5 @ 5455 updates, score 8.297) (writing took 0.3811093059994164 seconds)
[2023-03-28 00:00:53,518][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2023-03-28 00:00:53,518][train][INFO] - {"epoch": 5, "train_loss": "8.99", "train_ppl": "508.48", "train_wps": "101380", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "5455", "train_lr": "0.00038185", "train_gnorm": "0.654", "train_train_wall": "906", "train_gb_free": "7.5", "train_wall": "5793"}
[2023-03-28 00:00:53,520][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 00:00:53,551][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 00:00:53,553][fairseq.trainer][INFO] - begin training epoch 6
[2023-03-28 00:00:53,554][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 00:03:26,764][train_inner][INFO] - {"epoch": 6, "update": 5.133, "loss": "8.496", "ppl": "361.06", "wps": "100810", "ups": "0.94", "wpb": "107118", "bsz": "255.8", "num_updates": "5600", "lr": "0.000392", "gnorm": "0.82", "train_wall": "166", "gb_free": "7.5", "wall": "5947"}
[2023-03-28 00:06:57,656][train_inner][INFO] - {"epoch": 6, "update": 5.316, "loss": "8.344", "ppl": "325.04", "wps": "101494", "ups": "0.95", "wpb": "107021", "bsz": "256", "num_updates": "5800", "lr": "0.000406", "gnorm": "0.822", "train_wall": "166", "gb_free": "7.5", "wall": "6158"}
[2023-03-28 00:10:29,075][train_inner][INFO] - {"epoch": 6, "update": 5.5, "loss": "8.209", "ppl": "295.97", "wps": "101633", "ups": "0.95", "wpb": "107435", "bsz": "256", "num_updates": "6000", "lr": "0.00042", "gnorm": "0.822", "train_wall": "166", "gb_free": "7.5", "wall": "6369"}
[2023-03-28 00:14:00,665][train_inner][INFO] - {"epoch": 6, "update": 5.683, "loss": "8.029", "ppl": "261.22", "wps": "101581", "ups": "0.95", "wpb": "107468", "bsz": "256", "num_updates": "6200", "lr": "0.000434", "gnorm": "0.808", "train_wall": "166", "gb_free": "7.5", "wall": "6581"}
[2023-03-28 00:17:31,597][train_inner][INFO] - {"epoch": 6, "update": 5.866, "loss": "7.824", "ppl": "226.53", "wps": "101515", "ups": "0.95", "wpb": "107064", "bsz": "256", "num_updates": "6400", "lr": "0.000448", "gnorm": "0.801", "train_wall": "166", "gb_free": "7.5", "wall": "6791"}
[2023-03-28 00:20:05,571][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 00:20:05,572][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 00:20:06,523][valid][INFO] - {"epoch": 6, "valid_loss": "7.219", "valid_ppl": "149.03", "valid_wps": "265642", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "6546", "valid_best_loss": "7.219"}
[2023-03-28 00:20:06,524][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 6546 updates
[2023-03-28 00:20:06,525][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 00:20:06,759][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 00:20:06,904][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 6 @ 6546 updates, score 7.219) (writing took 0.38040694300070754 seconds)
[2023-03-28 00:20:06,905][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2023-03-28 00:20:06,905][train][INFO] - {"epoch": 6, "train_loss": "8.096", "train_ppl": "273.69", "train_wps": "101408", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "6546", "train_lr": "0.00045822", "train_gnorm": "0.813", "train_train_wall": "905", "train_gb_free": "7.5", "train_wall": "6947"}
[2023-03-28 00:20:06,907][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 00:20:06,940][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 00:20:06,942][fairseq.trainer][INFO] - begin training epoch 7
[2023-03-28 00:20:06,943][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 00:21:04,288][train_inner][INFO] - {"epoch": 7, "update": 6.049, "loss": "7.669", "ppl": "203.47", "wps": "100611", "ups": "0.94", "wpb": "106995", "bsz": "255.8", "num_updates": "6600", "lr": "0.000462", "gnorm": "0.814", "train_wall": "166", "gb_free": "7.5", "wall": "7004"}
[2023-03-28 00:24:35,181][train_inner][INFO] - {"epoch": 7, "update": 6.233, "loss": "7.518", "ppl": "183.25", "wps": "101497", "ups": "0.95", "wpb": "107026", "bsz": "256", "num_updates": "6800", "lr": "0.000476", "gnorm": "0.816", "train_wall": "166", "gb_free": "7.5", "wall": "7215"}
[2023-03-28 00:28:06,470][train_inner][INFO] - {"epoch": 7, "update": 6.416, "loss": "7.428", "ppl": "172.16", "wps": "101597", "ups": "0.95", "wpb": "107332", "bsz": "256", "num_updates": "7000", "lr": "0.00049", "gnorm": "0.805", "train_wall": "166", "gb_free": "7.5", "wall": "7426"}
[2023-03-28 00:31:37,613][train_inner][INFO] - {"epoch": 7, "update": 6.599, "loss": "7.327", "ppl": "160.57", "wps": "101565", "ups": "0.95", "wpb": "107223", "bsz": "256", "num_updates": "7200", "lr": "0.000504", "gnorm": "0.824", "train_wall": "166", "gb_free": "7.5", "wall": "7637"}
[2023-03-28 00:35:09,002][train_inner][INFO] - {"epoch": 7, "update": 6.783, "loss": "7.233", "ppl": "150.47", "wps": "101575", "ups": "0.95", "wpb": "107359", "bsz": "256", "num_updates": "7400", "lr": "0.000518", "gnorm": "0.809", "train_wall": "166", "gb_free": "7.5", "wall": "7849"}
[2023-03-28 00:38:40,378][train_inner][INFO] - {"epoch": 7, "update": 6.966, "loss": "7.023", "ppl": "130.07", "wps": "101484", "ups": "0.95", "wpb": "107256", "bsz": "256", "num_updates": "7600", "lr": "0.000532", "gnorm": "0.786", "train_wall": "166", "gb_free": "7.5", "wall": "8060"}
[2023-03-28 00:39:19,354][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 00:39:19,355][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 00:39:20,239][valid][INFO] - {"epoch": 7, "valid_loss": "6.22", "valid_ppl": "74.52", "valid_wps": "282062", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "7637", "valid_best_loss": "6.22"}
[2023-03-28 00:39:20,240][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 7637 updates
[2023-03-28 00:39:20,241][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 00:39:20,802][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 00:39:21,108][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 7 @ 7637 updates, score 6.22) (writing took 0.8681148670002585 seconds)
[2023-03-28 00:39:21,108][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2023-03-28 00:39:21,109][train][INFO] - {"epoch": 7, "train_loss": "7.3", "train_ppl": "157.57", "train_wps": "101336", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "7637", "train_lr": "0.00053459", "train_gnorm": "0.806", "train_train_wall": "906", "train_gb_free": "7.5", "train_wall": "8101"}
[2023-03-28 00:39:21,111][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 00:39:21,144][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 00:39:21,146][fairseq.trainer][INFO] - begin training epoch 8
[2023-03-28 00:39:21,147][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 00:42:13,327][train_inner][INFO] - {"epoch": 8, "update": 7.149, "loss": "6.607", "ppl": "97.45", "wps": "100528", "ups": "0.94", "wpb": "107037", "bsz": "255.8", "num_updates": "7800", "lr": "0.000546", "gnorm": "0.745", "train_wall": "166", "gb_free": "7.5", "wall": "8273"}
[2023-03-28 00:45:44,611][train_inner][INFO] - {"epoch": 8, "update": 7.333, "loss": "6.431", "ppl": "86.28", "wps": "101711", "ups": "0.95", "wpb": "107450", "bsz": "256", "num_updates": "8000", "lr": "0.00056", "gnorm": "0.736", "train_wall": "166", "gb_free": "7.5", "wall": "8484"}
[2023-03-28 00:49:15,291][train_inner][INFO] - {"epoch": 8, "update": 7.516, "loss": "6.335", "ppl": "80.73", "wps": "101570", "ups": "0.95", "wpb": "106994", "bsz": "256", "num_updates": "8200", "lr": "0.000574", "gnorm": "0.733", "train_wall": "166", "gb_free": "7.5", "wall": "8695"}
[2023-03-28 00:52:46,405][train_inner][INFO] - {"epoch": 8, "update": 7.699, "loss": "6.255", "ppl": "76.36", "wps": "101637", "ups": "0.95", "wpb": "107285", "bsz": "256", "num_updates": "8400", "lr": "0.000588", "gnorm": "0.715", "train_wall": "166", "gb_free": "7.5", "wall": "8906"}
[2023-03-28 00:56:17,527][train_inner][INFO] - {"epoch": 8, "update": 7.883, "loss": "6.191", "ppl": "73.04", "wps": "101606", "ups": "0.95", "wpb": "107256", "bsz": "256", "num_updates": "8600", "lr": "0.000602", "gnorm": "0.719", "train_wall": "166", "gb_free": "7.5", "wall": "9117"}
[2023-03-28 00:58:32,372][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 00:58:32,372][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 00:58:33,319][valid][INFO] - {"epoch": 8, "valid_loss": "5.645", "valid_ppl": "50.03", "valid_wps": "263262", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "8728", "valid_best_loss": "5.645"}
[2023-03-28 00:58:33,320][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 8728 updates
[2023-03-28 00:58:33,321][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 00:58:33,814][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 00:58:34,019][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 8 @ 8728 updates, score 5.645) (writing took 0.6984813980016042 seconds)
[2023-03-28 00:58:34,019][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2023-03-28 00:58:34,020][train][INFO] - {"epoch": 8, "train_loss": "6.324", "train_ppl": "80.14", "train_wps": "101449", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "8728", "train_lr": "0.00061096", "train_gnorm": "0.727", "train_train_wall": "905", "train_gb_free": "7.5", "train_wall": "9254"}
[2023-03-28 00:58:34,022][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 00:58:34,053][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 00:58:34,055][fairseq.trainer][INFO] - begin training epoch 9
[2023-03-28 00:58:34,056][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 00:59:50,314][train_inner][INFO] - {"epoch": 9, "update": 8.066, "loss": "6.098", "ppl": "68.49", "wps": "100632", "ups": "0.94", "wpb": "107066", "bsz": "255.8", "num_updates": "8800", "lr": "0.000616", "gnorm": "0.72", "train_wall": "166", "gb_free": "7.5", "wall": "9330"}
[2023-03-28 01:03:21,389][train_inner][INFO] - {"epoch": 9, "update": 8.249, "loss": "5.993", "ppl": "63.69", "wps": "101618", "ups": "0.95", "wpb": "107246", "bsz": "256", "num_updates": "9000", "lr": "0.00063", "gnorm": "0.714", "train_wall": "166", "gb_free": "7.5", "wall": "9541"}
[2023-03-28 01:06:52,561][train_inner][INFO] - {"epoch": 9, "update": 8.433, "loss": "5.971", "ppl": "62.75", "wps": "101579", "ups": "0.95", "wpb": "107253", "bsz": "256", "num_updates": "9200", "lr": "0.000644", "gnorm": "0.699", "train_wall": "166", "gb_free": "7.5", "wall": "9752"}
[2023-03-28 01:10:23,286][train_inner][INFO] - {"epoch": 9, "update": 8.616, "loss": "5.947", "ppl": "61.68", "wps": "101570", "ups": "0.95", "wpb": "107017", "bsz": "256", "num_updates": "9400", "lr": "0.000658", "gnorm": "0.699", "train_wall": "166", "gb_free": "7.5", "wall": "9963"}
[2023-03-28 01:13:54,243][train_inner][INFO] - {"epoch": 9, "update": 8.799, "loss": "5.922", "ppl": "60.61", "wps": "101661", "ups": "0.95", "wpb": "107231", "bsz": "256", "num_updates": "9600", "lr": "0.000672", "gnorm": "0.685", "train_wall": "166", "gb_free": "7.5", "wall": "10174"}
[2023-03-28 01:17:25,429][train_inner][INFO] - {"epoch": 9, "update": 8.983, "loss": "5.884", "ppl": "59.07", "wps": "101660", "ups": "0.95", "wpb": "107346", "bsz": "256", "num_updates": "9800", "lr": "0.000686", "gnorm": "0.679", "train_wall": "166", "gb_free": "7.5", "wall": "10385"}
[2023-03-28 01:17:45,470][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 01:17:45,471][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 01:17:46,353][valid][INFO] - {"epoch": 9, "valid_loss": "5.397", "valid_ppl": "42.14", "valid_wps": "282223", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "9819", "valid_best_loss": "5.397"}
[2023-03-28 01:17:46,354][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 9 @ 9819 updates
[2023-03-28 01:17:46,355][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 01:17:47,017][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 01:17:47,561][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 9 @ 9819 updates, score 5.397) (writing took 1.2066319559999101 seconds)
[2023-03-28 01:17:47,561][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2023-03-28 01:17:47,561][train][INFO] - {"epoch": 9, "train_loss": "5.947", "train_ppl": "61.69", "train_wps": "101394", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "9819", "train_lr": "0.00068733", "train_gnorm": "0.697", "train_train_wall": "905", "train_gb_free": "7.5", "train_wall": "10407"}
[2023-03-28 01:17:47,563][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 01:17:47,594][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 01:17:47,597][fairseq.trainer][INFO] - begin training epoch 10
[2023-03-28 01:17:47,597][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 01:20:58,624][train_inner][INFO] - {"epoch": 10, "update": 9.166, "loss": "5.764", "ppl": "54.35", "wps": "100430", "ups": "0.94", "wpb": "107055", "bsz": "255.8", "num_updates": "10000", "lr": "0.0007", "gnorm": "0.674", "train_wall": "166", "gb_free": "7.5", "wall": "10598"}
[2023-03-28 01:24:29,587][train_inner][INFO] - {"epoch": 10, "update": 9.349, "loss": "5.756", "ppl": "54.05", "wps": "101608", "ups": "0.95", "wpb": "107178", "bsz": "256", "num_updates": "10200", "lr": "0.000698783", "gnorm": "0.665", "train_wall": "166", "gb_free": "7.5", "wall": "10809"}
[2023-03-28 01:28:00,521][train_inner][INFO] - {"epoch": 10, "update": 9.533, "loss": "5.753", "ppl": "53.94", "wps": "101613", "ups": "0.95", "wpb": "107168", "bsz": "256", "num_updates": "10400", "lr": "0.000697565", "gnorm": "0.661", "train_wall": "166", "gb_free": "7.5", "wall": "11020"}
[2023-03-28 01:31:31,416][train_inner][INFO] - {"epoch": 10, "update": 9.716, "loss": "5.734", "ppl": "53.23", "wps": "101600", "ups": "0.95", "wpb": "107134", "bsz": "256", "num_updates": "10600", "lr": "0.000696348", "gnorm": "0.648", "train_wall": "166", "gb_free": "7.5", "wall": "11231"}
[2023-03-28 01:35:02,658][train_inner][INFO] - {"epoch": 10, "update": 9.899, "loss": "5.726", "ppl": "52.94", "wps": "101615", "ups": "0.95", "wpb": "107327", "bsz": "256", "num_updates": "10800", "lr": "0.00069513", "gnorm": "0.644", "train_wall": "166", "gb_free": "7.5", "wall": "11443"}
[2023-03-28 01:36:58,892][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 01:36:58,892][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 01:36:59,785][valid][INFO] - {"epoch": 10, "valid_loss": "5.246", "valid_ppl": "37.95", "valid_wps": "279258", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "10910", "valid_best_loss": "5.246"}
[2023-03-28 01:36:59,786][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 10910 updates
[2023-03-28 01:36:59,787][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 01:37:00,429][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 01:37:00,734][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 10 @ 10910 updates, score 5.246) (writing took 0.9474870470003225 seconds)
[2023-03-28 01:37:00,734][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2023-03-28 01:37:00,735][train][INFO] - {"epoch": 10, "train_loss": "5.741", "train_ppl": "53.49", "train_wps": "101426", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "10910", "train_lr": "0.000694461", "train_gnorm": "0.655", "train_train_wall": "905", "train_gb_free": "7.5", "train_wall": "11561"}
[2023-03-28 01:37:00,736][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 01:37:00,769][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 01:37:00,772][fairseq.trainer][INFO] - begin training epoch 11
[2023-03-28 01:37:00,772][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 01:38:36,115][train_inner][INFO] - {"epoch": 11, "update": 10.082, "loss": "5.655", "ppl": "50.37", "wps": "100660", "ups": "0.94", "wpb": "107433", "bsz": "255.8", "num_updates": "11000", "lr": "0.000693913", "gnorm": "0.634", "train_wall": "166", "gb_free": "7.5", "wall": "11656"}
[2023-03-28 01:42:07,028][train_inner][INFO] - {"epoch": 11, "update": 10.266, "loss": "5.597", "ppl": "48.42", "wps": "101590", "ups": "0.95", "wpb": "107133", "bsz": "256", "num_updates": "11200", "lr": "0.000692696", "gnorm": "0.645", "train_wall": "166", "gb_free": "7.5", "wall": "11867"}
[2023-03-28 01:45:38,256][train_inner][INFO] - {"epoch": 11, "update": 10.449, "loss": "5.604", "ppl": "48.65", "wps": "101704", "ups": "0.95", "wpb": "107414", "bsz": "256", "num_updates": "11400", "lr": "0.000691478", "gnorm": "0.621", "train_wall": "166", "gb_free": "7.5", "wall": "12078"}
[2023-03-28 01:49:08,931][train_inner][INFO] - {"epoch": 11, "update": 10.632, "loss": "5.601", "ppl": "48.53", "wps": "101587", "ups": "0.95", "wpb": "107009", "bsz": "256", "num_updates": "11600", "lr": "0.000690261", "gnorm": "0.621", "train_wall": "166", "gb_free": "7.5", "wall": "12289"}
[2023-03-28 01:52:39,711][train_inner][INFO] - {"epoch": 11, "update": 10.816, "loss": "5.592", "ppl": "48.24", "wps": "101693", "ups": "0.95", "wpb": "107174", "bsz": "256", "num_updates": "11800", "lr": "0.000689043", "gnorm": "0.62", "train_wall": "166", "gb_free": "7.5", "wall": "12500"}
[2023-03-28 01:56:10,946][train_inner][INFO] - {"epoch": 11, "update": 10.999, "loss": "5.6", "ppl": "48.5", "wps": "101596", "ups": "0.95", "wpb": "107303", "bsz": "256", "num_updates": "12000", "lr": "0.000687826", "gnorm": "0.602", "train_wall": "166", "gb_free": "7.5", "wall": "12711"}
[2023-03-28 01:56:11,823][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 01:56:11,824][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 01:56:12,870][valid][INFO] - {"epoch": 11, "valid_loss": "5.15", "valid_ppl": "35.5", "valid_wps": "237979", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "12001", "valid_best_loss": "5.15"}
[2023-03-28 01:56:12,871][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 11 @ 12001 updates
[2023-03-28 01:56:12,872][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 01:56:13,120][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 01:56:13,268][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 11 @ 12001 updates, score 5.15) (writing took 0.3965472529998806 seconds)
[2023-03-28 01:56:13,268][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2023-03-28 01:56:13,269][train][INFO] - {"epoch": 11, "train_loss": "5.598", "train_ppl": "48.43", "train_wps": "101482", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "12001", "train_lr": "0.00068782", "train_gnorm": "0.624", "train_train_wall": "905", "train_gb_free": "7.5", "train_wall": "12713"}
[2023-03-28 01:56:13,271][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 01:56:13,303][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 01:56:13,306][fairseq.trainer][INFO] - begin training epoch 12
[2023-03-28 01:56:13,306][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 01:59:43,677][train_inner][INFO] - {"epoch": 12, "update": 11.182, "loss": "5.469", "ppl": "44.28", "wps": "100877", "ups": "0.94", "wpb": "107298", "bsz": "255.8", "num_updates": "12200", "lr": "0.000686609", "gnorm": "0.611", "train_wall": "166", "gb_free": "7.5", "wall": "12924"}
[2023-03-28 02:03:14,452][train_inner][INFO] - {"epoch": 12, "update": 11.366, "loss": "5.495", "ppl": "45.09", "wps": "101647", "ups": "0.95", "wpb": "107124", "bsz": "256", "num_updates": "12400", "lr": "0.000685391", "gnorm": "0.613", "train_wall": "166", "gb_free": "7.5", "wall": "13134"}
[2023-03-28 02:06:45,113][train_inner][INFO] - {"epoch": 12, "update": 11.549, "loss": "5.5", "ppl": "45.25", "wps": "101601", "ups": "0.95", "wpb": "107016", "bsz": "256", "num_updates": "12600", "lr": "0.000684174", "gnorm": "0.6", "train_wall": "166", "gb_free": "7.5", "wall": "13345"}
[2023-03-28 02:10:16,041][train_inner][INFO] - {"epoch": 12, "update": 11.732, "loss": "5.508", "ppl": "45.5", "wps": "101686", "ups": "0.95", "wpb": "107242", "bsz": "256", "num_updates": "12800", "lr": "0.000682957", "gnorm": "0.598", "train_wall": "166", "gb_free": "7.5", "wall": "13556"}
[2023-03-28 02:13:47,083][train_inner][INFO] - {"epoch": 12, "update": 11.916, "loss": "5.501", "ppl": "45.28", "wps": "101676", "ups": "0.95", "wpb": "107290", "bsz": "256", "num_updates": "13000", "lr": "0.000681739", "gnorm": "0.59", "train_wall": "166", "gb_free": "7.5", "wall": "13767"}
[2023-03-28 02:15:24,187][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 02:15:24,188][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 02:15:25,079][valid][INFO] - {"epoch": 12, "valid_loss": "5.067", "valid_ppl": "33.53", "valid_wps": "279731", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "13092", "valid_best_loss": "5.067"}
[2023-03-28 02:15:25,080][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 12 @ 13092 updates
[2023-03-28 02:15:25,081][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 02:15:25,554][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 02:15:25,755][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 12 @ 13092 updates, score 5.067) (writing took 0.6746545579990197 seconds)
[2023-03-28 02:15:25,755][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2023-03-28 02:15:25,756][train][INFO] - {"epoch": 12, "train_loss": "5.495", "train_ppl": "45.1", "train_wps": "101487", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "13092", "train_lr": "0.000681179", "train_gnorm": "0.601", "train_train_wall": "905", "train_gb_free": "7.5", "train_wall": "13866"}
[2023-03-28 02:15:25,758][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 02:15:25,791][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 02:15:25,793][fairseq.trainer][INFO] - begin training epoch 13
[2023-03-28 02:15:25,794][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 02:17:19,909][train_inner][INFO] - {"epoch": 13, "update": 12.099, "loss": "5.433", "ppl": "43.2", "wps": "100752", "ups": "0.94", "wpb": "107213", "bsz": "255.8", "num_updates": "13200", "lr": "0.000680522", "gnorm": "0.594", "train_wall": "166", "gb_free": "7.5", "wall": "13980"}
[2023-03-28 02:20:50,611][train_inner][INFO] - {"epoch": 13, "update": 12.282, "loss": "5.4", "ppl": "42.22", "wps": "101495", "ups": "0.95", "wpb": "106926", "bsz": "256", "num_updates": "13400", "lr": "0.000679304", "gnorm": "0.592", "train_wall": "166", "gb_free": "7.5", "wall": "14190"}
[2023-03-28 02:24:21,683][train_inner][INFO] - {"epoch": 13, "update": 12.466, "loss": "5.412", "ppl": "42.56", "wps": "101626", "ups": "0.95", "wpb": "107252", "bsz": "256", "num_updates": "13600", "lr": "0.000678087", "gnorm": "0.587", "train_wall": "166", "gb_free": "7.5", "wall": "14402"}
[2023-03-28 02:27:52,608][train_inner][INFO] - {"epoch": 13, "update": 12.649, "loss": "5.431", "ppl": "43.13", "wps": "101678", "ups": "0.95", "wpb": "107232", "bsz": "256", "num_updates": "13800", "lr": "0.00067687", "gnorm": "0.583", "train_wall": "166", "gb_free": "7.5", "wall": "14612"}
[2023-03-28 02:31:23,852][train_inner][INFO] - {"epoch": 13, "update": 12.832, "loss": "5.438", "ppl": "43.36", "wps": "101620", "ups": "0.95", "wpb": "107333", "bsz": "256", "num_updates": "14000", "lr": "0.000675652", "gnorm": "0.58", "train_wall": "166", "gb_free": "7.5", "wall": "14824"}
[2023-03-28 02:34:36,994][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 02:34:36,995][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 02:34:37,939][valid][INFO] - {"epoch": 13, "valid_loss": "5.008", "valid_ppl": "32.17", "valid_wps": "264457", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "14183", "valid_best_loss": "5.008"}
[2023-03-28 02:34:37,940][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 13 @ 14183 updates
[2023-03-28 02:34:37,941][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 02:34:38,296][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 02:34:38,492][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 13 @ 14183 updates, score 5.008) (writing took 0.5517916709977726 seconds)
[2023-03-28 02:34:38,492][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2023-03-28 02:34:38,492][train][INFO] - {"epoch": 13, "train_loss": "5.418", "train_ppl": "42.76", "train_wps": "101465", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "14183", "train_lr": "0.000674538", "train_gnorm": "0.586", "train_train_wall": "905", "train_gb_free": "7.5", "train_wall": "15018"}
[2023-03-28 02:34:38,494][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 02:34:38,526][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 02:34:38,528][fairseq.trainer][INFO] - begin training epoch 14
[2023-03-28 02:34:38,529][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 02:34:56,815][train_inner][INFO] - {"epoch": 14, "update": 13.016, "loss": "5.423", "ppl": "42.9", "wps": "100721", "ups": "0.94", "wpb": "107249", "bsz": "255.8", "num_updates": "14200", "lr": "0.000674435", "gnorm": "0.579", "train_wall": "166", "gb_free": "7.5", "wall": "15037"}
[2023-03-28 02:38:27,763][train_inner][INFO] - {"epoch": 14, "update": 13.199, "loss": "5.32", "ppl": "39.95", "wps": "101628", "ups": "0.95", "wpb": "107191", "bsz": "256", "num_updates": "14400", "lr": "0.000673217", "gnorm": "0.582", "train_wall": "166", "gb_free": "7.5", "wall": "15248"}
[2023-03-28 02:41:58,754][train_inner][INFO] - {"epoch": 14, "update": 13.382, "loss": "5.351", "ppl": "40.8", "wps": "101706", "ups": "0.95", "wpb": "107294", "bsz": "256", "num_updates": "14600", "lr": "0.000672", "gnorm": "0.575", "train_wall": "166", "gb_free": "7.5", "wall": "15459"}
[2023-03-28 02:45:29,750][train_inner][INFO] - {"epoch": 14, "update": 13.566, "loss": "5.364", "ppl": "41.18", "wps": "101653", "ups": "0.95", "wpb": "107242", "bsz": "256", "num_updates": "14800", "lr": "0.000670783", "gnorm": "0.572", "train_wall": "166", "gb_free": "7.5", "wall": "15670"}
[2023-03-28 02:49:00,611][train_inner][INFO] - {"epoch": 14, "update": 13.749, "loss": "5.383", "ppl": "41.73", "wps": "101653", "ups": "0.95", "wpb": "107174", "bsz": "256", "num_updates": "15000", "lr": "0.000669565", "gnorm": "0.569", "train_wall": "166", "gb_free": "7.5", "wall": "15880"}
[2023-03-28 02:52:31,265][train_inner][INFO] - {"epoch": 14, "update": 13.932, "loss": "5.376", "ppl": "41.52", "wps": "101698", "ups": "0.95", "wpb": "107115", "bsz": "256", "num_updates": "15200", "lr": "0.000668348", "gnorm": "0.562", "train_wall": "166", "gb_free": "7.5", "wall": "16091"}
[2023-03-28 02:53:49,209][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 02:53:49,210][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 02:53:50,095][valid][INFO] - {"epoch": 14, "valid_loss": "4.958", "valid_ppl": "31.07", "valid_wps": "283523", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "15274", "valid_best_loss": "4.958"}
[2023-03-28 02:53:50,096][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 14 @ 15274 updates
[2023-03-28 02:53:50,097][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 02:53:50,351][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 02:53:50,522][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 14 @ 15274 updates, score 4.958) (writing took 0.4258315550032421 seconds)
[2023-03-28 02:53:50,522][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2023-03-28 02:53:50,522][train][INFO] - {"epoch": 14, "train_loss": "5.359", "train_ppl": "41.04", "train_wps": "101527", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "15274", "train_lr": "0.000667897", "train_gnorm": "0.572", "train_train_wall": "904", "train_gb_free": "7.5", "train_wall": "16170"}
[2023-03-28 02:53:50,524][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 02:53:50,555][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 02:53:50,557][fairseq.trainer][INFO] - begin training epoch 15
[2023-03-28 02:53:50,557][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 02:56:03,503][train_inner][INFO] - {"epoch": 15, "update": 14.115, "loss": "5.299", "ppl": "39.37", "wps": "101132", "ups": "0.94", "wpb": "107320", "bsz": "255.8", "num_updates": "15400", "lr": "0.00066713", "gnorm": "0.568", "train_wall": "166", "gb_free": "7.5", "wall": "16303"}
[2023-03-28 02:59:34,393][train_inner][INFO] - {"epoch": 15, "update": 14.299, "loss": "5.293", "ppl": "39.2", "wps": "101798", "ups": "0.95", "wpb": "107340", "bsz": "256", "num_updates": "15600", "lr": "0.000665913", "gnorm": "0.571", "train_wall": "166", "gb_free": "7.5", "wall": "16514"}
[2023-03-28 03:03:04,836][train_inner][INFO] - {"epoch": 15, "update": 14.482, "loss": "5.316", "ppl": "39.84", "wps": "101762", "ups": "0.95", "wpb": "107075", "bsz": "256", "num_updates": "15800", "lr": "0.000664696", "gnorm": "0.57", "train_wall": "165", "gb_free": "7.5", "wall": "16725"}
[2023-03-28 03:06:35,815][train_inner][INFO] - {"epoch": 15, "update": 14.665, "loss": "5.325", "ppl": "40.09", "wps": "101911", "ups": "0.95", "wpb": "107505", "bsz": "256", "num_updates": "16000", "lr": "0.000663478", "gnorm": "0.564", "train_wall": "166", "gb_free": "7.5", "wall": "16936"}
[2023-03-28 03:10:06,099][train_inner][INFO] - {"epoch": 15, "update": 14.849, "loss": "5.329", "ppl": "40.21", "wps": "101672", "ups": "0.95", "wpb": "106900", "bsz": "256", "num_updates": "16200", "lr": "0.000662261", "gnorm": "0.568", "train_wall": "165", "gb_free": "7.5", "wall": "17146"}
[2023-03-28 03:12:59,700][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 03:12:59,700][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 03:13:00,625][valid][INFO] - {"epoch": 15, "valid_loss": "4.921", "valid_ppl": "30.29", "valid_wps": "269884", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "16365", "valid_best_loss": "4.921"}
[2023-03-28 03:13:00,626][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 15 @ 16365 updates
[2023-03-28 03:13:00,627][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 03:13:00,936][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 03:13:01,152][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 15 @ 16365 updates, score 4.921) (writing took 0.5260463410013472 seconds)
[2023-03-28 03:13:01,153][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2023-03-28 03:13:01,153][train][INFO] - {"epoch": 15, "train_loss": "5.311", "train_ppl": "39.7", "train_wps": "101650", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "16365", "train_lr": "0.000661257", "train_gnorm": "0.566", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "17321"}
[2023-03-28 03:13:01,155][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 03:13:01,186][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 03:13:01,189][fairseq.trainer][INFO] - begin training epoch 16
[2023-03-28 03:13:01,189][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 03:13:38,344][train_inner][INFO] - {"epoch": 16, "update": 15.032, "loss": "5.31", "ppl": "39.67", "wps": "100885", "ups": "0.94", "wpb": "107062", "bsz": "255.8", "num_updates": "16400", "lr": "0.000661043", "gnorm": "0.557", "train_wall": "165", "gb_free": "7.5", "wall": "17358"}
[2023-03-28 03:17:09,025][train_inner][INFO] - {"epoch": 16, "update": 15.215, "loss": "5.234", "ppl": "37.64", "wps": "101736", "ups": "0.95", "wpb": "107169", "bsz": "256", "num_updates": "16600", "lr": "0.000659826", "gnorm": "0.566", "train_wall": "166", "gb_free": "7.5", "wall": "17569"}
[2023-03-28 03:20:39,609][train_inner][INFO] - {"epoch": 16, "update": 15.399, "loss": "5.267", "ppl": "38.49", "wps": "101820", "ups": "0.95", "wpb": "107208", "bsz": "256", "num_updates": "16800", "lr": "0.000658609", "gnorm": "0.56", "train_wall": "166", "gb_free": "7.5", "wall": "17779"}
[2023-03-28 03:24:10,820][train_inner][INFO] - {"epoch": 16, "update": 15.582, "loss": "5.284", "ppl": "38.95", "wps": "101811", "ups": "0.95", "wpb": "107518", "bsz": "256", "num_updates": "17000", "lr": "0.000657391", "gnorm": "0.561", "train_wall": "166", "gb_free": "7.5", "wall": "17991"}
[2023-03-28 03:27:41,404][train_inner][INFO] - {"epoch": 16, "update": 15.765, "loss": "5.287", "ppl": "39.05", "wps": "101755", "ups": "0.95", "wpb": "107140", "bsz": "256", "num_updates": "17200", "lr": "0.000656174", "gnorm": "0.554", "train_wall": "165", "gb_free": "7.5", "wall": "18201"}
[2023-03-28 03:31:11,825][train_inner][INFO] - {"epoch": 16, "update": 15.949, "loss": "5.296", "ppl": "39.29", "wps": "101794", "ups": "0.95", "wpb": "107098", "bsz": "256", "num_updates": "17400", "lr": "0.000654957", "gnorm": "0.554", "train_wall": "165", "gb_free": "7.5", "wall": "18412"}
[2023-03-28 03:32:10,708][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 03:32:10,708][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 03:32:11,578][valid][INFO] - {"epoch": 16, "valid_loss": "4.895", "valid_ppl": "29.76", "valid_wps": "286182", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "17456", "valid_best_loss": "4.895"}
[2023-03-28 03:32:11,579][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 16 @ 17456 updates
[2023-03-28 03:32:11,580][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 03:32:11,809][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 03:32:11,954][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 16 @ 17456 updates, score 4.895) (writing took 0.37490429200261133 seconds)
[2023-03-28 03:32:11,954][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2023-03-28 03:32:11,955][train][INFO] - {"epoch": 16, "train_loss": "5.273", "train_ppl": "38.65", "train_wps": "101635", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "17456", "train_lr": "0.000654616", "train_gnorm": "0.559", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "18472"}
[2023-03-28 03:32:11,957][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 03:32:11,987][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 03:32:11,989][fairseq.trainer][INFO] - begin training epoch 17
[2023-03-28 03:32:11,989][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 03:34:43,649][train_inner][INFO] - {"epoch": 17, "update": 16.132, "loss": "5.22", "ppl": "37.27", "wps": "100975", "ups": "0.94", "wpb": "106945", "bsz": "255.8", "num_updates": "17600", "lr": "0.000653739", "gnorm": "0.559", "train_wall": "165", "gb_free": "7.5", "wall": "18623"}
[2023-03-28 03:38:14,715][train_inner][INFO] - {"epoch": 17, "update": 16.315, "loss": "5.213", "ppl": "37.09", "wps": "101884", "ups": "0.95", "wpb": "107521", "bsz": "256", "num_updates": "17800", "lr": "0.000652522", "gnorm": "0.558", "train_wall": "166", "gb_free": "7.5", "wall": "18835"}
[2023-03-28 03:41:45,043][train_inner][INFO] - {"epoch": 17, "update": 16.499, "loss": "5.234", "ppl": "37.65", "wps": "101770", "ups": "0.95", "wpb": "107025", "bsz": "256", "num_updates": "18000", "lr": "0.000651304", "gnorm": "0.555", "train_wall": "165", "gb_free": "7.5", "wall": "19045"}
[2023-03-28 03:45:15,997][train_inner][INFO] - {"epoch": 17, "update": 16.682, "loss": "5.253", "ppl": "38.13", "wps": "101844", "ups": "0.95", "wpb": "107422", "bsz": "256", "num_updates": "18200", "lr": "0.000650087", "gnorm": "0.551", "train_wall": "166", "gb_free": "7.5", "wall": "19256"}
[2023-03-28 03:48:46,509][train_inner][INFO] - {"epoch": 17, "update": 16.865, "loss": "5.267", "ppl": "38.51", "wps": "101807", "ups": "0.95", "wpb": "107158", "bsz": "256", "num_updates": "18400", "lr": "0.00064887", "gnorm": "0.554", "train_wall": "165", "gb_free": "7.5", "wall": "19466"}
[2023-03-28 03:51:21,157][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 03:51:21,158][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 03:51:22,074][valid][INFO] - {"epoch": 17, "valid_loss": "4.874", "valid_ppl": "29.31", "valid_wps": "272626", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "18547", "valid_best_loss": "4.874"}
[2023-03-28 03:51:22,075][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 17 @ 18547 updates
[2023-03-28 03:51:22,076][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 03:51:22,629][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 03:51:23,088][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 17 @ 18547 updates, score 4.874) (writing took 1.0131152110006951 seconds)
[2023-03-28 03:51:23,088][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2023-03-28 03:51:23,089][train][INFO] - {"epoch": 17, "train_loss": "5.239", "train_ppl": "37.76", "train_wps": "101606", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "18547", "train_lr": "0.000647975", "train_gnorm": "0.555", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "19623"}
[2023-03-28 03:51:23,090][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 03:51:23,122][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 03:51:23,124][fairseq.trainer][INFO] - begin training epoch 18
[2023-03-28 03:51:23,124][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 03:52:19,547][train_inner][INFO] - {"epoch": 18, "update": 17.049, "loss": "5.236", "ppl": "37.69", "wps": "100630", "ups": "0.94", "wpb": "107190", "bsz": "255.8", "num_updates": "18600", "lr": "0.000647652", "gnorm": "0.548", "train_wall": "166", "gb_free": "7.5", "wall": "19679"}
[2023-03-28 03:55:50,188][train_inner][INFO] - {"epoch": 18, "update": 17.232, "loss": "5.176", "ppl": "36.16", "wps": "101765", "ups": "0.95", "wpb": "107180", "bsz": "256", "num_updates": "18800", "lr": "0.000646435", "gnorm": "0.554", "train_wall": "166", "gb_free": "7.5", "wall": "19890"}
[2023-03-28 03:59:20,755][train_inner][INFO] - {"epoch": 18, "update": 17.415, "loss": "5.196", "ppl": "36.67", "wps": "101760", "ups": "0.95", "wpb": "107136", "bsz": "256", "num_updates": "19000", "lr": "0.000645217", "gnorm": "0.553", "train_wall": "166", "gb_free": "7.5", "wall": "20101"}
[2023-03-28 04:02:51,129][train_inner][INFO] - {"epoch": 18, "update": 17.599, "loss": "5.223", "ppl": "37.34", "wps": "101748", "ups": "0.95", "wpb": "107025", "bsz": "256", "num_updates": "19200", "lr": "0.000644", "gnorm": "0.55", "train_wall": "165", "gb_free": "7.5", "wall": "20311"}
[2023-03-28 04:06:21,827][train_inner][INFO] - {"epoch": 18, "update": 17.782, "loss": "5.232", "ppl": "37.59", "wps": "101777", "ups": "0.95", "wpb": "107221", "bsz": "256", "num_updates": "19400", "lr": "0.000642783", "gnorm": "0.548", "train_wall": "166", "gb_free": "7.5", "wall": "20522"}
[2023-03-28 04:09:52,553][train_inner][INFO] - {"epoch": 18, "update": 17.965, "loss": "5.238", "ppl": "37.75", "wps": "101838", "ups": "0.95", "wpb": "107300", "bsz": "256", "num_updates": "19600", "lr": "0.000641565", "gnorm": "0.547", "train_wall": "166", "gb_free": "7.5", "wall": "20732"}
[2023-03-28 04:10:32,726][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 04:10:32,727][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 04:10:33,604][valid][INFO] - {"epoch": 18, "valid_loss": "4.845", "valid_ppl": "28.74", "valid_wps": "284188", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "19638", "valid_best_loss": "4.845"}
[2023-03-28 04:10:33,605][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 18 @ 19638 updates
[2023-03-28 04:10:33,606][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 04:10:33,873][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 04:10:34,061][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 18 @ 19638 updates, score 4.845) (writing took 0.4552130010051769 seconds)
[2023-03-28 04:10:34,061][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2023-03-28 04:10:34,061][train][INFO] - {"epoch": 18, "train_loss": "5.211", "train_ppl": "37.03", "train_wps": "101620", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "19638", "train_lr": "0.000641334", "train_gnorm": "0.55", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "20774"}
[2023-03-28 04:10:34,063][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 04:10:34,094][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 04:10:34,096][fairseq.trainer][INFO] - begin training epoch 19
[2023-03-28 04:10:34,096][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 04:13:24,477][train_inner][INFO] - {"epoch": 19, "update": 18.148, "loss": "5.148", "ppl": "35.46", "wps": "101032", "ups": "0.94", "wpb": "107055", "bsz": "255.8", "num_updates": "19800", "lr": "0.000640348", "gnorm": "0.552", "train_wall": "165", "gb_free": "7.5", "wall": "20944"}
[2023-03-28 04:16:55,606][train_inner][INFO] - {"epoch": 19, "update": 18.332, "loss": "5.164", "ppl": "35.86", "wps": "101946", "ups": "0.95", "wpb": "107619", "bsz": "256", "num_updates": "20000", "lr": "0.00063913", "gnorm": "0.549", "train_wall": "166", "gb_free": "7.5", "wall": "21155"}
[2023-03-28 04:20:26,312][train_inner][INFO] - {"epoch": 19, "update": 18.515, "loss": "5.194", "ppl": "36.61", "wps": "101861", "ups": "0.95", "wpb": "107314", "bsz": "256", "num_updates": "20200", "lr": "0.000637913", "gnorm": "0.546", "train_wall": "166", "gb_free": "7.5", "wall": "21366"}
[2023-03-28 04:23:56,777][train_inner][INFO] - {"epoch": 19, "update": 18.698, "loss": "5.2", "ppl": "36.76", "wps": "101728", "ups": "0.95", "wpb": "107051", "bsz": "256", "num_updates": "20400", "lr": "0.000636696", "gnorm": "0.547", "train_wall": "165", "gb_free": "7.5", "wall": "21577"}
[2023-03-28 04:27:27,375][train_inner][INFO] - {"epoch": 19, "update": 18.882, "loss": "5.215", "ppl": "37.14", "wps": "101839", "ups": "0.95", "wpb": "107235", "bsz": "256", "num_updates": "20600", "lr": "0.000635478", "gnorm": "0.546", "train_wall": "166", "gb_free": "7.5", "wall": "21787"}
[2023-03-28 04:29:43,040][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 04:29:43,040][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 04:29:43,970][valid][INFO] - {"epoch": 19, "valid_loss": "4.824", "valid_ppl": "28.33", "valid_wps": "268275", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "20729", "valid_best_loss": "4.824"}
[2023-03-28 04:29:43,971][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 19 @ 20729 updates
[2023-03-28 04:29:43,971][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 04:29:44,181][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 04:29:44,322][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 19 @ 20729 updates, score 4.824) (writing took 0.35180812700127717 seconds)
[2023-03-28 04:29:44,323][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2023-03-28 04:29:44,323][train][INFO] - {"epoch": 19, "train_loss": "5.187", "train_ppl": "36.42", "train_wps": "101683", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "20729", "train_lr": "0.000634693", "train_gnorm": "0.548", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "21924"}
[2023-03-28 04:29:44,325][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 04:29:44,355][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 04:29:44,357][fairseq.trainer][INFO] - begin training epoch 20
[2023-03-28 04:29:44,358][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 04:30:59,337][train_inner][INFO] - {"epoch": 20, "update": 19.065, "loss": "5.176", "ppl": "36.16", "wps": "100967", "ups": "0.94", "wpb": "107006", "bsz": "255.8", "num_updates": "20800", "lr": "0.000634261", "gnorm": "0.549", "train_wall": "165", "gb_free": "7.5", "wall": "21999"}
[2023-03-28 04:34:29,831][train_inner][INFO] - {"epoch": 20, "update": 19.248, "loss": "5.127", "ppl": "34.95", "wps": "101798", "ups": "0.95", "wpb": "107140", "bsz": "256", "num_updates": "21000", "lr": "0.000633043", "gnorm": "0.548", "train_wall": "165", "gb_free": "7.5", "wall": "22210"}
[2023-03-28 04:38:00,359][train_inner][INFO] - {"epoch": 20, "update": 19.432, "loss": "5.154", "ppl": "35.6", "wps": "101800", "ups": "0.95", "wpb": "107159", "bsz": "256", "num_updates": "21200", "lr": "0.000631826", "gnorm": "0.548", "train_wall": "166", "gb_free": "7.5", "wall": "22420"}
[2023-03-28 04:41:31,057][train_inner][INFO] - {"epoch": 20, "update": 19.615, "loss": "5.174", "ppl": "36.1", "wps": "101754", "ups": "0.95", "wpb": "107196", "bsz": "256", "num_updates": "21400", "lr": "0.000630609", "gnorm": "0.546", "train_wall": "166", "gb_free": "7.5", "wall": "22631"}
[2023-03-28 04:45:01,558][train_inner][INFO] - {"epoch": 20, "update": 19.798, "loss": "5.187", "ppl": "36.42", "wps": "101826", "ups": "0.95", "wpb": "107173", "bsz": "256", "num_updates": "21600", "lr": "0.000629391", "gnorm": "0.545", "train_wall": "165", "gb_free": "7.5", "wall": "22841"}
[2023-03-28 04:48:32,670][train_inner][INFO] - {"epoch": 20, "update": 19.982, "loss": "5.202", "ppl": "36.81", "wps": "101812", "ups": "0.95", "wpb": "107468", "bsz": "256", "num_updates": "21800", "lr": "0.000628174", "gnorm": "0.544", "train_wall": "166", "gb_free": "7.5", "wall": "23053"}
[2023-03-28 04:48:53,781][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 04:48:53,782][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 04:48:54,654][valid][INFO] - {"epoch": 20, "valid_loss": "4.811", "valid_ppl": "28.08", "valid_wps": "285591", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "21820", "valid_best_loss": "4.811"}
[2023-03-28 04:48:54,655][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 21820 updates
[2023-03-28 04:48:54,656][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 04:48:55,122][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 04:48:55,381][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 20 @ 21820 updates, score 4.811) (writing took 0.7260273439969751 seconds)
[2023-03-28 04:48:55,381][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2023-03-28 04:48:55,382][train][INFO] - {"epoch": 20, "train_loss": "5.164", "train_ppl": "35.86", "train_wps": "101613", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "21820", "train_lr": "0.000628052", "train_gnorm": "0.547", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "23075"}
[2023-03-28 04:48:55,384][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 04:48:55,414][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 04:48:55,417][fairseq.trainer][INFO] - begin training epoch 21
[2023-03-28 04:48:55,417][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 04:52:04,782][train_inner][INFO] - {"epoch": 21, "update": 20.165, "loss": "5.096", "ppl": "34.19", "wps": "100896", "ups": "0.94", "wpb": "107006", "bsz": "255.8", "num_updates": "22000", "lr": "0.000626957", "gnorm": "0.545", "train_wall": "165", "gb_free": "7.5", "wall": "23265"}
[2023-03-28 04:55:35,422][train_inner][INFO] - {"epoch": 21, "update": 20.348, "loss": "5.124", "ppl": "34.86", "wps": "101744", "ups": "0.95", "wpb": "107157", "bsz": "256", "num_updates": "22200", "lr": "0.000625739", "gnorm": "0.545", "train_wall": "166", "gb_free": "7.5", "wall": "23475"}
[2023-03-28 04:59:06,043][train_inner][INFO] - {"epoch": 21, "update": 20.532, "loss": "5.147", "ppl": "35.42", "wps": "101838", "ups": "0.95", "wpb": "107247", "bsz": "256", "num_updates": "22400", "lr": "0.000624522", "gnorm": "0.543", "train_wall": "166", "gb_free": "7.5", "wall": "23686"}
[2023-03-28 05:02:36,805][train_inner][INFO] - {"epoch": 21, "update": 20.715, "loss": "5.169", "ppl": "35.97", "wps": "101857", "ups": "0.95", "wpb": "107338", "bsz": "256", "num_updates": "22600", "lr": "0.000623304", "gnorm": "0.547", "train_wall": "166", "gb_free": "7.5", "wall": "23897"}
[2023-03-28 05:06:07,342][train_inner][INFO] - {"epoch": 21, "update": 20.898, "loss": "5.174", "ppl": "36.1", "wps": "101797", "ups": "0.95", "wpb": "107160", "bsz": "256", "num_updates": "22800", "lr": "0.000622087", "gnorm": "0.539", "train_wall": "165", "gb_free": "7.5", "wall": "24107"}
[2023-03-28 05:08:04,299][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 05:08:04,300][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 05:08:05,170][valid][INFO] - {"epoch": 21, "valid_loss": "4.8", "valid_ppl": "27.86", "valid_wps": "286222", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "22911", "valid_best_loss": "4.8"}
[2023-03-28 05:08:05,171][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 21 @ 22911 updates
[2023-03-28 05:08:05,172][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 05:08:05,676][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 05:08:06,016][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 21 @ 22911 updates, score 4.8) (writing took 0.8450454350022483 seconds)
[2023-03-28 05:08:06,017][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2023-03-28 05:08:06,017][train][INFO] - {"epoch": 21, "train_loss": "5.145", "train_ppl": "35.38", "train_wps": "101650", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "22911", "train_lr": "0.000621411", "train_gnorm": "0.544", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "24226"}
[2023-03-28 05:08:06,019][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 05:08:06,050][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 05:08:06,052][fairseq.trainer][INFO] - begin training epoch 22
[2023-03-28 05:08:06,052][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 05:09:40,069][train_inner][INFO] - {"epoch": 22, "update": 21.082, "loss": "5.127", "ppl": "34.94", "wps": "100868", "ups": "0.94", "wpb": "107286", "bsz": "255.8", "num_updates": "23000", "lr": "0.00062087", "gnorm": "0.542", "train_wall": "166", "gb_free": "7.5", "wall": "24320"}
[2023-03-28 05:13:10,265][train_inner][INFO] - {"epoch": 22, "update": 21.265, "loss": "5.093", "ppl": "34.14", "wps": "101712", "ups": "0.95", "wpb": "106897", "bsz": "256", "num_updates": "23200", "lr": "0.000619652", "gnorm": "0.548", "train_wall": "165", "gb_free": "7.5", "wall": "24530"}
[2023-03-28 05:16:40,643][train_inner][INFO] - {"epoch": 22, "update": 21.448, "loss": "5.121", "ppl": "34.8", "wps": "101827", "ups": "0.95", "wpb": "107111", "bsz": "256", "num_updates": "23400", "lr": "0.000618435", "gnorm": "0.545", "train_wall": "165", "gb_free": "7.5", "wall": "24740"}
[2023-03-28 05:20:11,377][train_inner][INFO] - {"epoch": 22, "update": 21.632, "loss": "5.138", "ppl": "35.21", "wps": "101855", "ups": "0.95", "wpb": "107322", "bsz": "256", "num_updates": "23600", "lr": "0.000617217", "gnorm": "0.544", "train_wall": "166", "gb_free": "7.5", "wall": "24951"}
[2023-03-28 05:23:42,202][train_inner][INFO] - {"epoch": 22, "update": 21.815, "loss": "5.151", "ppl": "35.54", "wps": "101849", "ups": "0.95", "wpb": "107361", "bsz": "256", "num_updates": "23800", "lr": "0.000616", "gnorm": "0.542", "train_wall": "166", "gb_free": "7.5", "wall": "25162"}
[2023-03-28 05:27:13,229][train_inner][INFO] - {"epoch": 22, "update": 21.998, "loss": "5.164", "ppl": "35.86", "wps": "101795", "ups": "0.95", "wpb": "107407", "bsz": "256", "num_updates": "24000", "lr": "0.000614783", "gnorm": "0.537", "train_wall": "166", "gb_free": "7.5", "wall": "25373"}
[2023-03-28 05:27:15,236][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 05:27:15,237][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 05:27:16,254][valid][INFO] - {"epoch": 22, "valid_loss": "4.788", "valid_ppl": "27.62", "valid_wps": "245090", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "24002", "valid_best_loss": "4.788"}
[2023-03-28 05:27:16,255][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 22 @ 24002 updates
[2023-03-28 05:27:16,256][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 05:27:16,494][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 05:27:16,643][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 22 @ 24002 updates, score 4.788) (writing took 0.3880851539943251 seconds)
[2023-03-28 05:27:16,643][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2023-03-28 05:27:16,644][train][INFO] - {"epoch": 22, "train_loss": "5.128", "train_ppl": "34.96", "train_wps": "101651", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "24002", "train_lr": "0.00061477", "train_gnorm": "0.543", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "25376"}
[2023-03-28 05:27:16,646][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 05:27:16,675][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 05:27:16,677][fairseq.trainer][INFO] - begin training epoch 23
[2023-03-28 05:27:16,677][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 05:30:45,326][train_inner][INFO] - {"epoch": 23, "update": 22.181, "loss": "5.052", "ppl": "33.18", "wps": "101046", "ups": "0.94", "wpb": "107158", "bsz": "255.8", "num_updates": "24200", "lr": "0.000613565", "gnorm": "0.546", "train_wall": "166", "gb_free": "7.5", "wall": "25585"}
[2023-03-28 05:34:15,700][train_inner][INFO] - {"epoch": 23, "update": 22.365, "loss": "5.099", "ppl": "34.28", "wps": "101708", "ups": "0.95", "wpb": "106984", "bsz": "256", "num_updates": "24400", "lr": "0.000612348", "gnorm": "0.545", "train_wall": "165", "gb_free": "7.5", "wall": "25796"}
[2023-03-28 05:37:46,599][train_inner][INFO] - {"epoch": 23, "update": 22.548, "loss": "5.114", "ppl": "34.64", "wps": "101789", "ups": "0.95", "wpb": "107336", "bsz": "256", "num_updates": "24600", "lr": "0.00061113", "gnorm": "0.54", "train_wall": "166", "gb_free": "7.5", "wall": "26006"}
[2023-03-28 05:41:17,223][train_inner][INFO] - {"epoch": 23, "update": 22.731, "loss": "5.133", "ppl": "35.09", "wps": "101739", "ups": "0.95", "wpb": "107144", "bsz": "256", "num_updates": "24800", "lr": "0.000609913", "gnorm": "0.54", "train_wall": "165", "gb_free": "7.5", "wall": "26217"}
[2023-03-28 05:44:47,991][train_inner][INFO] - {"epoch": 23, "update": 22.915, "loss": "5.14", "ppl": "35.25", "wps": "101768", "ups": "0.95", "wpb": "107248", "bsz": "256", "num_updates": "25000", "lr": "0.000608696", "gnorm": "0.54", "train_wall": "166", "gb_free": "7.5", "wall": "26428"}
[2023-03-28 05:46:26,163][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 05:46:26,164][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 05:46:27,038][valid][INFO] - {"epoch": 23, "valid_loss": "4.766", "valid_ppl": "27.22", "valid_wps": "285667", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "25093", "valid_best_loss": "4.766"}
[2023-03-28 05:46:27,039][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 23 @ 25093 updates
[2023-03-28 05:46:27,040][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 05:46:27,394][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 05:46:27,623][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 23 @ 25093 updates, score 4.766) (writing took 0.5837299249978969 seconds)
[2023-03-28 05:46:27,623][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2023-03-28 05:46:27,624][train][INFO] - {"epoch": 23, "train_loss": "5.111", "train_ppl": "34.56", "train_wps": "101620", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "25093", "train_lr": "0.00060813", "train_gnorm": "0.542", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "26527"}
[2023-03-28 05:46:27,625][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 05:46:27,657][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 05:46:27,659][fairseq.trainer][INFO] - begin training epoch 24
[2023-03-28 05:46:27,660][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 05:48:20,306][train_inner][INFO] - {"epoch": 24, "update": 23.098, "loss": "5.083", "ppl": "33.9", "wps": "100908", "ups": "0.94", "wpb": "107121", "bsz": "255.8", "num_updates": "25200", "lr": "0.000607478", "gnorm": "0.541", "train_wall": "166", "gb_free": "7.5", "wall": "26640"}
[2023-03-28 05:51:51,163][train_inner][INFO] - {"epoch": 24, "update": 23.281, "loss": "5.071", "ppl": "33.61", "wps": "101774", "ups": "0.95", "wpb": "107298", "bsz": "256", "num_updates": "25400", "lr": "0.000606261", "gnorm": "0.545", "train_wall": "166", "gb_free": "7.5", "wall": "26851"}
[2023-03-28 05:55:21,605][train_inner][INFO] - {"epoch": 24, "update": 23.465, "loss": "5.087", "ppl": "33.99", "wps": "101725", "ups": "0.95", "wpb": "107035", "bsz": "256", "num_updates": "25600", "lr": "0.000605043", "gnorm": "0.545", "train_wall": "165", "gb_free": "7.5", "wall": "27061"}
[2023-03-28 05:58:52,595][train_inner][INFO] - {"epoch": 24, "update": 23.648, "loss": "5.108", "ppl": "34.5", "wps": "101842", "ups": "0.95", "wpb": "107438", "bsz": "256", "num_updates": "25800", "lr": "0.000603826", "gnorm": "0.542", "train_wall": "166", "gb_free": "7.5", "wall": "27272"}
[2023-03-28 06:02:23,423][train_inner][INFO] - {"epoch": 24, "update": 23.831, "loss": "5.124", "ppl": "34.88", "wps": "101860", "ups": "0.95", "wpb": "107375", "bsz": "256", "num_updates": "26000", "lr": "0.000602609", "gnorm": "0.54", "train_wall": "166", "gb_free": "7.5", "wall": "27483"}
[2023-03-28 06:05:37,187][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 06:05:37,187][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 06:05:38,125][valid][INFO] - {"epoch": 24, "valid_loss": "4.766", "valid_ppl": "27.21", "valid_wps": "266803", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "26184", "valid_best_loss": "4.766"}
[2023-03-28 06:05:38,126][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 24 @ 26184 updates
[2023-03-28 06:05:38,127][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 06:05:38,355][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 06:05:38,500][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 24 @ 26184 updates, score 4.766) (writing took 0.3736784409993561 seconds)
[2023-03-28 06:05:38,500][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2023-03-28 06:05:38,500][train][INFO] - {"epoch": 24, "train_loss": "5.098", "train_ppl": "34.24", "train_wps": "101629", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "26184", "train_lr": "0.000601489", "train_gnorm": "0.543", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "27678"}
[2023-03-28 06:05:38,502][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 06:05:38,532][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 06:05:38,535][fairseq.trainer][INFO] - begin training epoch 25
[2023-03-28 06:05:38,535][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 06:05:55,681][train_inner][INFO] - {"epoch": 25, "update": 24.015, "loss": "5.127", "ppl": "34.94", "wps": "100870", "ups": "0.94", "wpb": "107052", "bsz": "255.8", "num_updates": "26200", "lr": "0.000601391", "gnorm": "0.54", "train_wall": "166", "gb_free": "7.5", "wall": "27696"}
[2023-03-28 06:09:26,222][train_inner][INFO] - {"epoch": 25, "update": 24.198, "loss": "5.035", "ppl": "32.78", "wps": "101725", "ups": "0.95", "wpb": "107086", "bsz": "256", "num_updates": "26400", "lr": "0.000600174", "gnorm": "0.543", "train_wall": "165", "gb_free": "7.5", "wall": "27906"}
[2023-03-28 06:12:56,829][train_inner][INFO] - {"epoch": 25, "update": 24.381, "loss": "5.069", "ppl": "33.57", "wps": "101798", "ups": "0.95", "wpb": "107197", "bsz": "256", "num_updates": "26600", "lr": "0.000598957", "gnorm": "0.546", "train_wall": "166", "gb_free": "7.5", "wall": "28117"}
[2023-03-28 06:16:27,773][train_inner][INFO] - {"epoch": 25, "update": 24.565, "loss": "5.085", "ppl": "33.95", "wps": "101922", "ups": "0.95", "wpb": "107500", "bsz": "256", "num_updates": "26800", "lr": "0.000597739", "gnorm": "0.542", "train_wall": "166", "gb_free": "7.5", "wall": "28328"}
[2023-03-28 06:19:58,115][train_inner][INFO] - {"epoch": 25, "update": 24.748, "loss": "5.103", "ppl": "34.37", "wps": "101701", "ups": "0.95", "wpb": "106960", "bsz": "256", "num_updates": "27000", "lr": "0.000596522", "gnorm": "0.545", "train_wall": "165", "gb_free": "7.5", "wall": "28538"}
[2023-03-28 06:23:29,013][train_inner][INFO] - {"epoch": 25, "update": 24.931, "loss": "5.122", "ppl": "34.83", "wps": "101853", "ups": "0.95", "wpb": "107403", "bsz": "256", "num_updates": "27200", "lr": "0.000595304", "gnorm": "0.539", "train_wall": "166", "gb_free": "7.5", "wall": "28749"}
[2023-03-28 06:24:47,936][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 06:24:47,937][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 06:24:48,810][valid][INFO] - {"epoch": 25, "valid_loss": "4.757", "valid_ppl": "27.04", "valid_wps": "285561", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "27275", "valid_best_loss": "4.757"}
[2023-03-28 06:24:48,811][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 25 @ 27275 updates
[2023-03-28 06:24:48,811][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 06:24:49,035][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 06:24:49,179][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 25 @ 27275 updates, score 4.757) (writing took 0.36879378400044516 seconds)
[2023-03-28 06:24:49,180][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2023-03-28 06:24:49,180][train][INFO] - {"epoch": 25, "train_loss": "5.085", "train_ppl": "33.94", "train_wps": "101646", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "27275", "train_lr": "0.000594848", "train_gnorm": "0.543", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "28829"}
[2023-03-28 06:24:49,182][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 06:24:49,213][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 06:24:49,215][fairseq.trainer][INFO] - begin training epoch 26
[2023-03-28 06:24:49,215][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 06:27:01,185][train_inner][INFO] - {"epoch": 26, "update": 25.115, "loss": "5.052", "ppl": "33.18", "wps": "101054", "ups": "0.94", "wpb": "107204", "bsz": "255.8", "num_updates": "27400", "lr": "0.000594087", "gnorm": "0.545", "train_wall": "166", "gb_free": "7.5", "wall": "28961"}
[2023-03-28 06:30:32,204][train_inner][INFO] - {"epoch": 26, "update": 25.298, "loss": "5.043", "ppl": "32.96", "wps": "101803", "ups": "0.95", "wpb": "107411", "bsz": "256", "num_updates": "27600", "lr": "0.00059287", "gnorm": "0.544", "train_wall": "166", "gb_free": "7.5", "wall": "29172"}
[2023-03-28 06:34:03,067][train_inner][INFO] - {"epoch": 26, "update": 25.481, "loss": "5.069", "ppl": "33.57", "wps": "101835", "ups": "0.95", "wpb": "107367", "bsz": "256", "num_updates": "27800", "lr": "0.000591652", "gnorm": "0.541", "train_wall": "166", "gb_free": "7.5", "wall": "29383"}
[2023-03-28 06:37:33,738][train_inner][INFO] - {"epoch": 26, "update": 25.665, "loss": "5.091", "ppl": "34.08", "wps": "101788", "ups": "0.95", "wpb": "107218", "bsz": "256", "num_updates": "28000", "lr": "0.000590435", "gnorm": "0.541", "train_wall": "166", "gb_free": "7.5", "wall": "29594"}
[2023-03-28 06:41:04,379][train_inner][INFO] - {"epoch": 26, "update": 25.848, "loss": "5.105", "ppl": "34.43", "wps": "101763", "ups": "0.95", "wpb": "107177", "bsz": "256", "num_updates": "28200", "lr": "0.000589217", "gnorm": "0.539", "train_wall": "166", "gb_free": "7.5", "wall": "29804"}
[2023-03-28 06:43:58,570][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 06:43:58,570][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 06:43:59,519][valid][INFO] - {"epoch": 26, "valid_loss": "4.746", "valid_ppl": "26.83", "valid_wps": "263004", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "28366", "valid_best_loss": "4.746"}
[2023-03-28 06:43:59,520][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 26 @ 28366 updates
[2023-03-28 06:43:59,521][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 06:43:59,752][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 06:43:59,902][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 26 @ 28366 updates, score 4.746) (writing took 0.3819909110025037 seconds)
[2023-03-28 06:43:59,903][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2023-03-28 06:43:59,903][train][INFO] - {"epoch": 26, "train_loss": "5.074", "train_ppl": "33.68", "train_wps": "101642", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "28366", "train_lr": "0.000588207", "train_gnorm": "0.542", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "29980"}
[2023-03-28 06:43:59,905][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 06:43:59,936][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 06:43:59,938][fairseq.trainer][INFO] - begin training epoch 27
[2023-03-28 06:43:59,938][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 06:44:36,119][train_inner][INFO] - {"epoch": 27, "update": 26.031, "loss": "5.087", "ppl": "33.99", "wps": "100858", "ups": "0.94", "wpb": "106778", "bsz": "255.8", "num_updates": "28400", "lr": "0.000588", "gnorm": "0.541", "train_wall": "165", "gb_free": "7.5", "wall": "30016"}
[2023-03-28 06:48:06,869][train_inner][INFO] - {"epoch": 27, "update": 26.214, "loss": "5.021", "ppl": "32.46", "wps": "101765", "ups": "0.95", "wpb": "107235", "bsz": "256", "num_updates": "28600", "lr": "0.000586783", "gnorm": "0.544", "train_wall": "166", "gb_free": "7.5", "wall": "30227"}
[2023-03-28 06:51:37,506][train_inner][INFO] - {"epoch": 27, "update": 26.398, "loss": "5.048", "ppl": "33.08", "wps": "101816", "ups": "0.95", "wpb": "107231", "bsz": "256", "num_updates": "28800", "lr": "0.000585565", "gnorm": "0.544", "train_wall": "166", "gb_free": "7.5", "wall": "30437"}
[2023-03-28 06:55:07,760][train_inner][INFO] - {"epoch": 27, "update": 26.581, "loss": "5.066", "ppl": "33.49", "wps": "101668", "ups": "0.95", "wpb": "106880", "bsz": "256", "num_updates": "29000", "lr": "0.000584348", "gnorm": "0.543", "train_wall": "165", "gb_free": "7.5", "wall": "30648"}
[2023-03-28 06:58:38,777][train_inner][INFO] - {"epoch": 27, "update": 26.764, "loss": "5.085", "ppl": "33.93", "wps": "101916", "ups": "0.95", "wpb": "107530", "bsz": "256", "num_updates": "29200", "lr": "0.00058313", "gnorm": "0.54", "train_wall": "166", "gb_free": "7.5", "wall": "30859"}
[2023-03-28 07:02:09,323][train_inner][INFO] - {"epoch": 27, "update": 26.948, "loss": "5.092", "ppl": "34.1", "wps": "101693", "ups": "0.95", "wpb": "107056", "bsz": "256", "num_updates": "29400", "lr": "0.000581913", "gnorm": "0.542", "train_wall": "165", "gb_free": "7.5", "wall": "31069"}
[2023-03-28 07:03:09,502][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 07:03:09,503][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 07:03:10,381][valid][INFO] - {"epoch": 27, "valid_loss": "4.746", "valid_ppl": "26.84", "valid_wps": "283490", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "29457", "valid_best_loss": "4.746"}
[2023-03-28 07:03:10,382][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 27 @ 29457 updates
[2023-03-28 07:03:10,383][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 07:03:10,746][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 07:03:10,999][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 27 @ 29457 updates, score 4.746) (writing took 0.6172485319984844 seconds)
[2023-03-28 07:03:11,000][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2023-03-28 07:03:11,000][train][INFO] - {"epoch": 27, "train_loss": "5.063", "train_ppl": "33.42", "train_wps": "101609", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "29457", "train_lr": "0.000581566", "train_gnorm": "0.543", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "31131"}
[2023-03-28 07:03:11,002][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 07:03:11,033][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 07:03:11,035][fairseq.trainer][INFO] - begin training epoch 28
[2023-03-28 07:03:11,036][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 07:05:42,083][train_inner][INFO] - {"epoch": 28, "update": 27.131, "loss": "5.027", "ppl": "32.61", "wps": "100828", "ups": "0.94", "wpb": "107261", "bsz": "255.8", "num_updates": "29600", "lr": "0.000580696", "gnorm": "0.543", "train_wall": "166", "gb_free": "7.5", "wall": "31282"}
[2023-03-28 07:09:12,725][train_inner][INFO] - {"epoch": 28, "update": 27.314, "loss": "5.023", "ppl": "32.53", "wps": "101783", "ups": "0.95", "wpb": "107199", "bsz": "256", "num_updates": "29800", "lr": "0.000579478", "gnorm": "0.547", "train_wall": "166", "gb_free": "7.5", "wall": "31493"}
[2023-03-28 07:12:43,348][train_inner][INFO] - {"epoch": 28, "update": 27.498, "loss": "5.055", "ppl": "33.25", "wps": "101836", "ups": "0.95", "wpb": "107245", "bsz": "256", "num_updates": "30000", "lr": "0.000578261", "gnorm": "0.542", "train_wall": "166", "gb_free": "7.5", "wall": "31703"}
[2023-03-28 07:16:14,026][train_inner][INFO] - {"epoch": 28, "update": 27.681, "loss": "5.068", "ppl": "33.54", "wps": "101718", "ups": "0.95", "wpb": "107148", "bsz": "256", "num_updates": "30200", "lr": "0.000577043", "gnorm": "0.542", "train_wall": "166", "gb_free": "7.5", "wall": "31914"}
[2023-03-28 07:19:44,614][train_inner][INFO] - {"epoch": 28, "update": 27.864, "loss": "5.082", "ppl": "33.87", "wps": "101799", "ups": "0.95", "wpb": "107188", "bsz": "256", "num_updates": "30400", "lr": "0.000575826", "gnorm": "0.54", "train_wall": "166", "gb_free": "7.5", "wall": "32124"}
[2023-03-28 07:22:20,484][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 07:22:20,485][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 07:22:21,435][valid][INFO] - {"epoch": 28, "valid_loss": "4.731", "valid_ppl": "26.55", "valid_wps": "262896", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "30548", "valid_best_loss": "4.731"}
[2023-03-28 07:22:21,436][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 28 @ 30548 updates
[2023-03-28 07:22:21,437][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 07:22:21,666][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 07:22:21,812][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 28 @ 30548 updates, score 4.731) (writing took 0.37594655500288354 seconds)
[2023-03-28 07:22:21,812][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2023-03-28 07:22:21,812][train][INFO] - {"epoch": 28, "train_loss": "5.052", "train_ppl": "33.18", "train_wps": "101634", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "30548", "train_lr": "0.000574925", "train_gnorm": "0.543", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "32282"}
[2023-03-28 07:22:21,814][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 07:22:21,844][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 07:22:21,847][fairseq.trainer][INFO] - begin training epoch 29
[2023-03-28 07:22:21,847][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 07:23:16,840][train_inner][INFO] - {"epoch": 29, "update": 28.048, "loss": "5.06", "ppl": "33.35", "wps": "100989", "ups": "0.94", "wpb": "107163", "bsz": "255.8", "num_updates": "30600", "lr": "0.000574609", "gnorm": "0.542", "train_wall": "166", "gb_free": "7.5", "wall": "32337"}
[2023-03-28 07:26:47,317][train_inner][INFO] - {"epoch": 29, "update": 28.231, "loss": "4.999", "ppl": "31.97", "wps": "101825", "ups": "0.95", "wpb": "107158", "bsz": "256", "num_updates": "30800", "lr": "0.000573391", "gnorm": "0.546", "train_wall": "165", "gb_free": "7.5", "wall": "32547"}
[2023-03-28 07:30:18,271][train_inner][INFO] - {"epoch": 29, "update": 28.414, "loss": "5.03", "ppl": "32.67", "wps": "101901", "ups": "0.95", "wpb": "107482", "bsz": "256", "num_updates": "31000", "lr": "0.000572174", "gnorm": "0.547", "train_wall": "166", "gb_free": "7.5", "wall": "32758"}
[2023-03-28 07:33:48,920][train_inner][INFO] - {"epoch": 29, "update": 28.598, "loss": "5.053", "ppl": "33.19", "wps": "101780", "ups": "0.95", "wpb": "107199", "bsz": "256", "num_updates": "31200", "lr": "0.000570957", "gnorm": "0.543", "train_wall": "166", "gb_free": "7.5", "wall": "32969"}
[2023-03-28 07:37:19,604][train_inner][INFO] - {"epoch": 29, "update": 28.781, "loss": "5.065", "ppl": "33.47", "wps": "101838", "ups": "0.95", "wpb": "107278", "bsz": "256", "num_updates": "31400", "lr": "0.000569739", "gnorm": "0.541", "train_wall": "166", "gb_free": "7.5", "wall": "33179"}
[2023-03-28 07:40:50,285][train_inner][INFO] - {"epoch": 29, "update": 28.964, "loss": "5.08", "ppl": "33.82", "wps": "101758", "ups": "0.95", "wpb": "107192", "bsz": "256", "num_updates": "31600", "lr": "0.000568522", "gnorm": "0.54", "train_wall": "166", "gb_free": "7.5", "wall": "33390"}
[2023-03-28 07:41:31,166][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 07:41:31,167][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 07:41:32,042][valid][INFO] - {"epoch": 29, "valid_loss": "4.731", "valid_ppl": "26.56", "valid_wps": "285057", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "31639", "valid_best_loss": "4.731"}
[2023-03-28 07:41:32,042][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 29 @ 31639 updates
[2023-03-28 07:41:32,043][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 07:41:32,431][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 07:41:32,715][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 29 @ 31639 updates, score 4.731) (writing took 0.6727511360004428 seconds)
[2023-03-28 07:41:32,715][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2023-03-28 07:41:32,716][train][INFO] - {"epoch": 29, "train_loss": "5.043", "train_ppl": "32.97", "train_wps": "101626", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "31639", "train_lr": "0.000568284", "train_gnorm": "0.543", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "33433"}
[2023-03-28 07:41:32,718][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 07:41:32,748][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 07:41:32,750][fairseq.trainer][INFO] - begin training epoch 30
[2023-03-28 07:41:32,751][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 07:44:22,552][train_inner][INFO] - {"epoch": 30, "update": 29.148, "loss": "4.99", "ppl": "31.77", "wps": "100902", "ups": "0.94", "wpb": "107090", "bsz": "255.8", "num_updates": "31800", "lr": "0.000567304", "gnorm": "0.545", "train_wall": "165", "gb_free": "7.5", "wall": "33602"}
[2023-03-28 07:47:54,793][train_inner][INFO] - {"epoch": 30, "update": 29.331, "loss": "5.008", "ppl": "32.17", "wps": "101076", "ups": "0.94", "wpb": "107262", "bsz": "256", "num_updates": "32000", "lr": "0.000566087", "gnorm": "0.546", "train_wall": "167", "gb_free": "7.5", "wall": "33815"}
[2023-03-28 07:51:27,230][train_inner][INFO] - {"epoch": 30, "update": 29.514, "loss": "5.034", "ppl": "32.76", "wps": "100937", "ups": "0.94", "wpb": "107213", "bsz": "256", "num_updates": "32200", "lr": "0.00056487", "gnorm": "0.543", "train_wall": "167", "gb_free": "7.5", "wall": "34027"}
[2023-03-28 07:54:58,957][train_inner][INFO] - {"epoch": 30, "update": 29.698, "loss": "5.055", "ppl": "33.25", "wps": "101366", "ups": "0.94", "wpb": "107310", "bsz": "256", "num_updates": "32400", "lr": "0.000563652", "gnorm": "0.543", "train_wall": "166", "gb_free": "7.5", "wall": "34239"}
[2023-03-28 07:58:29,687][train_inner][INFO] - {"epoch": 30, "update": 29.881, "loss": "5.066", "ppl": "33.5", "wps": "101837", "ups": "0.95", "wpb": "107300", "bsz": "256", "num_updates": "32600", "lr": "0.000562435", "gnorm": "0.544", "train_wall": "166", "gb_free": "7.5", "wall": "34450"}
[2023-03-28 08:00:46,144][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 08:00:46,145][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 08:00:47,131][valid][INFO] - {"epoch": 30, "valid_loss": "4.717", "valid_ppl": "26.29", "valid_wps": "252418", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "32730", "valid_best_loss": "4.717"}
[2023-03-28 08:00:47,132][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 32730 updates
[2023-03-28 08:00:47,133][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 08:00:47,583][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 08:00:47,898][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 30 @ 32730 updates, score 4.717) (writing took 0.7658705650028423 seconds)
[2023-03-28 08:00:47,898][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2023-03-28 08:00:47,898][train][INFO] - {"epoch": 30, "train_loss": "5.035", "train_ppl": "32.79", "train_wps": "101250", "train_ups": "0.94", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "32730", "train_lr": "0.000561643", "train_gnorm": "0.544", "train_train_wall": "907", "train_gb_free": "7.5", "train_wall": "34588"}
[2023-03-28 08:00:47,900][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 08:00:47,932][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 08:00:47,934][fairseq.trainer][INFO] - begin training epoch 31
[2023-03-28 08:00:47,934][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 08:02:01,963][train_inner][INFO] - {"epoch": 31, "update": 30.064, "loss": "5.033", "ppl": "32.75", "wps": "100712", "ups": "0.94", "wpb": "106893", "bsz": "255.8", "num_updates": "32800", "lr": "0.000561217", "gnorm": "0.543", "train_wall": "165", "gb_free": "7.5", "wall": "34662"}
[2023-03-28 08:05:32,552][train_inner][INFO] - {"epoch": 31, "update": 30.247, "loss": "4.987", "ppl": "31.72", "wps": "101747", "ups": "0.95", "wpb": "107134", "bsz": "256", "num_updates": "33000", "lr": "0.00056", "gnorm": "0.547", "train_wall": "165", "gb_free": "7.5", "wall": "34872"}
[2023-03-28 08:09:03,013][train_inner][INFO] - {"epoch": 31, "update": 30.431, "loss": "5.013", "ppl": "32.29", "wps": "101883", "ups": "0.95", "wpb": "107209", "bsz": "256", "num_updates": "33200", "lr": "0.000558783", "gnorm": "0.547", "train_wall": "165", "gb_free": "7.5", "wall": "35083"}
[2023-03-28 08:12:33,893][train_inner][INFO] - {"epoch": 31, "update": 30.614, "loss": "5.029", "ppl": "32.66", "wps": "101870", "ups": "0.95", "wpb": "107412", "bsz": "256", "num_updates": "33400", "lr": "0.000557565", "gnorm": "0.545", "train_wall": "166", "gb_free": "7.5", "wall": "35294"}
[2023-03-28 08:16:04,430][train_inner][INFO] - {"epoch": 31, "update": 30.797, "loss": "5.058", "ppl": "33.31", "wps": "101907", "ups": "0.95", "wpb": "107276", "bsz": "256", "num_updates": "33600", "lr": "0.000556348", "gnorm": "0.543", "train_wall": "166", "gb_free": "7.5", "wall": "35504"}
[2023-03-28 08:19:34,893][train_inner][INFO] - {"epoch": 31, "update": 30.981, "loss": "5.066", "ppl": "33.5", "wps": "101828", "ups": "0.95", "wpb": "107155", "bsz": "256", "num_updates": "33800", "lr": "0.00055513", "gnorm": "0.541", "train_wall": "165", "gb_free": "7.5", "wall": "35715"}
[2023-03-28 08:19:56,832][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 08:19:56,833][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 08:19:57,708][valid][INFO] - {"epoch": 31, "valid_loss": "4.718", "valid_ppl": "26.32", "valid_wps": "285087", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "33821", "valid_best_loss": "4.717"}
[2023-03-28 08:19:57,709][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 31 @ 33821 updates
[2023-03-28 08:19:57,710][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 08:19:57,972][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 08:19:57,978][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 31 @ 33821 updates, score 4.718) (writing took 0.26888636899820995 seconds)
[2023-03-28 08:19:57,978][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2023-03-28 08:19:57,979][train][INFO] - {"epoch": 31, "train_loss": "5.026", "train_ppl": "32.58", "train_wps": "101699", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "33821", "train_lr": "0.000555003", "train_gnorm": "0.545", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "35738"}
[2023-03-28 08:19:57,981][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 08:19:58,010][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 08:19:58,012][fairseq.trainer][INFO] - begin training epoch 32
[2023-03-28 08:19:58,013][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 08:23:06,608][train_inner][INFO] - {"epoch": 32, "update": 31.164, "loss": "4.973", "ppl": "31.4", "wps": "101117", "ups": "0.94", "wpb": "107040", "bsz": "255.8", "num_updates": "34000", "lr": "0.000553913", "gnorm": "0.55", "train_wall": "165", "gb_free": "7.5", "wall": "35926"}
[2023-03-28 08:26:42,384][train_inner][INFO] - {"epoch": 32, "update": 31.347, "loss": "4.994", "ppl": "31.86", "wps": "99291.3", "ups": "0.93", "wpb": "107123", "bsz": "256", "num_updates": "34200", "lr": "0.000552696", "gnorm": "0.548", "train_wall": "170", "gb_free": "7.5", "wall": "36142"}
[2023-03-28 08:30:24,721][train_inner][INFO] - {"epoch": 32, "update": 31.531, "loss": "5.018", "ppl": "32.41", "wps": "96549.3", "ups": "0.9", "wpb": "107332", "bsz": "256", "num_updates": "34400", "lr": "0.000551478", "gnorm": "0.546", "train_wall": "174", "gb_free": "7.5", "wall": "36365"}
[2023-03-28 08:34:07,199][train_inner][INFO] - {"epoch": 32, "update": 31.714, "loss": "5.036", "ppl": "32.8", "wps": "96476.4", "ups": "0.9", "wpb": "107319", "bsz": "256", "num_updates": "34600", "lr": "0.000550261", "gnorm": "0.544", "train_wall": "174", "gb_free": "7.5", "wall": "36587"}
[2023-03-28 08:38:18,346][train_inner][INFO] - {"epoch": 32, "update": 31.897, "loss": "5.053", "ppl": "33.2", "wps": "85181.3", "ups": "0.8", "wpb": "106962", "bsz": "256", "num_updates": "34800", "lr": "0.000549043", "gnorm": "0.546", "train_wall": "196", "gb_free": "7.5", "wall": "36838"}
[2023-03-28 08:40:35,449][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 08:40:35,450][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 08:40:36,547][valid][INFO] - {"epoch": 32, "valid_loss": "4.72", "valid_ppl": "26.36", "valid_wps": "227151", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "34912", "valid_best_loss": "4.717"}
[2023-03-28 08:40:36,548][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 32 @ 34912 updates
[2023-03-28 08:40:36,548][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 08:40:37,063][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 08:40:37,067][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 32 @ 34912 updates, score 4.72) (writing took 0.5191688790000626 seconds)
[2023-03-28 08:40:37,067][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2023-03-28 08:40:37,068][train][INFO] - {"epoch": 32, "train_loss": "5.019", "train_ppl": "32.42", "train_wps": "94393.6", "train_ups": "0.88", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "34912", "train_lr": "0.000548362", "train_gnorm": "0.546", "train_train_wall": "971", "train_gb_free": "7.5", "train_wall": "36977"}
[2023-03-28 08:40:37,070][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 08:40:37,102][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 08:40:37,104][fairseq.trainer][INFO] - begin training epoch 33
[2023-03-28 08:40:37,104][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 08:42:24,150][train_inner][INFO] - {"epoch": 33, "update": 32.081, "loss": "5.01", "ppl": "32.22", "wps": "87320.4", "ups": "0.81", "wpb": "107318", "bsz": "255.8", "num_updates": "35000", "lr": "0.000547826", "gnorm": "0.544", "train_wall": "193", "gb_free": "7.5", "wall": "37084"}
[2023-03-28 08:46:28,235][train_inner][INFO] - {"epoch": 33, "update": 32.264, "loss": "4.975", "ppl": "31.46", "wps": "88018.8", "ups": "0.82", "wpb": "107421", "bsz": "256", "num_updates": "35200", "lr": "0.000546609", "gnorm": "0.548", "train_wall": "193", "gb_free": "7.5", "wall": "37328"}
[2023-03-28 08:50:25,516][train_inner][INFO] - {"epoch": 33, "update": 32.447, "loss": "5.003", "ppl": "32.06", "wps": "90158.4", "ups": "0.84", "wpb": "106964", "bsz": "256", "num_updates": "35400", "lr": "0.000545391", "gnorm": "0.548", "train_wall": "187", "gb_free": "7.5", "wall": "37565"}
[2023-03-28 08:53:58,198][train_inner][INFO] - {"epoch": 33, "update": 32.631, "loss": "5.024", "ppl": "32.54", "wps": "100902", "ups": "0.94", "wpb": "107300", "bsz": "256", "num_updates": "35600", "lr": "0.000544174", "gnorm": "0.548", "train_wall": "167", "gb_free": "7.5", "wall": "37778"}
[2023-03-28 08:57:38,450][train_inner][INFO] - {"epoch": 33, "update": 32.814, "loss": "5.038", "ppl": "32.85", "wps": "97350.3", "ups": "0.91", "wpb": "107208", "bsz": "256", "num_updates": "35800", "lr": "0.000542957", "gnorm": "0.545", "train_wall": "173", "gb_free": "7.5", "wall": "37998"}
[2023-03-28 09:01:44,631][train_inner][INFO] - {"epoch": 33, "update": 32.997, "loss": "5.05", "ppl": "33.13", "wps": "87055", "ups": "0.81", "wpb": "107157", "bsz": "256", "num_updates": "36000", "lr": "0.000541739", "gnorm": "0.546", "train_wall": "195", "gb_free": "7.5", "wall": "38244"}
[2023-03-28 09:01:48,372][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 09:01:48,373][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 09:01:49,422][valid][INFO] - {"epoch": 33, "valid_loss": "4.707", "valid_ppl": "26.11", "valid_wps": "237343", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "36003", "valid_best_loss": "4.707"}
[2023-03-28 09:01:49,423][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 33 @ 36003 updates
[2023-03-28 09:01:49,424][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 09:01:49,673][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 09:01:49,824][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 33 @ 36003 updates, score 4.707) (writing took 0.4012400610008626 seconds)
[2023-03-28 09:01:49,825][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2023-03-28 09:01:49,825][train][INFO] - {"epoch": 33, "train_loss": "5.012", "train_ppl": "32.26", "train_wps": "91896.5", "train_ups": "0.86", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "36003", "train_lr": "0.000541721", "train_gnorm": "0.547", "train_train_wall": "1003", "train_gb_free": "7.5", "train_wall": "38250"}
[2023-03-28 09:01:49,828][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 09:01:49,862][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 09:01:49,865][fairseq.trainer][INFO] - begin training epoch 34
[2023-03-28 09:01:49,865][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 09:05:25,759][train_inner][INFO] - {"epoch": 34, "update": 33.181, "loss": "4.946", "ppl": "30.83", "wps": "97110.5", "ups": "0.9", "wpb": "107369", "bsz": "255.8", "num_updates": "36200", "lr": "0.000540522", "gnorm": "0.552", "train_wall": "172", "gb_free": "7.5", "wall": "38466"}
[2023-03-28 09:08:58,098][train_inner][INFO] - {"epoch": 34, "update": 33.364, "loss": "4.982", "ppl": "31.6", "wps": "100822", "ups": "0.94", "wpb": "107042", "bsz": "256", "num_updates": "36400", "lr": "0.000539304", "gnorm": "0.549", "train_wall": "166", "gb_free": "7.5", "wall": "38678"}
[2023-03-28 09:12:47,569][train_inner][INFO] - {"epoch": 34, "update": 33.547, "loss": "5.006", "ppl": "32.13", "wps": "93183", "ups": "0.87", "wpb": "106914", "bsz": "256", "num_updates": "36600", "lr": "0.000538087", "gnorm": "0.547", "train_wall": "181", "gb_free": "7.5", "wall": "38907"}
[2023-03-28 09:16:49,200][train_inner][INFO] - {"epoch": 34, "update": 33.731, "loss": "5.029", "ppl": "32.65", "wps": "88844.3", "ups": "0.83", "wpb": "107337", "bsz": "256", "num_updates": "36800", "lr": "0.00053687", "gnorm": "0.547", "train_wall": "191", "gb_free": "7.5", "wall": "39149"}
[2023-03-28 09:20:51,018][train_inner][INFO] - {"epoch": 34, "update": 33.914, "loss": "5.046", "ppl": "33.04", "wps": "88957.3", "ups": "0.83", "wpb": "107558", "bsz": "256", "num_updates": "37000", "lr": "0.000535652", "gnorm": "0.546", "train_wall": "192", "gb_free": "7.5", "wall": "39391"}
[2023-03-28 09:22:43,215][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 09:22:43,215][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 09:22:44,207][valid][INFO] - {"epoch": 34, "valid_loss": "4.703", "valid_ppl": "26.04", "valid_wps": "251208", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "37094", "valid_best_loss": "4.703"}
[2023-03-28 09:22:44,208][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 34 @ 37094 updates
[2023-03-28 09:22:44,209][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 09:22:44,456][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 09:22:44,619][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 34 @ 37094 updates, score 4.703) (writing took 0.4111736370032304 seconds)
[2023-03-28 09:22:44,619][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2023-03-28 09:22:44,620][train][INFO] - {"epoch": 34, "train_loss": "5.005", "train_ppl": "32.11", "train_wps": "93212.1", "train_ups": "0.87", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "37094", "train_lr": "0.00053508", "train_gnorm": "0.548", "train_train_wall": "989", "train_gb_free": "7.5", "train_wall": "39504"}
[2023-03-28 09:22:44,622][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 09:22:44,655][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 09:22:44,657][fairseq.trainer][INFO] - begin training epoch 35
[2023-03-28 09:22:44,658][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 09:24:52,822][train_inner][INFO] - {"epoch": 35, "update": 34.097, "loss": "4.981", "ppl": "31.59", "wps": "88655.7", "ups": "0.83", "wpb": "107186", "bsz": "255.8", "num_updates": "37200", "lr": "0.000534435", "gnorm": "0.548", "train_wall": "190", "gb_free": "7.5", "wall": "39633"}
[2023-03-28 09:28:52,218][train_inner][INFO] - {"epoch": 35, "update": 34.28, "loss": "4.966", "ppl": "31.26", "wps": "89469.5", "ups": "0.84", "wpb": "107093", "bsz": "256", "num_updates": "37400", "lr": "0.000533217", "gnorm": "0.549", "train_wall": "189", "gb_free": "7.5", "wall": "39872"}
[2023-03-28 09:32:51,529][train_inner][INFO] - {"epoch": 35, "update": 34.464, "loss": "4.986", "ppl": "31.69", "wps": "89584.5", "ups": "0.84", "wpb": "107193", "bsz": "256", "num_updates": "37600", "lr": "0.000532", "gnorm": "0.551", "train_wall": "189", "gb_free": "7.5", "wall": "40111"}
[2023-03-28 09:36:51,110][train_inner][INFO] - {"epoch": 35, "update": 34.647, "loss": "5.015", "ppl": "32.33", "wps": "89586.7", "ups": "0.83", "wpb": "107316", "bsz": "256", "num_updates": "37800", "lr": "0.000530783", "gnorm": "0.551", "train_wall": "190", "gb_free": "7.5", "wall": "40351"}
[2023-03-28 09:40:50,549][train_inner][INFO] - {"epoch": 35, "update": 34.83, "loss": "5.027", "ppl": "32.61", "wps": "89261.5", "ups": "0.84", "wpb": "106863", "bsz": "256", "num_updates": "38000", "lr": "0.000529565", "gnorm": "0.549", "train_wall": "189", "gb_free": "7.5", "wall": "40590"}
[2023-03-28 09:44:36,245][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 09:44:36,246][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 09:44:37,372][valid][INFO] - {"epoch": 35, "valid_loss": "4.697", "valid_ppl": "25.94", "valid_wps": "221290", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "38185", "valid_best_loss": "4.697"}
[2023-03-28 09:44:37,373][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 35 @ 38185 updates
[2023-03-28 09:44:37,374][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 09:44:37,740][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 09:44:38,047][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 35 @ 38185 updates, score 4.697) (writing took 0.6736845519990311 seconds)
[2023-03-28 09:44:38,047][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2023-03-28 09:44:38,047][train][INFO] - {"epoch": 35, "train_loss": "4.998", "train_ppl": "31.96", "train_wps": "89051", "train_ups": "0.83", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "38185", "train_lr": "0.000528439", "train_gnorm": "0.549", "train_train_wall": "1038", "train_gb_free": "7.5", "train_wall": "40818"}
[2023-03-28 09:44:38,049][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 09:44:38,080][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 09:44:38,082][fairseq.trainer][INFO] - begin training epoch 36
[2023-03-28 09:44:38,083][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 09:44:56,775][train_inner][INFO] - {"epoch": 36, "update": 35.014, "loss": "5.026", "ppl": "32.59", "wps": "87230.4", "ups": "0.81", "wpb": "107392", "bsz": "255.8", "num_updates": "38200", "lr": "0.000528348", "gnorm": "0.547", "train_wall": "193", "gb_free": "7.5", "wall": "40837"}
[2023-03-28 09:49:00,897][train_inner][INFO] - {"epoch": 36, "update": 35.197, "loss": "4.938", "ppl": "30.66", "wps": "87792.5", "ups": "0.82", "wpb": "107160", "bsz": "256", "num_updates": "38400", "lr": "0.00052713", "gnorm": "0.555", "train_wall": "193", "gb_free": "7.5", "wall": "41081"}
[2023-03-28 09:53:02,111][train_inner][INFO] - {"epoch": 36, "update": 35.38, "loss": "4.974", "ppl": "31.42", "wps": "88644.1", "ups": "0.83", "wpb": "106911", "bsz": "256", "num_updates": "38600", "lr": "0.000525913", "gnorm": "0.553", "train_wall": "191", "gb_free": "7.5", "wall": "41322"}
[2023-03-28 09:57:02,462][train_inner][INFO] - {"epoch": 36, "update": 35.564, "loss": "4.998", "ppl": "31.95", "wps": "89183.3", "ups": "0.83", "wpb": "107177", "bsz": "256", "num_updates": "38800", "lr": "0.000524696", "gnorm": "0.552", "train_wall": "190", "gb_free": "7.5", "wall": "41562"}
[2023-03-28 10:01:02,923][train_inner][INFO] - {"epoch": 36, "update": 35.747, "loss": "5.023", "ppl": "32.51", "wps": "89325.5", "ups": "0.83", "wpb": "107396", "bsz": "256", "num_updates": "39000", "lr": "0.000523478", "gnorm": "0.549", "train_wall": "190", "gb_free": "7.5", "wall": "41803"}
[2023-03-28 10:05:04,481][train_inner][INFO] - {"epoch": 36, "update": 35.93, "loss": "5.021", "ppl": "32.46", "wps": "88761.9", "ups": "0.83", "wpb": "107206", "bsz": "256", "num_updates": "39200", "lr": "0.000522261", "gnorm": "0.55", "train_wall": "191", "gb_free": "7.5", "wall": "42044"}
[2023-03-28 10:06:36,041][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 10:06:36,042][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 10:06:37,031][valid][INFO] - {"epoch": 36, "valid_loss": "4.694", "valid_ppl": "25.89", "valid_wps": "251963", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "39276", "valid_best_loss": "4.694"}
[2023-03-28 10:06:37,032][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 36 @ 39276 updates
[2023-03-28 10:06:37,033][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 10:06:37,298][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 10:06:37,442][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 36 @ 39276 updates, score 4.694) (writing took 0.4097826159995748 seconds)
[2023-03-28 10:06:37,442][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2023-03-28 10:06:37,443][train][INFO] - {"epoch": 36, "train_loss": "4.993", "train_ppl": "31.85", "train_wps": "88648.2", "train_ups": "0.83", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "39276", "train_lr": "0.000521798", "train_gnorm": "0.551", "train_train_wall": "1043", "train_gb_free": "7.5", "train_wall": "42137"}
[2023-03-28 10:06:37,445][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 10:06:37,479][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 10:06:37,481][fairseq.trainer][INFO] - begin training epoch 37
[2023-03-28 10:06:37,481][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 10:09:07,081][train_inner][INFO] - {"epoch": 37, "update": 36.114, "loss": "4.97", "ppl": "31.34", "wps": "88448.3", "ups": "0.82", "wpb": "107288", "bsz": "255.8", "num_updates": "39400", "lr": "0.000521043", "gnorm": "0.552", "train_wall": "191", "gb_free": "7.5", "wall": "42287"}
[2023-03-28 10:13:09,269][train_inner][INFO] - {"epoch": 37, "update": 36.297, "loss": "4.954", "ppl": "31", "wps": "88532.7", "ups": "0.83", "wpb": "107208", "bsz": "256", "num_updates": "39600", "lr": "0.000519826", "gnorm": "0.558", "train_wall": "192", "gb_free": "7.5", "wall": "42529"}
[2023-03-28 10:17:11,317][train_inner][INFO] - {"epoch": 37, "update": 36.48, "loss": "4.983", "ppl": "31.63", "wps": "88469", "ups": "0.83", "wpb": "107069", "bsz": "256", "num_updates": "39800", "lr": "0.000518609", "gnorm": "0.554", "train_wall": "192", "gb_free": "7.5", "wall": "42771"}
[2023-03-28 10:21:21,132][train_inner][INFO] - {"epoch": 37, "update": 36.664, "loss": "4.995", "ppl": "31.9", "wps": "85780.6", "ups": "0.8", "wpb": "107146", "bsz": "256", "num_updates": "40000", "lr": "0.000517391", "gnorm": "0.55", "train_wall": "197", "gb_free": "7.5", "wall": "43021"}
[2023-03-28 10:25:23,509][train_inner][INFO] - {"epoch": 37, "update": 36.847, "loss": "5.02", "ppl": "32.44", "wps": "88743.1", "ups": "0.83", "wpb": "107546", "bsz": "256", "num_updates": "40200", "lr": "0.000516174", "gnorm": "0.55", "train_wall": "192", "gb_free": "7.5", "wall": "43263"}
[2023-03-28 10:28:46,108][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 10:28:46,109][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 10:28:47,173][valid][INFO] - {"epoch": 37, "valid_loss": "4.686", "valid_ppl": "25.75", "valid_wps": "233965", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "40367", "valid_best_loss": "4.686"}
[2023-03-28 10:28:47,174][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 37 @ 40367 updates
[2023-03-28 10:28:47,175][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 10:28:47,649][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 10:28:47,993][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 37 @ 40367 updates, score 4.686) (writing took 0.8192513009998947 seconds)
[2023-03-28 10:28:47,993][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2023-03-28 10:28:47,994][train][INFO] - {"epoch": 37, "train_loss": "4.987", "train_ppl": "31.71", "train_wps": "87905", "train_ups": "0.82", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "40367", "train_lr": "0.000515157", "train_gnorm": "0.552", "train_train_wall": "1051", "train_gb_free": "7.5", "train_wall": "43468"}
[2023-03-28 10:28:47,996][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 10:28:48,030][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 10:28:48,033][fairseq.trainer][INFO] - begin training epoch 38
[2023-03-28 10:28:48,033][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 10:29:28,973][train_inner][INFO] - {"epoch": 38, "update": 37.03, "loss": "5.006", "ppl": "32.14", "wps": "87422.2", "ups": "0.81", "wpb": "107295", "bsz": "255.8", "num_updates": "40400", "lr": "0.000514957", "gnorm": "0.55", "train_wall": "193", "gb_free": "7.5", "wall": "43509"}
[2023-03-28 10:33:33,220][train_inner][INFO] - {"epoch": 38, "update": 37.214, "loss": "4.932", "ppl": "30.53", "wps": "87860.7", "ups": "0.82", "wpb": "107298", "bsz": "256", "num_updates": "40600", "lr": "0.000513739", "gnorm": "0.555", "train_wall": "193", "gb_free": "7.5", "wall": "43753"}
[2023-03-28 10:37:42,881][train_inner][INFO] - {"epoch": 38, "update": 37.397, "loss": "4.961", "ppl": "31.16", "wps": "85811.8", "ups": "0.8", "wpb": "107119", "bsz": "256", "num_updates": "40800", "lr": "0.000512522", "gnorm": "0.555", "train_wall": "198", "gb_free": "7.5", "wall": "44003"}
[2023-03-28 10:41:44,929][train_inner][INFO] - {"epoch": 38, "update": 37.58, "loss": "4.987", "ppl": "31.71", "wps": "88583.4", "ups": "0.83", "wpb": "107207", "bsz": "256", "num_updates": "41000", "lr": "0.000511304", "gnorm": "0.553", "train_wall": "191", "gb_free": "7.5", "wall": "44245"}
[2023-03-28 10:45:49,362][train_inner][INFO] - {"epoch": 38, "update": 37.764, "loss": "5.001", "ppl": "32.02", "wps": "87581.9", "ups": "0.82", "wpb": "107039", "bsz": "256", "num_updates": "41200", "lr": "0.000510087", "gnorm": "0.554", "train_wall": "193", "gb_free": "7.5", "wall": "44489"}
[2023-03-28 10:49:52,126][train_inner][INFO] - {"epoch": 38, "update": 37.947, "loss": "5.021", "ppl": "32.48", "wps": "88374", "ups": "0.82", "wpb": "107270", "bsz": "256", "num_updates": "41400", "lr": "0.00050887", "gnorm": "0.553", "train_wall": "192", "gb_free": "7.5", "wall": "44732"}
[2023-03-28 10:51:02,446][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 10:51:02,447][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 10:51:03,472][valid][INFO] - {"epoch": 38, "valid_loss": "4.684", "valid_ppl": "25.71", "valid_wps": "243379", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "41458", "valid_best_loss": "4.684"}
[2023-03-28 10:51:03,473][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 38 @ 41458 updates
[2023-03-28 10:51:03,474][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 10:51:03,727][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 10:51:03,879][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 38 @ 41458 updates, score 4.684) (writing took 0.4059875969978748 seconds)
[2023-03-28 10:51:03,879][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2023-03-28 10:51:03,880][train][INFO] - {"epoch": 38, "train_loss": "4.98", "train_ppl": "31.57", "train_wps": "87553.9", "train_ups": "0.82", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "41458", "train_lr": "0.000508517", "train_gnorm": "0.554", "train_train_wall": "1056", "train_gb_free": "7.5", "train_wall": "44804"}
[2023-03-28 10:51:03,882][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 10:51:03,918][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 10:51:03,921][fairseq.trainer][INFO] - begin training epoch 39
[2023-03-28 10:51:03,921][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 10:53:58,530][train_inner][INFO] - {"epoch": 39, "update": 38.13, "loss": "4.94", "ppl": "30.69", "wps": "87236.5", "ups": "0.81", "wpb": "107477", "bsz": "255.8", "num_updates": "41600", "lr": "0.000507652", "gnorm": "0.553", "train_wall": "194", "gb_free": "7.5", "wall": "44978"}
[2023-03-28 10:58:04,118][train_inner][INFO] - {"epoch": 39, "update": 38.313, "loss": "4.945", "ppl": "30.79", "wps": "87410.2", "ups": "0.81", "wpb": "107334", "bsz": "256", "num_updates": "41800", "lr": "0.000506435", "gnorm": "0.56", "train_wall": "195", "gb_free": "7.5", "wall": "45224"}
[2023-03-28 11:01:40,313][train_inner][INFO] - {"epoch": 39, "update": 38.497, "loss": "4.98", "ppl": "31.57", "wps": "98840.2", "ups": "0.93", "wpb": "106844", "bsz": "256", "num_updates": "42000", "lr": "0.000505217", "gnorm": "0.556", "train_wall": "170", "gb_free": "7.5", "wall": "45440"}
[2023-03-28 11:05:13,429][train_inner][INFO] - {"epoch": 39, "update": 38.68, "loss": "4.994", "ppl": "31.87", "wps": "100568", "ups": "0.94", "wpb": "107163", "bsz": "256", "num_updates": "42200", "lr": "0.000504", "gnorm": "0.557", "train_wall": "167", "gb_free": "7.5", "wall": "45653"}
[2023-03-28 11:09:21,914][train_inner][INFO] - {"epoch": 39, "update": 38.863, "loss": "5.006", "ppl": "32.12", "wps": "86388.8", "ups": "0.8", "wpb": "107332", "bsz": "256", "num_updates": "42400", "lr": "0.000502783", "gnorm": "0.554", "train_wall": "196", "gb_free": "7.5", "wall": "45902"}
[2023-03-28 11:12:23,608][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 11:12:23,609][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 11:12:24,696][valid][INFO] - {"epoch": 39, "valid_loss": "4.686", "valid_ppl": "25.74", "valid_wps": "228140", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "42549", "valid_best_loss": "4.684"}
[2023-03-28 11:12:24,697][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 39 @ 42549 updates
[2023-03-28 11:12:24,698][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 11:12:24,945][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 11:12:24,951][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 39 @ 42549 updates, score 4.686) (writing took 0.2536124460020801 seconds)
[2023-03-28 11:12:24,951][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2023-03-28 11:12:24,952][train][INFO] - {"epoch": 39, "train_loss": "4.976", "train_ppl": "31.47", "train_wps": "91300.1", "train_ups": "0.85", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "42549", "train_lr": "0.000501876", "train_gnorm": "0.556", "train_train_wall": "1010", "train_gb_free": "7.5", "train_wall": "46085"}
[2023-03-28 11:12:24,954][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 11:12:24,987][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 11:12:24,989][fairseq.trainer][INFO] - begin training epoch 40
[2023-03-28 11:12:24,989][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 11:13:28,278][train_inner][INFO] - {"epoch": 40, "update": 39.047, "loss": "4.979", "ppl": "31.54", "wps": "87006.7", "ups": "0.81", "wpb": "107177", "bsz": "255.8", "num_updates": "42600", "lr": "0.000501565", "gnorm": "0.557", "train_wall": "194", "gb_free": "7.5", "wall": "46148"}
[2023-03-28 11:17:39,180][train_inner][INFO] - {"epoch": 40, "update": 39.23, "loss": "4.921", "ppl": "30.3", "wps": "85445.8", "ups": "0.8", "wpb": "107192", "bsz": "256", "num_updates": "42800", "lr": "0.000500348", "gnorm": "0.558", "train_wall": "198", "gb_free": "7.5", "wall": "46399"}
[2023-03-28 11:21:59,022][train_inner][INFO] - {"epoch": 40, "update": 39.413, "loss": "4.953", "ppl": "30.97", "wps": "82462.1", "ups": "0.77", "wpb": "107136", "bsz": "256", "num_updates": "43000", "lr": "0.00049913", "gnorm": "0.561", "train_wall": "203", "gb_free": "7.5", "wall": "46659"}
[2023-03-28 11:26:15,230][train_inner][INFO] - {"epoch": 40, "update": 39.597, "loss": "4.981", "ppl": "31.58", "wps": "83596.2", "ups": "0.78", "wpb": "107090", "bsz": "256", "num_updates": "43200", "lr": "0.000497913", "gnorm": "0.558", "train_wall": "199", "gb_free": "7.5", "wall": "46915"}
[2023-03-28 11:30:25,890][train_inner][INFO] - {"epoch": 40, "update": 39.78, "loss": "5.003", "ppl": "32.06", "wps": "85515.4", "ups": "0.8", "wpb": "107176", "bsz": "256", "num_updates": "43400", "lr": "0.000496696", "gnorm": "0.557", "train_wall": "197", "gb_free": "7.5", "wall": "47166"}
[2023-03-28 11:34:47,845][train_inner][INFO] - {"epoch": 40, "update": 39.963, "loss": "5.007", "ppl": "32.15", "wps": "81962.7", "ups": "0.76", "wpb": "107353", "bsz": "256", "num_updates": "43600", "lr": "0.000495478", "gnorm": "0.554", "train_wall": "208", "gb_free": "7.5", "wall": "47428"}
[2023-03-28 11:35:30,286][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 11:35:30,287][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 11:35:31,174][valid][INFO] - {"epoch": 40, "valid_loss": "4.677", "valid_ppl": "25.58", "valid_wps": "281263", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "43640", "valid_best_loss": "4.677"}
[2023-03-28 11:35:31,175][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 43640 updates
[2023-03-28 11:35:31,175][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 11:35:31,711][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 11:35:31,980][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 40 @ 43640 updates, score 4.677) (writing took 0.8052507410029648 seconds)
[2023-03-28 11:35:31,980][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2023-03-28 11:35:31,981][train][INFO] - {"epoch": 40, "train_loss": "4.97", "train_ppl": "31.34", "train_wps": "84325.6", "train_ups": "0.79", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "43640", "train_lr": "0.000495235", "train_gnorm": "0.558", "train_train_wall": "1088", "train_gb_free": "7.5", "train_wall": "47472"}
[2023-03-28 11:35:31,983][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 11:35:32,015][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 11:35:32,017][fairseq.trainer][INFO] - begin training epoch 41
[2023-03-28 11:35:32,017][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 11:38:22,242][train_inner][INFO] - {"epoch": 41, "update": 40.147, "loss": "4.923", "ppl": "30.34", "wps": "99964.9", "ups": "0.93", "wpb": "107161", "bsz": "255.8", "num_updates": "43800", "lr": "0.000494261", "gnorm": "0.561", "train_wall": "167", "gb_free": "7.5", "wall": "47642"}
[2023-03-28 11:41:54,985][train_inner][INFO] - {"epoch": 41, "update": 40.33, "loss": "4.947", "ppl": "30.84", "wps": "100964", "ups": "0.94", "wpb": "107396", "bsz": "256", "num_updates": "44000", "lr": "0.000493043", "gnorm": "0.56", "train_wall": "167", "gb_free": "7.5", "wall": "47855"}
[2023-03-28 11:46:04,549][train_inner][INFO] - {"epoch": 41, "update": 40.513, "loss": "4.959", "ppl": "31.09", "wps": "85724.5", "ups": "0.8", "wpb": "106968", "bsz": "256", "num_updates": "44200", "lr": "0.000491826", "gnorm": "0.56", "train_wall": "197", "gb_free": "7.5", "wall": "48104"}
[2023-03-28 11:50:25,353][train_inner][INFO] - {"epoch": 41, "update": 40.697, "loss": "4.981", "ppl": "31.57", "wps": "82462.4", "ups": "0.77", "wpb": "107532", "bsz": "256", "num_updates": "44400", "lr": "0.000490609", "gnorm": "0.559", "train_wall": "203", "gb_free": "7.5", "wall": "48365"}
[2023-03-28 11:54:43,989][train_inner][INFO] - {"epoch": 41, "update": 40.88, "loss": "5", "ppl": "32", "wps": "82958.7", "ups": "0.77", "wpb": "107280", "bsz": "256", "num_updates": "44600", "lr": "0.000489391", "gnorm": "0.557", "train_wall": "200", "gb_free": "7.5", "wall": "48624"}
[2023-03-28 11:57:29,971][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 11:57:29,972][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 11:57:31,147][valid][INFO] - {"epoch": 41, "valid_loss": "4.673", "valid_ppl": "25.51", "valid_wps": "212238", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "44731", "valid_best_loss": "4.673"}
[2023-03-28 11:57:31,148][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 41 @ 44731 updates
[2023-03-28 11:57:31,149][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 11:57:31,857][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 11:57:32,375][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 41 @ 44731 updates, score 4.673) (writing took 1.2271224200012512 seconds)
[2023-03-28 11:57:32,376][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2023-03-28 11:57:32,376][train][INFO] - {"epoch": 41, "train_loss": "4.965", "train_ppl": "31.24", "train_wps": "88581.1", "train_ups": "0.83", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "44731", "train_lr": "0.000488594", "train_gnorm": "0.56", "train_train_wall": "1029", "train_gb_free": "7.5", "train_wall": "48792"}
[2023-03-28 11:57:32,378][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 11:57:32,418][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 11:57:32,420][fairseq.trainer][INFO] - begin training epoch 42
[2023-03-28 11:57:32,421][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 11:59:05,241][train_inner][INFO] - {"epoch": 42, "update": 41.063, "loss": "4.967", "ppl": "31.29", "wps": "81838.4", "ups": "0.77", "wpb": "106902", "bsz": "255.8", "num_updates": "44800", "lr": "0.000488174", "gnorm": "0.56", "train_wall": "202", "gb_free": "7.5", "wall": "48885"}
[2023-03-28 12:05:06,456][train_inner][INFO] - {"epoch": 42, "update": 41.247, "loss": "4.923", "ppl": "30.33", "wps": "59311.6", "ups": "0.55", "wpb": "107121", "bsz": "256", "num_updates": "45000", "lr": "0.000486957", "gnorm": "0.563", "train_wall": "281", "gb_free": "7.5", "wall": "49246"}
[2023-03-28 12:09:47,008][train_inner][INFO] - {"epoch": 42, "update": 41.43, "loss": "4.943", "ppl": "30.75", "wps": "76459.9", "ups": "0.71", "wpb": "107254", "bsz": "256", "num_updates": "45200", "lr": "0.000485739", "gnorm": "0.563", "train_wall": "219", "gb_free": "7.5", "wall": "49527"}
[2023-03-28 12:14:28,258][train_inner][INFO] - {"epoch": 42, "update": 41.613, "loss": "4.972", "ppl": "31.39", "wps": "76293.1", "ups": "0.71", "wpb": "107287", "bsz": "256", "num_updates": "45400", "lr": "0.000484522", "gnorm": "0.56", "train_wall": "219", "gb_free": "7.5", "wall": "49808"}
[2023-03-28 12:21:04,759][train_inner][INFO] - {"epoch": 42, "update": 41.797, "loss": "4.988", "ppl": "31.73", "wps": "54137.9", "ups": "0.5", "wpb": "107328", "bsz": "256", "num_updates": "45600", "lr": "0.000483304", "gnorm": "0.56", "train_wall": "306", "gb_free": "7.5", "wall": "50205"}
[2023-03-28 12:25:46,748][train_inner][INFO] - {"epoch": 42, "update": 41.98, "loss": "4.997", "ppl": "31.93", "wps": "75908", "ups": "0.71", "wpb": "107026", "bsz": "256", "num_updates": "45800", "lr": "0.000482087", "gnorm": "0.562", "train_wall": "220", "gb_free": "7.5", "wall": "50487"}
[2023-03-28 12:26:18,213][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 12:26:18,221][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 12:26:19,470][valid][INFO] - {"epoch": 42, "valid_loss": "4.667", "valid_ppl": "25.41", "valid_wps": "199198", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "45822", "valid_best_loss": "4.667"}
[2023-03-28 12:26:19,471][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 42 @ 45822 updates
[2023-03-28 12:26:19,472][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 12:26:19,716][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 12:26:19,880][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 42 @ 45822 updates, score 4.667) (writing took 0.40854399599629687 seconds)
[2023-03-28 12:26:19,881][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2023-03-28 12:26:19,884][train][INFO] - {"epoch": 42, "train_loss": "4.961", "train_ppl": "31.14", "train_wps": "67705.6", "train_ups": "0.63", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "45822", "train_lr": "0.000481953", "train_gnorm": "0.561", "train_train_wall": "1342", "train_gb_free": "7.5", "train_wall": "50520"}
[2023-03-28 12:26:19,887][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 12:26:19,930][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 12:26:19,933][fairseq.trainer][INFO] - begin training epoch 43
[2023-03-28 12:26:19,934][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 12:30:31,453][train_inner][INFO] - {"epoch": 43, "update": 42.163, "loss": "4.91", "ppl": "30.07", "wps": "75323.5", "ups": "0.7", "wpb": "107222", "bsz": "255.8", "num_updates": "46000", "lr": "0.00048087", "gnorm": "0.566", "train_wall": "221", "gb_free": "7.5", "wall": "50771"}
[2023-03-28 12:35:13,492][train_inner][INFO] - {"epoch": 43, "update": 42.346, "loss": "4.932", "ppl": "30.52", "wps": "76217.3", "ups": "0.71", "wpb": "107478", "bsz": "256", "num_updates": "46200", "lr": "0.000479652", "gnorm": "0.562", "train_wall": "221", "gb_free": "7.5", "wall": "51053"}
[2023-03-28 12:39:34,946][train_inner][INFO] - {"epoch": 43, "update": 42.53, "loss": "4.959", "ppl": "31.1", "wps": "82108.8", "ups": "0.76", "wpb": "107339", "bsz": "256", "num_updates": "46400", "lr": "0.000478435", "gnorm": "0.562", "train_wall": "208", "gb_free": "7.5", "wall": "51315"}
[2023-03-28 12:43:31,879][train_inner][INFO] - {"epoch": 43, "update": 42.713, "loss": "4.972", "ppl": "31.39", "wps": "90561.8", "ups": "0.84", "wpb": "107285", "bsz": "256", "num_updates": "46600", "lr": "0.000477217", "gnorm": "0.564", "train_wall": "187", "gb_free": "7.5", "wall": "51552"}
[2023-03-28 12:47:17,401][train_inner][INFO] - {"epoch": 43, "update": 42.896, "loss": "4.981", "ppl": "31.58", "wps": "94922.3", "ups": "0.89", "wpb": "107035", "bsz": "256", "num_updates": "46800", "lr": "0.000476", "gnorm": "0.56", "train_wall": "177", "gb_free": "7.5", "wall": "51777"}
[2023-03-28 12:49:45,141][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 12:49:45,143][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 12:49:46,316][valid][INFO] - {"epoch": 43, "valid_loss": "4.668", "valid_ppl": "25.42", "valid_wps": "211773", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "46913", "valid_best_loss": "4.667"}
[2023-03-28 12:49:46,317][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 43 @ 46913 updates
[2023-03-28 12:49:46,317][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 12:49:46,572][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 12:49:46,579][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 43 @ 46913 updates, score 4.668) (writing took 0.2624875589972362 seconds)
[2023-03-28 12:49:46,579][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2023-03-28 12:49:46,580][train][INFO] - {"epoch": 43, "train_loss": "4.955", "train_ppl": "31.02", "train_wps": "83146.7", "train_ups": "0.78", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "46913", "train_lr": "0.000475312", "train_gnorm": "0.563", "train_train_wall": "1106", "train_gb_free": "7.5", "train_wall": "51926"}
[2023-03-28 12:49:46,581][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 12:49:46,614][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 12:49:46,616][fairseq.trainer][INFO] - begin training epoch 44
[2023-03-28 12:49:46,617][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 12:51:37,670][train_inner][INFO] - {"epoch": 44, "update": 43.08, "loss": "4.949", "ppl": "30.88", "wps": "82053.2", "ups": "0.77", "wpb": "106779", "bsz": "255.8", "num_updates": "47000", "lr": "0.000474783", "gnorm": "0.565", "train_wall": "204", "gb_free": "7.5", "wall": "52038"}
[2023-03-28 12:55:32,644][train_inner][INFO] - {"epoch": 44, "update": 43.263, "loss": "4.918", "ppl": "30.24", "wps": "91334.9", "ups": "0.85", "wpb": "107306", "bsz": "256", "num_updates": "47200", "lr": "0.000473565", "gnorm": "0.567", "train_wall": "184", "gb_free": "7.5", "wall": "52272"}
[2023-03-28 12:59:04,886][train_inner][INFO] - {"epoch": 44, "update": 43.446, "loss": "4.938", "ppl": "30.65", "wps": "100952", "ups": "0.94", "wpb": "107131", "bsz": "256", "num_updates": "47400", "lr": "0.000472348", "gnorm": "0.566", "train_wall": "167", "gb_free": "7.5", "wall": "52485"}
[2023-03-28 13:02:37,085][train_inner][INFO] - {"epoch": 44, "update": 43.63, "loss": "4.96", "ppl": "31.13", "wps": "100959", "ups": "0.94", "wpb": "107117", "bsz": "256", "num_updates": "47600", "lr": "0.00047113", "gnorm": "0.563", "train_wall": "167", "gb_free": "7.5", "wall": "52697"}
[2023-03-28 13:06:07,767][train_inner][INFO] - {"epoch": 44, "update": 43.813, "loss": "4.98", "ppl": "31.55", "wps": "101686", "ups": "0.95", "wpb": "107116", "bsz": "256", "num_updates": "47800", "lr": "0.000469913", "gnorm": "0.565", "train_wall": "166", "gb_free": "7.5", "wall": "52908"}
[2023-03-28 13:09:38,542][train_inner][INFO] - {"epoch": 44, "update": 43.996, "loss": "4.991", "ppl": "31.79", "wps": "101962", "ups": "0.95", "wpb": "107455", "bsz": "256", "num_updates": "48000", "lr": "0.000468696", "gnorm": "0.563", "train_wall": "166", "gb_free": "7.5", "wall": "53118"}
[2023-03-28 13:09:42,728][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 13:09:42,729][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 13:09:43,602][valid][INFO] - {"epoch": 44, "valid_loss": "4.666", "valid_ppl": "25.38", "valid_wps": "285584", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "48004", "valid_best_loss": "4.666"}
[2023-03-28 13:09:43,603][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 44 @ 48004 updates
[2023-03-28 13:09:43,604][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 13:09:43,795][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 13:09:43,939][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 44 @ 48004 updates, score 4.666) (writing took 0.3357635940046748 seconds)
[2023-03-28 13:09:43,939][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2023-03-28 13:09:43,939][train][INFO] - {"epoch": 44, "train_loss": "4.951", "train_ppl": "30.93", "train_wps": "97683.3", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "48004", "train_lr": "0.000468671", "train_gnorm": "0.565", "train_train_wall": "940", "train_gb_free": "7.5", "train_wall": "53124"}
[2023-03-28 13:09:43,941][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 13:09:43,971][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 13:09:43,973][fairseq.trainer][INFO] - begin training epoch 45
[2023-03-28 13:09:43,974][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 13:13:10,883][train_inner][INFO] - {"epoch": 45, "update": 44.18, "loss": "4.89", "ppl": "29.65", "wps": "101086", "ups": "0.94", "wpb": "107323", "bsz": "255.8", "num_updates": "48200", "lr": "0.000467478", "gnorm": "0.567", "train_wall": "166", "gb_free": "7.5", "wall": "53331"}
[2023-03-28 13:16:41,541][train_inner][INFO] - {"epoch": 45, "update": 44.363, "loss": "4.924", "ppl": "30.35", "wps": "101768", "ups": "0.95", "wpb": "107190", "bsz": "256", "num_updates": "48400", "lr": "0.000466261", "gnorm": "0.567", "train_wall": "166", "gb_free": "7.5", "wall": "53541"}
[2023-03-28 13:20:12,361][train_inner][INFO] - {"epoch": 45, "update": 44.546, "loss": "4.948", "ppl": "30.87", "wps": "101974", "ups": "0.95", "wpb": "107490", "bsz": "256", "num_updates": "48600", "lr": "0.000465043", "gnorm": "0.568", "train_wall": "166", "gb_free": "7.5", "wall": "53752"}
[2023-03-28 13:23:42,904][train_inner][INFO] - {"epoch": 45, "update": 44.73, "loss": "4.967", "ppl": "31.27", "wps": "101737", "ups": "0.95", "wpb": "107100", "bsz": "256", "num_updates": "48800", "lr": "0.000463826", "gnorm": "0.569", "train_wall": "165", "gb_free": "7.5", "wall": "53963"}
[2023-03-28 13:27:13,054][train_inner][INFO] - {"epoch": 45, "update": 44.913, "loss": "4.984", "ppl": "31.64", "wps": "101770", "ups": "0.95", "wpb": "106936", "bsz": "256", "num_updates": "49000", "lr": "0.000462609", "gnorm": "0.568", "train_wall": "165", "gb_free": "7.5", "wall": "54173"}
[2023-03-28 13:28:52,939][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 13:28:52,940][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 13:28:53,810][valid][INFO] - {"epoch": 45, "valid_loss": "4.668", "valid_ppl": "25.43", "valid_wps": "286632", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "49095", "valid_best_loss": "4.666"}
[2023-03-28 13:28:53,811][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 45 @ 49095 updates
[2023-03-28 13:28:53,812][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 13:28:54,151][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 13:28:54,152][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 45 @ 49095 updates, score 4.668) (writing took 0.3404055559949484 seconds)
[2023-03-28 13:28:54,152][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2023-03-28 13:28:54,153][train][INFO] - {"epoch": 45, "train_loss": "4.946", "train_ppl": "30.83", "train_wps": "101687", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "49095", "train_lr": "0.00046203", "train_gnorm": "0.568", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "54274"}
[2023-03-28 13:28:54,155][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 13:28:54,186][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 13:28:54,188][fairseq.trainer][INFO] - begin training epoch 46
[2023-03-28 13:28:54,189][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 13:30:44,929][train_inner][INFO] - {"epoch": 46, "update": 45.096, "loss": "4.93", "ppl": "30.49", "wps": "101189", "ups": "0.94", "wpb": "107196", "bsz": "255.8", "num_updates": "49200", "lr": "0.000461391", "gnorm": "0.567", "train_wall": "165", "gb_free": "7.5", "wall": "54385"}
[2023-03-28 13:34:15,773][train_inner][INFO] - {"epoch": 46, "update": 45.28, "loss": "4.908", "ppl": "30.03", "wps": "101960", "ups": "0.95", "wpb": "107488", "bsz": "256", "num_updates": "49400", "lr": "0.000460174", "gnorm": "0.573", "train_wall": "166", "gb_free": "7.5", "wall": "54596"}
[2023-03-28 13:37:46,029][train_inner][INFO] - {"epoch": 46, "update": 45.463, "loss": "4.927", "ppl": "30.43", "wps": "101833", "ups": "0.95", "wpb": "107055", "bsz": "256", "num_updates": "49600", "lr": "0.000458957", "gnorm": "0.571", "train_wall": "165", "gb_free": "7.5", "wall": "54806"}
[2023-03-28 13:41:16,412][train_inner][INFO] - {"epoch": 46, "update": 45.646, "loss": "4.956", "ppl": "31.03", "wps": "101823", "ups": "0.95", "wpb": "107110", "bsz": "256", "num_updates": "49800", "lr": "0.000457739", "gnorm": "0.568", "train_wall": "165", "gb_free": "7.5", "wall": "55016"}
[2023-03-28 13:44:46,951][train_inner][INFO] - {"epoch": 46, "update": 45.83, "loss": "4.97", "ppl": "31.35", "wps": "101922", "ups": "0.95", "wpb": "107292", "bsz": "256", "num_updates": "50000", "lr": "0.000456522", "gnorm": "0.569", "train_wall": "166", "gb_free": "7.5", "wall": "55227"}
[2023-03-28 13:48:02,455][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 13:48:02,455][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 13:48:03,413][valid][INFO] - {"epoch": 46, "valid_loss": "4.666", "valid_ppl": "25.39", "valid_wps": "260682", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "50186", "valid_best_loss": "4.666"}
[2023-03-28 13:48:03,414][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 46 @ 50186 updates
[2023-03-28 13:48:03,415][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 13:48:03,780][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 13:48:04,064][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 46 @ 50186 updates, score 4.666) (writing took 0.6499783430044772 seconds)
[2023-03-28 13:48:04,064][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2023-03-28 13:48:04,065][train][INFO] - {"epoch": 46, "train_loss": "4.942", "train_ppl": "30.73", "train_wps": "101714", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "50186", "train_lr": "0.00045539", "train_gnorm": "0.57", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "55424"}
[2023-03-28 13:48:04,066][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 13:48:04,097][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 13:48:04,099][fairseq.trainer][INFO] - begin training epoch 47
[2023-03-28 13:48:04,100][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 13:48:19,127][train_inner][INFO] - {"epoch": 47, "update": 46.013, "loss": "4.973", "ppl": "31.42", "wps": "100858", "ups": "0.94", "wpb": "106998", "bsz": "255.8", "num_updates": "50200", "lr": "0.000455304", "gnorm": "0.567", "train_wall": "165", "gb_free": "7.5", "wall": "55439"}
[2023-03-28 13:51:49,087][train_inner][INFO] - {"epoch": 47, "update": 46.196, "loss": "4.892", "ppl": "29.68", "wps": "101718", "ups": "0.95", "wpb": "106783", "bsz": "256", "num_updates": "50400", "lr": "0.000454087", "gnorm": "0.574", "train_wall": "165", "gb_free": "7.5", "wall": "55649"}
[2023-03-28 13:55:20,240][train_inner][INFO] - {"epoch": 47, "update": 46.379, "loss": "4.919", "ppl": "30.25", "wps": "102010", "ups": "0.95", "wpb": "107698", "bsz": "256", "num_updates": "50600", "lr": "0.00045287", "gnorm": "0.571", "train_wall": "166", "gb_free": "7.5", "wall": "55860"}
[2023-03-28 13:58:50,741][train_inner][INFO] - {"epoch": 47, "update": 46.563, "loss": "4.948", "ppl": "30.87", "wps": "101743", "ups": "0.95", "wpb": "107086", "bsz": "256", "num_updates": "50800", "lr": "0.000451652", "gnorm": "0.572", "train_wall": "165", "gb_free": "7.5", "wall": "56071"}
[2023-03-28 14:02:21,539][train_inner][INFO] - {"epoch": 47, "update": 46.746, "loss": "4.953", "ppl": "30.98", "wps": "101891", "ups": "0.95", "wpb": "107392", "bsz": "256", "num_updates": "51000", "lr": "0.000450435", "gnorm": "0.57", "train_wall": "166", "gb_free": "7.5", "wall": "56281"}
[2023-03-28 14:05:51,917][train_inner][INFO] - {"epoch": 47, "update": 46.929, "loss": "4.973", "ppl": "31.4", "wps": "101852", "ups": "0.95", "wpb": "107137", "bsz": "256", "num_updates": "51200", "lr": "0.000449217", "gnorm": "0.57", "train_wall": "165", "gb_free": "7.5", "wall": "56492"}
[2023-03-28 14:07:12,949][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 14:07:12,950][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 14:07:13,833][valid][INFO] - {"epoch": 47, "valid_loss": "4.665", "valid_ppl": "25.38", "valid_wps": "282657", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "51277", "valid_best_loss": "4.665"}
[2023-03-28 14:07:13,834][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 47 @ 51277 updates
[2023-03-28 14:07:13,835][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 14:07:14,049][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 14:07:14,194][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 47 @ 51277 updates, score 4.665) (writing took 0.3605198430013843 seconds)
[2023-03-28 14:07:14,195][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2023-03-28 14:07:14,195][train][INFO] - {"epoch": 47, "train_loss": "4.938", "train_ppl": "30.66", "train_wps": "101695", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "51277", "train_lr": "0.000448749", "train_gnorm": "0.571", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "56574"}
[2023-03-28 14:07:14,197][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 14:07:14,228][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 14:07:14,231][fairseq.trainer][INFO] - begin training epoch 48
[2023-03-28 14:07:14,231][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 14:09:23,811][train_inner][INFO] - {"epoch": 48, "update": 47.113, "loss": "4.912", "ppl": "30.11", "wps": "101134", "ups": "0.94", "wpb": "107148", "bsz": "255.8", "num_updates": "51400", "lr": "0.000448", "gnorm": "0.572", "train_wall": "165", "gb_free": "7.5", "wall": "56704"}
[2023-03-28 14:12:54,136][train_inner][INFO] - {"epoch": 48, "update": 47.296, "loss": "4.909", "ppl": "30.04", "wps": "101769", "ups": "0.95", "wpb": "107022", "bsz": "256", "num_updates": "51600", "lr": "0.000446783", "gnorm": "0.574", "train_wall": "165", "gb_free": "7.5", "wall": "56914"}
[2023-03-28 14:16:33,169][train_inner][INFO] - {"epoch": 48, "update": 47.479, "loss": "4.931", "ppl": "30.51", "wps": "98017.5", "ups": "0.91", "wpb": "107345", "bsz": "256", "num_updates": "51800", "lr": "0.000445565", "gnorm": "0.573", "train_wall": "172", "gb_free": "7.5", "wall": "57133"}
[2023-03-28 14:21:00,590][train_inner][INFO] - {"epoch": 48, "update": 47.663, "loss": "4.952", "ppl": "30.95", "wps": "80358.7", "ups": "0.75", "wpb": "107448", "bsz": "256", "num_updates": "52000", "lr": "0.000444348", "gnorm": "0.572", "train_wall": "208", "gb_free": "7.5", "wall": "57400"}
[2023-03-28 14:25:18,154][train_inner][INFO] - {"epoch": 48, "update": 47.846, "loss": "4.957", "ppl": "31.07", "wps": "83199.1", "ups": "0.78", "wpb": "107142", "bsz": "256", "num_updates": "52200", "lr": "0.00044313", "gnorm": "0.573", "train_wall": "201", "gb_free": "7.5", "wall": "57658"}
[2023-03-28 14:28:54,447][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 14:28:54,449][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 14:28:55,626][valid][INFO] - {"epoch": 48, "valid_loss": "4.658", "valid_ppl": "25.25", "valid_wps": "212022", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "52368", "valid_best_loss": "4.658"}
[2023-03-28 14:28:55,627][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 48 @ 52368 updates
[2023-03-28 14:28:55,628][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 14:28:56,020][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 14:28:56,275][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 48 @ 52368 updates, score 4.658) (writing took 0.6481664530001581 seconds)
[2023-03-28 14:28:56,276][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2023-03-28 14:28:56,276][train][INFO] - {"epoch": 48, "train_loss": "4.935", "train_ppl": "30.58", "train_wps": "89827", "train_ups": "0.84", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "52368", "train_lr": "0.000442108", "train_gnorm": "0.573", "train_train_wall": "1017", "train_gb_free": "7.5", "train_wall": "57876"}
[2023-03-28 14:28:56,278][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 14:28:56,317][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 14:28:56,319][fairseq.trainer][INFO] - begin training epoch 49
[2023-03-28 14:28:56,320][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 14:29:38,629][train_inner][INFO] - {"epoch": 49, "update": 48.029, "loss": "4.949", "ppl": "30.89", "wps": "82266.5", "ups": "0.77", "wpb": "107142", "bsz": "255.8", "num_updates": "52400", "lr": "0.000441913", "gnorm": "0.573", "train_wall": "202", "gb_free": "7.5", "wall": "57918"}
[2023-03-28 14:33:51,938][train_inner][INFO] - {"epoch": 49, "update": 48.213, "loss": "4.886", "ppl": "29.57", "wps": "84478.2", "ups": "0.79", "wpb": "106995", "bsz": "256", "num_updates": "52600", "lr": "0.000440696", "gnorm": "0.58", "train_wall": "198", "gb_free": "7.5", "wall": "58172"}
[2023-03-28 14:38:08,749][train_inner][INFO] - {"epoch": 49, "update": 48.396, "loss": "4.917", "ppl": "30.2", "wps": "83605.6", "ups": "0.78", "wpb": "107354", "bsz": "256", "num_updates": "52800", "lr": "0.000439478", "gnorm": "0.576", "train_wall": "202", "gb_free": "7.5", "wall": "58429"}
[2023-03-28 14:42:22,044][train_inner][INFO] - {"epoch": 49, "update": 48.579, "loss": "4.937", "ppl": "30.62", "wps": "84612.6", "ups": "0.79", "wpb": "107159", "bsz": "256", "num_updates": "53000", "lr": "0.000438261", "gnorm": "0.578", "train_wall": "200", "gb_free": "7.5", "wall": "58682"}
[2023-03-28 14:46:37,078][train_inner][INFO] - {"epoch": 49, "update": 48.763, "loss": "4.945", "ppl": "30.8", "wps": "83997.6", "ups": "0.78", "wpb": "107112", "bsz": "256", "num_updates": "53200", "lr": "0.000437043", "gnorm": "0.576", "train_wall": "201", "gb_free": "7.5", "wall": "58937"}
[2023-03-28 14:50:52,472][train_inner][INFO] - {"epoch": 49, "update": 48.946, "loss": "4.972", "ppl": "31.38", "wps": "84213.8", "ups": "0.78", "wpb": "107538", "bsz": "256", "num_updates": "53400", "lr": "0.000435826", "gnorm": "0.573", "train_wall": "202", "gb_free": "7.5", "wall": "59192"}
[2023-03-28 14:52:07,313][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 14:52:07,314][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 14:52:08,417][valid][INFO] - {"epoch": 49, "valid_loss": "4.651", "valid_ppl": "25.13", "valid_wps": "226000", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "53459", "valid_best_loss": "4.651"}
[2023-03-28 14:52:08,418][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 49 @ 53459 updates
[2023-03-28 14:52:08,419][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 14:52:08,664][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 14:52:08,816][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 49 @ 53459 updates, score 4.651) (writing took 0.3975283549953019 seconds)
[2023-03-28 14:52:08,816][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2023-03-28 14:52:08,817][train][INFO] - {"epoch": 49, "train_loss": "4.931", "train_ppl": "30.51", "train_wps": "83991.8", "train_ups": "0.78", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "53459", "train_lr": "0.000435467", "train_gnorm": "0.576", "train_train_wall": "1094", "train_gb_free": "7.5", "train_wall": "59269"}
[2023-03-28 14:52:08,818][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 14:52:08,852][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 14:52:08,854][fairseq.trainer][INFO] - begin training epoch 50
[2023-03-28 14:52:08,854][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 14:55:09,780][train_inner][INFO] - {"epoch": 50, "update": 49.129, "loss": "4.897", "ppl": "29.79", "wps": "83317.4", "ups": "0.78", "wpb": "107191", "bsz": "255.8", "num_updates": "53600", "lr": "0.000434609", "gnorm": "0.576", "train_wall": "201", "gb_free": "7.5", "wall": "59450"}
[2023-03-28 14:59:26,720][train_inner][INFO] - {"epoch": 50, "update": 49.313, "loss": "4.894", "ppl": "29.74", "wps": "83263.6", "ups": "0.78", "wpb": "106969", "bsz": "256", "num_updates": "53800", "lr": "0.000433391", "gnorm": "0.579", "train_wall": "203", "gb_free": "7.5", "wall": "59707"}
[2023-03-28 15:03:44,803][train_inner][INFO] - {"epoch": 50, "update": 49.496, "loss": "4.921", "ppl": "30.29", "wps": "83305", "ups": "0.77", "wpb": "107498", "bsz": "256", "num_updates": "54000", "lr": "0.000432174", "gnorm": "0.58", "train_wall": "204", "gb_free": "7.5", "wall": "59965"}
[2023-03-28 15:08:05,523][train_inner][INFO] - {"epoch": 50, "update": 49.679, "loss": "4.946", "ppl": "30.82", "wps": "82256", "ups": "0.77", "wpb": "107228", "bsz": "256", "num_updates": "54200", "lr": "0.000430957", "gnorm": "0.578", "train_wall": "206", "gb_free": "7.5", "wall": "60225"}
[2023-03-28 15:12:25,862][train_inner][INFO] - {"epoch": 50, "update": 49.863, "loss": "4.96", "ppl": "31.12", "wps": "82318.4", "ups": "0.77", "wpb": "107153", "bsz": "256", "num_updates": "54400", "lr": "0.000429739", "gnorm": "0.578", "train_wall": "206", "gb_free": "7.5", "wall": "60486"}
[2023-03-28 15:15:40,921][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 15:15:40,922][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 15:15:42,066][valid][INFO] - {"epoch": 50, "valid_loss": "4.654", "valid_ppl": "25.18", "valid_wps": "218277", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "54550", "valid_best_loss": "4.651"}
[2023-03-28 15:15:42,067][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 54550 updates
[2023-03-28 15:15:42,068][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 15:15:42,351][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 15:15:42,357][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 50 @ 54550 updates, score 4.654) (writing took 0.290374668998993 seconds)
[2023-03-28 15:15:42,358][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2023-03-28 15:15:42,358][train][INFO] - {"epoch": 50, "train_loss": "4.927", "train_ppl": "30.42", "train_wps": "82744", "train_ups": "0.77", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "54550", "train_lr": "0.000428826", "train_gnorm": "0.579", "train_train_wall": "1114", "train_gb_free": "7.5", "train_wall": "60682"}
[2023-03-28 15:15:42,360][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 15:15:42,392][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 15:15:42,394][fairseq.trainer][INFO] - begin training epoch 51
[2023-03-28 15:15:42,395][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 15:16:46,979][train_inner][INFO] - {"epoch": 51, "update": 50.046, "loss": "4.939", "ppl": "30.68", "wps": "81888.9", "ups": "0.77", "wpb": "106913", "bsz": "255.8", "num_updates": "54600", "lr": "0.000428522", "gnorm": "0.579", "train_wall": "204", "gb_free": "7.5", "wall": "60747"}
[2023-03-28 15:20:57,652][train_inner][INFO] - {"epoch": 51, "update": 50.229, "loss": "4.877", "ppl": "29.38", "wps": "85481.6", "ups": "0.8", "wpb": "107139", "bsz": "256", "num_updates": "54800", "lr": "0.000427304", "gnorm": "0.581", "train_wall": "197", "gb_free": "7.5", "wall": "60998"}
[2023-03-28 15:25:06,062][train_inner][INFO] - {"epoch": 51, "update": 50.412, "loss": "4.913", "ppl": "30.13", "wps": "86453.8", "ups": "0.81", "wpb": "107380", "bsz": "256", "num_updates": "55000", "lr": "0.000426087", "gnorm": "0.58", "train_wall": "196", "gb_free": "7.5", "wall": "61246"}
[2023-03-28 15:29:22,491][train_inner][INFO] - {"epoch": 51, "update": 50.596, "loss": "4.933", "ppl": "30.54", "wps": "83809.1", "ups": "0.78", "wpb": "107456", "bsz": "256", "num_updates": "55200", "lr": "0.00042487", "gnorm": "0.581", "train_wall": "202", "gb_free": "7.5", "wall": "61502"}
[2023-03-28 15:33:37,013][train_inner][INFO] - {"epoch": 51, "update": 50.779, "loss": "4.949", "ppl": "30.89", "wps": "84293.1", "ups": "0.79", "wpb": "107272", "bsz": "256", "num_updates": "55400", "lr": "0.000423652", "gnorm": "0.579", "train_wall": "202", "gb_free": "7.5", "wall": "61757"}
[2023-03-28 15:37:36,625][train_inner][INFO] - {"epoch": 51, "update": 50.962, "loss": "4.957", "ppl": "31.06", "wps": "89323.3", "ups": "0.83", "wpb": "107014", "bsz": "256", "num_updates": "55600", "lr": "0.000422435", "gnorm": "0.581", "train_wall": "189", "gb_free": "7.5", "wall": "61996"}
[2023-03-28 15:38:28,319][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 15:38:28,320][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 15:38:29,378][valid][INFO] - {"epoch": 51, "valid_loss": "4.643", "valid_ppl": "24.99", "valid_wps": "236179", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "55641", "valid_best_loss": "4.643"}
[2023-03-28 15:38:29,379][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 51 @ 55641 updates
[2023-03-28 15:38:29,380][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 15:38:29,626][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 15:38:29,777][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 51 @ 55641 updates, score 4.643) (writing took 0.39841324400913436 seconds)
[2023-03-28 15:38:29,777][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2023-03-28 15:38:29,778][train][INFO] - {"epoch": 51, "train_loss": "4.923", "train_ppl": "30.35", "train_wps": "85534.8", "train_ups": "0.8", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "55641", "train_lr": "0.000422185", "train_gnorm": "0.581", "train_train_wall": "1076", "train_gb_free": "7.5", "train_wall": "62050"}
[2023-03-28 15:38:29,780][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 15:38:29,815][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 15:38:29,817][fairseq.trainer][INFO] - begin training epoch 52
[2023-03-28 15:38:29,818][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 15:41:52,813][train_inner][INFO] - {"epoch": 52, "update": 51.146, "loss": "4.881", "ppl": "29.46", "wps": "83596.5", "ups": "0.78", "wpb": "107082", "bsz": "255.8", "num_updates": "55800", "lr": "0.000421217", "gnorm": "0.585", "train_wall": "201", "gb_free": "7.5", "wall": "62253"}
[2023-03-28 15:46:07,239][train_inner][INFO] - {"epoch": 52, "update": 51.329, "loss": "4.892", "ppl": "29.7", "wps": "84108.8", "ups": "0.79", "wpb": "106997", "bsz": "256", "num_updates": "56000", "lr": "0.00042", "gnorm": "0.584", "train_wall": "201", "gb_free": "7.5", "wall": "62507"}
[2023-03-28 15:50:23,281][train_inner][INFO] - {"epoch": 52, "update": 51.512, "loss": "4.922", "ppl": "30.32", "wps": "83691", "ups": "0.78", "wpb": "107139", "bsz": "256", "num_updates": "56200", "lr": "0.000418783", "gnorm": "0.584", "train_wall": "203", "gb_free": "7.5", "wall": "62763"}
[2023-03-28 15:54:36,007][train_inner][INFO] - {"epoch": 52, "update": 51.696, "loss": "4.938", "ppl": "30.65", "wps": "84928.1", "ups": "0.79", "wpb": "107317", "bsz": "256", "num_updates": "56400", "lr": "0.000417565", "gnorm": "0.581", "train_wall": "200", "gb_free": "7.5", "wall": "63016"}
[2023-03-28 15:58:49,809][train_inner][INFO] - {"epoch": 52, "update": 51.879, "loss": "4.942", "ppl": "30.73", "wps": "84430.8", "ups": "0.79", "wpb": "107144", "bsz": "256", "num_updates": "56600", "lr": "0.000416348", "gnorm": "0.582", "train_wall": "201", "gb_free": "7.5", "wall": "63270"}
[2023-03-28 16:01:36,798][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 16:01:36,799][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 16:01:37,919][valid][INFO] - {"epoch": 52, "valid_loss": "4.645", "valid_ppl": "25.02", "valid_wps": "221497", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "56732", "valid_best_loss": "4.643"}
[2023-03-28 16:01:37,920][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 52 @ 56732 updates
[2023-03-28 16:01:37,921][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 16:01:38,376][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 16:01:38,395][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 52 @ 56732 updates, score 4.645) (writing took 0.4745358509971993 seconds)
[2023-03-28 16:01:38,395][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2023-03-28 16:01:38,397][train][INFO] - {"epoch": 52, "train_loss": "4.919", "train_ppl": "30.26", "train_wps": "84229", "train_ups": "0.79", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "56732", "train_lr": "0.000415544", "train_gnorm": "0.583", "train_train_wall": "1099", "train_gb_free": "7.5", "train_wall": "63438"}
[2023-03-28 16:01:38,400][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 16:01:38,443][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 16:01:38,445][fairseq.trainer][INFO] - begin training epoch 53
[2023-03-28 16:01:38,446][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 16:03:04,705][train_inner][INFO] - {"epoch": 53, "update": 52.062, "loss": "4.926", "ppl": "30.4", "wps": "84242.5", "ups": "0.78", "wpb": "107365", "bsz": "255.8", "num_updates": "56800", "lr": "0.00041513", "gnorm": "0.584", "train_wall": "201", "gb_free": "7.5", "wall": "63525"}
[2023-03-28 16:07:17,202][train_inner][INFO] - {"epoch": 53, "update": 52.246, "loss": "4.87", "ppl": "29.25", "wps": "84871", "ups": "0.79", "wpb": "107148", "bsz": "256", "num_updates": "57000", "lr": "0.000413913", "gnorm": "0.587", "train_wall": "200", "gb_free": "7.5", "wall": "63777"}
[2023-03-28 16:11:33,239][train_inner][INFO] - {"epoch": 53, "update": 52.429, "loss": "4.906", "ppl": "29.99", "wps": "83765", "ups": "0.78", "wpb": "107234", "bsz": "256", "num_updates": "57200", "lr": "0.000412696", "gnorm": "0.587", "train_wall": "203", "gb_free": "7.5", "wall": "64033"}
[2023-03-28 16:15:37,971][train_inner][INFO] - {"epoch": 53, "update": 52.612, "loss": "4.924", "ppl": "30.36", "wps": "87659", "ups": "0.82", "wpb": "107265", "bsz": "256", "num_updates": "57400", "lr": "0.000411478", "gnorm": "0.584", "train_wall": "193", "gb_free": "7.5", "wall": "64278"}
[2023-03-28 16:19:44,478][train_inner][INFO] - {"epoch": 53, "update": 52.796, "loss": "4.941", "ppl": "30.72", "wps": "86978", "ups": "0.81", "wpb": "107203", "bsz": "256", "num_updates": "57600", "lr": "0.000410261", "gnorm": "0.585", "train_wall": "195", "gb_free": "7.5", "wall": "64524"}
[2023-03-28 16:24:01,898][train_inner][INFO] - {"epoch": 53, "update": 52.979, "loss": "4.957", "ppl": "31.06", "wps": "83415.9", "ups": "0.78", "wpb": "107364", "bsz": "256", "num_updates": "57800", "lr": "0.000409043", "gnorm": "0.585", "train_wall": "203", "gb_free": "7.5", "wall": "64782"}
[2023-03-28 16:24:31,400][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 16:24:31,400][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 16:24:32,455][valid][INFO] - {"epoch": 53, "valid_loss": "4.638", "valid_ppl": "24.89", "valid_wps": "235944", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "57823", "valid_best_loss": "4.638"}
[2023-03-28 16:24:32,456][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 53 @ 57823 updates
[2023-03-28 16:24:32,457][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 16:24:32,709][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 16:24:32,856][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 53 @ 57823 updates, score 4.638) (writing took 0.3999888660036959 seconds)
[2023-03-28 16:24:32,857][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2023-03-28 16:24:32,857][train][INFO] - {"epoch": 53, "train_loss": "4.916", "train_ppl": "30.2", "train_wps": "85096.7", "train_ups": "0.79", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "57823", "train_lr": "0.000408903", "train_gnorm": "0.586", "train_train_wall": "1085", "train_gb_free": "7.5", "train_wall": "64813"}
[2023-03-28 16:24:32,859][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 16:24:32,892][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 16:24:32,895][fairseq.trainer][INFO] - begin training epoch 54
[2023-03-28 16:24:32,895][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 16:28:01,785][train_inner][INFO] - {"epoch": 54, "update": 53.162, "loss": "4.869", "ppl": "29.21", "wps": "89322.6", "ups": "0.83", "wpb": "107137", "bsz": "255.8", "num_updates": "58000", "lr": "0.000407826", "gnorm": "0.587", "train_wall": "188", "gb_free": "7.5", "wall": "65022"}
[2023-03-28 16:31:41,891][train_inner][INFO] - {"epoch": 54, "update": 53.346, "loss": "4.892", "ppl": "29.69", "wps": "97275.7", "ups": "0.91", "wpb": "107055", "bsz": "256", "num_updates": "58200", "lr": "0.000406609", "gnorm": "0.59", "train_wall": "173", "gb_free": "7.5", "wall": "65242"}
[2023-03-28 16:35:14,448][train_inner][INFO] - {"epoch": 54, "update": 53.529, "loss": "4.905", "ppl": "29.95", "wps": "100777", "ups": "0.94", "wpb": "107104", "bsz": "256", "num_updates": "58400", "lr": "0.000405391", "gnorm": "0.588", "train_wall": "166", "gb_free": "7.5", "wall": "65454"}
[2023-03-28 16:38:47,267][train_inner][INFO] - {"epoch": 54, "update": 53.712, "loss": "4.936", "ppl": "30.61", "wps": "100924", "ups": "0.94", "wpb": "107393", "bsz": "256", "num_updates": "58600", "lr": "0.000404174", "gnorm": "0.587", "train_wall": "167", "gb_free": "7.5", "wall": "65667"}
[2023-03-28 16:42:23,994][train_inner][INFO] - {"epoch": 54, "update": 53.896, "loss": "4.942", "ppl": "30.73", "wps": "99056.5", "ups": "0.92", "wpb": "107341", "bsz": "256", "num_updates": "58800", "lr": "0.000402957", "gnorm": "0.587", "train_wall": "170", "gb_free": "7.5", "wall": "65884"}
[2023-03-28 16:44:28,693][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 16:44:28,693][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 16:44:29,656][valid][INFO] - {"epoch": 54, "valid_loss": "4.641", "valid_ppl": "24.94", "valid_wps": "259160", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "58914", "valid_best_loss": "4.638"}
[2023-03-28 16:44:29,657][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 54 @ 58914 updates
[2023-03-28 16:44:29,657][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 16:44:29,905][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 16:44:29,912][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 54 @ 58914 updates, score 4.641) (writing took 0.25561799301067367 seconds)
[2023-03-28 16:44:29,912][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2023-03-28 16:44:29,913][train][INFO] - {"epoch": 54, "train_loss": "4.913", "train_ppl": "30.12", "train_wps": "97708.1", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "58914", "train_lr": "0.000402263", "train_gnorm": "0.588", "train_train_wall": "940", "train_gb_free": "7.5", "train_wall": "66010"}
[2023-03-28 16:44:29,915][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 16:44:29,946][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 16:44:29,948][fairseq.trainer][INFO] - begin training epoch 55
[2023-03-28 16:44:29,949][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 16:46:04,282][train_inner][INFO] - {"epoch": 55, "update": 54.079, "loss": "4.909", "ppl": "30.04", "wps": "97142.3", "ups": "0.91", "wpb": "106996", "bsz": "255.8", "num_updates": "59000", "lr": "0.000401739", "gnorm": "0.587", "train_wall": "172", "gb_free": "7.5", "wall": "66104"}
[2023-03-28 16:49:43,343][train_inner][INFO] - {"epoch": 55, "update": 54.262, "loss": "4.876", "ppl": "29.36", "wps": "97976.2", "ups": "0.91", "wpb": "107313", "bsz": "256", "num_updates": "59200", "lr": "0.000400522", "gnorm": "0.591", "train_wall": "172", "gb_free": "7.5", "wall": "66323"}
[2023-03-28 16:53:22,252][train_inner][INFO] - {"epoch": 55, "update": 54.445, "loss": "4.896", "ppl": "29.78", "wps": "97928.1", "ups": "0.91", "wpb": "107183", "bsz": "256", "num_updates": "59400", "lr": "0.000399304", "gnorm": "0.591", "train_wall": "172", "gb_free": "7.5", "wall": "66542"}
[2023-03-28 16:57:01,224][train_inner][INFO] - {"epoch": 55, "update": 54.629, "loss": "4.926", "ppl": "30.39", "wps": "97916.1", "ups": "0.91", "wpb": "107204", "bsz": "256", "num_updates": "59600", "lr": "0.000398087", "gnorm": "0.588", "train_wall": "172", "gb_free": "7.5", "wall": "66761"}
[2023-03-28 17:00:40,177][train_inner][INFO] - {"epoch": 55, "update": 54.812, "loss": "4.934", "ppl": "30.57", "wps": "97957.2", "ups": "0.91", "wpb": "107240", "bsz": "256", "num_updates": "59800", "lr": "0.00039687", "gnorm": "0.591", "train_wall": "172", "gb_free": "7.5", "wall": "66980"}
[2023-03-28 17:04:19,129][train_inner][INFO] - {"epoch": 55, "update": 54.995, "loss": "4.946", "ppl": "30.82", "wps": "97953", "ups": "0.91", "wpb": "107234", "bsz": "256", "num_updates": "60000", "lr": "0.000395652", "gnorm": "0.59", "train_wall": "172", "gb_free": "7.5", "wall": "67199"}
[2023-03-28 17:04:24,567][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 17:04:24,568][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 17:04:25,474][valid][INFO] - {"epoch": 55, "valid_loss": "4.643", "valid_ppl": "24.99", "valid_wps": "275144", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "60005", "valid_best_loss": "4.638"}
[2023-03-28 17:04:25,475][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 55 @ 60005 updates
[2023-03-28 17:04:25,476][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 17:04:26,049][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 17:04:26,058][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 55 @ 60005 updates, score 4.643) (writing took 0.5831591109890724 seconds)
[2023-03-28 17:04:26,059][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2023-03-28 17:04:26,059][train][INFO] - {"epoch": 55, "train_loss": "4.91", "train_ppl": "30.07", "train_wps": "97782.4", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "60005", "train_lr": "0.000395622", "train_gnorm": "0.59", "train_train_wall": "940", "train_gb_free": "7.5", "train_wall": "67206"}
[2023-03-28 17:04:26,062][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 17:04:26,092][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 17:04:26,095][fairseq.trainer][INFO] - begin training epoch 56
[2023-03-28 17:04:26,095][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 17:07:59,613][train_inner][INFO] - {"epoch": 56, "update": 55.179, "loss": "4.859", "ppl": "29.02", "wps": "97231.2", "ups": "0.91", "wpb": "107190", "bsz": "255.8", "num_updates": "60200", "lr": "0.000394435", "gnorm": "0.592", "train_wall": "172", "gb_free": "7.5", "wall": "67419"}
[2023-03-28 17:11:38,925][train_inner][INFO] - {"epoch": 56, "update": 55.362, "loss": "4.885", "ppl": "29.55", "wps": "98017", "ups": "0.91", "wpb": "107478", "bsz": "256", "num_updates": "60400", "lr": "0.000393217", "gnorm": "0.593", "train_wall": "173", "gb_free": "7.5", "wall": "67639"}
[2023-03-28 17:15:17,279][train_inner][INFO] - {"epoch": 56, "update": 55.545, "loss": "4.911", "ppl": "30.08", "wps": "97773", "ups": "0.92", "wpb": "106746", "bsz": "256", "num_updates": "60600", "lr": "0.000392", "gnorm": "0.595", "train_wall": "172", "gb_free": "7.5", "wall": "67857"}
[2023-03-28 17:18:56,288][train_inner][INFO] - {"epoch": 56, "update": 55.729, "loss": "4.925", "ppl": "30.38", "wps": "97989.5", "ups": "0.91", "wpb": "107303", "bsz": "256", "num_updates": "60800", "lr": "0.000390783", "gnorm": "0.595", "train_wall": "172", "gb_free": "7.5", "wall": "68076"}
[2023-03-28 17:22:35,320][train_inner][INFO] - {"epoch": 56, "update": 55.912, "loss": "4.93", "ppl": "30.49", "wps": "97944.3", "ups": "0.91", "wpb": "107264", "bsz": "256", "num_updates": "61000", "lr": "0.000389565", "gnorm": "0.592", "train_wall": "172", "gb_free": "7.5", "wall": "68295"}
[2023-03-28 17:24:20,498][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 17:24:20,499][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 17:24:21,403][valid][INFO] - {"epoch": 56, "valid_loss": "4.639", "valid_ppl": "24.91", "valid_wps": "275689", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "61096", "valid_best_loss": "4.638"}
[2023-03-28 17:24:21,404][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 56 @ 61096 updates
[2023-03-28 17:24:21,405][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 17:24:21,667][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 17:24:21,681][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 56 @ 61096 updates, score 4.639) (writing took 0.27717952200328 seconds)
[2023-03-28 17:24:21,682][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2023-03-28 17:24:21,683][train][INFO] - {"epoch": 56, "train_loss": "4.906", "train_ppl": "29.98", "train_wps": "97825.2", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "61096", "train_lr": "0.000388981", "train_gnorm": "0.593", "train_train_wall": "940", "train_gb_free": "7.5", "train_wall": "68402"}
[2023-03-28 17:24:21,685][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 17:24:21,718][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 17:24:21,721][fairseq.trainer][INFO] - begin training epoch 57
[2023-03-28 17:24:21,721][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 17:26:16,196][train_inner][INFO] - {"epoch": 57, "update": 56.095, "loss": "4.889", "ppl": "29.62", "wps": "97307.9", "ups": "0.91", "wpb": "107465", "bsz": "255.8", "num_updates": "61200", "lr": "0.000388348", "gnorm": "0.591", "train_wall": "173", "gb_free": "7.5", "wall": "68516"}
[2023-03-28 17:29:55,104][train_inner][INFO] - {"epoch": 57, "update": 56.279, "loss": "4.868", "ppl": "29.2", "wps": "97863.7", "ups": "0.91", "wpb": "107112", "bsz": "256", "num_updates": "61400", "lr": "0.00038713", "gnorm": "0.598", "train_wall": "172", "gb_free": "7.5", "wall": "68735"}
[2023-03-28 17:33:34,171][train_inner][INFO] - {"epoch": 57, "update": 56.462, "loss": "4.894", "ppl": "29.73", "wps": "97934.6", "ups": "0.91", "wpb": "107271", "bsz": "256", "num_updates": "61600", "lr": "0.000385913", "gnorm": "0.594", "train_wall": "172", "gb_free": "7.5", "wall": "68954"}
[2023-03-28 17:37:13,229][train_inner][INFO] - {"epoch": 57, "update": 56.645, "loss": "4.914", "ppl": "30.15", "wps": "97941.4", "ups": "0.91", "wpb": "107274", "bsz": "256", "num_updates": "61800", "lr": "0.000384696", "gnorm": "0.596", "train_wall": "172", "gb_free": "7.5", "wall": "69173"}
[2023-03-28 17:40:51,972][train_inner][INFO] - {"epoch": 57, "update": 56.829, "loss": "4.932", "ppl": "30.54", "wps": "97915.1", "ups": "0.91", "wpb": "107091", "bsz": "256", "num_updates": "62000", "lr": "0.000383478", "gnorm": "0.593", "train_wall": "172", "gb_free": "7.5", "wall": "69392"}
[2023-03-28 17:44:16,328][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 17:44:16,329][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 17:44:17,291][valid][INFO] - {"epoch": 57, "valid_loss": "4.634", "valid_ppl": "24.82", "valid_wps": "259831", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "62187", "valid_best_loss": "4.634"}
[2023-03-28 17:44:17,292][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 57 @ 62187 updates
[2023-03-28 17:44:17,293][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 17:44:17,534][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 17:44:17,677][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 57 @ 62187 updates, score 4.634) (writing took 0.38480337300279643 seconds)
[2023-03-28 17:44:17,677][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2023-03-28 17:44:17,677][train][INFO] - {"epoch": 57, "train_loss": "4.902", "train_ppl": "29.89", "train_wps": "97794.8", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "62187", "train_lr": "0.00038234", "train_gnorm": "0.595", "train_train_wall": "940", "train_gb_free": "7.5", "train_wall": "69598"}
[2023-03-28 17:44:17,679][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 17:44:17,710][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 17:44:17,712][fairseq.trainer][INFO] - begin training epoch 58
[2023-03-28 17:44:17,712][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 17:44:32,174][train_inner][INFO] - {"epoch": 58, "update": 57.012, "loss": "4.929", "ppl": "30.46", "wps": "97167.7", "ups": "0.91", "wpb": "106983", "bsz": "255.8", "num_updates": "62200", "lr": "0.000382261", "gnorm": "0.594", "train_wall": "172", "gb_free": "7.5", "wall": "69612"}
[2023-03-28 17:48:11,335][train_inner][INFO] - {"epoch": 58, "update": 57.195, "loss": "4.852", "ppl": "28.88", "wps": "97958.3", "ups": "0.91", "wpb": "107343", "bsz": "256", "num_updates": "62400", "lr": "0.000381043", "gnorm": "0.599", "train_wall": "172", "gb_free": "7.5", "wall": "69831"}
[2023-03-28 17:51:50,616][train_inner][INFO] - {"epoch": 58, "update": 57.379, "loss": "4.883", "ppl": "29.51", "wps": "97958.4", "ups": "0.91", "wpb": "107402", "bsz": "256", "num_updates": "62600", "lr": "0.000379826", "gnorm": "0.597", "train_wall": "173", "gb_free": "7.5", "wall": "70050"}
[2023-03-28 17:55:29,587][train_inner][INFO] - {"epoch": 58, "update": 57.562, "loss": "4.899", "ppl": "29.84", "wps": "97948.1", "ups": "0.91", "wpb": "107239", "bsz": "256", "num_updates": "62800", "lr": "0.000378609", "gnorm": "0.599", "train_wall": "172", "gb_free": "7.5", "wall": "70269"}
[2023-03-28 17:59:08,754][train_inner][INFO] - {"epoch": 58, "update": 57.745, "loss": "4.915", "ppl": "30.17", "wps": "97982.8", "ups": "0.91", "wpb": "107373", "bsz": "256", "num_updates": "63000", "lr": "0.000377391", "gnorm": "0.596", "train_wall": "172", "gb_free": "7.5", "wall": "70489"}
[2023-03-28 18:02:47,162][train_inner][INFO] - {"epoch": 58, "update": 57.929, "loss": "4.935", "ppl": "30.59", "wps": "97876.6", "ups": "0.92", "wpb": "106885", "bsz": "256", "num_updates": "63200", "lr": "0.000376174", "gnorm": "0.598", "train_wall": "172", "gb_free": "7.5", "wall": "70707"}
[2023-03-28 18:04:12,266][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 18:04:12,267][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 18:04:13,172][valid][INFO] - {"epoch": 58, "valid_loss": "4.633", "valid_ppl": "24.82", "valid_wps": "275582", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "63278", "valid_best_loss": "4.633"}
[2023-03-28 18:04:13,173][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 58 @ 63278 updates
[2023-03-28 18:04:13,174][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 18:04:13,749][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 18:04:14,263][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 58 @ 63278 updates, score 4.633) (writing took 1.0902030209981604 seconds)
[2023-03-28 18:04:14,263][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2023-03-28 18:04:14,264][train][INFO] - {"epoch": 58, "train_loss": "4.899", "train_ppl": "29.84", "train_wps": "97746.4", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "63278", "train_lr": "0.000375699", "train_gnorm": "0.598", "train_train_wall": "940", "train_gb_free": "7.5", "train_wall": "70794"}
[2023-03-28 18:04:14,265][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 18:04:14,299][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 18:04:14,301][fairseq.trainer][INFO] - begin training epoch 59
[2023-03-28 18:04:14,302][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 18:06:27,904][train_inner][INFO] - {"epoch": 59, "update": 58.112, "loss": "4.877", "ppl": "29.39", "wps": "96933.5", "ups": "0.91", "wpb": "106986", "bsz": "255.8", "num_updates": "63400", "lr": "0.000374957", "gnorm": "0.6", "train_wall": "172", "gb_free": "7.5", "wall": "70928"}
[2023-03-28 18:10:06,907][train_inner][INFO] - {"epoch": 59, "update": 58.295, "loss": "4.869", "ppl": "29.23", "wps": "97945.4", "ups": "0.91", "wpb": "107252", "bsz": "256", "num_updates": "63600", "lr": "0.000373739", "gnorm": "0.601", "train_wall": "172", "gb_free": "7.5", "wall": "71147"}
[2023-03-28 18:13:45,635][train_inner][INFO] - {"epoch": 59, "update": 58.478, "loss": "4.889", "ppl": "29.62", "wps": "97939.2", "ups": "0.91", "wpb": "107110", "bsz": "256", "num_updates": "63800", "lr": "0.000372522", "gnorm": "0.601", "train_wall": "172", "gb_free": "7.5", "wall": "71365"}
[2023-03-28 18:17:25,101][train_inner][INFO] - {"epoch": 59, "update": 58.662, "loss": "4.91", "ppl": "30.07", "wps": "98062.7", "ups": "0.91", "wpb": "107607", "bsz": "256", "num_updates": "64000", "lr": "0.000371304", "gnorm": "0.599", "train_wall": "173", "gb_free": "7.5", "wall": "71585"}
[2023-03-28 18:21:03,746][train_inner][INFO] - {"epoch": 59, "update": 58.845, "loss": "4.921", "ppl": "30.3", "wps": "97923.5", "ups": "0.91", "wpb": "107049", "bsz": "256", "num_updates": "64200", "lr": "0.000370087", "gnorm": "0.602", "train_wall": "172", "gb_free": "7.5", "wall": "71804"}
[2023-03-28 18:24:08,708][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 18:24:08,709][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 18:24:09,665][valid][INFO] - {"epoch": 59, "valid_loss": "4.634", "valid_ppl": "24.83", "valid_wps": "260361", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "64369", "valid_best_loss": "4.633"}
[2023-03-28 18:24:09,667][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 59 @ 64369 updates
[2023-03-28 18:24:09,668][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 18:24:09,912][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 18:24:09,919][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 59 @ 64369 updates, score 4.634) (writing took 0.25181522499769926 seconds)
[2023-03-28 18:24:09,919][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2023-03-28 18:24:09,919][train][INFO] - {"epoch": 59, "train_loss": "4.896", "train_ppl": "29.78", "train_wps": "97822.5", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "64369", "train_lr": "0.000369058", "train_gnorm": "0.601", "train_train_wall": "940", "train_gb_free": "7.5", "train_wall": "71990"}
[2023-03-28 18:24:09,921][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 18:24:09,951][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 18:24:09,953][fairseq.trainer][INFO] - begin training epoch 60
[2023-03-28 18:24:09,954][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 18:24:44,322][train_inner][INFO] - {"epoch": 60, "update": 59.028, "loss": "4.918", "ppl": "30.22", "wps": "97185.8", "ups": "0.91", "wpb": "107184", "bsz": "255.8", "num_updates": "64400", "lr": "0.00036887", "gnorm": "0.6", "train_wall": "172", "gb_free": "7.5", "wall": "72024"}
[2023-03-28 18:28:22,923][train_inner][INFO] - {"epoch": 60, "update": 59.212, "loss": "4.85", "ppl": "28.83", "wps": "97891.4", "ups": "0.91", "wpb": "106995", "bsz": "256", "num_updates": "64600", "lr": "0.000367652", "gnorm": "0.605", "train_wall": "172", "gb_free": "7.5", "wall": "72243"}
[2023-03-28 18:32:01,935][train_inner][INFO] - {"epoch": 60, "update": 59.395, "loss": "4.88", "ppl": "29.45", "wps": "97786.9", "ups": "0.91", "wpb": "107079", "bsz": "256", "num_updates": "64800", "lr": "0.000366435", "gnorm": "0.605", "train_wall": "172", "gb_free": "7.5", "wall": "72462"}
[2023-03-28 18:35:40,969][train_inner][INFO] - {"epoch": 60, "update": 59.578, "loss": "4.898", "ppl": "29.81", "wps": "98009.4", "ups": "0.91", "wpb": "107334", "bsz": "256", "num_updates": "65000", "lr": "0.000365217", "gnorm": "0.602", "train_wall": "172", "gb_free": "7.5", "wall": "72681"}
[2023-03-28 18:39:20,100][train_inner][INFO] - {"epoch": 60, "update": 59.762, "loss": "4.912", "ppl": "30.12", "wps": "98053.2", "ups": "0.91", "wpb": "107429", "bsz": "256", "num_updates": "65200", "lr": "0.000364", "gnorm": "0.602", "train_wall": "173", "gb_free": "7.5", "wall": "72900"}
[2023-03-28 18:42:58,952][train_inner][INFO] - {"epoch": 60, "update": 59.945, "loss": "4.927", "ppl": "30.42", "wps": "97914.5", "ups": "0.91", "wpb": "107144", "bsz": "256", "num_updates": "65400", "lr": "0.000362783", "gnorm": "0.603", "train_wall": "172", "gb_free": "7.5", "wall": "73119"}
[2023-03-28 18:44:04,531][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 18:44:04,532][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 18:44:05,436][valid][INFO] - {"epoch": 60, "valid_loss": "4.634", "valid_ppl": "24.83", "valid_wps": "275882", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "65460", "valid_best_loss": "4.633"}
[2023-03-28 18:44:05,437][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 65460 updates
[2023-03-28 18:44:05,437][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 18:44:05,761][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 18:44:05,767][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 60 @ 65460 updates, score 4.634) (writing took 0.33054146901122294 seconds)
[2023-03-28 18:44:05,767][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2023-03-28 18:44:05,768][train][INFO] - {"epoch": 60, "train_loss": "4.894", "train_ppl": "29.73", "train_wps": "97806.7", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "65460", "train_lr": "0.000362417", "train_gnorm": "0.603", "train_train_wall": "940", "train_gb_free": "7.5", "train_wall": "73186"}
[2023-03-28 18:44:05,769][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 18:44:05,799][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 18:44:05,801][fairseq.trainer][INFO] - begin training epoch 61
[2023-03-28 18:44:05,801][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 18:46:39,482][train_inner][INFO] - {"epoch": 61, "update": 60.128, "loss": "4.863", "ppl": "29.09", "wps": "97356.8", "ups": "0.91", "wpb": "107350", "bsz": "255.8", "num_updates": "65600", "lr": "0.000361565", "gnorm": "0.605", "train_wall": "172", "gb_free": "7.5", "wall": "73339"}
[2023-03-28 18:50:18,422][train_inner][INFO] - {"epoch": 61, "update": 60.312, "loss": "4.863", "ppl": "29.11", "wps": "97832.6", "ups": "0.91", "wpb": "107097", "bsz": "256", "num_updates": "65800", "lr": "0.000360348", "gnorm": "0.606", "train_wall": "172", "gb_free": "7.5", "wall": "73558"}
[2023-03-28 18:53:57,646][train_inner][INFO] - {"epoch": 61, "update": 60.495, "loss": "4.886", "ppl": "29.57", "wps": "97967.8", "ups": "0.91", "wpb": "107381", "bsz": "256", "num_updates": "66000", "lr": "0.00035913", "gnorm": "0.605", "train_wall": "172", "gb_free": "7.5", "wall": "73777"}
[2023-03-28 18:57:36,717][train_inner][INFO] - {"epoch": 61, "update": 60.678, "loss": "4.907", "ppl": "30", "wps": "97970.4", "ups": "0.91", "wpb": "107312", "bsz": "256", "num_updates": "66200", "lr": "0.000357913", "gnorm": "0.606", "train_wall": "172", "gb_free": "7.5", "wall": "73997"}
[2023-03-28 19:01:15,181][train_inner][INFO] - {"epoch": 61, "update": 60.862, "loss": "4.923", "ppl": "30.33", "wps": "97882.1", "ups": "0.92", "wpb": "106919", "bsz": "256", "num_updates": "66400", "lr": "0.000356696", "gnorm": "0.605", "train_wall": "172", "gb_free": "7.5", "wall": "74215"}
[2023-03-28 19:04:00,371][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 19:04:00,372][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 19:04:01,339][valid][INFO] - {"epoch": 61, "valid_loss": "4.631", "valid_ppl": "24.79", "valid_wps": "259056", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "66551", "valid_best_loss": "4.631"}
[2023-03-28 19:04:01,340][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 61 @ 66551 updates
[2023-03-28 19:04:01,340][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 19:04:01,785][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 19:04:02,100][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 61 @ 66551 updates, score 4.631) (writing took 0.7608183249976719 seconds)
[2023-03-28 19:04:02,101][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2023-03-28 19:04:02,101][train][INFO] - {"epoch": 61, "train_loss": "4.891", "train_ppl": "29.66", "train_wps": "97767.1", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "66551", "train_lr": "0.000355777", "train_gnorm": "0.606", "train_train_wall": "940", "train_gb_free": "7.5", "train_wall": "74382"}
[2023-03-28 19:04:02,103][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 19:04:02,134][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 19:04:02,137][fairseq.trainer][INFO] - begin training epoch 62
[2023-03-28 19:04:02,137][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 19:04:56,067][train_inner][INFO] - {"epoch": 62, "update": 61.045, "loss": "4.901", "ppl": "29.88", "wps": "96970.4", "ups": "0.91", "wpb": "107097", "bsz": "255.8", "num_updates": "66600", "lr": "0.000355478", "gnorm": "0.606", "train_wall": "172", "gb_free": "7.5", "wall": "74436"}
[2023-03-28 19:08:35,752][train_inner][INFO] - {"epoch": 62, "update": 61.228, "loss": "4.849", "ppl": "28.83", "wps": "98027.8", "ups": "0.91", "wpb": "107676", "bsz": "256", "num_updates": "66800", "lr": "0.000354261", "gnorm": "0.609", "train_wall": "173", "gb_free": "7.5", "wall": "74656"}
[2023-03-28 19:12:14,656][train_inner][INFO] - {"epoch": 62, "update": 61.412, "loss": "4.873", "ppl": "29.3", "wps": "97905.8", "ups": "0.91", "wpb": "107160", "bsz": "256", "num_updates": "67000", "lr": "0.000353043", "gnorm": "0.611", "train_wall": "172", "gb_free": "7.5", "wall": "74875"}
[2023-03-28 19:15:53,242][train_inner][INFO] - {"epoch": 62, "update": 61.595, "loss": "4.896", "ppl": "29.78", "wps": "97974.7", "ups": "0.91", "wpb": "107080", "bsz": "256", "num_updates": "67200", "lr": "0.000351826", "gnorm": "0.611", "train_wall": "172", "gb_free": "7.5", "wall": "75093"}
[2023-03-28 19:19:32,183][train_inner][INFO] - {"epoch": 62, "update": 61.778, "loss": "4.904", "ppl": "29.94", "wps": "97944", "ups": "0.91", "wpb": "107220", "bsz": "256", "num_updates": "67400", "lr": "0.000350609", "gnorm": "0.608", "train_wall": "172", "gb_free": "7.5", "wall": "75312"}
[2023-03-28 19:23:10,875][train_inner][INFO] - {"epoch": 62, "update": 61.962, "loss": "4.919", "ppl": "30.25", "wps": "97826.9", "ups": "0.91", "wpb": "106970", "bsz": "256", "num_updates": "67600", "lr": "0.000349391", "gnorm": "0.609", "train_wall": "172", "gb_free": "7.5", "wall": "75531"}
[2023-03-28 19:23:56,789][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 19:23:56,790][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 19:23:57,696][valid][INFO] - {"epoch": 62, "valid_loss": "4.627", "valid_ppl": "24.71", "valid_wps": "275344", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "67642", "valid_best_loss": "4.627"}
[2023-03-28 19:23:57,697][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 62 @ 67642 updates
[2023-03-28 19:23:57,698][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 19:23:57,960][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 19:23:58,107][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 62 @ 67642 updates, score 4.627) (writing took 0.4102791379991686 seconds)
[2023-03-28 19:23:58,107][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2023-03-28 19:23:58,108][train][INFO] - {"epoch": 62, "train_loss": "4.887", "train_ppl": "29.6", "train_wps": "97793.8", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "67642", "train_lr": "0.000349136", "train_gnorm": "0.609", "train_train_wall": "940", "train_gb_free": "7.5", "train_wall": "75578"}
[2023-03-28 19:23:58,110][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 19:23:58,141][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 19:23:58,144][fairseq.trainer][INFO] - begin training epoch 63
[2023-03-28 19:23:58,144][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 19:26:51,594][train_inner][INFO] - {"epoch": 63, "update": 62.145, "loss": "4.855", "ppl": "28.93", "wps": "97282.3", "ups": "0.91", "wpb": "107360", "bsz": "255.8", "num_updates": "67800", "lr": "0.000348174", "gnorm": "0.611", "train_wall": "173", "gb_free": "7.5", "wall": "75751"}
[2023-03-28 19:30:30,375][train_inner][INFO] - {"epoch": 63, "update": 62.328, "loss": "4.862", "ppl": "29.08", "wps": "97968.2", "ups": "0.91", "wpb": "107165", "bsz": "256", "num_updates": "68000", "lr": "0.000346957", "gnorm": "0.614", "train_wall": "172", "gb_free": "7.5", "wall": "75970"}
[2023-03-28 19:34:09,317][train_inner][INFO] - {"epoch": 63, "update": 62.511, "loss": "4.881", "ppl": "29.46", "wps": "97895.2", "ups": "0.91", "wpb": "107166", "bsz": "256", "num_updates": "68200", "lr": "0.000345739", "gnorm": "0.613", "train_wall": "172", "gb_free": "7.5", "wall": "76189"}
[2023-03-28 19:37:48,279][train_inner][INFO] - {"epoch": 63, "update": 62.695, "loss": "4.896", "ppl": "29.77", "wps": "97995.4", "ups": "0.91", "wpb": "107286", "bsz": "256", "num_updates": "68400", "lr": "0.000344522", "gnorm": "0.612", "train_wall": "172", "gb_free": "7.5", "wall": "76408"}
[2023-03-28 19:41:27,237][train_inner][INFO] - {"epoch": 63, "update": 62.878, "loss": "4.914", "ppl": "30.15", "wps": "97984.9", "ups": "0.91", "wpb": "107273", "bsz": "256", "num_updates": "68600", "lr": "0.000343304", "gnorm": "0.611", "train_wall": "172", "gb_free": "7.5", "wall": "76627"}
[2023-03-28 19:43:52,400][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 19:43:52,400][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 19:43:53,364][valid][INFO] - {"epoch": 63, "valid_loss": "4.623", "valid_ppl": "24.64", "valid_wps": "258827", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "68733", "valid_best_loss": "4.623"}
[2023-03-28 19:43:53,365][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 63 @ 68733 updates
[2023-03-28 19:43:53,366][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 19:43:53,608][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 19:43:53,754][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 63 @ 68733 updates, score 4.623) (writing took 0.38873321800201666 seconds)
[2023-03-28 19:43:53,754][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2023-03-28 19:43:53,754][train][INFO] - {"epoch": 63, "train_loss": "4.884", "train_ppl": "29.53", "train_wps": "97823.2", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "68733", "train_lr": "0.000342495", "train_gnorm": "0.613", "train_train_wall": "940", "train_gb_free": "7.5", "train_wall": "76774"}
[2023-03-28 19:43:53,756][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 19:43:53,787][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 19:43:53,789][fairseq.trainer][INFO] - begin training epoch 64
[2023-03-28 19:43:53,790][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 19:45:07,438][train_inner][INFO] - {"epoch": 64, "update": 63.061, "loss": "4.881", "ppl": "29.47", "wps": "97135.8", "ups": "0.91", "wpb": "106947", "bsz": "255.8", "num_updates": "68800", "lr": "0.000342087", "gnorm": "0.614", "train_wall": "172", "gb_free": "7.5", "wall": "76847"}
[2023-03-28 19:48:45,857][train_inner][INFO] - {"epoch": 64, "update": 63.245, "loss": "4.848", "ppl": "28.79", "wps": "97912.9", "ups": "0.92", "wpb": "106930", "bsz": "256", "num_updates": "69000", "lr": "0.00034087", "gnorm": "0.617", "train_wall": "172", "gb_free": "7.5", "wall": "77066"}
[2023-03-28 19:52:24,648][train_inner][INFO] - {"epoch": 64, "update": 63.428, "loss": "4.874", "ppl": "29.32", "wps": "97915", "ups": "0.91", "wpb": "107114", "bsz": "256", "num_updates": "69200", "lr": "0.000339652", "gnorm": "0.614", "train_wall": "172", "gb_free": "7.5", "wall": "77284"}
[2023-03-28 19:56:03,717][train_inner][INFO] - {"epoch": 64, "update": 63.611, "loss": "4.886", "ppl": "29.56", "wps": "98009.8", "ups": "0.91", "wpb": "107354", "bsz": "256", "num_updates": "69400", "lr": "0.000338435", "gnorm": "0.613", "train_wall": "172", "gb_free": "7.5", "wall": "77504"}
[2023-03-28 19:59:43,108][train_inner][INFO] - {"epoch": 64, "update": 63.795, "loss": "4.906", "ppl": "29.99", "wps": "98049", "ups": "0.91", "wpb": "107556", "bsz": "256", "num_updates": "69600", "lr": "0.000337217", "gnorm": "0.613", "train_wall": "173", "gb_free": "7.5", "wall": "77723"}
[2023-03-28 20:03:24,628][train_inner][INFO] - {"epoch": 64, "update": 63.978, "loss": "4.915", "ppl": "30.17", "wps": "96717.1", "ups": "0.9", "wpb": "107124", "bsz": "256", "num_updates": "69800", "lr": "0.000336", "gnorm": "0.616", "train_wall": "174", "gb_free": "7.5", "wall": "77944"}
[2023-03-28 20:03:56,940][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 20:03:56,941][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 20:03:58,029][valid][INFO] - {"epoch": 64, "valid_loss": "4.62", "valid_ppl": "24.58", "valid_wps": "229138", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "69824", "valid_best_loss": "4.62"}
[2023-03-28 20:03:58,030][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 64 @ 69824 updates
[2023-03-28 20:03:58,031][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 20:03:58,290][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 20:03:58,445][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 64 @ 69824 updates, score 4.62) (writing took 0.41490502600208856 seconds)
[2023-03-28 20:03:58,445][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2023-03-28 20:03:58,445][train][INFO] - {"epoch": 64, "train_loss": "4.882", "train_ppl": "29.48", "train_wps": "97088.8", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "69824", "train_lr": "0.000335854", "train_gnorm": "0.614", "train_train_wall": "945", "train_gb_free": "7.5", "train_wall": "77978"}
[2023-03-28 20:03:58,447][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 20:03:58,480][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 20:03:58,482][fairseq.trainer][INFO] - begin training epoch 65
[2023-03-28 20:03:58,482][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 20:07:39,255][train_inner][INFO] - {"epoch": 65, "update": 64.161, "loss": "4.835", "ppl": "28.55", "wps": "84279.7", "ups": "0.79", "wpb": "107299", "bsz": "255.8", "num_updates": "70000", "lr": "0.000334783", "gnorm": "0.617", "train_wall": "199", "gb_free": "7.5", "wall": "78199"}
[2023-03-28 20:11:54,493][train_inner][INFO] - {"epoch": 65, "update": 64.345, "loss": "4.861", "ppl": "29.06", "wps": "84089.3", "ups": "0.78", "wpb": "107314", "bsz": "256", "num_updates": "70200", "lr": "0.000333565", "gnorm": "0.619", "train_wall": "202", "gb_free": "7.5", "wall": "78454"}
[2023-03-28 20:16:04,960][train_inner][INFO] - {"epoch": 65, "update": 64.528, "loss": "4.881", "ppl": "29.47", "wps": "85614.1", "ups": "0.8", "wpb": "107214", "bsz": "256", "num_updates": "70400", "lr": "0.000332348", "gnorm": "0.618", "train_wall": "199", "gb_free": "7.5", "wall": "78705"}
[2023-03-28 20:20:14,290][train_inner][INFO] - {"epoch": 65, "update": 64.711, "loss": "4.889", "ppl": "29.62", "wps": "85794.8", "ups": "0.8", "wpb": "106956", "bsz": "256", "num_updates": "70600", "lr": "0.00033113", "gnorm": "0.618", "train_wall": "197", "gb_free": "7.5", "wall": "78954"}
[2023-03-28 20:24:33,205][train_inner][INFO] - {"epoch": 65, "update": 64.895, "loss": "4.903", "ppl": "29.92", "wps": "82866.9", "ups": "0.77", "wpb": "107277", "bsz": "256", "num_updates": "70800", "lr": "0.000329913", "gnorm": "0.617", "train_wall": "205", "gb_free": "7.5", "wall": "79213"}
[2023-03-28 20:27:00,063][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 20:27:00,064][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 20:27:01,173][valid][INFO] - {"epoch": 65, "valid_loss": "4.623", "valid_ppl": "24.64", "valid_wps": "225818", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "70915", "valid_best_loss": "4.62"}
[2023-03-28 20:27:01,174][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 65 @ 70915 updates
[2023-03-28 20:27:01,175][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 20:27:01,662][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 20:27:01,670][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 65 @ 70915 updates, score 4.623) (writing took 0.4956761109933723 seconds)
[2023-03-28 20:27:01,670][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2023-03-28 20:27:01,670][train][INFO] - {"epoch": 65, "train_loss": "4.878", "train_ppl": "29.4", "train_wps": "84557.5", "train_ups": "0.79", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "70915", "train_lr": "0.000329213", "train_gnorm": "0.618", "train_train_wall": "1093", "train_gb_free": "7.5", "train_wall": "79362"}
[2023-03-28 20:27:01,672][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 20:27:01,706][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 20:27:01,709][fairseq.trainer][INFO] - begin training epoch 66
[2023-03-28 20:27:01,709][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 20:28:52,538][train_inner][INFO] - {"epoch": 66, "update": 65.078, "loss": "4.876", "ppl": "29.36", "wps": "82638.9", "ups": "0.77", "wpb": "107155", "bsz": "255.8", "num_updates": "71000", "lr": "0.000328696", "gnorm": "0.619", "train_wall": "204", "gb_free": "7.5", "wall": "79472"}
[2023-03-28 20:33:08,782][train_inner][INFO] - {"epoch": 66, "update": 65.261, "loss": "4.844", "ppl": "28.73", "wps": "83713.8", "ups": "0.78", "wpb": "107256", "bsz": "256", "num_updates": "71200", "lr": "0.000327478", "gnorm": "0.619", "train_wall": "204", "gb_free": "7.5", "wall": "79729"}
[2023-03-28 20:37:21,378][train_inner][INFO] - {"epoch": 66, "update": 65.445, "loss": "4.868", "ppl": "29.21", "wps": "84795.8", "ups": "0.79", "wpb": "107095", "bsz": "256", "num_updates": "71400", "lr": "0.000326261", "gnorm": "0.622", "train_wall": "201", "gb_free": "7.5", "wall": "79981"}
[2023-03-28 20:41:37,923][train_inner][INFO] - {"epoch": 66, "update": 65.628, "loss": "4.889", "ppl": "29.64", "wps": "83665", "ups": "0.78", "wpb": "107319", "bsz": "256", "num_updates": "71600", "lr": "0.000325043", "gnorm": "0.621", "train_wall": "204", "gb_free": "7.5", "wall": "80238"}
[2023-03-28 20:45:57,000][train_inner][INFO] - {"epoch": 66, "update": 65.811, "loss": "4.896", "ppl": "29.77", "wps": "82761", "ups": "0.77", "wpb": "107207", "bsz": "256", "num_updates": "71800", "lr": "0.000323826", "gnorm": "0.621", "train_wall": "205", "gb_free": "7.5", "wall": "80497"}
[2023-03-28 20:50:15,597][train_inner][INFO] - {"epoch": 66, "update": 65.995, "loss": "4.909", "ppl": "30.05", "wps": "82928.7", "ups": "0.77", "wpb": "107225", "bsz": "256", "num_updates": "72000", "lr": "0.000322609", "gnorm": "0.62", "train_wall": "204", "gb_free": "7.5", "wall": "80755"}
[2023-03-28 20:50:23,144][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 20:50:23,145][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 20:50:24,201][valid][INFO] - {"epoch": 66, "valid_loss": "4.62", "valid_ppl": "24.59", "valid_wps": "236873", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "72006", "valid_best_loss": "4.62"}
[2023-03-28 20:50:24,202][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 66 @ 72006 updates
[2023-03-28 20:50:24,203][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 20:50:24,780][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 20:50:25,053][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 66 @ 72006 updates, score 4.62) (writing took 0.851641330998973 seconds)
[2023-03-28 20:50:25,054][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2023-03-28 20:50:25,055][train][INFO] - {"epoch": 66, "train_loss": "4.876", "train_ppl": "29.36", "train_wps": "83342.8", "train_ups": "0.78", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "72006", "train_lr": "0.000322572", "train_gnorm": "0.621", "train_train_wall": "1112", "train_gb_free": "7.5", "train_wall": "80765"}
[2023-03-28 20:50:25,058][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 20:50:25,094][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 20:50:25,096][fairseq.trainer][INFO] - begin training epoch 67
[2023-03-28 20:50:25,097][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 20:54:34,514][train_inner][INFO] - {"epoch": 67, "update": 66.178, "loss": "4.823", "ppl": "28.31", "wps": "82545.3", "ups": "0.77", "wpb": "106862", "bsz": "255.8", "num_updates": "72200", "lr": "0.000321391", "gnorm": "0.625", "train_wall": "204", "gb_free": "7.5", "wall": "81014"}
[2023-03-28 20:58:47,301][train_inner][INFO] - {"epoch": 67, "update": 66.361, "loss": "4.854", "ppl": "28.92", "wps": "84899.5", "ups": "0.79", "wpb": "107307", "bsz": "256", "num_updates": "72400", "lr": "0.000320174", "gnorm": "0.623", "train_wall": "201", "gb_free": "7.5", "wall": "81267"}
[2023-03-28 21:03:01,728][train_inner][INFO] - {"epoch": 67, "update": 66.544, "loss": "4.877", "ppl": "29.38", "wps": "84407.4", "ups": "0.79", "wpb": "107378", "bsz": "256", "num_updates": "72600", "lr": "0.000318957", "gnorm": "0.623", "train_wall": "203", "gb_free": "7.5", "wall": "81522"}
[2023-03-28 21:07:18,775][train_inner][INFO] - {"epoch": 67, "update": 66.728, "loss": "4.891", "ppl": "29.68", "wps": "83332.1", "ups": "0.78", "wpb": "107101", "bsz": "256", "num_updates": "72800", "lr": "0.000317739", "gnorm": "0.626", "train_wall": "204", "gb_free": "7.5", "wall": "81779"}
[2023-03-28 21:11:37,327][train_inner][INFO] - {"epoch": 67, "update": 66.911, "loss": "4.899", "ppl": "29.83", "wps": "82858.3", "ups": "0.77", "wpb": "107116", "bsz": "256", "num_updates": "73000", "lr": "0.000316522", "gnorm": "0.624", "train_wall": "207", "gb_free": "7.5", "wall": "82037"}
[2023-03-28 21:13:42,755][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 21:13:42,756][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 21:13:43,890][valid][INFO] - {"epoch": 67, "valid_loss": "4.616", "valid_ppl": "24.52", "valid_wps": "218848", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "73097", "valid_best_loss": "4.616"}
[2023-03-28 21:13:43,891][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 67 @ 73097 updates
[2023-03-28 21:13:43,892][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 21:13:44,421][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 21:13:44,711][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 67 @ 73097 updates, score 4.616) (writing took 0.8197815739986254 seconds)
[2023-03-28 21:13:44,712][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2023-03-28 21:13:44,713][train][INFO] - {"epoch": 67, "train_loss": "4.873", "train_ppl": "29.29", "train_wps": "83564.7", "train_ups": "0.78", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "73097", "train_lr": "0.000315931", "train_gnorm": "0.624", "train_train_wall": "1113", "train_gb_free": "7.5", "train_wall": "82165"}
[2023-03-28 21:13:44,717][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 21:13:44,769][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 21:13:44,772][fairseq.trainer][INFO] - begin training epoch 68
[2023-03-28 21:13:44,772][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 21:15:58,496][train_inner][INFO] - {"epoch": 68, "update": 67.094, "loss": "4.858", "ppl": "29", "wps": "82334.1", "ups": "0.77", "wpb": "107516", "bsz": "255.8", "num_updates": "73200", "lr": "0.000315304", "gnorm": "0.622", "train_wall": "206", "gb_free": "7.5", "wall": "82298"}
[2023-03-28 21:20:13,052][train_inner][INFO] - {"epoch": 68, "update": 67.278, "loss": "4.837", "ppl": "28.57", "wps": "84418.3", "ups": "0.79", "wpb": "107446", "bsz": "256", "num_updates": "73400", "lr": "0.000314087", "gnorm": "0.626", "train_wall": "203", "gb_free": "7.5", "wall": "82553"}
[2023-03-28 21:24:28,045][train_inner][INFO] - {"epoch": 68, "update": 67.461, "loss": "4.863", "ppl": "29.1", "wps": "83933.3", "ups": "0.78", "wpb": "107012", "bsz": "256", "num_updates": "73600", "lr": "0.00031287", "gnorm": "0.629", "train_wall": "203", "gb_free": "7.5", "wall": "82808"}
[2023-03-28 21:28:51,015][train_inner][INFO] - {"epoch": 68, "update": 67.644, "loss": "4.88", "ppl": "29.44", "wps": "81589.7", "ups": "0.76", "wpb": "107278", "bsz": "256", "num_updates": "73800", "lr": "0.000311652", "gnorm": "0.626", "train_wall": "207", "gb_free": "7.5", "wall": "83071"}
[2023-03-28 21:33:09,857][train_inner][INFO] - {"epoch": 68, "update": 67.828, "loss": "4.9", "ppl": "29.85", "wps": "82798.9", "ups": "0.77", "wpb": "107159", "bsz": "256", "num_updates": "74000", "lr": "0.000310435", "gnorm": "0.627", "train_wall": "205", "gb_free": "7.5", "wall": "83330"}
[2023-03-28 21:37:12,703][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 21:37:12,704][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 21:37:13,908][valid][INFO] - {"epoch": 68, "valid_loss": "4.616", "valid_ppl": "24.53", "valid_wps": "207421", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "74188", "valid_best_loss": "4.616"}
[2023-03-28 21:37:13,909][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 68 @ 74188 updates
[2023-03-28 21:37:13,910][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 21:37:14,192][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 21:37:14,385][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 68 @ 74188 updates, score 4.616) (writing took 0.4759785749920411 seconds)
[2023-03-28 21:37:14,386][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2023-03-28 21:37:14,386][train][INFO] - {"epoch": 68, "train_loss": "4.87", "train_ppl": "29.25", "train_wps": "82971", "train_ups": "0.77", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "74188", "train_lr": "0.00030929", "train_gnorm": "0.627", "train_train_wall": "1117", "train_gb_free": "7.5", "train_wall": "83574"}
[2023-03-28 21:37:14,388][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 21:37:14,422][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 21:37:14,424][fairseq.trainer][INFO] - begin training epoch 69
[2023-03-28 21:37:14,424][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 21:37:30,198][train_inner][INFO] - {"epoch": 69, "update": 68.011, "loss": "4.9", "ppl": "29.86", "wps": "82197", "ups": "0.77", "wpb": "106996", "bsz": "255.8", "num_updates": "74200", "lr": "0.000309217", "gnorm": "0.627", "train_wall": "204", "gb_free": "7.5", "wall": "83590"}
[2023-03-28 21:41:52,619][train_inner][INFO] - {"epoch": 69, "update": 68.194, "loss": "4.819", "ppl": "28.23", "wps": "81793", "ups": "0.76", "wpb": "107321", "bsz": "256", "num_updates": "74400", "lr": "0.000308", "gnorm": "0.629", "train_wall": "209", "gb_free": "7.5", "wall": "83852"}
[2023-03-28 21:46:07,947][train_inner][INFO] - {"epoch": 69, "update": 68.378, "loss": "4.858", "ppl": "29", "wps": "84160.2", "ups": "0.78", "wpb": "107442", "bsz": "256", "num_updates": "74600", "lr": "0.000306783", "gnorm": "0.629", "train_wall": "203", "gb_free": "7.5", "wall": "84108"}
[2023-03-28 21:50:12,987][train_inner][INFO] - {"epoch": 69, "update": 68.561, "loss": "4.866", "ppl": "29.16", "wps": "87185.4", "ups": "0.82", "wpb": "106819", "bsz": "256", "num_updates": "74800", "lr": "0.000305565", "gnorm": "0.63", "train_wall": "194", "gb_free": "7.5", "wall": "84353"}
[2023-03-28 21:54:32,404][train_inner][INFO] - {"epoch": 69, "update": 68.744, "loss": "4.891", "ppl": "29.68", "wps": "82888.3", "ups": "0.77", "wpb": "107513", "bsz": "256", "num_updates": "75000", "lr": "0.000304348", "gnorm": "0.628", "train_wall": "205", "gb_free": "7.5", "wall": "84612"}
[2023-03-28 21:58:17,667][train_inner][INFO] - {"epoch": 69, "update": 68.928, "loss": "4.895", "ppl": "29.76", "wps": "95066.6", "ups": "0.89", "wpb": "107075", "bsz": "256", "num_updates": "75200", "lr": "0.00030313", "gnorm": "0.63", "train_wall": "178", "gb_free": "7.5", "wall": "84838"}
[2023-03-28 21:59:41,359][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 21:59:41,360][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 21:59:42,240][valid][INFO] - {"epoch": 69, "valid_loss": "4.615", "valid_ppl": "24.5", "valid_wps": "283781", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "75279", "valid_best_loss": "4.615"}
[2023-03-28 21:59:42,241][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 69 @ 75279 updates
[2023-03-28 21:59:42,242][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 21:59:42,617][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 21:59:42,859][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 69 @ 75279 updates, score 4.615) (writing took 0.6184814689913765 seconds)
[2023-03-28 21:59:42,860][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2023-03-28 21:59:42,860][train][INFO] - {"epoch": 69, "train_loss": "4.867", "train_ppl": "29.19", "train_wps": "86736.6", "train_ups": "0.81", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "75279", "train_lr": "0.00030265", "train_gnorm": "0.629", "train_train_wall": "1068", "train_gb_free": "7.5", "train_wall": "84923"}
[2023-03-28 21:59:42,862][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 21:59:42,892][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 21:59:42,894][fairseq.trainer][INFO] - begin training epoch 70
[2023-03-28 21:59:42,895][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 22:01:51,020][train_inner][INFO] - {"epoch": 70, "update": 69.111, "loss": "4.84", "ppl": "28.64", "wps": "100330", "ups": "0.94", "wpb": "107028", "bsz": "255.8", "num_updates": "75400", "lr": "0.000301913", "gnorm": "0.631", "train_wall": "166", "gb_free": "7.5", "wall": "85051"}
[2023-03-28 22:05:21,732][train_inner][INFO] - {"epoch": 70, "update": 69.294, "loss": "4.843", "ppl": "28.69", "wps": "101859", "ups": "0.95", "wpb": "107314", "bsz": "256", "num_updates": "75600", "lr": "0.000300696", "gnorm": "0.634", "train_wall": "166", "gb_free": "7.5", "wall": "85262"}
[2023-03-28 22:08:52,431][train_inner][INFO] - {"epoch": 70, "update": 69.478, "loss": "4.857", "ppl": "28.98", "wps": "101877", "ups": "0.95", "wpb": "107327", "bsz": "256", "num_updates": "75800", "lr": "0.000299478", "gnorm": "0.633", "train_wall": "166", "gb_free": "7.5", "wall": "85472"}
[2023-03-28 22:12:22,904][train_inner][INFO] - {"epoch": 70, "update": 69.661, "loss": "4.871", "ppl": "29.26", "wps": "101838", "ups": "0.95", "wpb": "107170", "bsz": "256", "num_updates": "76000", "lr": "0.000298261", "gnorm": "0.633", "train_wall": "165", "gb_free": "7.5", "wall": "85683"}
[2023-03-28 22:15:53,162][train_inner][INFO] - {"epoch": 70, "update": 69.844, "loss": "4.891", "ppl": "29.68", "wps": "101828", "ups": "0.95", "wpb": "107050", "bsz": "256", "num_updates": "76200", "lr": "0.000297043", "gnorm": "0.633", "train_wall": "165", "gb_free": "7.5", "wall": "85893"}
[2023-03-28 22:18:51,972][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 22:18:51,973][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 22:18:52,883][valid][INFO] - {"epoch": 70, "valid_loss": "4.61", "valid_ppl": "24.43", "valid_wps": "275898", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "76370", "valid_best_loss": "4.61"}
[2023-03-28 22:18:52,884][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 70 @ 76370 updates
[2023-03-28 22:18:52,885][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 22:18:53,426][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 22:18:53,769][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 70 @ 76370 updates, score 4.61) (writing took 0.8851870380021865 seconds)
[2023-03-28 22:18:53,769][fairseq_cli.train][INFO] - end of epoch 70 (average epoch stats below)
[2023-03-28 22:18:53,770][train][INFO] - {"epoch": 70, "train_loss": "4.864", "train_ppl": "29.11", "train_wps": "101626", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "76370", "train_lr": "0.000296009", "train_gnorm": "0.633", "train_train_wall": "903", "train_gb_free": "7.5", "train_wall": "86074"}
[2023-03-28 22:18:53,771][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 22:18:53,801][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 22:18:53,803][fairseq.trainer][INFO] - begin training epoch 71
[2023-03-28 22:18:53,804][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 22:19:25,701][train_inner][INFO] - {"epoch": 71, "update": 70.027, "loss": "4.884", "ppl": "29.52", "wps": "100874", "ups": "0.94", "wpb": "107198", "bsz": "255.8", "num_updates": "76400", "lr": "0.000295826", "gnorm": "0.633", "train_wall": "165", "gb_free": "7.5", "wall": "86106"}
[2023-03-28 22:22:56,435][train_inner][INFO] - {"epoch": 71, "update": 70.211, "loss": "4.814", "ppl": "28.13", "wps": "101914", "ups": "0.95", "wpb": "107383", "bsz": "256", "num_updates": "76600", "lr": "0.000294609", "gnorm": "0.636", "train_wall": "166", "gb_free": "7.5", "wall": "86316"}
[2023-03-28 22:26:26,696][train_inner][INFO] - {"epoch": 71, "update": 70.394, "loss": "4.841", "ppl": "28.67", "wps": "101810", "ups": "0.95", "wpb": "107033", "bsz": "256", "num_updates": "76800", "lr": "0.000293391", "gnorm": "0.636", "train_wall": "165", "gb_free": "7.5", "wall": "86527"}
[2023-03-28 22:29:57,177][train_inner][INFO] - {"epoch": 71, "update": 70.577, "loss": "4.867", "ppl": "29.19", "wps": "101877", "ups": "0.95", "wpb": "107216", "bsz": "256", "num_updates": "77000", "lr": "0.000292174", "gnorm": "0.638", "train_wall": "165", "gb_free": "7.5", "wall": "86737"}
[2023-03-28 22:33:27,717][train_inner][INFO] - {"epoch": 71, "update": 70.761, "loss": "4.883", "ppl": "29.5", "wps": "101962", "ups": "0.95", "wpb": "107334", "bsz": "256", "num_updates": "77200", "lr": "0.000290957", "gnorm": "0.636", "train_wall": "166", "gb_free": "7.5", "wall": "86948"}
[2023-03-28 22:36:57,889][train_inner][INFO] - {"epoch": 71, "update": 70.944, "loss": "4.895", "ppl": "29.76", "wps": "101813", "ups": "0.95", "wpb": "106991", "bsz": "256", "num_updates": "77400", "lr": "0.000289739", "gnorm": "0.636", "train_wall": "165", "gb_free": "7.5", "wall": "87158"}
[2023-03-28 22:38:02,246][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 22:38:02,247][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 22:38:03,124][valid][INFO] - {"epoch": 71, "valid_loss": "4.608", "valid_ppl": "24.39", "valid_wps": "284497", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "77461", "valid_best_loss": "4.608"}
[2023-03-28 22:38:03,125][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 71 @ 77461 updates
[2023-03-28 22:38:03,126][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 22:38:03,602][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 22:38:03,916][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 71 @ 77461 updates, score 4.608) (writing took 0.7910812519985484 seconds)
[2023-03-28 22:38:03,916][fairseq_cli.train][INFO] - end of epoch 71 (average epoch stats below)
[2023-03-28 22:38:03,916][train][INFO] - {"epoch": 71, "train_loss": "4.861", "train_ppl": "29.07", "train_wps": "101693", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "77461", "train_lr": "0.000289368", "train_gnorm": "0.636", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "87224"}
[2023-03-28 22:38:03,918][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 22:38:03,949][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 22:38:03,952][fairseq.trainer][INFO] - begin training epoch 72
[2023-03-28 22:38:03,952][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 22:40:30,691][train_inner][INFO] - {"epoch": 72, "update": 71.127, "loss": "4.837", "ppl": "28.58", "wps": "100934", "ups": "0.94", "wpb": "107395", "bsz": "255.8", "num_updates": "77600", "lr": "0.000288522", "gnorm": "0.636", "train_wall": "166", "gb_free": "7.5", "wall": "87371"}
[2023-03-28 22:44:01,089][train_inner][INFO] - {"epoch": 72, "update": 71.311, "loss": "4.842", "ppl": "28.69", "wps": "101887", "ups": "0.95", "wpb": "107184", "bsz": "256", "num_updates": "77800", "lr": "0.000287304", "gnorm": "0.641", "train_wall": "165", "gb_free": "7.5", "wall": "87581"}
[2023-03-28 22:47:31,745][train_inner][INFO] - {"epoch": 72, "update": 71.494, "loss": "4.852", "ppl": "28.88", "wps": "101858", "ups": "0.95", "wpb": "107285", "bsz": "256", "num_updates": "78000", "lr": "0.000286087", "gnorm": "0.64", "train_wall": "166", "gb_free": "7.5", "wall": "87792"}
[2023-03-28 22:51:02,087][train_inner][INFO] - {"epoch": 72, "update": 71.677, "loss": "4.869", "ppl": "29.22", "wps": "101865", "ups": "0.95", "wpb": "107132", "bsz": "256", "num_updates": "78200", "lr": "0.00028487", "gnorm": "0.638", "train_wall": "165", "gb_free": "7.5", "wall": "88002"}
[2023-03-28 22:54:32,364][train_inner][INFO] - {"epoch": 72, "update": 71.861, "loss": "4.877", "ppl": "29.38", "wps": "101830", "ups": "0.95", "wpb": "107062", "bsz": "256", "num_updates": "78400", "lr": "0.000283652", "gnorm": "0.638", "train_wall": "165", "gb_free": "7.5", "wall": "88212"}
[2023-03-28 22:57:12,395][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 22:57:12,396][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 22:57:13,317][valid][INFO] - {"epoch": 72, "valid_loss": "4.608", "valid_ppl": "24.38", "valid_wps": "273095", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "78552", "valid_best_loss": "4.608"}
[2023-03-28 22:57:13,318][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 72 @ 78552 updates
[2023-03-28 22:57:13,319][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 22:57:13,743][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 22:57:14,062][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 72 @ 78552 updates, score 4.608) (writing took 0.7443249659991125 seconds)
[2023-03-28 22:57:14,062][fairseq_cli.train][INFO] - end of epoch 72 (average epoch stats below)
[2023-03-28 22:57:14,063][train][INFO] - {"epoch": 72, "train_loss": "4.858", "train_ppl": "29", "train_wps": "101693", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "78552", "train_lr": "0.000282727", "train_gnorm": "0.639", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "88374"}
[2023-03-28 22:57:14,064][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 22:57:14,096][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 22:57:14,098][fairseq.trainer][INFO] - begin training epoch 73
[2023-03-28 22:57:14,099][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 22:58:04,811][train_inner][INFO] - {"epoch": 73, "update": 72.044, "loss": "4.869", "ppl": "29.22", "wps": "100906", "ups": "0.94", "wpb": "107186", "bsz": "255.8", "num_updates": "78600", "lr": "0.000282435", "gnorm": "0.639", "train_wall": "165", "gb_free": "7.5", "wall": "88425"}
[2023-03-28 23:01:35,285][train_inner][INFO] - {"epoch": 73, "update": 72.227, "loss": "4.816", "ppl": "28.17", "wps": "101873", "ups": "0.95", "wpb": "107208", "bsz": "256", "num_updates": "78800", "lr": "0.000281217", "gnorm": "0.641", "train_wall": "165", "gb_free": "7.5", "wall": "88635"}
[2023-03-28 23:05:05,956][train_inner][INFO] - {"epoch": 73, "update": 72.411, "loss": "4.84", "ppl": "28.65", "wps": "101875", "ups": "0.95", "wpb": "107310", "bsz": "256", "num_updates": "79000", "lr": "0.00028", "gnorm": "0.643", "train_wall": "166", "gb_free": "7.5", "wall": "88846"}
[2023-03-28 23:08:36,737][train_inner][INFO] - {"epoch": 73, "update": 72.594, "loss": "4.86", "ppl": "29.04", "wps": "101801", "ups": "0.95", "wpb": "107288", "bsz": "256", "num_updates": "79200", "lr": "0.000278783", "gnorm": "0.643", "train_wall": "166", "gb_free": "7.5", "wall": "89057"}
[2023-03-28 23:12:06,963][train_inner][INFO] - {"epoch": 73, "update": 72.777, "loss": "4.875", "ppl": "29.35", "wps": "101824", "ups": "0.95", "wpb": "107030", "bsz": "256", "num_updates": "79400", "lr": "0.000277565", "gnorm": "0.642", "train_wall": "165", "gb_free": "7.5", "wall": "89267"}
[2023-03-28 23:15:37,585][train_inner][INFO] - {"epoch": 73, "update": 72.961, "loss": "4.89", "ppl": "29.64", "wps": "101948", "ups": "0.95", "wpb": "107362", "bsz": "256", "num_updates": "79600", "lr": "0.000276348", "gnorm": "0.64", "train_wall": "166", "gb_free": "7.5", "wall": "89477"}
[2023-03-28 23:16:22,723][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 23:16:22,723][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 23:16:23,594][valid][INFO] - {"epoch": 73, "valid_loss": "4.608", "valid_ppl": "24.39", "valid_wps": "286552", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "79643", "valid_best_loss": "4.608"}
[2023-03-28 23:16:23,595][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 73 @ 79643 updates
[2023-03-28 23:16:23,596][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 23:16:23,909][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 23:16:24,129][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 73 @ 79643 updates, score 4.608) (writing took 0.5337691010063281 seconds)
[2023-03-28 23:16:24,129][fairseq_cli.train][INFO] - end of epoch 73 (average epoch stats below)
[2023-03-28 23:16:24,130][train][INFO] - {"epoch": 73, "train_loss": "4.855", "train_ppl": "28.93", "train_wps": "101700", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "79643", "train_lr": "0.000276086", "train_gnorm": "0.642", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "89524"}
[2023-03-28 23:16:24,132][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 23:16:24,163][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 23:16:24,165][fairseq.trainer][INFO] - begin training epoch 74
[2023-03-28 23:16:24,166][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 23:19:09,490][train_inner][INFO] - {"epoch": 74, "update": 73.144, "loss": "4.822", "ppl": "28.29", "wps": "101065", "ups": "0.94", "wpb": "107081", "bsz": "255.8", "num_updates": "79800", "lr": "0.00027513", "gnorm": "0.644", "train_wall": "165", "gb_free": "7.5", "wall": "89689"}
[2023-03-28 23:22:39,588][train_inner][INFO] - {"epoch": 74, "update": 73.327, "loss": "4.833", "ppl": "28.5", "wps": "101864", "ups": "0.95", "wpb": "107006", "bsz": "256", "num_updates": "80000", "lr": "0.000273913", "gnorm": "0.646", "train_wall": "165", "gb_free": "7.5", "wall": "89899"}
[2023-03-28 23:26:10,375][train_inner][INFO] - {"epoch": 74, "update": 73.511, "loss": "4.846", "ppl": "28.77", "wps": "101970", "ups": "0.95", "wpb": "107470", "bsz": "256", "num_updates": "80200", "lr": "0.000272696", "gnorm": "0.646", "train_wall": "166", "gb_free": "7.5", "wall": "90110"}
[2023-03-28 23:29:40,981][train_inner][INFO] - {"epoch": 74, "update": 73.694, "loss": "4.866", "ppl": "29.16", "wps": "101996", "ups": "0.95", "wpb": "107405", "bsz": "256", "num_updates": "80400", "lr": "0.000271478", "gnorm": "0.645", "train_wall": "166", "gb_free": "7.5", "wall": "90321"}
[2023-03-28 23:33:11,234][train_inner][INFO] - {"epoch": 74, "update": 73.877, "loss": "4.88", "ppl": "29.44", "wps": "101822", "ups": "0.95", "wpb": "107042", "bsz": "256", "num_updates": "80600", "lr": "0.000270261", "gnorm": "0.643", "train_wall": "165", "gb_free": "7.5", "wall": "90531"}
[2023-03-28 23:35:32,099][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 23:35:32,099][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 23:35:33,062][valid][INFO] - {"epoch": 74, "valid_loss": "4.607", "valid_ppl": "24.37", "valid_wps": "258967", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "80734", "valid_best_loss": "4.607"}
[2023-03-28 23:35:33,063][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 74 @ 80734 updates
[2023-03-28 23:35:33,064][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 23:35:33,294][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-28 23:35:33,440][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 74 @ 80734 updates, score 4.607) (writing took 0.37750857799255755 seconds)
[2023-03-28 23:35:33,440][fairseq_cli.train][INFO] - end of epoch 74 (average epoch stats below)
[2023-03-28 23:35:33,441][train][INFO] - {"epoch": 74, "train_loss": "4.852", "train_ppl": "28.87", "train_wps": "101767", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "80734", "train_lr": "0.000269445", "train_gnorm": "0.645", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "90673"}
[2023-03-28 23:35:33,443][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 23:35:33,474][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 23:35:33,476][fairseq.trainer][INFO] - begin training epoch 75
[2023-03-28 23:35:33,476][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 23:36:43,103][train_inner][INFO] - {"epoch": 75, "update": 74.06, "loss": "4.852", "ppl": "28.88", "wps": "101062", "ups": "0.94", "wpb": "107060", "bsz": "255.8", "num_updates": "80800", "lr": "0.000269043", "gnorm": "0.647", "train_wall": "165", "gb_free": "7.5", "wall": "90743"}
[2023-03-28 23:40:13,634][train_inner][INFO] - {"epoch": 75, "update": 74.244, "loss": "4.817", "ppl": "28.18", "wps": "101878", "ups": "0.95", "wpb": "107243", "bsz": "256", "num_updates": "81000", "lr": "0.000267826", "gnorm": "0.651", "train_wall": "165", "gb_free": "7.5", "wall": "90953"}
[2023-03-28 23:43:44,068][train_inner][INFO] - {"epoch": 75, "update": 74.427, "loss": "4.842", "ppl": "28.67", "wps": "101888", "ups": "0.95", "wpb": "107203", "bsz": "256", "num_updates": "81200", "lr": "0.000266609", "gnorm": "0.648", "train_wall": "165", "gb_free": "7.5", "wall": "91164"}
[2023-03-28 23:47:14,562][train_inner][INFO] - {"epoch": 75, "update": 74.61, "loss": "4.858", "ppl": "29.01", "wps": "101932", "ups": "0.95", "wpb": "107280", "bsz": "256", "num_updates": "81400", "lr": "0.000265391", "gnorm": "0.649", "train_wall": "165", "gb_free": "7.5", "wall": "91374"}
[2023-03-28 23:50:44,987][train_inner][INFO] - {"epoch": 75, "update": 74.794, "loss": "4.872", "ppl": "29.28", "wps": "101827", "ups": "0.95", "wpb": "107135", "bsz": "256", "num_updates": "81600", "lr": "0.000264174", "gnorm": "0.649", "train_wall": "165", "gb_free": "7.5", "wall": "91585"}
[2023-03-28 23:54:15,548][train_inner][INFO] - {"epoch": 75, "update": 74.977, "loss": "4.876", "ppl": "29.37", "wps": "101891", "ups": "0.95", "wpb": "107271", "bsz": "256", "num_updates": "81800", "lr": "0.000262957", "gnorm": "0.648", "train_wall": "165", "gb_free": "7.5", "wall": "91795"}
[2023-03-28 23:54:41,860][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-28 23:54:41,861][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 23:54:42,737][valid][INFO] - {"epoch": 75, "valid_loss": "4.608", "valid_ppl": "24.38", "valid_wps": "284975", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "81825", "valid_best_loss": "4.607"}
[2023-03-28 23:54:42,738][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 75 @ 81825 updates
[2023-03-28 23:54:42,739][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 23:54:43,244][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-28 23:54:43,245][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 75 @ 81825 updates, score 4.608) (writing took 0.5069764879881404 seconds)
[2023-03-28 23:54:43,245][fairseq_cli.train][INFO] - end of epoch 75 (average epoch stats below)
[2023-03-28 23:54:43,245][train][INFO] - {"epoch": 75, "train_loss": "4.85", "train_ppl": "28.84", "train_wps": "101723", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "81825", "train_lr": "0.000262804", "train_gnorm": "0.649", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "91823"}
[2023-03-28 23:54:43,248][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-28 23:54:43,279][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-28 23:54:43,281][fairseq.trainer][INFO] - begin training epoch 76
[2023-03-28 23:54:43,282][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-28 23:57:47,985][train_inner][INFO] - {"epoch": 76, "update": 75.16, "loss": "4.819", "ppl": "28.22", "wps": "101052", "ups": "0.94", "wpb": "107335", "bsz": "255.8", "num_updates": "82000", "lr": "0.000261739", "gnorm": "0.651", "train_wall": "166", "gb_free": "7.5", "wall": "92008"}
[2023-03-29 00:01:18,943][train_inner][INFO] - {"epoch": 76, "update": 75.344, "loss": "4.834", "ppl": "28.52", "wps": "101837", "ups": "0.95", "wpb": "107417", "bsz": "256", "num_updates": "82200", "lr": "0.000260522", "gnorm": "0.653", "train_wall": "166", "gb_free": "7.5", "wall": "92219"}
[2023-03-29 00:04:49,378][train_inner][INFO] - {"epoch": 76, "update": 75.527, "loss": "4.847", "ppl": "28.79", "wps": "101740", "ups": "0.95", "wpb": "107048", "bsz": "256", "num_updates": "82400", "lr": "0.000259304", "gnorm": "0.653", "train_wall": "165", "gb_free": "7.5", "wall": "92429"}
[2023-03-29 00:08:19,762][train_inner][INFO] - {"epoch": 76, "update": 75.71, "loss": "4.854", "ppl": "28.92", "wps": "101785", "ups": "0.95", "wpb": "107070", "bsz": "256", "num_updates": "82600", "lr": "0.000258087", "gnorm": "0.652", "train_wall": "165", "gb_free": "7.5", "wall": "92640"}
[2023-03-29 00:11:50,098][train_inner][INFO] - {"epoch": 76, "update": 75.894, "loss": "4.869", "ppl": "29.22", "wps": "101912", "ups": "0.95", "wpb": "107178", "bsz": "256", "num_updates": "82800", "lr": "0.00025687", "gnorm": "0.652", "train_wall": "165", "gb_free": "7.5", "wall": "92850"}
[2023-03-29 00:13:52,122][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 00:13:52,122][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 00:13:53,051][valid][INFO] - {"epoch": 76, "valid_loss": "4.607", "valid_ppl": "24.37", "valid_wps": "269042", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "82916", "valid_best_loss": "4.607"}
[2023-03-29 00:13:53,052][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 76 @ 82916 updates
[2023-03-29 00:13:53,053][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 00:13:53,323][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 00:13:53,434][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 76 @ 82916 updates, score 4.607) (writing took 0.3825654719985323 seconds)
[2023-03-29 00:13:53,435][fairseq_cli.train][INFO] - end of epoch 76 (average epoch stats below)
[2023-03-29 00:13:53,435][train][INFO] - {"epoch": 76, "train_loss": "4.847", "train_ppl": "28.78", "train_wps": "101689", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "82916", "train_lr": "0.000256163", "train_gnorm": "0.652", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "92973"}
[2023-03-29 00:13:53,437][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 00:13:53,468][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 00:13:53,470][fairseq.trainer][INFO] - begin training epoch 77
[2023-03-29 00:13:53,470][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 00:15:22,154][train_inner][INFO] - {"epoch": 77, "update": 76.077, "loss": "4.846", "ppl": "28.76", "wps": "101039", "ups": "0.94", "wpb": "107130", "bsz": "255.8", "num_updates": "83000", "lr": "0.000255652", "gnorm": "0.653", "train_wall": "165", "gb_free": "7.5", "wall": "93062"}
[2023-03-29 00:18:52,991][train_inner][INFO] - {"epoch": 77, "update": 76.26, "loss": "4.816", "ppl": "28.17", "wps": "101880", "ups": "0.95", "wpb": "107400", "bsz": "256", "num_updates": "83200", "lr": "0.000254435", "gnorm": "0.654", "train_wall": "166", "gb_free": "7.5", "wall": "93273"}
[2023-03-29 00:22:23,305][train_inner][INFO] - {"epoch": 77, "update": 76.444, "loss": "4.829", "ppl": "28.42", "wps": "101901", "ups": "0.95", "wpb": "107156", "bsz": "256", "num_updates": "83400", "lr": "0.000253217", "gnorm": "0.656", "train_wall": "165", "gb_free": "7.5", "wall": "93483"}
[2023-03-29 00:25:53,684][train_inner][INFO] - {"epoch": 77, "update": 76.627, "loss": "4.854", "ppl": "28.92", "wps": "101830", "ups": "0.95", "wpb": "107114", "bsz": "256", "num_updates": "83600", "lr": "0.000252", "gnorm": "0.655", "train_wall": "165", "gb_free": "7.5", "wall": "93694"}
[2023-03-29 00:29:24,155][train_inner][INFO] - {"epoch": 77, "update": 76.81, "loss": "4.867", "ppl": "29.17", "wps": "101902", "ups": "0.95", "wpb": "107237", "bsz": "256", "num_updates": "83800", "lr": "0.000250783", "gnorm": "0.656", "train_wall": "165", "gb_free": "7.5", "wall": "93904"}
[2023-03-29 00:32:54,766][train_inner][INFO] - {"epoch": 77, "update": 76.994, "loss": "4.871", "ppl": "29.25", "wps": "101825", "ups": "0.95", "wpb": "107228", "bsz": "256", "num_updates": "84000", "lr": "0.000249565", "gnorm": "0.656", "train_wall": "165", "gb_free": "7.5", "wall": "94115"}
[2023-03-29 00:33:02,076][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 00:33:02,077][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 00:33:02,947][valid][INFO] - {"epoch": 77, "valid_loss": "4.603", "valid_ppl": "24.3", "valid_wps": "286868", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "84007", "valid_best_loss": "4.603"}
[2023-03-29 00:33:02,948][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 77 @ 84007 updates
[2023-03-29 00:33:02,949][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 00:33:03,226][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 00:33:03,381][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 77 @ 84007 updates, score 4.603) (writing took 0.4334321770002134 seconds)
[2023-03-29 00:33:03,382][fairseq_cli.train][INFO] - end of epoch 77 (average epoch stats below)
[2023-03-29 00:33:03,382][train][INFO] - {"epoch": 77, "train_loss": "4.843", "train_ppl": "28.7", "train_wps": "101711", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "84007", "train_lr": "0.000249523", "train_gnorm": "0.655", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "94123"}
[2023-03-29 00:33:03,384][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 00:33:03,415][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 00:33:03,417][fairseq.trainer][INFO] - begin training epoch 78
[2023-03-29 00:33:03,418][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 00:36:26,571][train_inner][INFO] - {"epoch": 78, "update": 77.177, "loss": "4.804", "ppl": "27.94", "wps": "101076", "ups": "0.94", "wpb": "107042", "bsz": "255.8", "num_updates": "84200", "lr": "0.000248348", "gnorm": "0.66", "train_wall": "165", "gb_free": "7.5", "wall": "94326"}
[2023-03-29 00:39:57,095][train_inner][INFO] - {"epoch": 78, "update": 77.36, "loss": "4.828", "ppl": "28.4", "wps": "101844", "ups": "0.95", "wpb": "107202", "bsz": "256", "num_updates": "84400", "lr": "0.00024713", "gnorm": "0.661", "train_wall": "165", "gb_free": "7.5", "wall": "94537"}
[2023-03-29 00:43:27,511][train_inner][INFO] - {"epoch": 78, "update": 77.544, "loss": "4.846", "ppl": "28.75", "wps": "101936", "ups": "0.95", "wpb": "107245", "bsz": "256", "num_updates": "84600", "lr": "0.000245913", "gnorm": "0.658", "train_wall": "165", "gb_free": "7.5", "wall": "94747"}
[2023-03-29 00:46:58,055][train_inner][INFO] - {"epoch": 78, "update": 77.727, "loss": "4.85", "ppl": "28.84", "wps": "101780", "ups": "0.95", "wpb": "107146", "bsz": "256", "num_updates": "84800", "lr": "0.000244696", "gnorm": "0.66", "train_wall": "165", "gb_free": "7.5", "wall": "94958"}
[2023-03-29 00:50:28,769][train_inner][INFO] - {"epoch": 78, "update": 77.91, "loss": "4.867", "ppl": "29.19", "wps": "101950", "ups": "0.95", "wpb": "107411", "bsz": "256", "num_updates": "85000", "lr": "0.000243478", "gnorm": "0.657", "train_wall": "166", "gb_free": "7.5", "wall": "95169"}
[2023-03-29 00:52:11,827][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 00:52:11,827][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 00:52:12,698][valid][INFO] - {"epoch": 78, "valid_loss": "4.601", "valid_ppl": "24.27", "valid_wps": "286642", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "85098", "valid_best_loss": "4.601"}
[2023-03-29 00:52:12,699][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 78 @ 85098 updates
[2023-03-29 00:52:12,700][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 00:52:12,937][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 00:52:13,088][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 78 @ 85098 updates, score 4.601) (writing took 0.3889492549933493 seconds)
[2023-03-29 00:52:13,088][fairseq_cli.train][INFO] - end of epoch 78 (average epoch stats below)
[2023-03-29 00:52:13,088][train][INFO] - {"epoch": 78, "train_loss": "4.842", "train_ppl": "28.67", "train_wps": "101732", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "85098", "train_lr": "0.000242882", "train_gnorm": "0.66", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "95273"}
[2023-03-29 00:52:13,090][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 00:52:13,121][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 00:52:13,123][fairseq.trainer][INFO] - begin training epoch 79
[2023-03-29 00:52:13,124][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 00:54:00,663][train_inner][INFO] - {"epoch": 79, "update": 78.093, "loss": "4.833", "ppl": "28.51", "wps": "101139", "ups": "0.94", "wpb": "107153", "bsz": "255.8", "num_updates": "85200", "lr": "0.000242261", "gnorm": "0.662", "train_wall": "165", "gb_free": "7.5", "wall": "95381"}
[2023-03-29 00:57:31,455][train_inner][INFO] - {"epoch": 79, "update": 78.277, "loss": "4.811", "ppl": "28.07", "wps": "101962", "ups": "0.95", "wpb": "107464", "bsz": "256", "num_updates": "85400", "lr": "0.000241043", "gnorm": "0.662", "train_wall": "166", "gb_free": "7.5", "wall": "95591"}
[2023-03-29 01:01:02,010][train_inner][INFO] - {"epoch": 79, "update": 78.46, "loss": "4.836", "ppl": "28.56", "wps": "101675", "ups": "0.95", "wpb": "107041", "bsz": "256", "num_updates": "85600", "lr": "0.000239826", "gnorm": "0.663", "train_wall": "165", "gb_free": "7.5", "wall": "95802"}
[2023-03-29 01:04:32,525][train_inner][INFO] - {"epoch": 79, "update": 78.643, "loss": "4.845", "ppl": "28.75", "wps": "101872", "ups": "0.95", "wpb": "107228", "bsz": "256", "num_updates": "85800", "lr": "0.000238609", "gnorm": "0.663", "train_wall": "165", "gb_free": "7.5", "wall": "96012"}
[2023-03-29 01:08:02,567][train_inner][INFO] - {"epoch": 79, "update": 78.827, "loss": "4.858", "ppl": "29.01", "wps": "101854", "ups": "0.95", "wpb": "106968", "bsz": "256", "num_updates": "86000", "lr": "0.000237391", "gnorm": "0.663", "train_wall": "165", "gb_free": "7.5", "wall": "96222"}
[2023-03-29 01:11:21,585][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 01:11:21,586][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 01:11:22,513][valid][INFO] - {"epoch": 79, "valid_loss": "4.597", "valid_ppl": "24.2", "valid_wps": "268765", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "86189", "valid_best_loss": "4.597"}
[2023-03-29 01:11:22,514][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 79 @ 86189 updates
[2023-03-29 01:11:22,515][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 01:11:22,935][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 01:11:23,244][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 79 @ 86189 updates, score 4.597) (writing took 0.7295503549976274 seconds)
[2023-03-29 01:11:23,244][fairseq_cli.train][INFO] - end of epoch 79 (average epoch stats below)
[2023-03-29 01:11:23,245][train][INFO] - {"epoch": 79, "train_loss": "4.839", "train_ppl": "28.62", "train_wps": "101692", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "86189", "train_lr": "0.000236241", "train_gnorm": "0.662", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "96423"}
[2023-03-29 01:11:23,246][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 01:11:23,277][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 01:11:23,279][fairseq.trainer][INFO] - begin training epoch 80
[2023-03-29 01:11:23,280][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 01:11:35,062][train_inner][INFO] - {"epoch": 80, "update": 79.01, "loss": "4.861", "ppl": "29.06", "wps": "100957", "ups": "0.94", "wpb": "107265", "bsz": "255.8", "num_updates": "86200", "lr": "0.000236174", "gnorm": "0.661", "train_wall": "165", "gb_free": "7.5", "wall": "96435"}
[2023-03-29 01:15:05,411][train_inner][INFO] - {"epoch": 80, "update": 79.193, "loss": "4.796", "ppl": "27.78", "wps": "101832", "ups": "0.95", "wpb": "107101", "bsz": "256", "num_updates": "86400", "lr": "0.000234957", "gnorm": "0.665", "train_wall": "165", "gb_free": "7.5", "wall": "96645"}
[2023-03-29 01:18:35,845][train_inner][INFO] - {"epoch": 80, "update": 79.377, "loss": "4.817", "ppl": "28.18", "wps": "101898", "ups": "0.95", "wpb": "107214", "bsz": "256", "num_updates": "86600", "lr": "0.000233739", "gnorm": "0.666", "train_wall": "165", "gb_free": "7.5", "wall": "96856"}
[2023-03-29 01:22:06,250][train_inner][INFO] - {"epoch": 80, "update": 79.56, "loss": "4.836", "ppl": "28.57", "wps": "101883", "ups": "0.95", "wpb": "107183", "bsz": "256", "num_updates": "86800", "lr": "0.000232522", "gnorm": "0.666", "train_wall": "165", "gb_free": "7.5", "wall": "97066"}
[2023-03-29 01:25:36,875][train_inner][INFO] - {"epoch": 80, "update": 79.743, "loss": "4.854", "ppl": "28.92", "wps": "101982", "ups": "0.95", "wpb": "107400", "bsz": "256", "num_updates": "87000", "lr": "0.000231304", "gnorm": "0.667", "train_wall": "166", "gb_free": "7.5", "wall": "97277"}
[2023-03-29 01:29:07,426][train_inner][INFO] - {"epoch": 80, "update": 79.927, "loss": "4.861", "ppl": "29.07", "wps": "101891", "ups": "0.95", "wpb": "107266", "bsz": "256", "num_updates": "87200", "lr": "0.000230087", "gnorm": "0.664", "train_wall": "165", "gb_free": "7.5", "wall": "97487"}
[2023-03-29 01:30:31,496][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 01:30:31,497][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 01:30:32,367][valid][INFO] - {"epoch": 80, "valid_loss": "4.599", "valid_ppl": "24.23", "valid_wps": "286747", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "87280", "valid_best_loss": "4.597"}
[2023-03-29 01:30:32,368][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 80 @ 87280 updates
[2023-03-29 01:30:32,369][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 01:30:32,706][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 01:30:32,711][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 80 @ 87280 updates, score 4.599) (writing took 0.3425874390086392 seconds)
[2023-03-29 01:30:32,711][fairseq_cli.train][INFO] - end of epoch 80 (average epoch stats below)
[2023-03-29 01:30:32,712][train][INFO] - {"epoch": 80, "train_loss": "4.835", "train_ppl": "28.54", "train_wps": "101753", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "87280", "train_lr": "0.0002296", "train_gnorm": "0.666", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "97573"}
[2023-03-29 01:30:32,713][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 01:30:32,742][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 01:30:32,744][fairseq.trainer][INFO] - begin training epoch 81
[2023-03-29 01:30:32,744][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 01:32:39,579][train_inner][INFO] - {"epoch": 81, "update": 80.11, "loss": "4.82", "ppl": "28.25", "wps": "101211", "ups": "0.94", "wpb": "107361", "bsz": "255.8", "num_updates": "87400", "lr": "0.00022887", "gnorm": "0.667", "train_wall": "166", "gb_free": "7.5", "wall": "97699"}
[2023-03-29 01:36:10,025][train_inner][INFO] - {"epoch": 81, "update": 80.293, "loss": "4.813", "ppl": "28.11", "wps": "101865", "ups": "0.95", "wpb": "107186", "bsz": "256", "num_updates": "87600", "lr": "0.000227652", "gnorm": "0.668", "train_wall": "165", "gb_free": "7.5", "wall": "97910"}
[2023-03-29 01:39:40,672][train_inner][INFO] - {"epoch": 81, "update": 80.477, "loss": "4.826", "ppl": "28.35", "wps": "101880", "ups": "0.95", "wpb": "107303", "bsz": "256", "num_updates": "87800", "lr": "0.000226435", "gnorm": "0.668", "train_wall": "166", "gb_free": "7.5", "wall": "98121"}
[2023-03-29 01:43:10,698][train_inner][INFO] - {"epoch": 81, "update": 80.66, "loss": "4.841", "ppl": "28.66", "wps": "101844", "ups": "0.95", "wpb": "106948", "bsz": "256", "num_updates": "88000", "lr": "0.000225217", "gnorm": "0.671", "train_wall": "165", "gb_free": "7.5", "wall": "98331"}
[2023-03-29 01:46:41,433][train_inner][INFO] - {"epoch": 81, "update": 80.843, "loss": "4.852", "ppl": "28.88", "wps": "101841", "ups": "0.95", "wpb": "107308", "bsz": "256", "num_updates": "88200", "lr": "0.000224", "gnorm": "0.668", "train_wall": "166", "gb_free": "7.5", "wall": "98541"}
[2023-03-29 01:49:41,155][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 01:49:41,156][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 01:49:42,075][valid][INFO] - {"epoch": 81, "valid_loss": "4.598", "valid_ppl": "24.22", "valid_wps": "271716", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "88371", "valid_best_loss": "4.597"}
[2023-03-29 01:49:42,076][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 81 @ 88371 updates
[2023-03-29 01:49:42,077][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 01:49:42,362][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 01:49:42,367][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 81 @ 88371 updates, score 4.598) (writing took 0.2908817290008301 seconds)
[2023-03-29 01:49:42,367][fairseq_cli.train][INFO] - end of epoch 81 (average epoch stats below)
[2023-03-29 01:49:42,367][train][INFO] - {"epoch": 81, "train_loss": "4.833", "train_ppl": "28.49", "train_wps": "101737", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "88371", "train_lr": "0.000222959", "train_gnorm": "0.669", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "98722"}
[2023-03-29 01:49:42,369][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 01:49:42,399][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 01:49:42,401][fairseq.trainer][INFO] - begin training epoch 82
[2023-03-29 01:49:42,402][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 01:50:13,252][train_inner][INFO] - {"epoch": 82, "update": 81.027, "loss": "4.853", "ppl": "28.9", "wps": "101059", "ups": "0.94", "wpb": "107031", "bsz": "255.8", "num_updates": "88400", "lr": "0.000222783", "gnorm": "0.669", "train_wall": "165", "gb_free": "7.5", "wall": "98753"}
[2023-03-29 01:53:43,741][train_inner][INFO] - {"epoch": 82, "update": 81.21, "loss": "4.793", "ppl": "27.73", "wps": "101940", "ups": "0.95", "wpb": "107286", "bsz": "256", "num_updates": "88600", "lr": "0.000221565", "gnorm": "0.672", "train_wall": "165", "gb_free": "7.5", "wall": "98964"}
[2023-03-29 01:57:14,559][train_inner][INFO] - {"epoch": 82, "update": 81.393, "loss": "4.816", "ppl": "28.17", "wps": "101928", "ups": "0.95", "wpb": "107441", "bsz": "256", "num_updates": "88800", "lr": "0.000220348", "gnorm": "0.671", "train_wall": "166", "gb_free": "7.5", "wall": "99174"}
[2023-03-29 02:00:45,074][train_inner][INFO] - {"epoch": 82, "update": 81.577, "loss": "4.833", "ppl": "28.5", "wps": "101878", "ups": "0.95", "wpb": "107234", "bsz": "256", "num_updates": "89000", "lr": "0.00021913", "gnorm": "0.673", "train_wall": "165", "gb_free": "7.5", "wall": "99385"}
[2023-03-29 02:04:15,030][train_inner][INFO] - {"epoch": 82, "update": 81.76, "loss": "4.845", "ppl": "28.75", "wps": "101812", "ups": "0.95", "wpb": "106880", "bsz": "256", "num_updates": "89200", "lr": "0.000217913", "gnorm": "0.672", "train_wall": "165", "gb_free": "7.5", "wall": "99595"}
[2023-03-29 02:07:45,405][train_inner][INFO] - {"epoch": 82, "update": 81.943, "loss": "4.856", "ppl": "28.95", "wps": "101839", "ups": "0.95", "wpb": "107122", "bsz": "256", "num_updates": "89400", "lr": "0.000216696", "gnorm": "0.674", "train_wall": "165", "gb_free": "7.5", "wall": "99805"}
[2023-03-29 02:08:50,755][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 02:08:50,755][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 02:08:51,623][valid][INFO] - {"epoch": 82, "valid_loss": "4.597", "valid_ppl": "24.19", "valid_wps": "287446", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "89462", "valid_best_loss": "4.597"}
[2023-03-29 02:08:51,624][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 82 @ 89462 updates
[2023-03-29 02:08:51,625][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 02:08:51,862][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 02:08:52,013][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 82 @ 89462 updates, score 4.597) (writing took 0.38859170299838297 seconds)
[2023-03-29 02:08:52,013][fairseq_cli.train][INFO] - end of epoch 82 (average epoch stats below)
[2023-03-29 02:08:52,014][train][INFO] - {"epoch": 82, "train_loss": "4.829", "train_ppl": "28.43", "train_wps": "101737", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "89462", "train_lr": "0.000216318", "train_gnorm": "0.672", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "99872"}
[2023-03-29 02:08:52,015][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 02:08:52,045][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 02:08:52,047][fairseq.trainer][INFO] - begin training epoch 83
[2023-03-29 02:08:52,048][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 02:11:17,266][train_inner][INFO] - {"epoch": 83, "update": 82.126, "loss": "4.806", "ppl": "27.98", "wps": "101153", "ups": "0.94", "wpb": "107152", "bsz": "255.8", "num_updates": "89600", "lr": "0.000215478", "gnorm": "0.673", "train_wall": "165", "gb_free": "7.5", "wall": "100017"}
[2023-03-29 02:14:47,817][train_inner][INFO] - {"epoch": 83, "update": 82.31, "loss": "4.811", "ppl": "28.07", "wps": "101874", "ups": "0.95", "wpb": "107248", "bsz": "256", "num_updates": "89800", "lr": "0.000214261", "gnorm": "0.675", "train_wall": "165", "gb_free": "7.5", "wall": "100228"}
[2023-03-29 02:18:18,476][train_inner][INFO] - {"epoch": 83, "update": 82.493, "loss": "4.816", "ppl": "28.17", "wps": "101918", "ups": "0.95", "wpb": "107350", "bsz": "256", "num_updates": "90000", "lr": "0.000213043", "gnorm": "0.675", "train_wall": "166", "gb_free": "7.5", "wall": "100438"}
[2023-03-29 02:21:48,915][train_inner][INFO] - {"epoch": 83, "update": 82.676, "loss": "4.84", "ppl": "28.64", "wps": "101907", "ups": "0.95", "wpb": "107226", "bsz": "256", "num_updates": "90200", "lr": "0.000211826", "gnorm": "0.677", "train_wall": "165", "gb_free": "7.5", "wall": "100649"}
[2023-03-29 02:25:19,642][train_inner][INFO] - {"epoch": 83, "update": 82.86, "loss": "4.852", "ppl": "28.87", "wps": "101850", "ups": "0.95", "wpb": "107312", "bsz": "256", "num_updates": "90400", "lr": "0.000210609", "gnorm": "0.675", "train_wall": "166", "gb_free": "7.5", "wall": "100859"}
[2023-03-29 02:28:00,398][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 02:28:00,399][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 02:28:01,324][valid][INFO] - {"epoch": 83, "valid_loss": "4.596", "valid_ppl": "24.18", "valid_wps": "269806", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "90553", "valid_best_loss": "4.596"}
[2023-03-29 02:28:01,325][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 83 @ 90553 updates
[2023-03-29 02:28:01,326][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 02:28:01,557][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 02:28:01,704][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 83 @ 90553 updates, score 4.596) (writing took 0.3791122130060103 seconds)
[2023-03-29 02:28:01,704][fairseq_cli.train][INFO] - end of epoch 83 (average epoch stats below)
[2023-03-29 02:28:01,704][train][INFO] - {"epoch": 83, "train_loss": "4.827", "train_ppl": "28.37", "train_wps": "101734", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "90553", "train_lr": "0.000209677", "train_gnorm": "0.675", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "101022"}
[2023-03-29 02:28:01,706][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 02:28:01,738][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 02:28:01,740][fairseq.trainer][INFO] - begin training epoch 84
[2023-03-29 02:28:01,740][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 02:28:51,463][train_inner][INFO] - {"epoch": 84, "update": 83.043, "loss": "4.83", "ppl": "28.43", "wps": "100986", "ups": "0.94", "wpb": "106955", "bsz": "255.8", "num_updates": "90600", "lr": "0.000209391", "gnorm": "0.675", "train_wall": "165", "gb_free": "7.5", "wall": "101071"}
[2023-03-29 02:32:22,037][train_inner][INFO] - {"epoch": 84, "update": 83.226, "loss": "4.797", "ppl": "27.81", "wps": "101956", "ups": "0.95", "wpb": "107346", "bsz": "256", "num_updates": "90800", "lr": "0.000208174", "gnorm": "0.678", "train_wall": "166", "gb_free": "7.5", "wall": "101282"}
[2023-03-29 02:35:52,608][train_inner][INFO] - {"epoch": 84, "update": 83.41, "loss": "4.815", "ppl": "28.15", "wps": "101879", "ups": "0.95", "wpb": "107264", "bsz": "256", "num_updates": "91000", "lr": "0.000206957", "gnorm": "0.678", "train_wall": "165", "gb_free": "7.5", "wall": "101492"}
[2023-03-29 02:39:23,049][train_inner][INFO] - {"epoch": 84, "update": 83.593, "loss": "4.831", "ppl": "28.47", "wps": "101954", "ups": "0.95", "wpb": "107277", "bsz": "256", "num_updates": "91200", "lr": "0.000205739", "gnorm": "0.679", "train_wall": "165", "gb_free": "7.5", "wall": "101703"}
[2023-03-29 02:42:53,681][train_inner][INFO] - {"epoch": 84, "update": 83.776, "loss": "4.836", "ppl": "28.56", "wps": "101801", "ups": "0.95", "wpb": "107212", "bsz": "256", "num_updates": "91400", "lr": "0.000204522", "gnorm": "0.677", "train_wall": "165", "gb_free": "7.5", "wall": "101914"}
[2023-03-29 02:46:24,053][train_inner][INFO] - {"epoch": 84, "update": 83.96, "loss": "4.851", "ppl": "28.86", "wps": "101795", "ups": "0.95", "wpb": "107074", "bsz": "256", "num_updates": "91600", "lr": "0.000203304", "gnorm": "0.679", "train_wall": "165", "gb_free": "7.5", "wall": "102124"}
[2023-03-29 02:47:10,281][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 02:47:10,282][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 02:47:11,158][valid][INFO] - {"epoch": 84, "valid_loss": "4.59", "valid_ppl": "24.09", "valid_wps": "284878", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "91644", "valid_best_loss": "4.59"}
[2023-03-29 02:47:11,159][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 84 @ 91644 updates
[2023-03-29 02:47:11,160][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 02:47:11,480][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 02:47:11,690][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 84 @ 91644 updates, score 4.59) (writing took 0.5313379370054463 seconds)
[2023-03-29 02:47:11,691][fairseq_cli.train][INFO] - end of epoch 84 (average epoch stats below)
[2023-03-29 02:47:11,691][train][INFO] - {"epoch": 84, "train_loss": "4.824", "train_ppl": "28.33", "train_wps": "101707", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "91644", "train_lr": "0.000203037", "train_gnorm": "0.678", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "102172"}
[2023-03-29 02:47:11,693][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 02:47:11,725][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 02:47:11,727][fairseq.trainer][INFO] - begin training epoch 85
[2023-03-29 02:47:11,728][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 02:49:55,870][train_inner][INFO] - {"epoch": 85, "update": 84.143, "loss": "4.792", "ppl": "27.71", "wps": "101080", "ups": "0.94", "wpb": "107052", "bsz": "255.8", "num_updates": "91800", "lr": "0.000202087", "gnorm": "0.682", "train_wall": "165", "gb_free": "7.5", "wall": "102336"}
[2023-03-29 02:53:26,508][train_inner][INFO] - {"epoch": 85, "update": 84.326, "loss": "4.798", "ppl": "27.82", "wps": "101939", "ups": "0.95", "wpb": "107361", "bsz": "256", "num_updates": "92000", "lr": "0.00020087", "gnorm": "0.682", "train_wall": "166", "gb_free": "7.5", "wall": "102546"}
[2023-03-29 02:56:57,398][train_inner][INFO] - {"epoch": 85, "update": 84.51, "loss": "4.818", "ppl": "28.2", "wps": "101967", "ups": "0.95", "wpb": "107519", "bsz": "256", "num_updates": "92200", "lr": "0.000199652", "gnorm": "0.68", "train_wall": "166", "gb_free": "7.5", "wall": "102757"}
[2023-03-29 03:00:27,275][train_inner][INFO] - {"epoch": 85, "update": 84.693, "loss": "4.836", "ppl": "28.56", "wps": "101824", "ups": "0.95", "wpb": "106852", "bsz": "256", "num_updates": "92400", "lr": "0.000198435", "gnorm": "0.684", "train_wall": "165", "gb_free": "7.5", "wall": "102967"}
[2023-03-29 03:03:57,901][train_inner][INFO] - {"epoch": 85, "update": 84.876, "loss": "4.839", "ppl": "28.62", "wps": "101834", "ups": "0.95", "wpb": "107244", "bsz": "256", "num_updates": "92600", "lr": "0.000197217", "gnorm": "0.681", "train_wall": "165", "gb_free": "7.5", "wall": "103178"}
[2023-03-29 03:06:19,789][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 03:06:19,790][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 03:06:20,718][valid][INFO] - {"epoch": 85, "valid_loss": "4.592", "valid_ppl": "24.12", "valid_wps": "269224", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "92735", "valid_best_loss": "4.59"}
[2023-03-29 03:06:20,719][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 85 @ 92735 updates
[2023-03-29 03:06:20,719][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 03:06:21,108][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 03:06:21,112][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 85 @ 92735 updates, score 4.592) (writing took 0.39369394999812357 seconds)
[2023-03-29 03:06:21,113][fairseq_cli.train][INFO] - end of epoch 85 (average epoch stats below)
[2023-03-29 03:06:21,113][train][INFO] - {"epoch": 85, "train_loss": "4.821", "train_ppl": "28.27", "train_wps": "101757", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "92735", "train_lr": "0.000196396", "train_gnorm": "0.682", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "103321"}
[2023-03-29 03:06:21,115][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 03:06:21,145][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 03:06:21,147][fairseq.trainer][INFO] - begin training epoch 86
[2023-03-29 03:06:21,148][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 03:07:29,799][train_inner][INFO] - {"epoch": 86, "update": 85.06, "loss": "4.834", "ppl": "28.52", "wps": "101075", "ups": "0.94", "wpb": "107088", "bsz": "255.8", "num_updates": "92800", "lr": "0.000196", "gnorm": "0.684", "train_wall": "165", "gb_free": "7.5", "wall": "103390"}
[2023-03-29 03:10:59,991][train_inner][INFO] - {"epoch": 86, "update": 85.243, "loss": "4.787", "ppl": "27.61", "wps": "101820", "ups": "0.95", "wpb": "107009", "bsz": "256", "num_updates": "93000", "lr": "0.000194783", "gnorm": "0.686", "train_wall": "165", "gb_free": "7.5", "wall": "103600"}
[2023-03-29 03:14:30,154][train_inner][INFO] - {"epoch": 86, "update": 85.426, "loss": "4.809", "ppl": "28.04", "wps": "101788", "ups": "0.95", "wpb": "106960", "bsz": "256", "num_updates": "93200", "lr": "0.000193565", "gnorm": "0.686", "train_wall": "165", "gb_free": "7.5", "wall": "103810"}
[2023-03-29 03:18:00,886][train_inner][INFO] - {"epoch": 86, "update": 85.61, "loss": "4.822", "ppl": "28.29", "wps": "101960", "ups": "0.95", "wpb": "107431", "bsz": "256", "num_updates": "93400", "lr": "0.000192348", "gnorm": "0.687", "train_wall": "166", "gb_free": "7.5", "wall": "104021"}
[2023-03-29 03:21:31,680][train_inner][INFO] - {"epoch": 86, "update": 85.793, "loss": "4.838", "ppl": "28.6", "wps": "101911", "ups": "0.95", "wpb": "107411", "bsz": "256", "num_updates": "93600", "lr": "0.00019113", "gnorm": "0.685", "train_wall": "166", "gb_free": "7.5", "wall": "104232"}
[2023-03-29 03:25:02,504][train_inner][INFO] - {"epoch": 86, "update": 85.976, "loss": "4.84", "ppl": "28.63", "wps": "101852", "ups": "0.95", "wpb": "107363", "bsz": "256", "num_updates": "93800", "lr": "0.000189913", "gnorm": "0.684", "train_wall": "166", "gb_free": "7.5", "wall": "104442"}
[2023-03-29 03:25:29,736][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 03:25:29,736][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 03:25:30,615][valid][INFO] - {"epoch": 86, "valid_loss": "4.592", "valid_ppl": "24.12", "valid_wps": "284263", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "93826", "valid_best_loss": "4.59"}
[2023-03-29 03:25:30,615][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 86 @ 93826 updates
[2023-03-29 03:25:30,616][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 03:25:30,988][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 03:25:30,993][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 86 @ 93826 updates, score 4.592) (writing took 0.377982357997098 seconds)
[2023-03-29 03:25:30,994][fairseq_cli.train][INFO] - end of epoch 86 (average epoch stats below)
[2023-03-29 03:25:30,994][train][INFO] - {"epoch": 86, "train_loss": "4.818", "train_ppl": "28.2", "train_wps": "101717", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "93826", "train_lr": "0.000189755", "train_gnorm": "0.685", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "104471"}
[2023-03-29 03:25:30,996][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 03:25:31,025][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 03:25:31,027][fairseq.trainer][INFO] - begin training epoch 87
[2023-03-29 03:25:31,028][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 03:28:34,404][train_inner][INFO] - {"epoch": 87, "update": 86.159, "loss": "4.791", "ppl": "27.69", "wps": "101164", "ups": "0.94", "wpb": "107183", "bsz": "255.8", "num_updates": "94000", "lr": "0.000188696", "gnorm": "0.689", "train_wall": "165", "gb_free": "7.5", "wall": "104654"}
[2023-03-29 03:32:05,243][train_inner][INFO] - {"epoch": 87, "update": 86.343, "loss": "4.796", "ppl": "27.78", "wps": "102071", "ups": "0.95", "wpb": "107602", "bsz": "256", "num_updates": "94200", "lr": "0.000187478", "gnorm": "0.687", "train_wall": "166", "gb_free": "7.5", "wall": "104865"}
[2023-03-29 03:35:35,346][train_inner][INFO] - {"epoch": 87, "update": 86.526, "loss": "4.813", "ppl": "28.12", "wps": "101781", "ups": "0.95", "wpb": "106922", "bsz": "256", "num_updates": "94400", "lr": "0.000186261", "gnorm": "0.69", "train_wall": "165", "gb_free": "7.5", "wall": "105075"}
[2023-03-29 03:39:05,758][train_inner][INFO] - {"epoch": 87, "update": 86.709, "loss": "4.828", "ppl": "28.4", "wps": "101850", "ups": "0.95", "wpb": "107152", "bsz": "256", "num_updates": "94600", "lr": "0.000185043", "gnorm": "0.689", "train_wall": "165", "gb_free": "7.5", "wall": "105286"}
[2023-03-29 03:42:36,270][train_inner][INFO] - {"epoch": 87, "update": 86.893, "loss": "4.838", "ppl": "28.6", "wps": "101838", "ups": "0.95", "wpb": "107190", "bsz": "256", "num_updates": "94800", "lr": "0.000183826", "gnorm": "0.69", "train_wall": "165", "gb_free": "7.5", "wall": "105496"}
[2023-03-29 03:44:39,219][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 03:44:39,219][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 03:44:40,145][valid][INFO] - {"epoch": 87, "valid_loss": "4.588", "valid_ppl": "24.05", "valid_wps": "269730", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "94917", "valid_best_loss": "4.588"}
[2023-03-29 03:44:40,146][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 87 @ 94917 updates
[2023-03-29 03:44:40,147][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 03:44:40,386][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 03:44:40,541][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 87 @ 94917 updates, score 4.588) (writing took 0.3952541860053316 seconds)
[2023-03-29 03:44:40,541][fairseq_cli.train][INFO] - end of epoch 87 (average epoch stats below)
[2023-03-29 03:44:40,542][train][INFO] - {"epoch": 87, "train_loss": "4.816", "train_ppl": "28.16", "train_wps": "101746", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "94917", "train_lr": "0.000183114", "train_gnorm": "0.689", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "105620"}
[2023-03-29 03:44:40,544][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 03:44:40,575][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 03:44:40,577][fairseq.trainer][INFO] - begin training epoch 88
[2023-03-29 03:44:40,577][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 03:46:08,223][train_inner][INFO] - {"epoch": 88, "update": 87.076, "loss": "4.809", "ppl": "28.03", "wps": "101044", "ups": "0.94", "wpb": "107083", "bsz": "255.8", "num_updates": "95000", "lr": "0.000182609", "gnorm": "0.69", "train_wall": "165", "gb_free": "7.5", "wall": "105708"}
[2023-03-29 03:49:38,575][train_inner][INFO] - {"epoch": 88, "update": 87.259, "loss": "4.787", "ppl": "27.61", "wps": "101850", "ups": "0.95", "wpb": "107122", "bsz": "256", "num_updates": "95200", "lr": "0.000181391", "gnorm": "0.694", "train_wall": "165", "gb_free": "7.5", "wall": "105918"}
[2023-03-29 03:53:09,015][train_inner][INFO] - {"epoch": 88, "update": 87.443, "loss": "4.809", "ppl": "28.04", "wps": "101859", "ups": "0.95", "wpb": "107176", "bsz": "256", "num_updates": "95400", "lr": "0.000180174", "gnorm": "0.693", "train_wall": "165", "gb_free": "7.5", "wall": "106129"}
[2023-03-29 03:56:39,509][train_inner][INFO] - {"epoch": 88, "update": 87.626, "loss": "4.819", "ppl": "28.22", "wps": "101958", "ups": "0.95", "wpb": "107307", "bsz": "256", "num_updates": "95600", "lr": "0.000178957", "gnorm": "0.693", "train_wall": "165", "gb_free": "7.5", "wall": "106339"}
[2023-03-29 04:00:09,831][train_inner][INFO] - {"epoch": 88, "update": 87.809, "loss": "4.826", "ppl": "28.37", "wps": "101915", "ups": "0.95", "wpb": "107175", "bsz": "256", "num_updates": "95800", "lr": "0.000177739", "gnorm": "0.694", "train_wall": "165", "gb_free": "7.5", "wall": "106550"}
[2023-03-29 04:03:40,556][train_inner][INFO] - {"epoch": 88, "update": 87.993, "loss": "4.841", "ppl": "28.67", "wps": "101866", "ups": "0.95", "wpb": "107329", "bsz": "256", "num_updates": "96000", "lr": "0.000176522", "gnorm": "0.692", "train_wall": "166", "gb_free": "7.5", "wall": "106760"}
[2023-03-29 04:03:48,950][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 04:03:48,951][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 04:03:49,828][valid][INFO] - {"epoch": 88, "valid_loss": "4.588", "valid_ppl": "24.05", "valid_wps": "284754", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "96008", "valid_best_loss": "4.588"}
[2023-03-29 04:03:49,829][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 88 @ 96008 updates
[2023-03-29 04:03:49,829][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 04:03:50,211][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 04:03:50,477][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 88 @ 96008 updates, score 4.588) (writing took 0.6487364849890582 seconds)
[2023-03-29 04:03:50,478][fairseq_cli.train][INFO] - end of epoch 88 (average epoch stats below)
[2023-03-29 04:03:50,478][train][INFO] - {"epoch": 88, "train_loss": "4.812", "train_ppl": "28.09", "train_wps": "101712", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "96008", "train_lr": "0.000176473", "train_gnorm": "0.693", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "106770"}
[2023-03-29 04:03:50,480][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 04:03:50,511][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 04:03:50,513][fairseq.trainer][INFO] - begin training epoch 89
[2023-03-29 04:03:50,514][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 04:07:12,662][train_inner][INFO] - {"epoch": 89, "update": 88.176, "loss": "4.774", "ppl": "27.35", "wps": "100882", "ups": "0.94", "wpb": "106988", "bsz": "255.8", "num_updates": "96200", "lr": "0.000175304", "gnorm": "0.695", "train_wall": "165", "gb_free": "7.5", "wall": "106973"}
[2023-03-29 04:10:43,404][train_inner][INFO] - {"epoch": 89, "update": 88.359, "loss": "4.799", "ppl": "27.83", "wps": "101912", "ups": "0.95", "wpb": "107386", "bsz": "256", "num_updates": "96400", "lr": "0.000174087", "gnorm": "0.696", "train_wall": "166", "gb_free": "7.5", "wall": "107183"}
[2023-03-29 04:14:13,425][train_inner][INFO] - {"epoch": 89, "update": 88.543, "loss": "4.818", "ppl": "28.2", "wps": "101836", "ups": "0.95", "wpb": "106938", "bsz": "256", "num_updates": "96600", "lr": "0.00017287", "gnorm": "0.697", "train_wall": "165", "gb_free": "7.5", "wall": "107393"}
[2023-03-29 04:17:44,309][train_inner][INFO] - {"epoch": 89, "update": 88.726, "loss": "4.824", "ppl": "28.33", "wps": "101930", "ups": "0.95", "wpb": "107476", "bsz": "256", "num_updates": "96800", "lr": "0.000171652", "gnorm": "0.695", "train_wall": "166", "gb_free": "7.5", "wall": "107604"}
[2023-03-29 04:21:14,994][train_inner][INFO] - {"epoch": 89, "update": 88.909, "loss": "4.824", "ppl": "28.32", "wps": "101853", "ups": "0.95", "wpb": "107294", "bsz": "256", "num_updates": "97000", "lr": "0.000170435", "gnorm": "0.695", "train_wall": "166", "gb_free": "7.5", "wall": "107815"}
[2023-03-29 04:22:59,083][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 04:22:59,084][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 04:22:59,954][valid][INFO] - {"epoch": 89, "valid_loss": "4.586", "valid_ppl": "24.02", "valid_wps": "286869", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "97099", "valid_best_loss": "4.586"}
[2023-03-29 04:22:59,955][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 89 @ 97099 updates
[2023-03-29 04:22:59,956][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 04:23:00,193][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 04:23:00,347][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 89 @ 97099 updates, score 4.586) (writing took 0.3914763400098309 seconds)
[2023-03-29 04:23:00,347][fairseq_cli.train][INFO] - end of epoch 89 (average epoch stats below)
[2023-03-29 04:23:00,347][train][INFO] - {"epoch": 89, "train_loss": "4.81", "train_ppl": "28.04", "train_wps": "101718", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "97099", "train_lr": "0.000169832", "train_gnorm": "0.696", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "107920"}
[2023-03-29 04:23:00,349][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 04:23:00,379][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 04:23:00,381][fairseq.trainer][INFO] - begin training epoch 90
[2023-03-29 04:23:00,382][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 04:24:46,834][train_inner][INFO] - {"epoch": 90, "update": 89.093, "loss": "4.797", "ppl": "27.8", "wps": "101010", "ups": "0.94", "wpb": "106990", "bsz": "255.8", "num_updates": "97200", "lr": "0.000169217", "gnorm": "0.699", "train_wall": "165", "gb_free": "7.5", "wall": "108027"}
[2023-03-29 04:28:17,341][train_inner][INFO] - {"epoch": 90, "update": 89.276, "loss": "4.783", "ppl": "27.53", "wps": "101845", "ups": "0.95", "wpb": "107196", "bsz": "256", "num_updates": "97400", "lr": "0.000168", "gnorm": "0.698", "train_wall": "165", "gb_free": "7.5", "wall": "108237"}
[2023-03-29 04:31:48,048][train_inner][INFO] - {"epoch": 90, "update": 89.459, "loss": "4.797", "ppl": "27.8", "wps": "101889", "ups": "0.95", "wpb": "107343", "bsz": "256", "num_updates": "97600", "lr": "0.000166783", "gnorm": "0.698", "train_wall": "166", "gb_free": "7.5", "wall": "108448"}
[2023-03-29 04:35:18,553][train_inner][INFO] - {"epoch": 90, "update": 89.643, "loss": "4.812", "ppl": "28.09", "wps": "101785", "ups": "0.95", "wpb": "107131", "bsz": "256", "num_updates": "97800", "lr": "0.000165565", "gnorm": "0.699", "train_wall": "165", "gb_free": "7.5", "wall": "108658"}
[2023-03-29 04:38:48,911][train_inner][INFO] - {"epoch": 90, "update": 89.826, "loss": "4.825", "ppl": "28.35", "wps": "101916", "ups": "0.95", "wpb": "107194", "bsz": "256", "num_updates": "98000", "lr": "0.000164348", "gnorm": "0.7", "train_wall": "165", "gb_free": "7.5", "wall": "108869"}
[2023-03-29 04:42:08,812][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 04:42:08,812][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 04:42:09,747][valid][INFO] - {"epoch": 90, "valid_loss": "4.584", "valid_ppl": "23.99", "valid_wps": "267152", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "98190", "valid_best_loss": "4.584"}
[2023-03-29 04:42:09,748][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 90 @ 98190 updates
[2023-03-29 04:42:09,749][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 04:42:10,049][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 04:42:10,225][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 90 @ 98190 updates, score 4.584) (writing took 0.4769758210022701 seconds)
[2023-03-29 04:42:10,225][fairseq_cli.train][INFO] - end of epoch 90 (average epoch stats below)
[2023-03-29 04:42:10,225][train][INFO] - {"epoch": 90, "train_loss": "4.806", "train_ppl": "27.97", "train_wps": "101717", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "98190", "train_lr": "0.000163191", "train_gnorm": "0.699", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "109070"}
[2023-03-29 04:42:10,227][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 04:42:10,258][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 04:42:10,260][fairseq.trainer][INFO] - begin training epoch 91
[2023-03-29 04:42:10,260][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 04:42:21,173][train_inner][INFO] - {"epoch": 91, "update": 90.009, "loss": "4.831", "ppl": "28.46", "wps": "101087", "ups": "0.94", "wpb": "107285", "bsz": "255.8", "num_updates": "98200", "lr": "0.00016313", "gnorm": "0.697", "train_wall": "166", "gb_free": "7.5", "wall": "109081"}
[2023-03-29 04:45:51,429][train_inner][INFO] - {"epoch": 91, "update": 90.192, "loss": "4.775", "ppl": "27.38", "wps": "101819", "ups": "0.95", "wpb": "107040", "bsz": "256", "num_updates": "98400", "lr": "0.000161913", "gnorm": "0.702", "train_wall": "165", "gb_free": "7.5", "wall": "109291"}
[2023-03-29 04:49:22,107][train_inner][INFO] - {"epoch": 91, "update": 90.376, "loss": "4.788", "ppl": "27.63", "wps": "101853", "ups": "0.95", "wpb": "107291", "bsz": "256", "num_updates": "98600", "lr": "0.000160696", "gnorm": "0.703", "train_wall": "166", "gb_free": "7.5", "wall": "109502"}
[2023-03-29 04:52:52,877][train_inner][INFO] - {"epoch": 91, "update": 90.559, "loss": "4.8", "ppl": "27.85", "wps": "101884", "ups": "0.95", "wpb": "107370", "bsz": "256", "num_updates": "98800", "lr": "0.000159478", "gnorm": "0.703", "train_wall": "166", "gb_free": "7.5", "wall": "109713"}
[2023-03-29 04:56:23,233][train_inner][INFO] - {"epoch": 91, "update": 90.742, "loss": "4.811", "ppl": "28.08", "wps": "101888", "ups": "0.95", "wpb": "107163", "bsz": "256", "num_updates": "99000", "lr": "0.000158261", "gnorm": "0.701", "train_wall": "165", "gb_free": "7.5", "wall": "109923"}
[2023-03-29 04:59:53,771][train_inner][INFO] - {"epoch": 91, "update": 90.926, "loss": "4.827", "ppl": "28.38", "wps": "101891", "ups": "0.95", "wpb": "107260", "bsz": "256", "num_updates": "99200", "lr": "0.000157043", "gnorm": "0.702", "train_wall": "165", "gb_free": "7.5", "wall": "110134"}
[2023-03-29 05:01:18,869][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 05:01:18,869][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 05:01:19,747][valid][INFO] - {"epoch": 91, "valid_loss": "4.583", "valid_ppl": "23.97", "valid_wps": "284451", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "99281", "valid_best_loss": "4.583"}
[2023-03-29 05:01:19,748][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 91 @ 99281 updates
[2023-03-29 05:01:19,748][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 05:01:19,994][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 05:01:20,145][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 91 @ 99281 updates, score 4.583) (writing took 0.39769310600240715 seconds)
[2023-03-29 05:01:20,146][fairseq_cli.train][INFO] - end of epoch 91 (average epoch stats below)
[2023-03-29 05:01:20,146][train][INFO] - {"epoch": 91, "train_loss": "4.802", "train_ppl": "27.9", "train_wps": "101713", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "99281", "train_lr": "0.00015655", "train_gnorm": "0.702", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "110220"}
[2023-03-29 05:01:20,148][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 05:01:20,181][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 05:01:20,183][fairseq.trainer][INFO] - begin training epoch 92
[2023-03-29 05:01:20,184][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 05:03:25,642][train_inner][INFO] - {"epoch": 92, "update": 91.109, "loss": "4.792", "ppl": "27.71", "wps": "101079", "ups": "0.94", "wpb": "107078", "bsz": "255.8", "num_updates": "99400", "lr": "0.000155826", "gnorm": "0.704", "train_wall": "165", "gb_free": "7.5", "wall": "110345"}
[2023-03-29 05:06:55,731][train_inner][INFO] - {"epoch": 92, "update": 91.292, "loss": "4.774", "ppl": "27.36", "wps": "101875", "ups": "0.95", "wpb": "107014", "bsz": "256", "num_updates": "99600", "lr": "0.000154609", "gnorm": "0.704", "train_wall": "165", "gb_free": "7.5", "wall": "110556"}
[2023-03-29 05:10:26,150][train_inner][INFO] - {"epoch": 92, "update": 91.476, "loss": "4.802", "ppl": "27.89", "wps": "101865", "ups": "0.95", "wpb": "107171", "bsz": "256", "num_updates": "99800", "lr": "0.000153391", "gnorm": "0.707", "train_wall": "165", "gb_free": "7.5", "wall": "110766"}
[2023-03-29 05:13:56,943][train_inner][INFO] - {"epoch": 92, "update": 91.659, "loss": "4.805", "ppl": "27.95", "wps": "101928", "ups": "0.95", "wpb": "107428", "bsz": "256", "num_updates": "100000", "lr": "0.000152174", "gnorm": "0.704", "train_wall": "166", "gb_free": "7.5", "wall": "110977"}
[2023-03-29 05:17:27,309][train_inner][INFO] - {"epoch": 92, "update": 91.842, "loss": "4.82", "ppl": "28.25", "wps": "101923", "ups": "0.95", "wpb": "107206", "bsz": "256", "num_updates": "100200", "lr": "0.000150957", "gnorm": "0.706", "train_wall": "165", "gb_free": "7.5", "wall": "111187"}
[2023-03-29 05:20:28,427][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 05:20:28,428][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 05:20:29,340][valid][INFO] - {"epoch": 92, "valid_loss": "4.58", "valid_ppl": "23.92", "valid_wps": "273641", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "100372", "valid_best_loss": "4.58"}
[2023-03-29 05:20:29,341][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 92 @ 100372 updates
[2023-03-29 05:20:29,342][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 05:20:29,579][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 05:20:29,736][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 92 @ 100372 updates, score 4.58) (writing took 0.3950809130037669 seconds)
[2023-03-29 05:20:29,736][fairseq_cli.train][INFO] - end of epoch 92 (average epoch stats below)
[2023-03-29 05:20:29,737][train][INFO] - {"epoch": 92, "train_loss": "4.8", "train_ppl": "27.85", "train_wps": "101742", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "100372", "train_lr": "0.00014991", "train_gnorm": "0.705", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "111370"}
[2023-03-29 05:20:29,738][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 05:20:29,768][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 05:20:29,771][fairseq.trainer][INFO] - begin training epoch 93
[2023-03-29 05:20:29,771][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 05:20:59,608][train_inner][INFO] - {"epoch": 93, "update": 92.026, "loss": "4.813", "ppl": "28.11", "wps": "101037", "ups": "0.94", "wpb": "107250", "bsz": "255.8", "num_updates": "100400", "lr": "0.000149739", "gnorm": "0.706", "train_wall": "166", "gb_free": "7.5", "wall": "111399"}
[2023-03-29 05:24:29,977][train_inner][INFO] - {"epoch": 93, "update": 92.209, "loss": "4.77", "ppl": "27.29", "wps": "101744", "ups": "0.95", "wpb": "107019", "bsz": "256", "num_updates": "100600", "lr": "0.000148522", "gnorm": "0.708", "train_wall": "165", "gb_free": "7.5", "wall": "111610"}
[2023-03-29 05:28:00,590][train_inner][INFO] - {"epoch": 93, "update": 92.392, "loss": "4.785", "ppl": "27.57", "wps": "101903", "ups": "0.95", "wpb": "107310", "bsz": "256", "num_updates": "100800", "lr": "0.000147304", "gnorm": "0.709", "train_wall": "166", "gb_free": "7.5", "wall": "111820"}
[2023-03-29 05:31:31,179][train_inner][INFO] - {"epoch": 93, "update": 92.576, "loss": "4.801", "ppl": "27.87", "wps": "101831", "ups": "0.95", "wpb": "107222", "bsz": "256", "num_updates": "101000", "lr": "0.000146087", "gnorm": "0.708", "train_wall": "165", "gb_free": "7.5", "wall": "112031"}
[2023-03-29 05:35:01,709][train_inner][INFO] - {"epoch": 93, "update": 92.759, "loss": "4.808", "ppl": "28.02", "wps": "101822", "ups": "0.95", "wpb": "107183", "bsz": "256", "num_updates": "101200", "lr": "0.00014487", "gnorm": "0.709", "train_wall": "165", "gb_free": "7.5", "wall": "112242"}
[2023-03-29 05:38:32,522][train_inner][INFO] - {"epoch": 93, "update": 92.942, "loss": "4.817", "ppl": "28.19", "wps": "101947", "ups": "0.95", "wpb": "107458", "bsz": "256", "num_updates": "101400", "lr": "0.000143652", "gnorm": "0.708", "train_wall": "166", "gb_free": "7.5", "wall": "112452"}
[2023-03-29 05:39:38,585][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 05:39:38,585][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 05:39:39,458][valid][INFO] - {"epoch": 93, "valid_loss": "4.579", "valid_ppl": "23.9", "valid_wps": "286008", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "101463", "valid_best_loss": "4.579"}
[2023-03-29 05:39:39,459][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 93 @ 101463 updates
[2023-03-29 05:39:39,460][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 05:39:39,766][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 05:39:39,979][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 93 @ 101463 updates, score 4.579) (writing took 0.5200063090014737 seconds)
[2023-03-29 05:39:39,979][fairseq_cli.train][INFO] - end of epoch 93 (average epoch stats below)
[2023-03-29 05:39:39,979][train][INFO] - {"epoch": 93, "train_loss": "4.797", "train_ppl": "27.79", "train_wps": "101685", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "101463", "train_lr": "0.000143269", "train_gnorm": "0.708", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "112520"}
[2023-03-29 05:39:39,981][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 05:39:40,012][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 05:39:40,014][fairseq.trainer][INFO] - begin training epoch 94
[2023-03-29 05:39:40,015][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 05:42:04,594][train_inner][INFO] - {"epoch": 94, "update": 93.126, "loss": "4.778", "ppl": "27.43", "wps": "101084", "ups": "0.94", "wpb": "107186", "bsz": "255.8", "num_updates": "101600", "lr": "0.000142435", "gnorm": "0.711", "train_wall": "165", "gb_free": "7.5", "wall": "112664"}
[2023-03-29 05:45:35,522][train_inner][INFO] - {"epoch": 94, "update": 93.309, "loss": "4.774", "ppl": "27.36", "wps": "101998", "ups": "0.95", "wpb": "107571", "bsz": "256", "num_updates": "101800", "lr": "0.000141217", "gnorm": "0.711", "train_wall": "166", "gb_free": "7.5", "wall": "112875"}
[2023-03-29 05:49:05,940][train_inner][INFO] - {"epoch": 94, "update": 93.492, "loss": "4.789", "ppl": "27.65", "wps": "101836", "ups": "0.95", "wpb": "107140", "bsz": "256", "num_updates": "102000", "lr": "0.00014", "gnorm": "0.712", "train_wall": "165", "gb_free": "7.5", "wall": "113086"}
[2023-03-29 05:52:36,128][train_inner][INFO] - {"epoch": 94, "update": 93.676, "loss": "4.805", "ppl": "27.96", "wps": "101838", "ups": "0.95", "wpb": "107026", "bsz": "256", "num_updates": "102200", "lr": "0.000138783", "gnorm": "0.713", "train_wall": "165", "gb_free": "7.5", "wall": "113296"}
[2023-03-29 05:56:06,518][train_inner][INFO] - {"epoch": 94, "update": 93.859, "loss": "4.813", "ppl": "28.1", "wps": "101843", "ups": "0.95", "wpb": "107133", "bsz": "256", "num_updates": "102400", "lr": "0.000137565", "gnorm": "0.712", "train_wall": "165", "gb_free": "7.5", "wall": "113506"}
[2023-03-29 05:58:48,280][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 05:58:48,281][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 05:58:49,221][valid][INFO] - {"epoch": 94, "valid_loss": "4.579", "valid_ppl": "23.9", "valid_wps": "265484", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "102554", "valid_best_loss": "4.579"}
[2023-03-29 05:58:49,223][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 94 @ 102554 updates
[2023-03-29 05:58:49,224][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 05:58:49,462][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 05:58:49,610][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 94 @ 102554 updates, score 4.579) (writing took 0.3876913200074341 seconds)
[2023-03-29 05:58:49,611][fairseq_cli.train][INFO] - end of epoch 94 (average epoch stats below)
[2023-03-29 05:58:49,611][train][INFO] - {"epoch": 94, "train_loss": "4.793", "train_ppl": "27.73", "train_wps": "101739", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "102554", "train_lr": "0.000136628", "train_gnorm": "0.712", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "113669"}
[2023-03-29 05:58:49,613][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 05:58:49,644][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 05:58:49,646][fairseq.trainer][INFO] - begin training epoch 95
[2023-03-29 05:58:49,647][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 05:59:38,491][train_inner][INFO] - {"epoch": 95, "update": 94.042, "loss": "4.8", "ppl": "27.85", "wps": "101019", "ups": "0.94", "wpb": "107066", "bsz": "255.8", "num_updates": "102600", "lr": "0.000136348", "gnorm": "0.712", "train_wall": "165", "gb_free": "7.5", "wall": "113718"}
[2023-03-29 06:03:09,260][train_inner][INFO] - {"epoch": 95, "update": 94.225, "loss": "4.77", "ppl": "27.29", "wps": "101859", "ups": "0.95", "wpb": "107344", "bsz": "256", "num_updates": "102800", "lr": "0.00013513", "gnorm": "0.713", "train_wall": "166", "gb_free": "7.5", "wall": "113929"}
[2023-03-29 06:06:39,558][train_inner][INFO] - {"epoch": 95, "update": 94.409, "loss": "4.783", "ppl": "27.54", "wps": "101817", "ups": "0.95", "wpb": "107059", "bsz": "256", "num_updates": "103000", "lr": "0.000133913", "gnorm": "0.715", "train_wall": "165", "gb_free": "7.5", "wall": "114139"}
[2023-03-29 06:10:09,854][train_inner][INFO] - {"epoch": 95, "update": 94.592, "loss": "4.794", "ppl": "27.74", "wps": "101909", "ups": "0.95", "wpb": "107156", "bsz": "256", "num_updates": "103200", "lr": "0.000132696", "gnorm": "0.716", "train_wall": "165", "gb_free": "7.5", "wall": "114350"}
[2023-03-29 06:13:40,289][train_inner][INFO] - {"epoch": 95, "update": 94.775, "loss": "4.798", "ppl": "27.83", "wps": "101868", "ups": "0.95", "wpb": "107183", "bsz": "256", "num_updates": "103400", "lr": "0.000131478", "gnorm": "0.714", "train_wall": "165", "gb_free": "7.5", "wall": "114560"}
[2023-03-29 06:17:11,065][train_inner][INFO] - {"epoch": 95, "update": 94.959, "loss": "4.812", "ppl": "28.08", "wps": "101935", "ups": "0.95", "wpb": "107427", "bsz": "256", "num_updates": "103600", "lr": "0.000130261", "gnorm": "0.713", "train_wall": "166", "gb_free": "7.5", "wall": "114771"}
[2023-03-29 06:17:58,125][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 06:17:58,126][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 06:17:58,998][valid][INFO] - {"epoch": 95, "valid_loss": "4.576", "valid_ppl": "23.85", "valid_wps": "285754", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "103645", "valid_best_loss": "4.576"}
[2023-03-29 06:17:58,999][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 95 @ 103645 updates
[2023-03-29 06:17:59,000][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 06:17:59,379][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 06:17:59,593][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 95 @ 103645 updates, score 4.576) (writing took 0.5933910589956213 seconds)
[2023-03-29 06:17:59,593][fairseq_cli.train][INFO] - end of epoch 95 (average epoch stats below)
[2023-03-29 06:17:59,594][train][INFO] - {"epoch": 95, "train_loss": "4.791", "train_ppl": "27.68", "train_wps": "101708", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "103645", "train_lr": "0.000129987", "train_gnorm": "0.714", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "114819"}
[2023-03-29 06:17:59,595][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 06:17:59,626][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 06:17:59,628][fairseq.trainer][INFO] - begin training epoch 96
[2023-03-29 06:17:59,628][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 06:20:42,735][train_inner][INFO] - {"epoch": 96, "update": 95.142, "loss": "4.773", "ppl": "27.34", "wps": "100977", "ups": "0.94", "wpb": "106869", "bsz": "255.8", "num_updates": "103800", "lr": "0.000129043", "gnorm": "0.717", "train_wall": "165", "gb_free": "7.5", "wall": "114983"}
[2023-03-29 06:24:13,419][train_inner][INFO] - {"epoch": 96, "update": 95.325, "loss": "4.777", "ppl": "27.42", "wps": "102004", "ups": "0.95", "wpb": "107453", "bsz": "256", "num_updates": "104000", "lr": "0.000127826", "gnorm": "0.717", "train_wall": "166", "gb_free": "7.5", "wall": "115193"}
[2023-03-29 06:27:43,518][train_inner][INFO] - {"epoch": 96, "update": 95.509, "loss": "4.789", "ppl": "27.65", "wps": "101845", "ups": "0.95", "wpb": "106987", "bsz": "256", "num_updates": "104200", "lr": "0.000126609", "gnorm": "0.718", "train_wall": "165", "gb_free": "7.5", "wall": "115403"}
[2023-03-29 06:31:14,185][train_inner][INFO] - {"epoch": 96, "update": 95.692, "loss": "4.79", "ppl": "27.67", "wps": "101850", "ups": "0.95", "wpb": "107282", "bsz": "256", "num_updates": "104400", "lr": "0.000125391", "gnorm": "0.717", "train_wall": "166", "gb_free": "7.5", "wall": "115614"}
[2023-03-29 06:34:44,576][train_inner][INFO] - {"epoch": 96, "update": 95.875, "loss": "4.798", "ppl": "27.82", "wps": "101919", "ups": "0.95", "wpb": "107214", "bsz": "256", "num_updates": "104600", "lr": "0.000124174", "gnorm": "0.718", "train_wall": "165", "gb_free": "7.5", "wall": "115824"}
[2023-03-29 06:37:07,775][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 06:37:07,776][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 06:37:08,709][valid][INFO] - {"epoch": 96, "valid_loss": "4.576", "valid_ppl": "23.86", "valid_wps": "267338", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "104736", "valid_best_loss": "4.576"}
[2023-03-29 06:37:08,710][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 96 @ 104736 updates
[2023-03-29 06:37:08,711][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 06:37:09,101][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 06:37:09,386][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 96 @ 104736 updates, score 4.576) (writing took 0.6764379189989995 seconds)
[2023-03-29 06:37:09,386][fairseq_cli.train][INFO] - end of epoch 96 (average epoch stats below)
[2023-03-29 06:37:09,387][train][INFO] - {"epoch": 96, "train_loss": "4.787", "train_ppl": "27.61", "train_wps": "101724", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "104736", "train_lr": "0.000123346", "train_gnorm": "0.718", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "115969"}
[2023-03-29 06:37:09,389][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 06:37:09,419][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 06:37:09,422][fairseq.trainer][INFO] - begin training epoch 97
[2023-03-29 06:37:09,422][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 06:38:17,055][train_inner][INFO] - {"epoch": 97, "update": 96.059, "loss": "4.791", "ppl": "27.69", "wps": "100892", "ups": "0.94", "wpb": "107187", "bsz": "255.8", "num_updates": "104800", "lr": "0.000122957", "gnorm": "0.719", "train_wall": "165", "gb_free": "7.5", "wall": "116037"}
[2023-03-29 06:41:47,609][train_inner][INFO] - {"epoch": 97, "update": 96.242, "loss": "4.763", "ppl": "27.16", "wps": "101848", "ups": "0.95", "wpb": "107223", "bsz": "256", "num_updates": "105000", "lr": "0.000121739", "gnorm": "0.721", "train_wall": "165", "gb_free": "7.5", "wall": "116247"}
[2023-03-29 06:45:18,013][train_inner][INFO] - {"epoch": 97, "update": 96.425, "loss": "4.778", "ppl": "27.44", "wps": "101920", "ups": "0.95", "wpb": "107222", "bsz": "256", "num_updates": "105200", "lr": "0.000120522", "gnorm": "0.72", "train_wall": "165", "gb_free": "7.5", "wall": "116458"}
[2023-03-29 06:48:48,605][train_inner][INFO] - {"epoch": 97, "update": 96.609, "loss": "4.792", "ppl": "27.7", "wps": "101887", "ups": "0.95", "wpb": "107283", "bsz": "256", "num_updates": "105400", "lr": "0.000119304", "gnorm": "0.721", "train_wall": "166", "gb_free": "7.5", "wall": "116668"}
[2023-03-29 06:52:18,969][train_inner][INFO] - {"epoch": 97, "update": 96.792, "loss": "4.797", "ppl": "27.8", "wps": "101848", "ups": "0.95", "wpb": "107125", "bsz": "256", "num_updates": "105600", "lr": "0.000118087", "gnorm": "0.721", "train_wall": "165", "gb_free": "7.5", "wall": "116879"}
[2023-03-29 06:55:49,587][train_inner][INFO] - {"epoch": 97, "update": 96.975, "loss": "4.798", "ppl": "27.82", "wps": "101874", "ups": "0.95", "wpb": "107282", "bsz": "256", "num_updates": "105800", "lr": "0.00011687", "gnorm": "0.721", "train_wall": "165", "gb_free": "7.5", "wall": "117089"}
[2023-03-29 06:56:17,966][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 06:56:17,967][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 06:56:18,836][valid][INFO] - {"epoch": 97, "valid_loss": "4.576", "valid_ppl": "23.85", "valid_wps": "287582", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "105827", "valid_best_loss": "4.576"}
[2023-03-29 06:56:18,837][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 97 @ 105827 updates
[2023-03-29 06:56:18,837][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 06:56:19,116][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 06:56:19,268][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 97 @ 105827 updates, score 4.576) (writing took 0.43111941299866885 seconds)
[2023-03-29 06:56:19,268][fairseq_cli.train][INFO] - end of epoch 97 (average epoch stats below)
[2023-03-29 06:56:19,268][train][INFO] - {"epoch": 97, "train_loss": "4.784", "train_ppl": "27.56", "train_wps": "101717", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "105827", "train_lr": "0.000116705", "train_gnorm": "0.721", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "117119"}
[2023-03-29 06:56:19,270][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 06:56:19,300][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 06:56:19,303][fairseq.trainer][INFO] - begin training epoch 98
[2023-03-29 06:56:19,303][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 06:59:21,738][train_inner][INFO] - {"epoch": 98, "update": 97.159, "loss": "4.757", "ppl": "27.03", "wps": "101054", "ups": "0.94", "wpb": "107193", "bsz": "255.8", "num_updates": "106000", "lr": "0.000115652", "gnorm": "0.722", "train_wall": "166", "gb_free": "7.5", "wall": "117302"}
[2023-03-29 07:02:52,150][train_inner][INFO] - {"epoch": 98, "update": 97.342, "loss": "4.768", "ppl": "27.24", "wps": "101884", "ups": "0.95", "wpb": "107188", "bsz": "256", "num_updates": "106200", "lr": "0.000114435", "gnorm": "0.724", "train_wall": "165", "gb_free": "7.5", "wall": "117512"}
[2023-03-29 07:06:22,709][train_inner][INFO] - {"epoch": 98, "update": 97.525, "loss": "4.785", "ppl": "27.57", "wps": "101922", "ups": "0.95", "wpb": "107302", "bsz": "256", "num_updates": "106400", "lr": "0.000113217", "gnorm": "0.725", "train_wall": "166", "gb_free": "7.5", "wall": "117723"}
[2023-03-29 07:09:53,266][train_inner][INFO] - {"epoch": 98, "update": 97.709, "loss": "4.79", "ppl": "27.66", "wps": "101854", "ups": "0.95", "wpb": "107230", "bsz": "256", "num_updates": "106600", "lr": "0.000112", "gnorm": "0.725", "train_wall": "165", "gb_free": "7.5", "wall": "117933"}
[2023-03-29 07:13:23,502][train_inner][INFO] - {"epoch": 98, "update": 97.892, "loss": "4.803", "ppl": "27.91", "wps": "101858", "ups": "0.95", "wpb": "107071", "bsz": "256", "num_updates": "106800", "lr": "0.000110783", "gnorm": "0.723", "train_wall": "165", "gb_free": "7.5", "wall": "118143"}
[2023-03-29 07:15:27,599][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 07:15:27,600][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 07:15:28,527][valid][INFO] - {"epoch": 98, "valid_loss": "4.57", "valid_ppl": "23.75", "valid_wps": "271288", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "106918", "valid_best_loss": "4.57"}
[2023-03-29 07:15:28,528][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 98 @ 106918 updates
[2023-03-29 07:15:28,529][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 07:15:28,884][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 07:15:29,088][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 98 @ 106918 updates, score 4.57) (writing took 0.5596982309943996 seconds)
[2023-03-29 07:15:29,088][fairseq_cli.train][INFO] - end of epoch 98 (average epoch stats below)
[2023-03-29 07:15:29,088][train][INFO] - {"epoch": 98, "train_loss": "4.781", "train_ppl": "27.5", "train_wps": "101722", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "106918", "train_lr": "0.000110064", "train_gnorm": "0.724", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "118269"}
[2023-03-29 07:15:29,090][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 07:15:29,120][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 07:15:29,122][fairseq.trainer][INFO] - begin training epoch 99
[2023-03-29 07:15:29,123][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 07:16:55,812][train_inner][INFO] - {"epoch": 99, "update": 98.075, "loss": "4.782", "ppl": "27.51", "wps": "101062", "ups": "0.94", "wpb": "107282", "bsz": "255.8", "num_updates": "107000", "lr": "0.000109565", "gnorm": "0.725", "train_wall": "166", "gb_free": "7.5", "wall": "118356"}
[2023-03-29 07:20:26,714][train_inner][INFO] - {"epoch": 99, "update": 98.258, "loss": "4.757", "ppl": "27.04", "wps": "101846", "ups": "0.95", "wpb": "107398", "bsz": "256", "num_updates": "107200", "lr": "0.000108348", "gnorm": "0.725", "train_wall": "166", "gb_free": "7.5", "wall": "118567"}
[2023-03-29 07:23:57,101][train_inner][INFO] - {"epoch": 99, "update": 98.442, "loss": "4.77", "ppl": "27.28", "wps": "101853", "ups": "0.95", "wpb": "107142", "bsz": "256", "num_updates": "107400", "lr": "0.00010713", "gnorm": "0.727", "train_wall": "165", "gb_free": "7.5", "wall": "118777"}
[2023-03-29 07:27:27,618][train_inner][INFO] - {"epoch": 99, "update": 98.625, "loss": "4.781", "ppl": "27.48", "wps": "101854", "ups": "0.95", "wpb": "107209", "bsz": "256", "num_updates": "107600", "lr": "0.000105913", "gnorm": "0.726", "train_wall": "165", "gb_free": "7.5", "wall": "118987"}
[2023-03-29 07:30:57,986][train_inner][INFO] - {"epoch": 99, "update": 98.808, "loss": "4.788", "ppl": "27.63", "wps": "101896", "ups": "0.95", "wpb": "107177", "bsz": "256", "num_updates": "107800", "lr": "0.000104696", "gnorm": "0.727", "train_wall": "165", "gb_free": "7.5", "wall": "119198"}
[2023-03-29 07:34:28,267][train_inner][INFO] - {"epoch": 99, "update": 98.992, "loss": "4.798", "ppl": "27.82", "wps": "101854", "ups": "0.95", "wpb": "107090", "bsz": "256", "num_updates": "108000", "lr": "0.000103478", "gnorm": "0.728", "train_wall": "165", "gb_free": "7.5", "wall": "119408"}
[2023-03-29 07:34:37,683][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 07:34:37,684][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 07:34:38,561][valid][INFO] - {"epoch": 99, "valid_loss": "4.574", "valid_ppl": "23.82", "valid_wps": "284751", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "108009", "valid_best_loss": "4.57"}
[2023-03-29 07:34:38,564][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 99 @ 108009 updates
[2023-03-29 07:34:38,566][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 07:34:38,996][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 07:34:39,002][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 99 @ 108009 updates, score 4.574) (writing took 0.4386477879888844 seconds)
[2023-03-29 07:34:39,003][fairseq_cli.train][INFO] - end of epoch 99 (average epoch stats below)
[2023-03-29 07:34:39,003][train][INFO] - {"epoch": 99, "train_loss": "4.777", "train_ppl": "27.42", "train_wps": "101714", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "108009", "train_lr": "0.000103423", "train_gnorm": "0.727", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "119419"}
[2023-03-29 07:34:39,005][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 07:34:39,035][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 07:34:39,037][fairseq.trainer][INFO] - begin training epoch 100
[2023-03-29 07:34:39,037][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 07:38:00,365][train_inner][INFO] - {"epoch": 100, "update": 99.175, "loss": "4.749", "ppl": "26.88", "wps": "101119", "ups": "0.94", "wpb": "107236", "bsz": "255.8", "num_updates": "108200", "lr": "0.000102261", "gnorm": "0.728", "train_wall": "166", "gb_free": "7.5", "wall": "119620"}
[2023-03-29 07:41:30,544][train_inner][INFO] - {"epoch": 100, "update": 99.358, "loss": "4.764", "ppl": "27.16", "wps": "101817", "ups": "0.95", "wpb": "106999", "bsz": "256", "num_updates": "108400", "lr": "0.000101043", "gnorm": "0.73", "train_wall": "165", "gb_free": "7.5", "wall": "119830"}
[2023-03-29 07:45:01,110][train_inner][INFO] - {"epoch": 100, "update": 99.542, "loss": "4.773", "ppl": "27.35", "wps": "101872", "ups": "0.95", "wpb": "107251", "bsz": "256", "num_updates": "108600", "lr": "9.98261e-05", "gnorm": "0.73", "train_wall": "165", "gb_free": "7.5", "wall": "120041"}
[2023-03-29 07:48:31,683][train_inner][INFO] - {"epoch": 100, "update": 99.725, "loss": "4.783", "ppl": "27.53", "wps": "101898", "ups": "0.95", "wpb": "107285", "bsz": "256", "num_updates": "108800", "lr": "9.86087e-05", "gnorm": "0.731", "train_wall": "165", "gb_free": "7.5", "wall": "120252"}
[2023-03-29 07:52:02,334][train_inner][INFO] - {"epoch": 100, "update": 99.908, "loss": "4.796", "ppl": "27.78", "wps": "101855", "ups": "0.95", "wpb": "107279", "bsz": "256", "num_updates": "109000", "lr": "9.73913e-05", "gnorm": "0.729", "train_wall": "165", "gb_free": "7.5", "wall": "120462"}
[2023-03-29 07:53:47,356][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 07:53:47,357][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 07:53:48,231][valid][INFO] - {"epoch": 100, "valid_loss": "4.571", "valid_ppl": "23.76", "valid_wps": "285606", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "109100", "valid_best_loss": "4.57"}
[2023-03-29 07:53:48,232][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 100 @ 109100 updates
[2023-03-29 07:53:48,233][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 07:53:48,576][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 07:53:48,583][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 100 @ 109100 updates, score 4.571) (writing took 0.3509639169787988 seconds)
[2023-03-29 07:53:48,583][fairseq_cli.train][INFO] - end of epoch 100 (average epoch stats below)
[2023-03-29 07:53:48,584][train][INFO] - {"epoch": 100, "train_loss": "4.775", "train_ppl": "27.38", "train_wps": "101743", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "109100", "train_lr": "9.67826e-05", "train_gnorm": "0.73", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "120568"}
[2023-03-29 07:53:48,585][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 07:53:48,615][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 07:53:48,617][fairseq.trainer][INFO] - begin training epoch 101
[2023-03-29 07:53:48,617][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 07:55:34,531][train_inner][INFO] - {"epoch": 101, "update": 100.092, "loss": "4.773", "ppl": "27.35", "wps": "101185", "ups": "0.94", "wpb": "107356", "bsz": "255.8", "num_updates": "109200", "lr": "9.61739e-05", "gnorm": "0.73", "train_wall": "166", "gb_free": "7.5", "wall": "120674"}
[2023-03-29 07:59:04,754][train_inner][INFO] - {"epoch": 101, "update": 100.275, "loss": "4.754", "ppl": "26.99", "wps": "101794", "ups": "0.95", "wpb": "106997", "bsz": "256", "num_updates": "109400", "lr": "9.49565e-05", "gnorm": "0.732", "train_wall": "165", "gb_free": "7.5", "wall": "120885"}
[2023-03-29 08:02:35,006][train_inner][INFO] - {"epoch": 101, "update": 100.458, "loss": "4.769", "ppl": "27.26", "wps": "101813", "ups": "0.95", "wpb": "107031", "bsz": "256", "num_updates": "109600", "lr": "9.37391e-05", "gnorm": "0.731", "train_wall": "165", "gb_free": "7.5", "wall": "121095"}
[2023-03-29 08:06:05,900][train_inner][INFO] - {"epoch": 101, "update": 100.642, "loss": "4.777", "ppl": "27.43", "wps": "101894", "ups": "0.95", "wpb": "107444", "bsz": "256", "num_updates": "109800", "lr": "9.25217e-05", "gnorm": "0.732", "train_wall": "166", "gb_free": "7.5", "wall": "121306"}
[2023-03-29 08:09:36,139][train_inner][INFO] - {"epoch": 101, "update": 100.825, "loss": "4.777", "ppl": "27.41", "wps": "101731", "ups": "0.95", "wpb": "106940", "bsz": "256", "num_updates": "110000", "lr": "9.13043e-05", "gnorm": "0.732", "train_wall": "165", "gb_free": "7.5", "wall": "121516"}
[2023-03-29 08:12:57,272][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 08:12:57,273][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 08:12:58,200][valid][INFO] - {"epoch": 101, "valid_loss": "4.57", "valid_ppl": "23.76", "valid_wps": "269117", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "110191", "valid_best_loss": "4.57"}
[2023-03-29 08:12:58,201][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 101 @ 110191 updates
[2023-03-29 08:12:58,202][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 08:12:58,449][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 08:12:58,603][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 101 @ 110191 updates, score 4.57) (writing took 0.40202574199065566 seconds)
[2023-03-29 08:12:58,603][fairseq_cli.train][INFO] - end of epoch 101 (average epoch stats below)
[2023-03-29 08:12:58,604][train][INFO] - {"epoch": 101, "train_loss": "4.772", "train_ppl": "27.32", "train_wps": "101704", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "110191", "train_lr": "9.01417e-05", "train_gnorm": "0.731", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "121718"}
[2023-03-29 08:12:58,606][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 08:12:58,635][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 08:12:58,637][fairseq.trainer][INFO] - begin training epoch 102
[2023-03-29 08:12:58,638][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 08:13:08,385][train_inner][INFO] - {"epoch": 102, "update": 101.008, "loss": "4.79", "ppl": "27.67", "wps": "101153", "ups": "0.94", "wpb": "107346", "bsz": "255.8", "num_updates": "110200", "lr": "9.0087e-05", "gnorm": "0.731", "train_wall": "166", "gb_free": "7.5", "wall": "121728"}
[2023-03-29 08:16:39,205][train_inner][INFO] - {"epoch": 102, "update": 101.192, "loss": "4.747", "ppl": "26.86", "wps": "101991", "ups": "0.95", "wpb": "107509", "bsz": "256", "num_updates": "110400", "lr": "8.88696e-05", "gnorm": "0.732", "train_wall": "166", "gb_free": "7.5", "wall": "121939"}
[2023-03-29 08:20:09,186][train_inner][INFO] - {"epoch": 102, "update": 101.375, "loss": "4.755", "ppl": "27", "wps": "101813", "ups": "0.95", "wpb": "106894", "bsz": "256", "num_updates": "110600", "lr": "8.76522e-05", "gnorm": "0.735", "train_wall": "165", "gb_free": "7.5", "wall": "122149"}
[2023-03-29 08:23:39,559][train_inner][INFO] - {"epoch": 102, "update": 101.558, "loss": "4.77", "ppl": "27.29", "wps": "101837", "ups": "0.95", "wpb": "107118", "bsz": "256", "num_updates": "110800", "lr": "8.64348e-05", "gnorm": "0.734", "train_wall": "165", "gb_free": "7.5", "wall": "122359"}
[2023-03-29 08:27:10,249][train_inner][INFO] - {"epoch": 102, "update": 101.742, "loss": "4.775", "ppl": "27.38", "wps": "101874", "ups": "0.95", "wpb": "107319", "bsz": "256", "num_updates": "111000", "lr": "8.52174e-05", "gnorm": "0.733", "train_wall": "166", "gb_free": "7.5", "wall": "122570"}
[2023-03-29 08:30:40,670][train_inner][INFO] - {"epoch": 102, "update": 101.925, "loss": "4.788", "ppl": "27.63", "wps": "101837", "ups": "0.95", "wpb": "107144", "bsz": "256", "num_updates": "111200", "lr": "8.4e-05", "gnorm": "0.735", "train_wall": "165", "gb_free": "7.5", "wall": "122781"}
[2023-03-29 08:32:07,073][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 08:32:07,073][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 08:32:07,946][valid][INFO] - {"epoch": 102, "valid_loss": "4.572", "valid_ppl": "23.78", "valid_wps": "285797", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "111282", "valid_best_loss": "4.57"}
[2023-03-29 08:32:07,947][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 102 @ 111282 updates
[2023-03-29 08:32:07,948][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 08:32:08,419][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_last.pt
[2023-03-29 08:32:08,425][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 102 @ 111282 updates, score 4.572) (writing took 0.4779974730045069 seconds)
[2023-03-29 08:32:08,426][fairseq_cli.train][INFO] - end of epoch 102 (average epoch stats below)
[2023-03-29 08:32:08,426][train][INFO] - {"epoch": 102, "train_loss": "4.768", "train_ppl": "27.24", "train_wps": "101722", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "111282", "train_lr": "8.35009e-05", "train_gnorm": "0.734", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "122868"}
[2023-03-29 08:32:08,428][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 08:32:08,456][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 08:32:08,458][fairseq.trainer][INFO] - begin training epoch 103
[2023-03-29 08:32:08,459][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 08:34:13,228][train_inner][INFO] - {"epoch": 103, "update": 102.108, "loss": "4.759", "ppl": "27.07", "wps": "101131", "ups": "0.94", "wpb": "107480", "bsz": "255.8", "num_updates": "111400", "lr": "8.27826e-05", "gnorm": "0.733", "train_wall": "166", "gb_free": "7.5", "wall": "122993"}
[2023-03-29 08:37:43,558][train_inner][INFO] - {"epoch": 103, "update": 102.291, "loss": "4.75", "ppl": "26.91", "wps": "101839", "ups": "0.95", "wpb": "107099", "bsz": "256", "num_updates": "111600", "lr": "8.15652e-05", "gnorm": "0.737", "train_wall": "165", "gb_free": "7.5", "wall": "123203"}
[2023-03-29 08:41:14,074][train_inner][INFO] - {"epoch": 103, "update": 102.475, "loss": "4.763", "ppl": "27.16", "wps": "101879", "ups": "0.95", "wpb": "107236", "bsz": "256", "num_updates": "111800", "lr": "8.03478e-05", "gnorm": "0.737", "train_wall": "165", "gb_free": "7.5", "wall": "123414"}
[2023-03-29 08:44:47,385][train_inner][INFO] - {"epoch": 103, "update": 102.658, "loss": "4.77", "ppl": "27.29", "wps": "100764", "ups": "0.94", "wpb": "107471", "bsz": "256", "num_updates": "112000", "lr": "7.91304e-05", "gnorm": "0.735", "train_wall": "168", "gb_free": "7.5", "wall": "123627"}
[2023-03-29 08:48:18,808][train_inner][INFO] - {"epoch": 103, "update": 102.841, "loss": "4.778", "ppl": "27.44", "wps": "101382", "ups": "0.95", "wpb": "107172", "bsz": "256", "num_updates": "112200", "lr": "7.7913e-05", "gnorm": "0.737", "train_wall": "166", "gb_free": "7.5", "wall": "123839"}
[2023-03-29 08:51:20,371][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 08:51:20,372][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 08:51:21,305][valid][INFO] - {"epoch": 103, "valid_loss": "4.568", "valid_ppl": "23.72", "valid_wps": "268906", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "112373", "valid_best_loss": "4.568"}
[2023-03-29 08:51:21,306][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 103 @ 112373 updates
[2023-03-29 08:51:21,307][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 08:51:21,723][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 08:51:21,869][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 103 @ 112373 updates, score 4.568) (writing took 0.5628756700025406 seconds)
[2023-03-29 08:51:21,869][fairseq_cli.train][INFO] - end of epoch 103 (average epoch stats below)
[2023-03-29 08:51:21,870][train][INFO] - {"epoch": 103, "train_loss": "4.765", "train_ppl": "27.18", "train_wps": "101402", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "112373", "train_lr": "7.686e-05", "train_gnorm": "0.736", "train_train_wall": "905", "train_gb_free": "7.5", "train_wall": "124022"}
[2023-03-29 08:51:21,872][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 08:51:21,901][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 08:51:21,904][fairseq.trainer][INFO] - begin training epoch 104
[2023-03-29 08:51:21,904][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 08:51:50,501][train_inner][INFO] - {"epoch": 104, "update": 103.025, "loss": "4.77", "ppl": "27.29", "wps": "100904", "ups": "0.94", "wpb": "106803", "bsz": "255.8", "num_updates": "112400", "lr": "7.66957e-05", "gnorm": "0.737", "train_wall": "165", "gb_free": "7.5", "wall": "124050"}
[2023-03-29 08:55:20,865][train_inner][INFO] - {"epoch": 104, "update": 103.208, "loss": "4.747", "ppl": "26.85", "wps": "101848", "ups": "0.95", "wpb": "107126", "bsz": "256", "num_updates": "112600", "lr": "7.54783e-05", "gnorm": "0.739", "train_wall": "165", "gb_free": "7.5", "wall": "124261"}
[2023-03-29 08:58:51,128][train_inner][INFO] - {"epoch": 104, "update": 103.391, "loss": "4.751", "ppl": "26.93", "wps": "101856", "ups": "0.95", "wpb": "107082", "bsz": "256", "num_updates": "112800", "lr": "7.42609e-05", "gnorm": "0.738", "train_wall": "165", "gb_free": "7.5", "wall": "124471"}
[2023-03-29 09:02:21,963][train_inner][INFO] - {"epoch": 104, "update": 103.575, "loss": "4.76", "ppl": "27.1", "wps": "101978", "ups": "0.95", "wpb": "107503", "bsz": "256", "num_updates": "113000", "lr": "7.30435e-05", "gnorm": "0.738", "train_wall": "166", "gb_free": "7.5", "wall": "124682"}
[2023-03-29 09:05:52,582][train_inner][INFO] - {"epoch": 104, "update": 103.758, "loss": "4.769", "ppl": "27.27", "wps": "101933", "ups": "0.95", "wpb": "107345", "bsz": "256", "num_updates": "113200", "lr": "7.18261e-05", "gnorm": "0.737", "train_wall": "166", "gb_free": "7.5", "wall": "124892"}
[2023-03-29 09:09:23,070][train_inner][INFO] - {"epoch": 104, "update": 103.941, "loss": "4.781", "ppl": "27.49", "wps": "101760", "ups": "0.95", "wpb": "107096", "bsz": "256", "num_updates": "113400", "lr": "7.06087e-05", "gnorm": "0.739", "train_wall": "165", "gb_free": "7.5", "wall": "125103"}
[2023-03-29 09:10:30,383][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 09:10:30,383][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 09:10:31,268][valid][INFO] - {"epoch": 104, "valid_loss": "4.568", "valid_ppl": "23.72", "valid_wps": "283937", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "113464", "valid_best_loss": "4.568"}
[2023-03-29 09:10:31,269][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 104 @ 113464 updates
[2023-03-29 09:10:31,270][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 09:10:31,518][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 09:10:31,664][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 104 @ 113464 updates, score 4.568) (writing took 0.3950100090005435 seconds)
[2023-03-29 09:10:31,665][fairseq_cli.train][INFO] - end of epoch 104 (average epoch stats below)
[2023-03-29 09:10:31,665][train][INFO] - {"epoch": 104, "train_loss": "4.761", "train_ppl": "27.12", "train_wps": "101724", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "113464", "train_lr": "7.02191e-05", "train_gnorm": "0.738", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "125172"}
[2023-03-29 09:10:31,667][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 09:10:31,698][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 09:10:31,700][fairseq.trainer][INFO] - begin training epoch 105
[2023-03-29 09:10:31,701][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 09:12:55,026][train_inner][INFO] - {"epoch": 105, "update": 104.125, "loss": "4.746", "ppl": "26.83", "wps": "101130", "ups": "0.94", "wpb": "107175", "bsz": "255.8", "num_updates": "113600", "lr": "6.93913e-05", "gnorm": "0.738", "train_wall": "165", "gb_free": "7.5", "wall": "125315"}
[2023-03-29 09:16:25,454][train_inner][INFO] - {"epoch": 105, "update": 104.308, "loss": "4.75", "ppl": "26.9", "wps": "101947", "ups": "0.95", "wpb": "107263", "bsz": "256", "num_updates": "113800", "lr": "6.81739e-05", "gnorm": "0.739", "train_wall": "165", "gb_free": "7.5", "wall": "125525"}
[2023-03-29 09:19:56,130][train_inner][INFO] - {"epoch": 105, "update": 104.491, "loss": "4.751", "ppl": "26.93", "wps": "101919", "ups": "0.95", "wpb": "107359", "bsz": "256", "num_updates": "114000", "lr": "6.69565e-05", "gnorm": "0.74", "train_wall": "166", "gb_free": "7.5", "wall": "125736"}
[2023-03-29 09:23:26,202][train_inner][INFO] - {"epoch": 105, "update": 104.675, "loss": "4.765", "ppl": "27.19", "wps": "101823", "ups": "0.95", "wpb": "106951", "bsz": "256", "num_updates": "114200", "lr": "6.57391e-05", "gnorm": "0.74", "train_wall": "165", "gb_free": "7.5", "wall": "125946"}
[2023-03-29 09:26:56,818][train_inner][INFO] - {"epoch": 105, "update": 104.858, "loss": "4.769", "ppl": "27.26", "wps": "101880", "ups": "0.95", "wpb": "107287", "bsz": "256", "num_updates": "114400", "lr": "6.45217e-05", "gnorm": "0.741", "train_wall": "166", "gb_free": "7.5", "wall": "126157"}
[2023-03-29 09:29:39,807][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 09:29:39,808][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 09:29:40,745][valid][INFO] - {"epoch": 105, "valid_loss": "4.565", "valid_ppl": "23.67", "valid_wps": "266514", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "114555", "valid_best_loss": "4.565"}
[2023-03-29 09:29:40,746][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 105 @ 114555 updates
[2023-03-29 09:29:40,747][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 09:29:41,031][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 09:29:41,227][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 105 @ 114555 updates, score 4.565) (writing took 0.48037143200053833 seconds)
[2023-03-29 09:29:41,227][fairseq_cli.train][INFO] - end of epoch 105 (average epoch stats below)
[2023-03-29 09:29:41,227][train][INFO] - {"epoch": 105, "train_loss": "4.758", "train_ppl": "27.06", "train_wps": "101745", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "114555", "train_lr": "6.35783e-05", "train_gnorm": "0.74", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "126321"}
[2023-03-29 09:29:41,229][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 09:29:41,260][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 09:29:41,262][fairseq.trainer][INFO] - begin training epoch 106
[2023-03-29 09:29:41,263][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 09:30:29,053][train_inner][INFO] - {"epoch": 106, "update": 105.041, "loss": "4.764", "ppl": "27.17", "wps": "101036", "ups": "0.94", "wpb": "107216", "bsz": "255.8", "num_updates": "114600", "lr": "6.33043e-05", "gnorm": "0.74", "train_wall": "166", "gb_free": "7.5", "wall": "126369"}
[2023-03-29 09:33:59,502][train_inner][INFO] - {"epoch": 106, "update": 105.225, "loss": "4.738", "ppl": "26.68", "wps": "101865", "ups": "0.95", "wpb": "107187", "bsz": "256", "num_updates": "114800", "lr": "6.2087e-05", "gnorm": "0.741", "train_wall": "165", "gb_free": "7.5", "wall": "126579"}
[2023-03-29 09:37:30,510][train_inner][INFO] - {"epoch": 106, "update": 105.408, "loss": "4.747", "ppl": "26.86", "wps": "101912", "ups": "0.95", "wpb": "107522", "bsz": "256", "num_updates": "115000", "lr": "6.08696e-05", "gnorm": "0.74", "train_wall": "166", "gb_free": "7.5", "wall": "126790"}
[2023-03-29 09:41:00,683][train_inner][INFO] - {"epoch": 106, "update": 105.591, "loss": "4.755", "ppl": "27", "wps": "101745", "ups": "0.95", "wpb": "106920", "bsz": "256", "num_updates": "115200", "lr": "5.96522e-05", "gnorm": "0.742", "train_wall": "165", "gb_free": "7.5", "wall": "127001"}
[2023-03-29 09:44:31,170][train_inner][INFO] - {"epoch": 106, "update": 105.775, "loss": "4.761", "ppl": "27.11", "wps": "101910", "ups": "0.95", "wpb": "107253", "bsz": "256", "num_updates": "115400", "lr": "5.84348e-05", "gnorm": "0.742", "train_wall": "165", "gb_free": "7.5", "wall": "127211"}
[2023-03-29 09:48:01,453][train_inner][INFO] - {"epoch": 106, "update": 105.958, "loss": "4.767", "ppl": "27.23", "wps": "101832", "ups": "0.95", "wpb": "107067", "bsz": "256", "num_updates": "115600", "lr": "5.72174e-05", "gnorm": "0.743", "train_wall": "165", "gb_free": "7.5", "wall": "127421"}
[2023-03-29 09:48:49,842][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 09:48:49,843][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 09:48:50,718][valid][INFO] - {"epoch": 106, "valid_loss": "4.564", "valid_ppl": "23.66", "valid_wps": "285563", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "115646", "valid_best_loss": "4.564"}
[2023-03-29 09:48:50,719][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 106 @ 115646 updates
[2023-03-29 09:48:50,720][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 09:48:51,151][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 09:48:51,414][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 106 @ 115646 updates, score 4.564) (writing took 0.6954619880125392 seconds)
[2023-03-29 09:48:51,415][fairseq_cli.train][INFO] - end of epoch 106 (average epoch stats below)
[2023-03-29 09:48:51,415][train][INFO] - {"epoch": 106, "train_loss": "4.754", "train_ppl": "26.97", "train_wps": "101690", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "115646", "train_lr": "5.69374e-05", "train_gnorm": "0.742", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "127471"}
[2023-03-29 09:48:51,417][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 09:48:51,447][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 09:48:51,449][fairseq.trainer][INFO] - begin training epoch 107
[2023-03-29 09:48:51,450][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 09:51:33,830][train_inner][INFO] - {"epoch": 107, "update": 106.141, "loss": "4.737", "ppl": "26.67", "wps": "101006", "ups": "0.94", "wpb": "107257", "bsz": "255.8", "num_updates": "115800", "lr": "5.6e-05", "gnorm": "0.743", "train_wall": "166", "gb_free": "7.5", "wall": "127634"}
[2023-03-29 09:55:04,114][train_inner][INFO] - {"epoch": 107, "update": 106.324, "loss": "4.745", "ppl": "26.82", "wps": "101866", "ups": "0.95", "wpb": "107104", "bsz": "256", "num_updates": "116000", "lr": "5.47826e-05", "gnorm": "0.744", "train_wall": "165", "gb_free": "7.5", "wall": "127844"}
[2023-03-29 09:58:34,406][train_inner][INFO] - {"epoch": 107, "update": 106.508, "loss": "4.748", "ppl": "26.87", "wps": "101912", "ups": "0.95", "wpb": "107157", "bsz": "256", "num_updates": "116200", "lr": "5.35652e-05", "gnorm": "0.744", "train_wall": "165", "gb_free": "7.5", "wall": "128054"}
[2023-03-29 10:02:04,922][train_inner][INFO] - {"epoch": 107, "update": 106.691, "loss": "4.757", "ppl": "27.04", "wps": "101850", "ups": "0.95", "wpb": "107205", "bsz": "256", "num_updates": "116400", "lr": "5.23478e-05", "gnorm": "0.744", "train_wall": "165", "gb_free": "7.5", "wall": "128265"}
[2023-03-29 10:05:35,548][train_inner][INFO] - {"epoch": 107, "update": 106.874, "loss": "4.763", "ppl": "27.15", "wps": "101858", "ups": "0.95", "wpb": "107270", "bsz": "256", "num_updates": "116600", "lr": "5.11304e-05", "gnorm": "0.743", "train_wall": "166", "gb_free": "7.5", "wall": "128475"}
[2023-03-29 10:07:59,722][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 10:07:59,723][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 10:08:00,633][valid][INFO] - {"epoch": 107, "valid_loss": "4.564", "valid_ppl": "23.65", "valid_wps": "274292", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "116737", "valid_best_loss": "4.564"}
[2023-03-29 10:08:00,634][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 107 @ 116737 updates
[2023-03-29 10:08:00,635][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 10:08:01,105][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 10:08:01,479][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 107 @ 116737 updates, score 4.564) (writing took 0.8451315910206176 seconds)
[2023-03-29 10:08:01,479][fairseq_cli.train][INFO] - end of epoch 107 (average epoch stats below)
[2023-03-29 10:08:01,480][train][INFO] - {"epoch": 107, "train_loss": "4.751", "train_ppl": "26.92", "train_wps": "101700", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "116737", "train_lr": "5.02965e-05", "train_gnorm": "0.743", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "128621"}
[2023-03-29 10:08:01,481][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 10:08:01,513][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 10:08:01,515][fairseq.trainer][INFO] - begin training epoch 108
[2023-03-29 10:08:01,515][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 10:09:08,170][train_inner][INFO] - {"epoch": 108, "update": 107.058, "loss": "4.755", "ppl": "26.99", "wps": "100930", "ups": "0.94", "wpb": "107299", "bsz": "255.8", "num_updates": "116800", "lr": "4.9913e-05", "gnorm": "0.744", "train_wall": "166", "gb_free": "7.5", "wall": "128688"}
[2023-03-29 10:12:38,806][train_inner][INFO] - {"epoch": 108, "update": 107.241, "loss": "4.733", "ppl": "26.59", "wps": "101839", "ups": "0.95", "wpb": "107255", "bsz": "256", "num_updates": "117000", "lr": "4.86957e-05", "gnorm": "0.744", "train_wall": "166", "gb_free": "7.5", "wall": "128899"}
[2023-03-29 10:16:09,512][train_inner][INFO] - {"epoch": 108, "update": 107.424, "loss": "4.74", "ppl": "26.71", "wps": "101913", "ups": "0.95", "wpb": "107368", "bsz": "256", "num_updates": "117200", "lr": "4.74783e-05", "gnorm": "0.745", "train_wall": "166", "gb_free": "7.5", "wall": "129109"}
[2023-03-29 10:19:40,344][train_inner][INFO] - {"epoch": 108, "update": 107.608, "loss": "4.746", "ppl": "26.84", "wps": "101884", "ups": "0.95", "wpb": "107402", "bsz": "256", "num_updates": "117400", "lr": "4.62609e-05", "gnorm": "0.744", "train_wall": "166", "gb_free": "7.5", "wall": "129320"}
[2023-03-29 10:23:10,616][train_inner][INFO] - {"epoch": 108, "update": 107.791, "loss": "4.757", "ppl": "27.05", "wps": "101923", "ups": "0.95", "wpb": "107158", "bsz": "256", "num_updates": "117600", "lr": "4.50435e-05", "gnorm": "0.745", "train_wall": "165", "gb_free": "7.5", "wall": "129530"}
[2023-03-29 10:26:40,800][train_inner][INFO] - {"epoch": 108, "update": 107.974, "loss": "4.762", "ppl": "27.13", "wps": "101780", "ups": "0.95", "wpb": "106963", "bsz": "256", "num_updates": "117800", "lr": "4.38261e-05", "gnorm": "0.746", "train_wall": "165", "gb_free": "7.5", "wall": "129741"}
[2023-03-29 10:27:10,053][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 10:27:10,054][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 10:27:10,928][valid][INFO] - {"epoch": 108, "valid_loss": "4.563", "valid_ppl": "23.65", "valid_wps": "285605", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "117828", "valid_best_loss": "4.563"}
[2023-03-29 10:27:10,929][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 108 @ 117828 updates
[2023-03-29 10:27:10,930][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 10:27:11,370][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 10:27:11,660][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 108 @ 117828 updates, score 4.563) (writing took 0.7306582420133054 seconds)
[2023-03-29 10:27:11,660][fairseq_cli.train][INFO] - end of epoch 108 (average epoch stats below)
[2023-03-29 10:27:11,661][train][INFO] - {"epoch": 108, "train_loss": "4.747", "train_ppl": "26.85", "train_wps": "101690", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "117828", "train_lr": "4.36557e-05", "train_gnorm": "0.745", "train_train_wall": "902", "train_gb_free": "7.5", "train_wall": "129772"}
[2023-03-29 10:27:11,662][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 10:27:11,694][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 10:27:11,696][fairseq.trainer][INFO] - begin training epoch 109
[2023-03-29 10:27:11,696][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 10:30:12,581][train_inner][INFO] - {"epoch": 109, "update": 108.158, "loss": "4.733", "ppl": "26.6", "wps": "100824", "ups": "0.94", "wpb": "106762", "bsz": "255.8", "num_updates": "118000", "lr": "4.26087e-05", "gnorm": "0.748", "train_wall": "165", "gb_free": "7.5", "wall": "129952"}
[2023-03-29 10:33:43,162][train_inner][INFO] - {"epoch": 109, "update": 108.341, "loss": "4.743", "ppl": "26.78", "wps": "101890", "ups": "0.95", "wpb": "107280", "bsz": "256", "num_updates": "118200", "lr": "4.13913e-05", "gnorm": "0.746", "train_wall": "166", "gb_free": "7.5", "wall": "130163"}
[2023-03-29 10:37:13,899][train_inner][INFO] - {"epoch": 109, "update": 108.524, "loss": "4.741", "ppl": "26.73", "wps": "101948", "ups": "0.95", "wpb": "107421", "bsz": "256", "num_updates": "118400", "lr": "4.01739e-05", "gnorm": "0.746", "train_wall": "166", "gb_free": "7.5", "wall": "130374"}
[2023-03-29 10:40:44,319][train_inner][INFO] - {"epoch": 109, "update": 108.708, "loss": "4.747", "ppl": "26.86", "wps": "101909", "ups": "0.95", "wpb": "107218", "bsz": "256", "num_updates": "118600", "lr": "3.89565e-05", "gnorm": "0.747", "train_wall": "165", "gb_free": "7.5", "wall": "130584"}
[2023-03-29 10:44:15,874][train_inner][INFO] - {"epoch": 109, "update": 108.891, "loss": "4.749", "ppl": "26.89", "wps": "101435", "ups": "0.95", "wpb": "107296", "bsz": "256", "num_updates": "118800", "lr": "3.77391e-05", "gnorm": "0.746", "train_wall": "166", "gb_free": "7.5", "wall": "130796"}
[2023-03-29 10:46:22,299][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 10:46:22,300][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 10:46:23,241][valid][INFO] - {"epoch": 109, "valid_loss": "4.563", "valid_ppl": "23.63", "valid_wps": "265240", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "118919", "valid_best_loss": "4.563"}
[2023-03-29 10:46:23,243][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 109 @ 118919 updates
[2023-03-29 10:46:23,244][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 10:46:23,764][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 10:46:24,107][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 109 @ 118919 updates, score 4.563) (writing took 0.8640261240070686 seconds)
[2023-03-29 10:46:24,107][fairseq_cli.train][INFO] - end of epoch 109 (average epoch stats below)
[2023-03-29 10:46:24,107][train][INFO] - {"epoch": 109, "train_loss": "4.743", "train_ppl": "26.79", "train_wps": "101490", "train_ups": "0.95", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "118919", "train_lr": "3.70148e-05", "train_gnorm": "0.747", "train_train_wall": "904", "train_gb_free": "7.5", "train_wall": "130924"}
[2023-03-29 10:46:24,109][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 10:46:24,142][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 10:46:24,144][fairseq.trainer][INFO] - begin training epoch 110
[2023-03-29 10:46:24,144][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 10:47:50,727][train_inner][INFO] - {"epoch": 110, "update": 109.074, "loss": "4.737", "ppl": "26.67", "wps": "99844.9", "ups": "0.93", "wpb": "107260", "bsz": "255.8", "num_updates": "119000", "lr": "3.65217e-05", "gnorm": "0.745", "train_wall": "167", "gb_free": "7.5", "wall": "131011"}
[2023-03-29 10:51:22,335][train_inner][INFO] - {"epoch": 110, "update": 109.258, "loss": "4.732", "ppl": "26.57", "wps": "100956", "ups": "0.95", "wpb": "106815", "bsz": "256", "num_updates": "119200", "lr": "3.53043e-05", "gnorm": "0.748", "train_wall": "166", "gb_free": "7.5", "wall": "131222"}
[2023-03-29 10:54:52,727][train_inner][INFO] - {"epoch": 110, "update": 109.441, "loss": "4.731", "ppl": "26.57", "wps": "101875", "ups": "0.95", "wpb": "107168", "bsz": "256", "num_updates": "119400", "lr": "3.4087e-05", "gnorm": "0.747", "train_wall": "165", "gb_free": "7.5", "wall": "131433"}
[2023-03-29 10:58:25,002][train_inner][INFO] - {"epoch": 110, "update": 109.624, "loss": "4.745", "ppl": "26.81", "wps": "101043", "ups": "0.94", "wpb": "107244", "bsz": "256", "num_updates": "119600", "lr": "3.28696e-05", "gnorm": "0.747", "train_wall": "167", "gb_free": "7.5", "wall": "131645"}
[2023-03-29 11:02:14,970][train_inner][INFO] - {"epoch": 110, "update": 109.808, "loss": "4.753", "ppl": "26.97", "wps": "93485.6", "ups": "0.87", "wpb": "107493", "bsz": "256", "num_updates": "119800", "lr": "3.16522e-05", "gnorm": "0.748", "train_wall": "179", "gb_free": "7.5", "wall": "131875"}
[2023-03-29 11:05:52,585][train_inner][INFO] - {"epoch": 110, "update": 109.991, "loss": "4.751", "ppl": "26.92", "wps": "98491.4", "ups": "0.92", "wpb": "107166", "bsz": "256", "num_updates": "120000", "lr": "3.04348e-05", "gnorm": "0.748", "train_wall": "171", "gb_free": "7.5", "wall": "132092"}
[2023-03-29 11:06:03,852][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 11:06:03,853][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 11:06:04,818][valid][INFO] - {"epoch": 110, "valid_loss": "4.561", "valid_ppl": "23.61", "valid_wps": "258747", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "120010", "valid_best_loss": "4.561"}
[2023-03-29 11:06:04,819][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 110 @ 120010 updates
[2023-03-29 11:06:04,820][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 11:06:05,282][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 11:06:05,605][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 110 @ 120010 updates, score 4.561) (writing took 0.7857163129956461 seconds)
[2023-03-29 11:06:05,606][fairseq_cli.train][INFO] - end of epoch 110 (average epoch stats below)
[2023-03-29 11:06:05,607][train][INFO] - {"epoch": 110, "train_loss": "4.74", "train_ppl": "26.73", "train_wps": "98994.6", "train_ups": "0.92", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "120010", "train_lr": "3.03739e-05", "train_gnorm": "0.747", "train_train_wall": "925", "train_gb_free": "7.5", "train_wall": "132105"}
[2023-03-29 11:06:05,616][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 11:06:05,685][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 11:06:05,689][fairseq.trainer][INFO] - begin training epoch 111
[2023-03-29 11:06:05,690][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 11:09:34,232][train_inner][INFO] - {"epoch": 111, "update": 110.174, "loss": "4.725", "ppl": "26.45", "wps": "96997.4", "ups": "0.9", "wpb": "107496", "bsz": "255.8", "num_updates": "120200", "lr": "2.92174e-05", "gnorm": "0.746", "train_wall": "172", "gb_free": "7.5", "wall": "132314"}
[2023-03-29 11:13:15,567][train_inner][INFO] - {"epoch": 111, "update": 110.357, "loss": "4.737", "ppl": "26.66", "wps": "96683.6", "ups": "0.9", "wpb": "106997", "bsz": "256", "num_updates": "120400", "lr": "2.8e-05", "gnorm": "0.748", "train_wall": "173", "gb_free": "7.5", "wall": "132535"}
[2023-03-29 11:16:53,261][train_inner][INFO] - {"epoch": 111, "update": 110.541, "loss": "4.737", "ppl": "26.66", "wps": "98187.4", "ups": "0.92", "wpb": "106874", "bsz": "256", "num_updates": "120600", "lr": "2.67826e-05", "gnorm": "0.749", "train_wall": "170", "gb_free": "7.5", "wall": "132753"}
[2023-03-29 11:20:35,471][train_inner][INFO] - {"epoch": 111, "update": 110.724, "loss": "4.737", "ppl": "26.67", "wps": "96458", "ups": "0.9", "wpb": "107170", "bsz": "256", "num_updates": "120800", "lr": "2.55652e-05", "gnorm": "0.748", "train_wall": "174", "gb_free": "7.5", "wall": "132975"}
[2023-03-29 11:24:18,940][train_inner][INFO] - {"epoch": 111, "update": 110.907, "loss": "4.745", "ppl": "26.81", "wps": "96117.7", "ups": "0.9", "wpb": "107394", "bsz": "256", "num_updates": "121000", "lr": "2.43478e-05", "gnorm": "0.749", "train_wall": "174", "gb_free": "7.5", "wall": "133199"}
[2023-03-29 11:26:11,811][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 11:26:11,812][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 11:26:12,698][valid][INFO] - {"epoch": 111, "valid_loss": "4.561", "valid_ppl": "23.61", "valid_wps": "282087", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "121101", "valid_best_loss": "4.561"}
[2023-03-29 11:26:12,700][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 111 @ 121101 updates
[2023-03-29 11:26:12,701][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 11:26:13,253][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 11:26:13,666][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 111 @ 121101 updates, score 4.561) (writing took 0.9663953949930146 seconds)
[2023-03-29 11:26:13,667][fairseq_cli.train][INFO] - end of epoch 111 (average epoch stats below)
[2023-03-29 11:26:13,667][train][INFO] - {"epoch": 111, "train_loss": "4.737", "train_ppl": "26.67", "train_wps": "96818.1", "train_ups": "0.9", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "121101", "train_lr": "2.3733e-05", "train_gnorm": "0.748", "train_train_wall": "941", "train_gb_free": "7.5", "train_wall": "133314"}
[2023-03-29 11:26:13,669][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 11:26:13,702][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 11:26:13,704][fairseq.trainer][INFO] - begin training epoch 112
[2023-03-29 11:26:13,704][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 11:28:03,187][train_inner][INFO] - {"epoch": 112, "update": 111.091, "loss": "4.733", "ppl": "26.6", "wps": "95724.8", "ups": "0.89", "wpb": "107329", "bsz": "255.8", "num_updates": "121200", "lr": "2.31304e-05", "gnorm": "0.748", "train_wall": "172", "gb_free": "7.5", "wall": "133423"}
[2023-03-29 11:31:37,341][train_inner][INFO] - {"epoch": 112, "update": 111.274, "loss": "4.733", "ppl": "26.6", "wps": "99933.2", "ups": "0.93", "wpb": "107005", "bsz": "256", "num_updates": "121400", "lr": "2.1913e-05", "gnorm": "0.75", "train_wall": "168", "gb_free": "7.5", "wall": "133637"}
[2023-03-29 11:35:13,806][train_inner][INFO] - {"epoch": 112, "update": 111.457, "loss": "4.731", "ppl": "26.56", "wps": "99224.6", "ups": "0.92", "wpb": "107390", "bsz": "256", "num_updates": "121600", "lr": "2.06957e-05", "gnorm": "0.748", "train_wall": "170", "gb_free": "7.5", "wall": "133854"}
[2023-03-29 11:38:57,210][train_inner][INFO] - {"epoch": 112, "update": 111.641, "loss": "4.734", "ppl": "26.61", "wps": "95885.8", "ups": "0.9", "wpb": "107106", "bsz": "256", "num_updates": "121800", "lr": "1.94783e-05", "gnorm": "0.75", "train_wall": "175", "gb_free": "7.5", "wall": "134077"}
[2023-03-29 11:42:44,442][train_inner][INFO] - {"epoch": 112, "update": 111.824, "loss": "4.732", "ppl": "26.58", "wps": "94659.7", "ups": "0.88", "wpb": "107549", "bsz": "256", "num_updates": "122000", "lr": "1.82609e-05", "gnorm": "0.748", "train_wall": "178", "gb_free": "7.5", "wall": "134304"}
[2023-03-29 11:46:12,612][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 11:46:12,613][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 11:46:13,568][valid][INFO] - {"epoch": 112, "valid_loss": "4.56", "valid_ppl": "23.58", "valid_wps": "261268", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "122192", "valid_best_loss": "4.56"}
[2023-03-29 11:46:13,569][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 112 @ 122192 updates
[2023-03-29 11:46:13,570][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 11:46:13,807][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 11:46:13,948][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 112 @ 122192 updates, score 4.56) (writing took 0.37853161999373697 seconds)
[2023-03-29 11:46:13,948][fairseq_cli.train][INFO] - end of epoch 112 (average epoch stats below)
[2023-03-29 11:46:13,949][train][INFO] - {"epoch": 112, "train_loss": "4.732", "train_ppl": "26.58", "train_wps": "97445.4", "train_ups": "0.91", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "122192", "train_lr": "1.70922e-05", "train_gnorm": "0.749", "train_train_wall": "938", "train_gb_free": "7.5", "train_wall": "134514"}
[2023-03-29 11:46:13,952][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 11:46:13,986][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 11:46:13,988][fairseq.trainer][INFO] - begin training epoch 113
[2023-03-29 11:46:13,989][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 11:46:23,070][train_inner][INFO] - {"epoch": 113, "update": 112.007, "loss": "4.74", "ppl": "26.72", "wps": "97759.3", "ups": "0.91", "wpb": "106864", "bsz": "255.8", "num_updates": "122200", "lr": "1.70435e-05", "gnorm": "0.75", "train_wall": "170", "gb_free": "7.5", "wall": "134523"}
[2023-03-29 11:50:05,627][train_inner][INFO] - {"epoch": 113, "update": 112.191, "loss": "4.724", "ppl": "26.43", "wps": "96376.3", "ups": "0.9", "wpb": "107246", "bsz": "256", "num_updates": "122400", "lr": "1.58261e-05", "gnorm": "0.749", "train_wall": "174", "gb_free": "7.5", "wall": "134745"}
[2023-03-29 11:53:47,185][train_inner][INFO] - {"epoch": 113, "update": 112.374, "loss": "4.724", "ppl": "26.44", "wps": "96847.3", "ups": "0.9", "wpb": "107286", "bsz": "256", "num_updates": "122600", "lr": "1.46087e-05", "gnorm": "0.748", "train_wall": "173", "gb_free": "7.5", "wall": "134967"}
[2023-03-29 11:57:29,544][train_inner][INFO] - {"epoch": 113, "update": 112.557, "loss": "4.731", "ppl": "26.56", "wps": "96380.3", "ups": "0.9", "wpb": "107155", "bsz": "256", "num_updates": "122800", "lr": "1.33913e-05", "gnorm": "0.75", "train_wall": "174", "gb_free": "7.5", "wall": "135189"}
[2023-03-29 12:01:11,956][train_inner][INFO] - {"epoch": 113, "update": 112.741, "loss": "4.732", "ppl": "26.57", "wps": "96350.7", "ups": "0.9", "wpb": "107148", "bsz": "256", "num_updates": "123000", "lr": "1.21739e-05", "gnorm": "0.749", "train_wall": "174", "gb_free": "7.5", "wall": "135412"}
[2023-03-29 12:04:49,052][train_inner][INFO] - {"epoch": 113, "update": 112.924, "loss": "4.731", "ppl": "26.56", "wps": "98814.4", "ups": "0.92", "wpb": "107261", "bsz": "256", "num_updates": "123200", "lr": "1.09565e-05", "gnorm": "0.75", "train_wall": "170", "gb_free": "7.5", "wall": "135629"}
[2023-03-29 12:06:21,304][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 12:06:21,304][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 12:06:22,261][valid][INFO] - {"epoch": 113, "valid_loss": "4.56", "valid_ppl": "23.59", "valid_wps": "261511", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "123283", "valid_best_loss": "4.56"}
[2023-03-29 12:06:22,262][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 113 @ 123283 updates
[2023-03-29 12:06:22,263][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 12:06:22,508][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 12:06:22,668][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 113 @ 123283 updates, score 4.56) (writing took 0.405648352985736 seconds)
[2023-03-29 12:06:22,668][fairseq_cli.train][INFO] - end of epoch 113 (average epoch stats below)
[2023-03-29 12:06:22,669][train][INFO] - {"epoch": 113, "train_loss": "4.729", "train_ppl": "26.53", "train_wps": "96765.3", "train_ups": "0.9", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "123283", "train_lr": "1.04513e-05", "train_gnorm": "0.749", "train_train_wall": "944", "train_gb_free": "7.5", "train_wall": "135723"}
[2023-03-29 12:06:22,670][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 12:06:22,702][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 12:06:22,704][fairseq.trainer][INFO] - begin training epoch 114
[2023-03-29 12:06:22,704][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 12:08:35,362][train_inner][INFO] - {"epoch": 114, "update": 113.107, "loss": "4.728", "ppl": "26.5", "wps": "94880.8", "ups": "0.88", "wpb": "107363", "bsz": "255.8", "num_updates": "123400", "lr": "9.73913e-06", "gnorm": "0.748", "train_wall": "176", "gb_free": "7.5", "wall": "135855"}
[2023-03-29 12:12:16,787][train_inner][INFO] - {"epoch": 114, "update": 113.291, "loss": "4.723", "ppl": "26.41", "wps": "96812.4", "ups": "0.9", "wpb": "107183", "bsz": "256", "num_updates": "123600", "lr": "8.52174e-06", "gnorm": "0.748", "train_wall": "173", "gb_free": "7.5", "wall": "136077"}
[2023-03-29 12:16:01,953][train_inner][INFO] - {"epoch": 114, "update": 113.474, "loss": "4.727", "ppl": "26.49", "wps": "95294.7", "ups": "0.89", "wpb": "107286", "bsz": "256", "num_updates": "123800", "lr": "7.30435e-06", "gnorm": "0.748", "train_wall": "176", "gb_free": "7.5", "wall": "136302"}
[2023-03-29 12:19:41,872][train_inner][INFO] - {"epoch": 114, "update": 113.657, "loss": "4.73", "ppl": "26.54", "wps": "97502.6", "ups": "0.91", "wpb": "107213", "bsz": "256", "num_updates": "124000", "lr": "6.08696e-06", "gnorm": "0.749", "train_wall": "172", "gb_free": "7.5", "wall": "136522"}
[2023-03-29 12:23:25,756][train_inner][INFO] - {"epoch": 114, "update": 113.841, "loss": "4.726", "ppl": "26.46", "wps": "95771.2", "ups": "0.89", "wpb": "107208", "bsz": "256", "num_updates": "124200", "lr": "4.86957e-06", "gnorm": "0.749", "train_wall": "174", "gb_free": "7.5", "wall": "136746"}
[2023-03-29 12:26:34,106][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 12:26:34,114][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 12:26:35,043][valid][INFO] - {"epoch": 114, "valid_loss": "4.559", "valid_ppl": "23.58", "valid_wps": "268798", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "124374", "valid_best_loss": "4.559"}
[2023-03-29 12:26:35,049][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 114 @ 124374 updates
[2023-03-29 12:26:35,050][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 12:26:35,284][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 12:26:35,425][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 114 @ 124374 updates, score 4.559) (writing took 0.37557369499700144 seconds)
[2023-03-29 12:26:35,425][fairseq_cli.train][INFO] - end of epoch 114 (average epoch stats below)
[2023-03-29 12:26:35,426][train][INFO] - {"epoch": 114, "train_loss": "4.726", "train_ppl": "26.46", "train_wps": "96443.1", "train_ups": "0.9", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "124374", "train_lr": "3.81043e-06", "train_gnorm": "0.748", "train_train_wall": "947", "train_gb_free": "7.5", "train_wall": "136935"}
[2023-03-29 12:26:35,427][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 12:26:35,459][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 12:26:35,462][fairseq.trainer][INFO] - begin training epoch 115
[2023-03-29 12:26:35,462][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 12:27:03,835][train_inner][INFO] - {"epoch": 115, "update": 114.024, "loss": "4.725", "ppl": "26.44", "wps": "98029.2", "ups": "0.92", "wpb": "106887", "bsz": "255.8", "num_updates": "124400", "lr": "3.65217e-06", "gnorm": "0.749", "train_wall": "169", "gb_free": "7.5", "wall": "136964"}
[2023-03-29 12:30:45,631][train_inner][INFO] - {"epoch": 115, "update": 114.207, "loss": "4.726", "ppl": "26.47", "wps": "96808.5", "ups": "0.9", "wpb": "107359", "bsz": "256", "num_updates": "124600", "lr": "2.43478e-06", "gnorm": "0.749", "train_wall": "174", "gb_free": "7.5", "wall": "137185"}
[2023-03-29 12:34:28,023][train_inner][INFO] - {"epoch": 115, "update": 114.39, "loss": "4.722", "ppl": "26.4", "wps": "96197.3", "ups": "0.9", "wpb": "106968", "bsz": "256", "num_updates": "124800", "lr": "1.21739e-06", "gnorm": "0.75", "train_wall": "174", "gb_free": "7.5", "wall": "137408"}
[2023-03-29 12:38:14,084][train_inner][INFO] - {"epoch": 115, "update": 114.574, "loss": "4.728", "ppl": "26.5", "wps": "94834.8", "ups": "0.88", "wpb": "107191", "bsz": "256", "num_updates": "125000", "lr": "0", "gnorm": "0.749", "train_wall": "176", "gb_free": "7.5", "wall": "137634"}
[2023-03-29 12:38:14,091][fairseq_cli.train][INFO] - Stopping training due to num_updates: 125000 >= max_update: 125000
[2023-03-29 12:38:14,091][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 12:38:14,092][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 12:38:15,115][valid][INFO] - {"epoch": 115, "valid_loss": "4.559", "valid_ppl": "23.58", "valid_wps": "243514", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "125000", "valid_best_loss": "4.559"}
[2023-03-29 12:38:15,117][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 115 @ 125000 updates
[2023-03-29 12:38:15,119][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 12:38:15,550][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-27/22-24-17/0/checkpoints/checkpoint_best.pt
[2023-03-29 12:38:16,010][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 115 @ 125000 updates, score 4.559) (writing took 0.8911638830031734 seconds)
[2023-03-29 12:38:16,011][fairseq_cli.train][INFO] - end of epoch 115 (average epoch stats below)
[2023-03-29 12:38:16,014][train][INFO] - {"epoch": 115, "train_loss": "4.725", "train_ppl": "26.45", "train_wps": "95737.1", "train_ups": "0.89", "train_wpb": "107144", "train_bsz": "256", "train_num_updates": "125000", "train_lr": "0", "train_gnorm": "0.749", "train_train_wall": "546", "train_gb_free": "7.5", "train_wall": "137636"}
[2023-03-29 12:38:16,017][fairseq_cli.train][INFO] - done training in 137634.2 seconds
