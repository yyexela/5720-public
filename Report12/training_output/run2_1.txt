initialize.py: running hydra_init
initialize.py: running hydra_init
[2023-03-29 22:39:35,519][HYDRA] Launching 1 jobs locally
[2023-03-29 22:39:35,519][HYDRA] 	#0 : task.data=/home/alexey/Desktop/fairseq/data-bin/wikitext-103
[2023-03-29 22:39:36,416][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': True, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 125000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [64], 'lr': [0.0007], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'roberta', 'max_positions': 512, 'dropout': 0.1, 'attention_dropout': 0.1}, 'task': {'_name': 'masked_lm', 'data': '/home/alexey/Desktop/fairseq/data-bin/wikitext-103', 'sample_break_mode': complete, 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': none, 'shorten_data_split_list': '', 'seed': 1, 'include_target_tokens': False, 'include_index': True, 'skip_masking': False, 'd2v2_multi': False}, 'criterion': {'_name': 'masked_lm', 'tpu': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 10000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 125000.0, 'lr': [0.0007]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2023-03-29 22:39:36,470][fairseq.tasks.masked_lm][INFO] - dictionary: 50264 types
[2023-03-29 22:39:37,156][fairseq_cli.train][INFO] - RobertaModel(
  (encoder): RobertaEncoder(
    (sentence_encoder): TransformerEncoder(
      (dropout_module): FairseqDropout()
      (embed_tokens): Embedding(50265, 768, padding_idx=1)
      (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)
      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0): TransformerEncoderLayerBase(
          (self_attn): MultiheadAttention(
            (dropout_module): FairseqDropout()
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (dropout_module): FairseqDropout()
          (activation_dropout_module): FairseqDropout()
          (fc1): Linear(in_features=768, out_features=192, bias=True)
          (fc2): Linear(in_features=192, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (lm_head): RobertaLMHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classification_heads): ModuleDict()
)
[2023-03-29 22:39:37,156][fairseq_cli.train][INFO] - task: MaskedLMTask
[2023-03-29 22:39:37,156][fairseq_cli.train][INFO] - model: RobertaModel
[2023-03-29 22:39:37,156][fairseq_cli.train][INFO] - criterion: MaskedLmLoss
[2023-03-29 22:39:37,157][fairseq_cli.train][INFO] - num. shared model params: 42,303,513 (num. trained: 42,303,513)
[2023-03-29 22:39:37,157][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-03-29 22:39:37,162][fairseq.data.data_utils][INFO] - loaded 3,760 examples from: /home/alexey/Desktop/fairseq/data-bin/wikitext-103/valid
[2023-03-29 22:39:37,166][fairseq.tasks.masked_lm][INFO] - loaded 580 blocks from: /home/alexey/Desktop/fairseq/data-bin/wikitext-103/valid
[2023-03-29 22:39:38,953][fairseq.trainer][INFO] - detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight
[2023-03-29 22:39:38,955][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-03-29 22:39:38,955][fairseq.utils][INFO] - rank   0: capabilities =  6.1  ; total memory = 7.921 GB ; name = NVIDIA GeForce GTX 1070                 
[2023-03-29 22:39:38,955][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-03-29 22:39:38,955][fairseq_cli.train][INFO] - training on 1 devices (GPUs/TPUs)
[2023-03-29 22:39:38,956][fairseq_cli.train][INFO] - max tokens per device = None and max sentences per device = 4
[2023-03-29 22:39:38,956][fairseq.trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-03-29 22:39:38,956][fairseq.trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-03-29 22:39:38,957][fairseq.trainer][INFO] - loading train data for epoch 1
[2023-03-29 22:39:39,251][fairseq.data.data_utils][INFO] - loaded 1,801,350 examples from: /home/alexey/Desktop/fairseq/data-bin/wikitext-103/train
[2023-03-29 22:39:39,329][fairseq.tasks.masked_lm][INFO] - loaded 280678 blocks from: /home/alexey/Desktop/fairseq/data-bin/wikitext-103/train
[2023-03-29 22:39:39,337][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 22:39:39,338][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2023-03-29 22:39:39,338][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2023-03-29 22:39:39,338][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2023-03-29 22:39:39,363][fairseq.tasks.fairseq_task][WARNING] - 1,414 samples have invalid sizes and will be skipped, max_positions=512, first few sample ids=[127070, 245388, 160963, 4508, 197654, 80339, 243532, 240011, 69697, 236498]
[2023-03-29 22:39:39,555][fairseq_cli.train][INFO] - begin dry-run validation on "valid" subset
[2023-03-29 22:39:39,556][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 22:39:39,557][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2023-03-29 22:39:39,557][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = False
[2023-03-29 22:39:39,557][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2023-03-29 22:39:40,290][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 22:39:40,293][fairseq.trainer][INFO] - begin training epoch 1
[2023-03-29 22:39:40,293][fairseq_cli.train][INFO] - Start iterating over samples
/home/alexey/Desktop/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[2023-03-29 22:47:10,876][train_inner][INFO] - {"epoch": 1, "update": 0.183, "loss": "15.021", "ppl": "33258", "wps": "47723.2", "ups": "0.45", "wpb": "107015", "bsz": "256", "num_updates": "200", "lr": "1.4e-05", "gnorm": "2.173", "train_wall": "404", "gb_free": "6.8", "wall": "452"}
[2023-03-29 22:54:35,990][train_inner][INFO] - {"epoch": 1, "update": 0.367, "loss": "11.812", "ppl": "3596.27", "wps": "48158.9", "ups": "0.45", "wpb": "107181", "bsz": "256", "num_updates": "400", "lr": "2.8e-05", "gnorm": "1.306", "train_wall": "400", "gb_free": "6.8", "wall": "897"}
[2023-03-29 23:02:03,113][train_inner][INFO] - {"epoch": 1, "update": 0.55, "loss": "10.666", "ppl": "1624.39", "wps": "47974.5", "ups": "0.45", "wpb": "107252", "bsz": "256", "num_updates": "600", "lr": "4.2e-05", "gnorm": "0.332", "train_wall": "401", "gb_free": "6.8", "wall": "1344"}
[2023-03-29 23:09:28,515][train_inner][INFO] - {"epoch": 1, "update": 0.733, "loss": "10.465", "ppl": "1413.11", "wps": "48251.7", "ups": "0.45", "wpb": "107457", "bsz": "256", "num_updates": "800", "lr": "5.6e-05", "gnorm": "0.33", "train_wall": "400", "gb_free": "6.8", "wall": "1790"}
[2023-03-29 23:16:52,732][train_inner][INFO] - {"epoch": 1, "update": 0.917, "loss": "10.301", "ppl": "1261.23", "wps": "48216.3", "ups": "0.45", "wpb": "107092", "bsz": "256", "num_updates": "1000", "lr": "7e-05", "gnorm": "0.361", "train_wall": "399", "gb_free": "6.8", "wall": "2234"}
[2023-03-29 23:20:15,072][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-29 23:20:15,073][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 23:20:16,828][valid][INFO] - {"epoch": 1, "valid_loss": "10.07", "valid_ppl": "1074.73", "valid_wps": "140687", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "1091"}
[2023-03-29 23:20:16,829][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 1091 updates
[2023-03-29 23:20:16,830][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-29 23:20:17,519][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-29 23:20:17,978][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 1 @ 1091 updates, score 10.07) (writing took 1.1496800360000634 seconds)
[2023-03-29 23:20:17,982][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2023-03-29 23:20:17,983][train][INFO] - {"epoch": 1, "train_loss": "11.528", "train_ppl": "2953.94", "train_wps": "48022.4", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "1091", "train_lr": "7.637e-05", "train_gnorm": "0.857", "train_train_wall": "2186", "train_gb_free": "6.8", "train_wall": "2439"}
[2023-03-29 23:20:17,986][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-29 23:20:18,018][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-29 23:20:18,020][fairseq.trainer][INFO] - begin training epoch 2
[2023-03-29 23:20:18,021][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-29 23:24:20,522][train_inner][INFO] - {"epoch": 2, "update": 1.1, "loss": "10.126", "ppl": "1117.09", "wps": "47907.2", "ups": "0.45", "wpb": "107262", "bsz": "255.8", "num_updates": "1200", "lr": "8.4e-05", "gnorm": "0.379", "train_wall": "399", "gb_free": "6.8", "wall": "2682"}
[2023-03-29 23:31:44,982][train_inner][INFO] - {"epoch": 2, "update": 1.283, "loss": "9.967", "ppl": "1000.61", "wps": "48219", "ups": "0.45", "wpb": "107157", "bsz": "256", "num_updates": "1400", "lr": "9.8e-05", "gnorm": "0.409", "train_wall": "399", "gb_free": "6.8", "wall": "3126"}
[2023-03-29 23:39:10,450][train_inner][INFO] - {"epoch": 2, "update": 1.467, "loss": "9.819", "ppl": "903", "wps": "48271.9", "ups": "0.45", "wpb": "107518", "bsz": "256", "num_updates": "1600", "lr": "0.000112", "gnorm": "0.431", "train_wall": "400", "gb_free": "6.8", "wall": "3571"}
[2023-03-29 23:46:34,925][train_inner][INFO] - {"epoch": 2, "update": 1.65, "loss": "9.612", "ppl": "782.56", "wps": "48227.4", "ups": "0.45", "wpb": "107179", "bsz": "256", "num_updates": "1800", "lr": "0.000126", "gnorm": "0.497", "train_wall": "399", "gb_free": "6.8", "wall": "4016"}
[2023-03-29 23:53:59,134][train_inner][INFO] - {"epoch": 2, "update": 1.833, "loss": "9.051", "ppl": "530.4", "wps": "48216.6", "ups": "0.45", "wpb": "107091", "bsz": "256", "num_updates": "2000", "lr": "0.00014", "gnorm": "0.586", "train_wall": "399", "gb_free": "6.8", "wall": "4460"}
[2023-03-30 00:00:43,002][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 00:00:43,003][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 00:00:44,727][valid][INFO] - {"epoch": 2, "valid_loss": "7.939", "valid_ppl": "245.32", "valid_wps": "143498", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "2182", "valid_best_loss": "7.939"}
[2023-03-30 00:00:44,728][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 2182 updates
[2023-03-30 00:00:44,729][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 00:00:45,689][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 00:00:46,221][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 2 @ 2182 updates, score 7.939) (writing took 1.4930604310011404 seconds)
[2023-03-30 00:00:46,221][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2023-03-30 00:00:46,222][train][INFO] - {"epoch": 2, "train_loss": "9.46", "train_ppl": "704.15", "train_wps": "48167.4", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "2182", "train_lr": "0.00015274", "train_gnorm": "0.498", "train_train_wall": "2177", "train_gb_free": "6.8", "train_wall": "4867"}
[2023-03-30 00:00:46,224][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 00:00:46,258][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 00:00:46,260][fairseq.trainer][INFO] - begin training epoch 3
[2023-03-30 00:00:46,260][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 00:01:26,647][train_inner][INFO] - {"epoch": 3, "update": 2.016, "loss": "8.39", "ppl": "335.54", "wps": "47867.6", "ups": "0.45", "wpb": "107107", "bsz": "255.8", "num_updates": "2200", "lr": "0.000154", "gnorm": "0.642", "train_wall": "399", "gb_free": "6.8", "wall": "4908"}
[2023-03-30 00:08:51,073][train_inner][INFO] - {"epoch": 3, "update": 2.2, "loss": "7.971", "ppl": "250.97", "wps": "48235.6", "ups": "0.45", "wpb": "107186", "bsz": "256", "num_updates": "2400", "lr": "0.000168", "gnorm": "0.693", "train_wall": "399", "gb_free": "6.8", "wall": "5352"}
[2023-03-30 00:16:15,394][train_inner][INFO] - {"epoch": 3, "update": 2.383, "loss": "7.434", "ppl": "172.92", "wps": "48235.6", "ups": "0.45", "wpb": "107160", "bsz": "256", "num_updates": "2600", "lr": "0.000182", "gnorm": "0.646", "train_wall": "399", "gb_free": "6.8", "wall": "5796"}
[2023-03-30 00:23:39,494][train_inner][INFO] - {"epoch": 3, "update": 2.566, "loss": "6.986", "ppl": "126.77", "wps": "48210.9", "ups": "0.45", "wpb": "107052", "bsz": "256", "num_updates": "2800", "lr": "0.000196", "gnorm": "0.605", "train_wall": "399", "gb_free": "6.8", "wall": "6241"}
[2023-03-30 00:31:04,420][train_inner][INFO] - {"epoch": 3, "update": 2.75, "loss": "6.733", "ppl": "106.4", "wps": "48276.9", "ups": "0.45", "wpb": "107398", "bsz": "256", "num_updates": "3000", "lr": "0.00021", "gnorm": "0.603", "train_wall": "400", "gb_free": "6.8", "wall": "6685"}
[2023-03-30 00:38:28,988][train_inner][INFO] - {"epoch": 3, "update": 2.933, "loss": "6.532", "ppl": "92.54", "wps": "48231.3", "ups": "0.45", "wpb": "107210", "bsz": "256", "num_updates": "3200", "lr": "0.000224", "gnorm": "0.613", "train_wall": "399", "gb_free": "6.8", "wall": "7130"}
[2023-03-30 00:41:11,009][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 00:41:11,009][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 00:41:12,761][valid][INFO] - {"epoch": 3, "valid_loss": "5.986", "valid_ppl": "63.4", "valid_wps": "141258", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "3273", "valid_best_loss": "5.986"}
[2023-03-30 00:41:12,762][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 3273 updates
[2023-03-30 00:41:12,763][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 00:41:15,373][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 00:41:15,941][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 3 @ 3273 updates, score 5.986) (writing took 3.1792396050004754 seconds)
[2023-03-30 00:41:15,942][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2023-03-30 00:41:15,942][train][INFO] - {"epoch": 3, "train_loss": "7.1", "train_ppl": "137.15", "train_wps": "48138.1", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "3273", "train_lr": "0.00022911", "train_gnorm": "0.631", "train_train_wall": "2177", "train_gb_free": "6.8", "train_wall": "7297"}
[2023-03-30 00:41:15,944][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 00:41:15,982][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 00:41:15,984][fairseq.trainer][INFO] - begin training epoch 4
[2023-03-30 00:41:15,985][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 00:45:58,600][train_inner][INFO] - {"epoch": 4, "update": 3.116, "loss": "6.296", "ppl": "78.6", "wps": "47725.1", "ups": "0.44", "wpb": "107289", "bsz": "255.8", "num_updates": "3400", "lr": "0.000238", "gnorm": "0.623", "train_wall": "399", "gb_free": "6.8", "wall": "7580"}
[2023-03-30 00:53:22,946][train_inner][INFO] - {"epoch": 4, "update": 3.3, "loss": "6.146", "ppl": "70.8", "wps": "48251.1", "ups": "0.45", "wpb": "107201", "bsz": "256", "num_updates": "3600", "lr": "0.000252", "gnorm": "0.641", "train_wall": "399", "gb_free": "6.8", "wall": "8024"}
[2023-03-30 01:00:46,954][train_inner][INFO] - {"epoch": 4, "update": 3.483, "loss": "6.032", "ppl": "65.43", "wps": "48242.8", "ups": "0.45", "wpb": "107101", "bsz": "256", "num_updates": "3800", "lr": "0.000266", "gnorm": "0.648", "train_wall": "399", "gb_free": "6.8", "wall": "8468"}
[2023-03-30 01:08:11,098][train_inner][INFO] - {"epoch": 4, "update": 3.666, "loss": "5.937", "ppl": "61.24", "wps": "48271.1", "ups": "0.45", "wpb": "107196", "bsz": "256", "num_updates": "4000", "lr": "0.00028", "gnorm": "0.659", "train_wall": "399", "gb_free": "6.8", "wall": "8912"}
[2023-03-30 01:15:34,773][train_inner][INFO] - {"epoch": 4, "update": 3.85, "loss": "5.846", "ppl": "57.5", "wps": "48284.6", "ups": "0.45", "wpb": "107113", "bsz": "256", "num_updates": "4200", "lr": "0.000294", "gnorm": "0.667", "train_wall": "399", "gb_free": "6.8", "wall": "9356"}
[2023-03-30 01:21:39,212][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 01:21:39,213][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 01:21:40,934][valid][INFO] - {"epoch": 4, "valid_loss": "5.327", "valid_ppl": "40.13", "valid_wps": "143634", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "4364", "valid_best_loss": "5.327"}
[2023-03-30 01:21:40,935][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 4364 updates
[2023-03-30 01:21:40,936][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 01:21:41,827][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 01:21:42,366][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 4 @ 4364 updates, score 5.327) (writing took 1.4310210539988475 seconds)
[2023-03-30 01:21:42,366][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2023-03-30 01:21:42,367][train][INFO] - {"epoch": 4, "train_loss": "5.985", "train_ppl": "63.35", "train_wps": "48203.4", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "4364", "train_lr": "0.00030548", "train_gnorm": "0.653", "train_train_wall": "2177", "train_gb_free": "6.8", "train_wall": "9723"}
[2023-03-30 01:21:42,369][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 01:21:42,401][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 01:21:42,404][fairseq.trainer][INFO] - begin training epoch 5
[2023-03-30 01:21:42,404][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 01:23:02,485][train_inner][INFO] - {"epoch": 5, "update": 4.033, "loss": "5.73", "ppl": "53.09", "wps": "47927.1", "ups": "0.45", "wpb": "107288", "bsz": "255.8", "num_updates": "4400", "lr": "0.000308", "gnorm": "0.668", "train_wall": "399", "gb_free": "6.8", "wall": "9804"}
[2023-03-30 01:30:25,998][train_inner][INFO] - {"epoch": 5, "update": 4.216, "loss": "5.554", "ppl": "46.97", "wps": "48295.7", "ups": "0.45", "wpb": "107099", "bsz": "256", "num_updates": "4600", "lr": "0.000322", "gnorm": "0.684", "train_wall": "399", "gb_free": "6.8", "wall": "10247"}
[2023-03-30 01:37:50,137][train_inner][INFO] - {"epoch": 5, "update": 4.4, "loss": "5.527", "ppl": "46.1", "wps": "48327.8", "ups": "0.45", "wpb": "107321", "bsz": "256", "num_updates": "4800", "lr": "0.000336", "gnorm": "0.69", "train_wall": "399", "gb_free": "6.8", "wall": "10691"}
[2023-03-30 01:45:13,792][train_inner][INFO] - {"epoch": 5, "update": 4.583, "loss": "5.481", "ppl": "44.65", "wps": "48304", "ups": "0.45", "wpb": "107152", "bsz": "256", "num_updates": "5000", "lr": "0.00035", "gnorm": "0.69", "train_wall": "399", "gb_free": "6.8", "wall": "11135"}
[2023-03-30 01:52:37,553][train_inner][INFO] - {"epoch": 5, "update": 4.766, "loss": "5.437", "ppl": "43.31", "wps": "48304.5", "ups": "0.45", "wpb": "107178", "bsz": "256", "num_updates": "5200", "lr": "0.000364", "gnorm": "0.691", "train_wall": "399", "gb_free": "6.8", "wall": "11579"}
[2023-03-30 02:00:02,033][train_inner][INFO] - {"epoch": 5, "update": 4.95, "loss": "5.406", "ppl": "42.39", "wps": "48330.2", "ups": "0.45", "wpb": "107409", "bsz": "256", "num_updates": "5400", "lr": "0.000378", "gnorm": "0.689", "train_wall": "400", "gb_free": "6.8", "wall": "12023"}
[2023-03-30 02:02:03,708][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 02:02:03,709][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 02:02:05,433][valid][INFO] - {"epoch": 5, "valid_loss": "5.008", "valid_ppl": "32.19", "valid_wps": "143554", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "5455", "valid_best_loss": "5.008"}
[2023-03-30 02:02:05,433][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 5455 updates
[2023-03-30 02:02:05,434][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 02:02:06,324][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 02:02:06,914][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 5 @ 5455 updates, score 5.008) (writing took 1.4808306670020102 seconds)
[2023-03-30 02:02:06,915][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2023-03-30 02:02:06,915][train][INFO] - {"epoch": 5, "train_loss": "5.478", "train_ppl": "44.56", "train_wps": "48240.7", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "5455", "train_lr": "0.00038185", "train_gnorm": "0.688", "train_train_wall": "2176", "train_gb_free": "6.8", "train_wall": "12148"}
[2023-03-30 02:02:06,917][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 02:02:06,950][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 02:02:06,952][fairseq.trainer][INFO] - begin training epoch 6
[2023-03-30 02:02:06,952][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 02:07:28,887][train_inner][INFO] - {"epoch": 6, "update": 5.133, "loss": "5.222", "ppl": "37.33", "wps": "47943.2", "ups": "0.45", "wpb": "107118", "bsz": "255.8", "num_updates": "5600", "lr": "0.000392", "gnorm": "0.701", "train_wall": "399", "gb_free": "6.8", "wall": "12470"}
[2023-03-30 02:14:52,127][train_inner][INFO] - {"epoch": 6, "update": 5.316, "loss": "5.182", "ppl": "36.29", "wps": "48290.3", "ups": "0.45", "wpb": "107021", "bsz": "256", "num_updates": "5800", "lr": "0.000406", "gnorm": "0.708", "train_wall": "398", "gb_free": "6.8", "wall": "12913"}
[2023-03-30 02:22:16,560][train_inner][INFO] - {"epoch": 6, "update": 5.5, "loss": "5.179", "ppl": "36.22", "wps": "48347.2", "ups": "0.45", "wpb": "107435", "bsz": "256", "num_updates": "6000", "lr": "0.00042", "gnorm": "0.708", "train_wall": "400", "gb_free": "6.8", "wall": "13358"}
[2023-03-30 02:29:41,246][train_inner][INFO] - {"epoch": 6, "update": 5.683, "loss": "5.178", "ppl": "36.2", "wps": "48334.2", "ups": "0.45", "wpb": "107468", "bsz": "256", "num_updates": "6200", "lr": "0.000434", "gnorm": "0.704", "train_wall": "400", "gb_free": "6.8", "wall": "13802"}
[2023-03-30 02:37:04,720][train_inner][INFO] - {"epoch": 6, "update": 5.866, "loss": "5.164", "ppl": "35.86", "wps": "48284.3", "ups": "0.45", "wpb": "107064", "bsz": "256", "num_updates": "6400", "lr": "0.000448", "gnorm": "0.7", "train_wall": "399", "gb_free": "6.8", "wall": "14246"}
[2023-03-30 02:42:28,224][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 02:42:28,225][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 02:42:29,967][valid][INFO] - {"epoch": 6, "valid_loss": "4.84", "valid_ppl": "28.65", "valid_wps": "142792", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "6546", "valid_best_loss": "4.84"}
[2023-03-30 02:42:29,968][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 6546 updates
[2023-03-30 02:42:29,969][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 02:42:31,879][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 02:42:32,642][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 6 @ 6546 updates, score 4.84) (writing took 2.673759407000034 seconds)
[2023-03-30 02:42:32,642][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2023-03-30 02:42:32,643][train][INFO] - {"epoch": 6, "train_loss": "5.172", "train_ppl": "36.06", "train_wps": "48217.3", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "6546", "train_lr": "0.00045822", "train_gnorm": "0.704", "train_train_wall": "2176", "train_gb_free": "6.8", "train_wall": "14574"}
[2023-03-30 02:42:32,645][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 02:42:32,683][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 02:42:32,686][fairseq.trainer][INFO] - begin training epoch 7
[2023-03-30 02:42:32,686][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 02:44:32,564][train_inner][INFO] - {"epoch": 7, "update": 6.049, "loss": "5.086", "ppl": "33.96", "wps": "47782.5", "ups": "0.45", "wpb": "106995", "bsz": "255.8", "num_updates": "6600", "lr": "0.000462", "gnorm": "0.697", "train_wall": "398", "gb_free": "6.8", "wall": "14694"}
[2023-03-30 02:51:55,864][train_inner][INFO] - {"epoch": 7, "update": 6.233, "loss": "4.927", "ppl": "30.42", "wps": "48285.8", "ups": "0.45", "wpb": "107026", "bsz": "256", "num_updates": "6800", "lr": "0.000476", "gnorm": "0.715", "train_wall": "398", "gb_free": "6.8", "wall": "15137"}
[2023-03-30 02:59:20,039][train_inner][INFO] - {"epoch": 7, "update": 6.416, "loss": "4.959", "ppl": "31.11", "wps": "48329.4", "ups": "0.45", "wpb": "107332", "bsz": "256", "num_updates": "7000", "lr": "0.00049", "gnorm": "0.71", "train_wall": "399", "gb_free": "6.8", "wall": "15581"}
[2023-03-30 03:06:43,847][train_inner][INFO] - {"epoch": 7, "update": 6.599, "loss": "4.977", "ppl": "31.5", "wps": "48319.7", "ups": "0.45", "wpb": "107223", "bsz": "256", "num_updates": "7200", "lr": "0.000504", "gnorm": "0.709", "train_wall": "399", "gb_free": "6.8", "wall": "16025"}
[2023-03-30 03:14:08,165][train_inner][INFO] - {"epoch": 7, "update": 6.783, "loss": "4.989", "ppl": "31.75", "wps": "48325.4", "ups": "0.45", "wpb": "107359", "bsz": "256", "num_updates": "7400", "lr": "0.000518", "gnorm": "0.698", "train_wall": "399", "gb_free": "6.8", "wall": "16469"}
[2023-03-30 03:21:32,162][train_inner][INFO] - {"epoch": 7, "update": 6.966, "loss": "4.991", "ppl": "31.8", "wps": "48313.9", "ups": "0.45", "wpb": "107256", "bsz": "256", "num_updates": "7600", "lr": "0.000532", "gnorm": "0.697", "train_wall": "399", "gb_free": "6.8", "wall": "16913"}
[2023-03-30 03:22:53,856][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 03:22:53,857][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 03:22:55,543][valid][INFO] - {"epoch": 7, "valid_loss": "4.739", "valid_ppl": "26.7", "valid_wps": "146700", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "7637", "valid_best_loss": "4.739"}
[2023-03-30 03:22:55,544][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 7637 updates
[2023-03-30 03:22:55,544][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 03:22:56,452][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 03:22:57,050][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 7 @ 7637 updates, score 4.739) (writing took 1.506138764001662 seconds)
[2023-03-30 03:22:57,051][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2023-03-30 03:22:57,051][train][INFO] - {"epoch": 7, "train_loss": "4.965", "train_ppl": "31.23", "train_wps": "48243.5", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "7637", "train_lr": "0.00053459", "train_gnorm": "0.705", "train_train_wall": "2176", "train_gb_free": "6.8", "train_wall": "16998"}
[2023-03-30 03:22:57,053][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 03:22:57,085][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 03:22:57,087][fairseq.trainer][INFO] - begin training epoch 8
[2023-03-30 03:22:57,088][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 03:28:58,863][train_inner][INFO] - {"epoch": 8, "update": 7.149, "loss": "4.782", "ppl": "27.51", "wps": "47923.3", "ups": "0.45", "wpb": "107037", "bsz": "255.8", "num_updates": "7800", "lr": "0.000546", "gnorm": "0.709", "train_wall": "398", "gb_free": "6.8", "wall": "17360"}
[2023-03-30 03:36:23,333][train_inner][INFO] - {"epoch": 8, "update": 7.333, "loss": "4.779", "ppl": "27.46", "wps": "48350.2", "ups": "0.45", "wpb": "107450", "bsz": "256", "num_updates": "8000", "lr": "0.00056", "gnorm": "0.704", "train_wall": "400", "gb_free": "6.8", "wall": "17804"}
[2023-03-30 03:43:46,509][train_inner][INFO] - {"epoch": 8, "update": 7.516, "loss": "4.818", "ppl": "28.21", "wps": "48285", "ups": "0.45", "wpb": "106994", "bsz": "256", "num_updates": "8200", "lr": "0.000574", "gnorm": "0.702", "train_wall": "398", "gb_free": "6.8", "wall": "18248"}
[2023-03-30 03:51:10,572][train_inner][INFO] - {"epoch": 8, "update": 7.699, "loss": "4.841", "ppl": "28.66", "wps": "48319.7", "ups": "0.45", "wpb": "107285", "bsz": "256", "num_updates": "8400", "lr": "0.000588", "gnorm": "0.692", "train_wall": "399", "gb_free": "6.8", "wall": "18692"}
[2023-03-30 03:58:34,437][train_inner][INFO] - {"epoch": 8, "update": 7.883, "loss": "4.855", "ppl": "28.95", "wps": "48328.2", "ups": "0.45", "wpb": "107256", "bsz": "256", "num_updates": "8600", "lr": "0.000602", "gnorm": "0.683", "train_wall": "399", "gb_free": "6.8", "wall": "19135"}
[2023-03-30 04:03:18,054][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 04:03:18,055][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 04:03:19,774][valid][INFO] - {"epoch": 8, "valid_loss": "4.686", "valid_ppl": "25.74", "valid_wps": "143878", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "8728", "valid_best_loss": "4.686"}
[2023-03-30 04:03:19,775][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 8728 updates
[2023-03-30 04:03:19,776][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 04:03:20,682][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 04:03:21,274][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 8 @ 8728 updates, score 4.686) (writing took 1.4987584070004232 seconds)
[2023-03-30 04:03:21,274][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2023-03-30 04:03:21,275][train][INFO] - {"epoch": 8, "train_loss": "4.816", "train_ppl": "28.16", "train_wps": "48247.2", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "8728", "train_lr": "0.00061096", "train_gnorm": "0.695", "train_train_wall": "2176", "train_gb_free": "6.8", "train_wall": "19422"}
[2023-03-30 04:03:21,279][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 04:03:21,315][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 04:03:21,318][fairseq.trainer][INFO] - begin training epoch 9
[2023-03-30 04:03:21,318][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 04:06:01,218][train_inner][INFO] - {"epoch": 9, "update": 8.066, "loss": "4.765", "ppl": "27.19", "wps": "47927.9", "ups": "0.45", "wpb": "107066", "bsz": "255.8", "num_updates": "8800", "lr": "0.000616", "gnorm": "0.681", "train_wall": "399", "gb_free": "6.8", "wall": "19582"}
[2023-03-30 04:13:25,161][train_inner][INFO] - {"epoch": 9, "update": 8.249, "loss": "4.627", "ppl": "24.71", "wps": "48314.9", "ups": "0.45", "wpb": "107246", "bsz": "256", "num_updates": "9000", "lr": "0.00063", "gnorm": "0.692", "train_wall": "399", "gb_free": "6.8", "wall": "20026"}
[2023-03-30 04:20:49,119][train_inner][INFO] - {"epoch": 9, "update": 8.433, "loss": "4.682", "ppl": "25.66", "wps": "48317.3", "ups": "0.45", "wpb": "107253", "bsz": "256", "num_updates": "9200", "lr": "0.000644", "gnorm": "0.687", "train_wall": "399", "gb_free": "6.8", "wall": "20470"}
[2023-03-30 04:28:12,377][train_inner][INFO] - {"epoch": 9, "update": 8.616, "loss": "4.722", "ppl": "26.39", "wps": "48286.5", "ups": "0.45", "wpb": "107017", "bsz": "256", "num_updates": "9400", "lr": "0.000658", "gnorm": "0.68", "train_wall": "398", "gb_free": "6.8", "wall": "20913"}
[2023-03-30 04:35:36,276][train_inner][INFO] - {"epoch": 9, "update": 8.799, "loss": "4.751", "ppl": "26.93", "wps": "48313.2", "ups": "0.45", "wpb": "107231", "bsz": "256", "num_updates": "9600", "lr": "0.000672", "gnorm": "0.67", "train_wall": "399", "gb_free": "6.8", "wall": "21357"}
[2023-03-30 04:43:00,584][train_inner][INFO] - {"epoch": 9, "update": 8.983, "loss": "4.761", "ppl": "27.12", "wps": "48320.4", "ups": "0.45", "wpb": "107346", "bsz": "256", "num_updates": "9800", "lr": "0.000686", "gnorm": "0.659", "train_wall": "399", "gb_free": "6.8", "wall": "21802"}
[2023-03-30 04:43:42,643][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 04:43:42,644][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 04:43:44,334][valid][INFO] - {"epoch": 9, "valid_loss": "4.628", "valid_ppl": "24.73", "valid_wps": "146748", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "9819", "valid_best_loss": "4.628"}
[2023-03-30 04:43:44,335][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 9 @ 9819 updates
[2023-03-30 04:43:44,336][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 04:43:45,871][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 04:43:46,458][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 9 @ 9819 updates, score 4.628) (writing took 2.1230332060004002 seconds)
[2023-03-30 04:43:46,458][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2023-03-30 04:43:46,459][train][INFO] - {"epoch": 9, "train_loss": "4.701", "train_ppl": "26.01", "train_wps": "48228.1", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "9819", "train_lr": "0.00068733", "train_gnorm": "0.678", "train_train_wall": "2176", "train_gb_free": "6.8", "train_wall": "21848"}
[2023-03-30 04:43:46,460][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 04:43:46,493][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 04:43:46,496][fairseq.trainer][INFO] - begin training epoch 10
[2023-03-30 04:43:46,496][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 04:50:27,964][train_inner][INFO] - {"epoch": 10, "update": 9.166, "loss": "4.518", "ppl": "22.91", "wps": "47858.8", "ups": "0.45", "wpb": "107055", "bsz": "255.8", "num_updates": "10000", "lr": "0.0007", "gnorm": "0.671", "train_wall": "399", "gb_free": "6.8", "wall": "22249"}
[2023-03-30 04:57:51,620][train_inner][INFO] - {"epoch": 10, "update": 9.349, "loss": "4.563", "ppl": "23.63", "wps": "48315.9", "ups": "0.45", "wpb": "107178", "bsz": "256", "num_updates": "10200", "lr": "0.000698783", "gnorm": "0.669", "train_wall": "399", "gb_free": "6.8", "wall": "22693"}
[2023-03-30 05:05:15,258][train_inner][INFO] - {"epoch": 10, "update": 9.533, "loss": "4.609", "ppl": "24.41", "wps": "48313.3", "ups": "0.45", "wpb": "107168", "bsz": "256", "num_updates": "10400", "lr": "0.000697565", "gnorm": "0.663", "train_wall": "399", "gb_free": "6.8", "wall": "23136"}
[2023-03-30 05:12:38,959][train_inner][INFO] - {"epoch": 10, "update": 9.716, "loss": "4.631", "ppl": "24.78", "wps": "48291.3", "ups": "0.45", "wpb": "107134", "bsz": "256", "num_updates": "10600", "lr": "0.000696348", "gnorm": "0.652", "train_wall": "399", "gb_free": "6.8", "wall": "23580"}
[2023-03-30 05:20:03,001][train_inner][INFO] - {"epoch": 10, "update": 9.899, "loss": "4.655", "ppl": "25.19", "wps": "48341", "ups": "0.45", "wpb": "107327", "bsz": "256", "num_updates": "10800", "lr": "0.00069513", "gnorm": "0.649", "train_wall": "399", "gb_free": "6.8", "wall": "24024"}
[2023-03-30 05:24:07,448][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 05:24:07,449][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 05:24:09,166][valid][INFO] - {"epoch": 10, "valid_loss": "4.588", "valid_ppl": "24.05", "valid_wps": "144100", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "10910", "valid_best_loss": "4.588"}
[2023-03-30 05:24:09,167][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 10910 updates
[2023-03-30 05:24:09,168][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 05:24:10,074][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 05:24:10,663][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 10 @ 10910 updates, score 4.588) (writing took 1.4954248659996665 seconds)
[2023-03-30 05:24:10,663][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2023-03-30 05:24:10,663][train][INFO] - {"epoch": 10, "train_loss": "4.599", "train_ppl": "24.23", "train_wps": "48247.6", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "10910", "train_lr": "0.000694461", "train_gnorm": "0.659", "train_train_wall": "2176", "train_gb_free": "6.8", "train_wall": "24272"}
[2023-03-30 05:24:10,665][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 05:24:10,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 05:24:10,700][fairseq.trainer][INFO] - begin training epoch 11
[2023-03-30 05:24:10,700][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 05:27:30,879][train_inner][INFO] - {"epoch": 11, "update": 10.082, "loss": "4.521", "ppl": "22.96", "wps": "47974.3", "ups": "0.45", "wpb": "107433", "bsz": "255.8", "num_updates": "11000", "lr": "0.000693913", "gnorm": "0.65", "train_wall": "400", "gb_free": "6.8", "wall": "24472"}
[2023-03-30 05:34:54,342][train_inner][INFO] - {"epoch": 11, "update": 10.266, "loss": "4.416", "ppl": "21.34", "wps": "48316.5", "ups": "0.45", "wpb": "107133", "bsz": "256", "num_updates": "11200", "lr": "0.000692696", "gnorm": "0.661", "train_wall": "399", "gb_free": "6.8", "wall": "24915"}
[2023-03-30 05:42:18,664][train_inner][INFO] - {"epoch": 11, "update": 10.449, "loss": "4.47", "ppl": "22.16", "wps": "48349.6", "ups": "0.45", "wpb": "107414", "bsz": "256", "num_updates": "11400", "lr": "0.000691478", "gnorm": "0.657", "train_wall": "399", "gb_free": "6.8", "wall": "25360"}
[2023-03-30 05:49:41,739][train_inner][INFO] - {"epoch": 11, "update": 10.632, "loss": "4.504", "ppl": "22.68", "wps": "48303", "ups": "0.45", "wpb": "107009", "bsz": "256", "num_updates": "11600", "lr": "0.000690261", "gnorm": "0.651", "train_wall": "398", "gb_free": "6.8", "wall": "25803"}
[2023-03-30 05:57:05,414][train_inner][INFO] - {"epoch": 11, "update": 10.816, "loss": "4.525", "ppl": "23.02", "wps": "48311.9", "ups": "0.45", "wpb": "107174", "bsz": "256", "num_updates": "11800", "lr": "0.000689043", "gnorm": "0.643", "train_wall": "399", "gb_free": "6.8", "wall": "26246"}
[2023-03-30 06:04:29,515][train_inner][INFO] - {"epoch": 11, "update": 10.999, "loss": "4.556", "ppl": "23.52", "wps": "48323.6", "ups": "0.45", "wpb": "107303", "bsz": "256", "num_updates": "12000", "lr": "0.000687826", "gnorm": "0.639", "train_wall": "399", "gb_free": "6.8", "wall": "26691"}
[2023-03-30 06:04:31,395][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 06:04:31,396][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 06:04:33,176][valid][INFO] - {"epoch": 11, "valid_loss": "4.557", "valid_ppl": "23.55", "valid_wps": "138939", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "12001", "valid_best_loss": "4.557"}
[2023-03-30 06:04:33,177][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 11 @ 12001 updates
[2023-03-30 06:04:33,177][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 06:04:34,608][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 06:04:35,202][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 11 @ 12001 updates, score 4.557) (writing took 2.0258565719996113 seconds)
[2023-03-30 06:04:35,203][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2023-03-30 06:04:35,203][train][INFO] - {"epoch": 11, "train_loss": "4.482", "train_ppl": "22.34", "train_wps": "48240.9", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "12001", "train_lr": "0.00068782", "train_gnorm": "0.651", "train_train_wall": "2176", "train_gb_free": "6.8", "train_wall": "26696"}
[2023-03-30 06:04:35,205][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 06:04:35,236][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 06:04:35,238][fairseq.trainer][INFO] - begin training epoch 12
[2023-03-30 06:04:35,239][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 06:11:57,332][train_inner][INFO] - {"epoch": 12, "update": 11.182, "loss": "4.269", "ppl": "19.28", "wps": "47920.6", "ups": "0.45", "wpb": "107298", "bsz": "255.8", "num_updates": "12200", "lr": "0.000686609", "gnorm": "0.655", "train_wall": "399", "gb_free": "6.8", "wall": "27138"}
[2023-03-30 06:19:20,974][train_inner][INFO] - {"epoch": 12, "update": 11.366, "loss": "4.35", "ppl": "20.4", "wps": "48292.8", "ups": "0.45", "wpb": "107124", "bsz": "256", "num_updates": "12400", "lr": "0.000685391", "gnorm": "0.653", "train_wall": "399", "gb_free": "6.8", "wall": "27582"}
[2023-03-30 06:26:44,142][train_inner][INFO] - {"epoch": 12, "update": 11.549, "loss": "4.39", "ppl": "20.97", "wps": "48296.2", "ups": "0.45", "wpb": "107016", "bsz": "256", "num_updates": "12600", "lr": "0.000684174", "gnorm": "0.648", "train_wall": "398", "gb_free": "6.8", "wall": "28025"}
[2023-03-30 06:34:07,990][train_inner][INFO] - {"epoch": 12, "update": 11.732, "loss": "4.427", "ppl": "21.51", "wps": "48323.8", "ups": "0.45", "wpb": "107242", "bsz": "256", "num_updates": "12800", "lr": "0.000682957", "gnorm": "0.647", "train_wall": "399", "gb_free": "6.8", "wall": "28469"}
[2023-03-30 06:41:32,062][train_inner][INFO] - {"epoch": 12, "update": 11.916, "loss": "4.446", "ppl": "21.8", "wps": "48320.9", "ups": "0.45", "wpb": "107290", "bsz": "256", "num_updates": "13000", "lr": "0.000681739", "gnorm": "0.643", "train_wall": "399", "gb_free": "6.8", "wall": "28913"}
[2023-03-30 06:44:56,069][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 06:44:56,070][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 06:44:57,792][valid][INFO] - {"epoch": 12, "valid_loss": "4.539", "valid_ppl": "23.25", "valid_wps": "143606", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "13092", "valid_best_loss": "4.539"}
[2023-03-30 06:44:57,793][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 12 @ 13092 updates
[2023-03-30 06:44:57,794][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 06:44:59,147][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 06:44:59,902][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 12 @ 13092 updates, score 4.539) (writing took 2.108681155994418 seconds)
[2023-03-30 06:44:59,902][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2023-03-30 06:44:59,903][train][INFO] - {"epoch": 12, "train_loss": "4.384", "train_ppl": "20.88", "train_wps": "48237.7", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "13092", "train_lr": "0.000681179", "train_gnorm": "0.648", "train_train_wall": "2176", "train_gb_free": "6.8", "train_wall": "29121"}
[2023-03-30 06:44:59,905][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 06:44:59,952][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 06:44:59,956][fairseq.trainer][INFO] - begin training epoch 13
[2023-03-30 06:44:59,956][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 06:48:59,815][train_inner][INFO] - {"epoch": 13, "update": 12.099, "loss": "4.297", "ppl": "19.66", "wps": "47889.5", "ups": "0.45", "wpb": "107213", "bsz": "255.8", "num_updates": "13200", "lr": "0.000680522", "gnorm": "0.649", "train_wall": "399", "gb_free": "6.8", "wall": "29361"}
[2023-03-30 06:56:22,814][train_inner][INFO] - {"epoch": 13, "update": 12.282, "loss": "4.229", "ppl": "18.75", "wps": "48273.5", "ups": "0.45", "wpb": "106926", "bsz": "256", "num_updates": "13400", "lr": "0.000679304", "gnorm": "0.657", "train_wall": "398", "gb_free": "6.8", "wall": "29804"}
[2023-03-30 07:03:46,624][train_inner][INFO] - {"epoch": 13, "update": 12.466, "loss": "4.285", "ppl": "19.49", "wps": "48333.3", "ups": "0.45", "wpb": "107252", "bsz": "256", "num_updates": "13600", "lr": "0.000678087", "gnorm": "0.648", "train_wall": "399", "gb_free": "6.8", "wall": "30248"}
[2023-03-30 07:11:10,487][train_inner][INFO] - {"epoch": 13, "update": 12.649, "loss": "4.333", "ppl": "20.16", "wps": "48317.7", "ups": "0.45", "wpb": "107232", "bsz": "256", "num_updates": "13800", "lr": "0.00067687", "gnorm": "0.65", "train_wall": "399", "gb_free": "6.8", "wall": "30692"}
[2023-03-30 07:18:34,867][train_inner][INFO] - {"epoch": 13, "update": 12.832, "loss": "4.363", "ppl": "20.58", "wps": "48306.7", "ups": "0.45", "wpb": "107333", "bsz": "256", "num_updates": "14000", "lr": "0.000675652", "gnorm": "0.648", "train_wall": "400", "gb_free": "6.8", "wall": "31136"}
[2023-03-30 07:25:21,005][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 07:25:21,005][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 07:25:22,730][valid][INFO] - {"epoch": 13, "valid_loss": "4.538", "valid_ppl": "23.24", "valid_wps": "143559", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "14183", "valid_best_loss": "4.538"}
[2023-03-30 07:25:22,731][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 13 @ 14183 updates
[2023-03-30 07:25:22,732][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 07:25:24,006][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 07:25:24,676][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 13 @ 14183 updates, score 4.538) (writing took 1.945000717001676 seconds)
[2023-03-30 07:25:24,676][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2023-03-30 07:25:24,677][train][INFO] - {"epoch": 13, "train_loss": "4.302", "train_ppl": "19.73", "train_wps": "48236.2", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "14183", "train_lr": "0.000674538", "train_gnorm": "0.649", "train_train_wall": "2176", "train_gb_free": "6.8", "train_wall": "31546"}
[2023-03-30 07:25:24,681][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 07:25:24,720][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 07:25:24,722][fairseq.trainer][INFO] - begin training epoch 14
[2023-03-30 07:25:24,722][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 07:26:02,707][train_inner][INFO] - {"epoch": 14, "update": 13.016, "loss": "4.356", "ppl": "20.47", "wps": "47896.3", "ups": "0.45", "wpb": "107249", "bsz": "255.8", "num_updates": "14200", "lr": "0.000674435", "gnorm": "0.644", "train_wall": "399", "gb_free": "6.8", "wall": "31584"}
[2023-03-30 07:33:26,338][train_inner][INFO] - {"epoch": 14, "update": 13.199, "loss": "4.118", "ppl": "17.36", "wps": "48324.6", "ups": "0.45", "wpb": "107191", "bsz": "256", "num_updates": "14400", "lr": "0.000673217", "gnorm": "0.659", "train_wall": "399", "gb_free": "6.8", "wall": "32027"}
[2023-03-30 07:40:50,357][train_inner][INFO] - {"epoch": 14, "update": 13.382, "loss": "4.196", "ppl": "18.33", "wps": "48329.4", "ups": "0.45", "wpb": "107294", "bsz": "256", "num_updates": "14600", "lr": "0.000672", "gnorm": "0.658", "train_wall": "399", "gb_free": "6.8", "wall": "32471"}
[2023-03-30 07:48:14,171][train_inner][INFO] - {"epoch": 14, "update": 13.566, "loss": "4.24", "ppl": "18.89", "wps": "48327.3", "ups": "0.45", "wpb": "107242", "bsz": "256", "num_updates": "14800", "lr": "0.000670783", "gnorm": "0.654", "train_wall": "399", "gb_free": "6.8", "wall": "32915"}
[2023-03-30 07:55:37,797][train_inner][INFO] - {"epoch": 14, "update": 13.749, "loss": "4.288", "ppl": "19.54", "wps": "48317.2", "ups": "0.45", "wpb": "107174", "bsz": "256", "num_updates": "15000", "lr": "0.000669565", "gnorm": "0.651", "train_wall": "399", "gb_free": "6.8", "wall": "33359"}
[2023-03-30 08:03:01,326][train_inner][INFO] - {"epoch": 14, "update": 13.932, "loss": "4.303", "ppl": "19.74", "wps": "48301.2", "ups": "0.45", "wpb": "107115", "bsz": "256", "num_updates": "15200", "lr": "0.000668348", "gnorm": "0.65", "train_wall": "399", "gb_free": "6.8", "wall": "33802"}
[2023-03-30 08:05:45,768][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 08:05:45,769][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 08:05:47,510][valid][INFO] - {"epoch": 14, "valid_loss": "4.521", "valid_ppl": "22.96", "valid_wps": "142612", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "15274", "valid_best_loss": "4.521"}
[2023-03-30 08:05:47,511][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 14 @ 15274 updates
[2023-03-30 08:05:47,512][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 08:05:48,419][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 08:05:49,010][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 14 @ 15274 updates, score 4.521) (writing took 1.4988690710015362 seconds)
[2023-03-30 08:05:49,011][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2023-03-30 08:05:49,013][train][INFO] - {"epoch": 14, "train_loss": "4.232", "train_ppl": "18.79", "train_wps": "48245", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "15274", "train_lr": "0.000667897", "train_gnorm": "0.654", "train_train_wall": "2176", "train_gb_free": "6.8", "train_wall": "33970"}
[2023-03-30 08:05:49,020][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 08:05:49,077][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 08:05:49,081][fairseq.trainer][INFO] - begin training epoch 15
[2023-03-30 08:05:49,082][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 08:10:29,305][train_inner][INFO] - {"epoch": 15, "update": 14.115, "loss": "4.133", "ppl": "17.54", "wps": "47913.1", "ups": "0.45", "wpb": "107320", "bsz": "255.8", "num_updates": "15400", "lr": "0.00066713", "gnorm": "0.654", "train_wall": "400", "gb_free": "6.8", "wall": "34250"}
[2023-03-30 08:17:53,353][train_inner][INFO] - {"epoch": 15, "update": 14.299, "loss": "4.104", "ppl": "17.2", "wps": "48346.3", "ups": "0.45", "wpb": "107340", "bsz": "256", "num_updates": "15600", "lr": "0.000665913", "gnorm": "0.657", "train_wall": "399", "gb_free": "6.8", "wall": "34694"}
[2023-03-30 08:25:16,914][train_inner][INFO] - {"epoch": 15, "update": 14.482, "loss": "4.166", "ppl": "17.95", "wps": "48279.8", "ups": "0.45", "wpb": "107075", "bsz": "256", "num_updates": "15800", "lr": "0.000664696", "gnorm": "0.661", "train_wall": "399", "gb_free": "6.8", "wall": "35138"}
[2023-03-30 08:32:42,795][train_inner][INFO] - {"epoch": 15, "update": 14.665, "loss": "4.204", "ppl": "18.43", "wps": "48221.4", "ups": "0.45", "wpb": "107505", "bsz": "256", "num_updates": "16000", "lr": "0.000663478", "gnorm": "0.656", "train_wall": "401", "gb_free": "6.8", "wall": "35584"}
[2023-03-30 08:40:09,497][train_inner][INFO] - {"epoch": 15, "update": 14.849, "loss": "4.232", "ppl": "18.8", "wps": "47862.2", "ups": "0.45", "wpb": "106900", "bsz": "256", "num_updates": "16200", "lr": "0.000662261", "gnorm": "0.663", "train_wall": "402", "gb_free": "6.8", "wall": "36031"}
[2023-03-30 08:46:16,106][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 08:46:16,107][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 08:46:17,895][valid][INFO] - {"epoch": 15, "valid_loss": "4.515", "valid_ppl": "22.87", "valid_wps": "138368", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "16365", "valid_best_loss": "4.515"}
[2023-03-30 08:46:17,896][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 15 @ 16365 updates
[2023-03-30 08:46:17,897][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 08:46:19,162][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_best.pt
[2023-03-30 08:46:19,922][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 15 @ 16365 updates, score 4.515) (writing took 2.026400103000924 seconds)
[2023-03-30 08:46:19,923][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2023-03-30 08:46:19,924][train][INFO] - {"epoch": 15, "train_loss": "4.171", "train_ppl": "18.01", "train_wps": "48114.5", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "16365", "train_lr": "0.000661257", "train_gnorm": "0.658", "train_train_wall": "2182", "train_gb_free": "6.8", "train_wall": "36401"}
[2023-03-30 08:46:19,927][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 08:46:19,967][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 08:46:19,969][fairseq.trainer][INFO] - begin training epoch 16
[2023-03-30 08:46:19,969][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 08:47:37,704][train_inner][INFO] - {"epoch": 16, "update": 15.032, "loss": "4.202", "ppl": "18.4", "wps": "47774", "ups": "0.45", "wpb": "107062", "bsz": "255.8", "num_updates": "16400", "lr": "0.000661043", "gnorm": "0.655", "train_wall": "399", "gb_free": "6.8", "wall": "36479"}
[2023-03-30 08:55:01,342][train_inner][INFO] - {"epoch": 16, "update": 15.215, "loss": "4.009", "ppl": "16.1", "wps": "48313.9", "ups": "0.45", "wpb": "107169", "bsz": "256", "num_updates": "16600", "lr": "0.000659826", "gnorm": "0.667", "train_wall": "399", "gb_free": "6.8", "wall": "36922"}
[2023-03-30 09:02:24,997][train_inner][INFO] - {"epoch": 16, "update": 15.399, "loss": "4.085", "ppl": "16.97", "wps": "48329.5", "ups": "0.45", "wpb": "107208", "bsz": "256", "num_updates": "16800", "lr": "0.000658609", "gnorm": "0.665", "train_wall": "399", "gb_free": "6.8", "wall": "37366"}
[2023-03-30 09:09:49,704][train_inner][INFO] - {"epoch": 16, "update": 15.582, "loss": "4.136", "ppl": "17.59", "wps": "48354.8", "ups": "0.45", "wpb": "107518", "bsz": "256", "num_updates": "17000", "lr": "0.000657391", "gnorm": "0.664", "train_wall": "400", "gb_free": "6.8", "wall": "37811"}
[2023-03-30 09:17:13,127][train_inner][INFO] - {"epoch": 16, "update": 15.765, "loss": "4.165", "ppl": "17.94", "wps": "48324", "ups": "0.45", "wpb": "107140", "bsz": "256", "num_updates": "17200", "lr": "0.000656174", "gnorm": "0.661", "train_wall": "399", "gb_free": "6.8", "wall": "38254"}
[2023-03-30 09:24:36,362][train_inner][INFO] - {"epoch": 16, "update": 15.949, "loss": "4.196", "ppl": "18.33", "wps": "48325.7", "ups": "0.45", "wpb": "107098", "bsz": "256", "num_updates": "17400", "lr": "0.000654957", "gnorm": "0.656", "train_wall": "398", "gb_free": "6.8", "wall": "38697"}
[2023-03-30 09:26:40,409][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 09:26:40,409][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 09:26:42,114][valid][INFO] - {"epoch": 16, "valid_loss": "4.527", "valid_ppl": "23.06", "valid_wps": "145104", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "17456", "valid_best_loss": "4.515"}
[2023-03-30 09:26:42,115][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 16 @ 17456 updates
[2023-03-30 09:26:42,116][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 09:26:43,597][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 09:26:43,619][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 16 @ 17456 updates, score 4.527) (writing took 1.503661529000965 seconds)
[2023-03-30 09:26:43,619][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2023-03-30 09:26:43,620][train][INFO] - {"epoch": 16, "train_loss": "4.117", "train_ppl": "17.36", "train_wps": "48257.7", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "17456", "train_lr": "0.000654616", "train_gnorm": "0.662", "train_train_wall": "2175", "train_gb_free": "6.8", "train_wall": "38825"}
[2023-03-30 09:26:43,622][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 09:26:43,652][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 09:26:43,654][fairseq.trainer][INFO] - begin training epoch 17
[2023-03-30 09:26:43,655][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 09:32:02,745][train_inner][INFO] - {"epoch": 17, "update": 16.132, "loss": "4.013", "ppl": "16.15", "wps": "47916.1", "ups": "0.45", "wpb": "106945", "bsz": "255.8", "num_updates": "17600", "lr": "0.000653739", "gnorm": "0.664", "train_wall": "398", "gb_free": "6.8", "wall": "39144"}
[2023-03-30 09:39:27,481][train_inner][INFO] - {"epoch": 17, "update": 16.315, "loss": "4.001", "ppl": "16.01", "wps": "48352.7", "ups": "0.45", "wpb": "107521", "bsz": "256", "num_updates": "17800", "lr": "0.000652522", "gnorm": "0.664", "train_wall": "400", "gb_free": "6.8", "wall": "39589"}
[2023-03-30 09:46:52,463][train_inner][INFO] - {"epoch": 17, "update": 16.499, "loss": "4.059", "ppl": "16.67", "wps": "48103.2", "ups": "0.45", "wpb": "107025", "bsz": "256", "num_updates": "18000", "lr": "0.000651304", "gnorm": "0.662", "train_wall": "400", "gb_free": "6.8", "wall": "40034"}
[2023-03-30 09:54:17,381][train_inner][INFO] - {"epoch": 17, "update": 16.682, "loss": "4.105", "ppl": "17.21", "wps": "48288.5", "ups": "0.45", "wpb": "107422", "bsz": "256", "num_updates": "18200", "lr": "0.000650087", "gnorm": "0.664", "train_wall": "400", "gb_free": "6.8", "wall": "40478"}
[2023-03-30 10:01:41,331][train_inner][INFO] - {"epoch": 17, "update": 16.865, "loss": "4.141", "ppl": "17.64", "wps": "48274.6", "ups": "0.45", "wpb": "107158", "bsz": "256", "num_updates": "18400", "lr": "0.00064887", "gnorm": "0.66", "train_wall": "399", "gb_free": "6.8", "wall": "40922"}
[2023-03-30 10:07:07,446][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 10:07:07,447][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 10:07:09,202][valid][INFO] - {"epoch": 17, "valid_loss": "4.523", "valid_ppl": "22.99", "valid_wps": "140814", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "18547", "valid_best_loss": "4.515"}
[2023-03-30 10:07:09,203][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 17 @ 18547 updates
[2023-03-30 10:07:09,204][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 10:07:11,435][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 10:07:11,456][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 17 @ 18547 updates, score 4.523) (writing took 2.253043657998205 seconds)
[2023-03-30 10:07:11,456][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2023-03-30 10:07:11,457][train][INFO] - {"epoch": 17, "train_loss": "4.07", "train_ppl": "16.79", "train_wps": "48175.4", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "18547", "train_lr": "0.000647975", "train_gnorm": "0.663", "train_train_wall": "2178", "train_gb_free": "6.8", "train_wall": "41253"}
[2023-03-30 10:07:11,458][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 10:07:11,490][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 10:07:11,492][fairseq.trainer][INFO] - begin training epoch 18
[2023-03-30 10:07:11,493][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 10:09:09,806][train_inner][INFO] - {"epoch": 18, "update": 17.049, "loss": "4.082", "ppl": "16.94", "wps": "47802.2", "ups": "0.45", "wpb": "107190", "bsz": "255.8", "num_updates": "18600", "lr": "0.000647652", "gnorm": "0.661", "train_wall": "399", "gb_free": "6.8", "wall": "41371"}
[2023-03-30 10:16:33,691][train_inner][INFO] - {"epoch": 18, "update": 17.232, "loss": "3.927", "ppl": "15.21", "wps": "48291.5", "ups": "0.45", "wpb": "107180", "bsz": "256", "num_updates": "18800", "lr": "0.000646435", "gnorm": "0.663", "train_wall": "399", "gb_free": "6.8", "wall": "41815"}
[2023-03-30 10:23:57,642][train_inner][INFO] - {"epoch": 18, "update": 17.415, "loss": "3.99", "ppl": "15.89", "wps": "48264.9", "ups": "0.45", "wpb": "107136", "bsz": "256", "num_updates": "19000", "lr": "0.000645217", "gnorm": "0.669", "train_wall": "399", "gb_free": "6.8", "wall": "42259"}
[2023-03-30 10:31:20,743][train_inner][INFO] - {"epoch": 18, "update": 17.599, "loss": "4.046", "ppl": "16.52", "wps": "48307.5", "ups": "0.45", "wpb": "107025", "bsz": "256", "num_updates": "19200", "lr": "0.000644", "gnorm": "0.668", "train_wall": "398", "gb_free": "6.8", "wall": "42702"}
[2023-03-30 10:38:44,884][train_inner][INFO] - {"epoch": 18, "update": 17.782, "loss": "4.084", "ppl": "16.96", "wps": "48282.6", "ups": "0.45", "wpb": "107221", "bsz": "256", "num_updates": "19400", "lr": "0.000642783", "gnorm": "0.664", "train_wall": "399", "gb_free": "6.8", "wall": "43146"}
[2023-03-30 10:46:08,816][train_inner][INFO] - {"epoch": 18, "update": 17.965, "loss": "4.109", "ppl": "17.25", "wps": "48340.7", "ups": "0.45", "wpb": "107300", "bsz": "256", "num_updates": "19600", "lr": "0.000641565", "gnorm": "0.663", "train_wall": "399", "gb_free": "6.8", "wall": "43590"}
[2023-03-30 10:47:33,309][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 10:47:33,309][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 10:47:34,986][valid][INFO] - {"epoch": 18, "valid_loss": "4.537", "valid_ppl": "23.22", "valid_wps": "147469", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "19638", "valid_best_loss": "4.515"}
[2023-03-30 10:47:34,987][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 18 @ 19638 updates
[2023-03-30 10:47:34,988][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 10:47:36,451][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 10:47:36,471][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 18 @ 19638 updates, score 4.537) (writing took 1.4838324320007814 seconds)
[2023-03-30 10:47:36,471][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2023-03-30 10:47:36,472][train][INFO] - {"epoch": 18, "train_loss": "4.026", "train_ppl": "16.29", "train_wps": "48231.5", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "19638", "train_lr": "0.000641334", "train_gnorm": "0.666", "train_train_wall": "2177", "train_gb_free": "6.8", "train_wall": "43678"}
[2023-03-30 10:47:36,473][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 10:47:36,504][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 10:47:36,506][fairseq.trainer][INFO] - begin training epoch 19
[2023-03-30 10:47:36,507][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 10:53:35,265][train_inner][INFO] - {"epoch": 19, "update": 18.148, "loss": "3.9", "ppl": "14.93", "wps": "47958.5", "ups": "0.45", "wpb": "107055", "bsz": "255.8", "num_updates": "19800", "lr": "0.000640348", "gnorm": "0.67", "train_wall": "398", "gb_free": "6.8", "wall": "44036"}
[2023-03-30 11:01:00,290][train_inner][INFO] - {"epoch": 19, "update": 18.332, "loss": "3.928", "ppl": "15.22", "wps": "48365.3", "ups": "0.45", "wpb": "107619", "bsz": "256", "num_updates": "20000", "lr": "0.00063913", "gnorm": "0.67", "train_wall": "400", "gb_free": "6.8", "wall": "44481"}
[2023-03-30 11:08:36,426][train_inner][INFO] - {"epoch": 19, "update": 18.515, "loss": "3.987", "ppl": "15.86", "wps": "47053.5", "ups": "0.44", "wpb": "107314", "bsz": "256", "num_updates": "20200", "lr": "0.000637913", "gnorm": "0.67", "train_wall": "409", "gb_free": "6.8", "wall": "44937"}
[2023-03-30 11:16:24,668][train_inner][INFO] - {"epoch": 19, "update": 18.698, "loss": "4.025", "ppl": "16.28", "wps": "45724.7", "ups": "0.43", "wpb": "107051", "bsz": "256", "num_updates": "20400", "lr": "0.000636696", "gnorm": "0.67", "train_wall": "419", "gb_free": "6.8", "wall": "45406"}
[2023-03-30 11:24:07,377][train_inner][INFO] - {"epoch": 19, "update": 18.882, "loss": "4.058", "ppl": "16.66", "wps": "46350.8", "ups": "0.43", "wpb": "107235", "bsz": "256", "num_updates": "20600", "lr": "0.000635478", "gnorm": "0.671", "train_wall": "416", "gb_free": "6.8", "wall": "45868"}
[2023-03-30 11:29:01,994][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 11:29:01,995][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 11:29:03,899][valid][INFO] - {"epoch": 19, "valid_loss": "4.525", "valid_ppl": "23.02", "valid_wps": "130166", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "20729", "valid_best_loss": "4.515"}
[2023-03-30 11:29:03,900][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 19 @ 20729 updates
[2023-03-30 11:29:03,901][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 11:29:05,007][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 11:29:05,030][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 19 @ 20729 updates, score 4.525) (writing took 1.129667036999308 seconds)
[2023-03-30 11:29:05,030][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2023-03-30 11:29:05,030][train][INFO] - {"epoch": 19, "train_loss": "3.987", "train_ppl": "15.86", "train_wps": "46999.9", "train_ups": "0.44", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "20729", "train_lr": "0.000634693", "train_gnorm": "0.67", "train_train_wall": "2230", "train_gb_free": "6.8", "train_wall": "46166"}
[2023-03-30 11:29:05,032][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 11:29:05,063][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 11:29:05,065][fairseq.trainer][INFO] - begin training epoch 20
[2023-03-30 11:29:05,066][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 11:31:46,644][train_inner][INFO] - {"epoch": 20, "update": 19.065, "loss": "3.98", "ppl": "15.78", "wps": "46598.5", "ups": "0.44", "wpb": "107006", "bsz": "255.8", "num_updates": "20800", "lr": "0.000634261", "gnorm": "0.671", "train_wall": "410", "gb_free": "6.8", "wall": "46328"}
[2023-03-30 11:39:30,881][train_inner][INFO] - {"epoch": 20, "update": 19.248, "loss": "3.857", "ppl": "14.49", "wps": "46157.4", "ups": "0.43", "wpb": "107140", "bsz": "256", "num_updates": "21000", "lr": "0.000633043", "gnorm": "0.671", "train_wall": "417", "gb_free": "6.8", "wall": "46792"}
[2023-03-30 11:47:17,358][train_inner][INFO] - {"epoch": 20, "update": 19.432, "loss": "3.921", "ppl": "15.15", "wps": "45944", "ups": "0.43", "wpb": "107159", "bsz": "256", "num_updates": "21200", "lr": "0.000631826", "gnorm": "0.675", "train_wall": "418", "gb_free": "6.8", "wall": "47258"}
[2023-03-30 11:55:01,168][train_inner][INFO] - {"epoch": 20, "update": 19.615, "loss": "3.973", "ppl": "15.7", "wps": "46224.2", "ups": "0.43", "wpb": "107196", "bsz": "256", "num_updates": "21400", "lr": "0.000630609", "gnorm": "0.674", "train_wall": "416", "gb_free": "6.8", "wall": "47722"}
[2023-03-30 12:02:38,202][train_inner][INFO] - {"epoch": 20, "update": 19.798, "loss": "4.01", "ppl": "16.11", "wps": "46899.3", "ups": "0.44", "wpb": "107173", "bsz": "256", "num_updates": "21600", "lr": "0.000629391", "gnorm": "0.67", "train_wall": "411", "gb_free": "6.8", "wall": "48179"}
[2023-03-30 12:10:05,971][train_inner][INFO] - {"epoch": 20, "update": 19.982, "loss": "4.045", "ppl": "16.51", "wps": "48002.4", "ups": "0.45", "wpb": "107468", "bsz": "256", "num_updates": "21800", "lr": "0.000628174", "gnorm": "0.675", "train_wall": "403", "gb_free": "6.8", "wall": "48627"}
[2023-03-30 12:10:50,448][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 12:10:50,449][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 12:10:52,135][valid][INFO] - {"epoch": 20, "valid_loss": "4.545", "valid_ppl": "23.34", "valid_wps": "146749", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "21820", "valid_best_loss": "4.515"}
[2023-03-30 12:10:52,136][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 21820 updates
[2023-03-30 12:10:52,137][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 12:10:53,014][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 12:10:53,037][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 20 @ 21820 updates, score 4.545) (writing took 0.9008744720049435 seconds)
[2023-03-30 12:10:53,037][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2023-03-30 12:10:53,038][train][INFO] - {"epoch": 20, "train_loss": "3.951", "train_ppl": "15.47", "train_wps": "46635.4", "train_ups": "0.44", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "21820", "train_lr": "0.000628052", "train_gnorm": "0.673", "train_train_wall": "2250", "train_gb_free": "6.8", "train_wall": "48674"}
[2023-03-30 12:10:53,039][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 12:10:53,069][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 12:10:53,071][fairseq.trainer][INFO] - begin training epoch 21
[2023-03-30 12:10:53,072][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 12:17:32,558][train_inner][INFO] - {"epoch": 21, "update": 20.165, "loss": "3.806", "ppl": "13.99", "wps": "47921.7", "ups": "0.45", "wpb": "107006", "bsz": "255.8", "num_updates": "22000", "lr": "0.000626957", "gnorm": "0.674", "train_wall": "399", "gb_free": "6.8", "wall": "49074"}
[2023-03-30 12:24:55,914][train_inner][INFO] - {"epoch": 21, "update": 20.348, "loss": "3.864", "ppl": "14.56", "wps": "48339", "ups": "0.45", "wpb": "107157", "bsz": "256", "num_updates": "22200", "lr": "0.000625739", "gnorm": "0.676", "train_wall": "399", "gb_free": "6.8", "wall": "49517"}
[2023-03-30 12:32:19,194][train_inner][INFO] - {"epoch": 21, "update": 20.532, "loss": "3.92", "ppl": "15.13", "wps": "48387.8", "ups": "0.45", "wpb": "107247", "bsz": "256", "num_updates": "22400", "lr": "0.000624522", "gnorm": "0.68", "train_wall": "399", "gb_free": "6.8", "wall": "49960"}
[2023-03-30 12:39:42,323][train_inner][INFO] - {"epoch": 21, "update": 20.715, "loss": "3.965", "ppl": "15.61", "wps": "48445.4", "ups": "0.45", "wpb": "107338", "bsz": "256", "num_updates": "22600", "lr": "0.000623304", "gnorm": "0.675", "train_wall": "399", "gb_free": "6.8", "wall": "50403"}
[2023-03-30 12:47:04,866][train_inner][INFO] - {"epoch": 21, "update": 20.898, "loss": "3.995", "ppl": "15.94", "wps": "48429.2", "ups": "0.45", "wpb": "107160", "bsz": "256", "num_updates": "22800", "lr": "0.000622087", "gnorm": "0.668", "train_wall": "398", "gb_free": "6.8", "wall": "50846"}
[2023-03-30 12:51:10,669][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 12:51:10,670][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 12:51:12,391][valid][INFO] - {"epoch": 21, "valid_loss": "4.553", "valid_ppl": "23.47", "valid_wps": "143711", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "22911", "valid_best_loss": "4.515"}
[2023-03-30 12:51:12,392][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 21 @ 22911 updates
[2023-03-30 12:51:12,393][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 12:51:14,204][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 12:51:14,228][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 21 @ 22911 updates, score 4.553) (writing took 1.8351960649961256 seconds)
[2023-03-30 12:51:14,228][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2023-03-30 12:51:14,228][train][INFO] - {"epoch": 21, "train_loss": "3.918", "train_ppl": "15.12", "train_wps": "48307.6", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "22911", "train_lr": "0.000621411", "train_gnorm": "0.675", "train_train_wall": "2174", "train_gb_free": "6.8", "train_wall": "51095"}
[2023-03-30 12:51:14,230][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 12:51:14,260][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 12:51:14,263][fairseq.trainer][INFO] - begin training epoch 22
[2023-03-30 12:51:14,263][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 12:54:31,507][train_inner][INFO] - {"epoch": 22, "update": 21.082, "loss": "3.888", "ppl": "14.81", "wps": "48042.3", "ups": "0.45", "wpb": "107286", "bsz": "255.8", "num_updates": "23000", "lr": "0.00062087", "gnorm": "0.677", "train_wall": "398", "gb_free": "6.8", "wall": "51293"}
[2023-03-30 13:01:53,972][train_inner][INFO] - {"epoch": 22, "update": 21.265, "loss": "3.802", "ppl": "13.95", "wps": "48318.8", "ups": "0.45", "wpb": "106897", "bsz": "256", "num_updates": "23200", "lr": "0.000619652", "gnorm": "0.679", "train_wall": "398", "gb_free": "6.8", "wall": "51735"}
[2023-03-30 13:09:16,515][train_inner][INFO] - {"epoch": 22, "update": 21.448, "loss": "3.866", "ppl": "14.58", "wps": "48406.8", "ups": "0.45", "wpb": "107111", "bsz": "256", "num_updates": "23400", "lr": "0.000618435", "gnorm": "0.68", "train_wall": "398", "gb_free": "6.8", "wall": "52178"}
[2023-03-30 13:16:39,595][train_inner][INFO] - {"epoch": 22, "update": 21.632, "loss": "3.912", "ppl": "15.05", "wps": "48443.7", "ups": "0.45", "wpb": "107322", "bsz": "256", "num_updates": "23600", "lr": "0.000617217", "gnorm": "0.675", "train_wall": "398", "gb_free": "6.8", "wall": "52621"}
[2023-03-30 13:24:02,742][train_inner][INFO] - {"epoch": 22, "update": 21.815, "loss": "3.951", "ppl": "15.47", "wps": "48454.1", "ups": "0.45", "wpb": "107361", "bsz": "256", "num_updates": "23800", "lr": "0.000616", "gnorm": "0.677", "train_wall": "399", "gb_free": "6.8", "wall": "53064"}
[2023-03-30 13:31:26,264][train_inner][INFO] - {"epoch": 22, "update": 21.998, "loss": "3.981", "ppl": "15.79", "wps": "48433.8", "ups": "0.45", "wpb": "107407", "bsz": "256", "num_updates": "24000", "lr": "0.000614783", "gnorm": "0.673", "train_wall": "399", "gb_free": "6.8", "wall": "53507"}
[2023-03-30 13:31:30,443][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 13:31:30,444][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 13:31:32,120][valid][INFO] - {"epoch": 22, "valid_loss": "4.562", "valid_ppl": "23.62", "valid_wps": "147545", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "24002", "valid_best_loss": "4.515"}
[2023-03-30 13:31:32,121][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 22 @ 24002 updates
[2023-03-30 13:31:32,122][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 13:31:33,750][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 13:31:33,779][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 22 @ 24002 updates, score 4.562) (writing took 1.658652591999271 seconds)
[2023-03-30 13:31:33,780][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2023-03-30 13:31:33,780][train][INFO] - {"epoch": 22, "train_loss": "3.888", "train_ppl": "14.81", "train_wps": "48340.4", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "24002", "train_lr": "0.00061477", "train_gnorm": "0.677", "train_train_wall": "2173", "train_gb_free": "6.8", "train_wall": "53515"}
[2023-03-30 13:31:33,782][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 13:31:33,812][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 13:31:33,814][fairseq.trainer][INFO] - begin training epoch 23
[2023-03-30 13:31:33,814][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 13:38:52,348][train_inner][INFO] - {"epoch": 23, "update": 22.181, "loss": "3.729", "ppl": "13.26", "wps": "48043.8", "ups": "0.45", "wpb": "107158", "bsz": "255.8", "num_updates": "24200", "lr": "0.000613565", "gnorm": "0.683", "train_wall": "398", "gb_free": "6.8", "wall": "53953"}
[2023-03-30 13:46:14,436][train_inner][INFO] - {"epoch": 23, "update": 22.365, "loss": "3.815", "ppl": "14.07", "wps": "48399.4", "ups": "0.45", "wpb": "106984", "bsz": "256", "num_updates": "24400", "lr": "0.000612348", "gnorm": "0.681", "train_wall": "397", "gb_free": "6.8", "wall": "54395"}
[2023-03-30 13:53:37,427][train_inner][INFO] - {"epoch": 23, "update": 22.548, "loss": "3.863", "ppl": "14.55", "wps": "48459.5", "ups": "0.45", "wpb": "107336", "bsz": "256", "num_updates": "24600", "lr": "0.00061113", "gnorm": "0.681", "train_wall": "398", "gb_free": "6.8", "wall": "54838"}
[2023-03-30 14:01:00,123][train_inner][INFO] - {"epoch": 23, "update": 22.731, "loss": "3.908", "ppl": "15.01", "wps": "48405.1", "ups": "0.45", "wpb": "107144", "bsz": "256", "num_updates": "24800", "lr": "0.000609913", "gnorm": "0.679", "train_wall": "398", "gb_free": "6.8", "wall": "55281"}
[2023-03-30 14:08:22,983][train_inner][INFO] - {"epoch": 23, "update": 22.915, "loss": "3.937", "ppl": "15.32", "wps": "48434.2", "ups": "0.45", "wpb": "107248", "bsz": "256", "num_updates": "25000", "lr": "0.000608696", "gnorm": "0.678", "train_wall": "398", "gb_free": "6.8", "wall": "55724"}
[2023-03-30 14:11:49,081][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 14:11:49,081][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 14:11:50,793][valid][INFO] - {"epoch": 23, "valid_loss": "4.564", "valid_ppl": "23.66", "valid_wps": "144601", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "25093", "valid_best_loss": "4.515"}
[2023-03-30 14:11:50,794][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 23 @ 25093 updates
[2023-03-30 14:11:50,795][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 14:11:51,641][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 14:11:51,664][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 23 @ 25093 updates, score 4.564) (writing took 0.8701057529979153 seconds)
[2023-03-30 14:11:51,664][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2023-03-30 14:11:51,664][train][INFO] - {"epoch": 23, "train_loss": "3.859", "train_ppl": "14.51", "train_wps": "48373.7", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "25093", "train_lr": "0.00060813", "train_gnorm": "0.68", "train_train_wall": "2172", "train_gb_free": "6.8", "train_wall": "55933"}
[2023-03-30 14:11:51,666][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 14:11:51,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 14:11:51,700][fairseq.trainer][INFO] - begin training epoch 24
[2023-03-30 14:11:51,700][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 14:15:48,187][train_inner][INFO] - {"epoch": 24, "update": 23.098, "loss": "3.809", "ppl": "14.01", "wps": "48122.3", "ups": "0.45", "wpb": "107121", "bsz": "255.8", "num_updates": "25200", "lr": "0.000607478", "gnorm": "0.677", "train_wall": "398", "gb_free": "6.8", "wall": "56169"}
[2023-03-30 14:23:11,396][train_inner][INFO] - {"epoch": 24, "update": 23.281, "loss": "3.759", "ppl": "13.54", "wps": "48419", "ups": "0.45", "wpb": "107298", "bsz": "256", "num_updates": "25400", "lr": "0.000606261", "gnorm": "0.69", "train_wall": "399", "gb_free": "6.8", "wall": "56612"}
[2023-03-30 14:30:33,603][train_inner][INFO] - {"epoch": 24, "update": 23.465, "loss": "3.811", "ppl": "14.04", "wps": "48409.7", "ups": "0.45", "wpb": "107035", "bsz": "256", "num_updates": "25600", "lr": "0.000605043", "gnorm": "0.682", "train_wall": "398", "gb_free": "6.8", "wall": "57055"}
[2023-03-30 14:37:57,130][train_inner][INFO] - {"epoch": 24, "update": 23.648, "loss": "3.861", "ppl": "14.53", "wps": "48447.1", "ups": "0.45", "wpb": "107438", "bsz": "256", "num_updates": "25800", "lr": "0.000603826", "gnorm": "0.684", "train_wall": "399", "gb_free": "6.8", "wall": "57498"}
[2023-03-30 14:45:20,339][train_inner][INFO] - {"epoch": 24, "update": 23.831, "loss": "3.897", "ppl": "14.89", "wps": "48453.6", "ups": "0.45", "wpb": "107375", "bsz": "256", "num_updates": "26000", "lr": "0.000602609", "gnorm": "0.683", "train_wall": "399", "gb_free": "6.8", "wall": "57941"}
[2023-03-30 14:52:07,235][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 14:52:07,236][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 14:52:08,957][valid][INFO] - {"epoch": 24, "valid_loss": "4.594", "valid_ppl": "24.16", "valid_wps": "143841", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "26184", "valid_best_loss": "4.515"}
[2023-03-30 14:52:08,958][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 24 @ 26184 updates
[2023-03-30 14:52:08,959][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 14:52:09,800][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 14:52:09,825][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 24 @ 26184 updates, score 4.594) (writing took 0.8671569700090913 seconds)
[2023-03-30 14:52:09,825][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2023-03-30 14:52:09,826][train][INFO] - {"epoch": 24, "train_loss": "3.833", "train_ppl": "14.26", "train_wps": "48368.2", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "26184", "train_lr": "0.000601489", "train_gnorm": "0.684", "train_train_wall": "2172", "train_gb_free": "6.8", "train_wall": "58351"}
[2023-03-30 14:52:09,827][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 14:52:09,859][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 14:52:09,861][fairseq.trainer][INFO] - begin training epoch 25
[2023-03-30 14:52:09,861][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 14:52:45,585][train_inner][INFO] - {"epoch": 25, "update": 24.015, "loss": "3.906", "ppl": "14.99", "wps": "48086.6", "ups": "0.45", "wpb": "107052", "bsz": "255.8", "num_updates": "26200", "lr": "0.000601391", "gnorm": "0.683", "train_wall": "398", "gb_free": "6.8", "wall": "58387"}
[2023-03-30 15:00:08,141][train_inner][INFO] - {"epoch": 25, "update": 24.198, "loss": "3.693", "ppl": "12.93", "wps": "48394.2", "ups": "0.45", "wpb": "107086", "bsz": "256", "num_updates": "26400", "lr": "0.000600174", "gnorm": "0.681", "train_wall": "398", "gb_free": "6.8", "wall": "58829"}
[2023-03-30 15:07:44,372][train_inner][INFO] - {"epoch": 25, "update": 24.381, "loss": "3.767", "ppl": "13.61", "wps": "46992.2", "ups": "0.44", "wpb": "107197", "bsz": "256", "num_updates": "26600", "lr": "0.000598957", "gnorm": "0.691", "train_wall": "410", "gb_free": "6.8", "wall": "59285"}
[2023-03-30 15:15:36,736][train_inner][INFO] - {"epoch": 25, "update": 24.565, "loss": "3.812", "ppl": "14.04", "wps": "45515.6", "ups": "0.42", "wpb": "107500", "bsz": "256", "num_updates": "26800", "lr": "0.000597739", "gnorm": "0.68", "train_wall": "424", "gb_free": "6.8", "wall": "59758"}
[2023-03-30 15:23:25,472][train_inner][INFO] - {"epoch": 25, "update": 24.748, "loss": "3.855", "ppl": "14.47", "wps": "45637.6", "ups": "0.43", "wpb": "106960", "bsz": "256", "num_updates": "27000", "lr": "0.000596522", "gnorm": "0.682", "train_wall": "420", "gb_free": "6.8", "wall": "60227"}
[2023-03-30 15:31:04,483][train_inner][INFO] - {"epoch": 25, "update": 24.931, "loss": "3.896", "ppl": "14.89", "wps": "46797.4", "ups": "0.44", "wpb": "107403", "bsz": "256", "num_updates": "27200", "lr": "0.000595304", "gnorm": "0.684", "train_wall": "413", "gb_free": "6.8", "wall": "60686"}
[2023-03-30 15:33:54,524][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 15:33:54,525][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 15:33:56,257][valid][INFO] - {"epoch": 25, "valid_loss": "4.588", "valid_ppl": "24.05", "valid_wps": "142929", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "27275", "valid_best_loss": "4.515"}
[2023-03-30 15:33:56,258][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 25 @ 27275 updates
[2023-03-30 15:33:56,259][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 15:33:57,444][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 15:33:57,460][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 25 @ 27275 updates, score 4.588) (writing took 1.2017906340042828 seconds)
[2023-03-30 15:33:57,460][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2023-03-30 15:33:57,461][train][INFO] - {"epoch": 25, "train_loss": "3.809", "train_ppl": "14.02", "train_wps": "46642.3", "train_ups": "0.44", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "27275", "train_lr": "0.000594848", "train_gnorm": "0.684", "train_train_wall": "2249", "train_gb_free": "6.8", "train_wall": "60859"}
[2023-03-30 15:33:57,463][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 15:33:57,496][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 15:33:57,498][fairseq.trainer][INFO] - begin training epoch 26
[2023-03-30 15:33:57,498][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 15:38:47,496][train_inner][INFO] - {"epoch": 26, "update": 25.115, "loss": "3.743", "ppl": "13.38", "wps": "46307.4", "ups": "0.43", "wpb": "107204", "bsz": "255.8", "num_updates": "27400", "lr": "0.000594087", "gnorm": "0.687", "train_wall": "413", "gb_free": "6.8", "wall": "61149"}
[2023-03-30 15:46:33,230][train_inner][INFO] - {"epoch": 26, "update": 25.298, "loss": "3.711", "ppl": "13.1", "wps": "46125.4", "ups": "0.43", "wpb": "107411", "bsz": "256", "num_updates": "27600", "lr": "0.00059287", "gnorm": "0.683", "train_wall": "418", "gb_free": "6.8", "wall": "61614"}
[2023-03-30 15:54:13,783][train_inner][INFO] - {"epoch": 26, "update": 25.481, "loss": "3.77", "ppl": "13.64", "wps": "46625.2", "ups": "0.43", "wpb": "107367", "bsz": "256", "num_updates": "27800", "lr": "0.000591652", "gnorm": "0.685", "train_wall": "413", "gb_free": "6.8", "wall": "62075"}
[2023-03-30 16:02:10,248][train_inner][INFO] - {"epoch": 26, "update": 25.665, "loss": "3.82", "ppl": "14.12", "wps": "45005.8", "ups": "0.42", "wpb": "107218", "bsz": "256", "num_updates": "28000", "lr": "0.000590435", "gnorm": "0.687", "train_wall": "424", "gb_free": "6.8", "wall": "62551"}
[2023-03-30 16:10:10,967][train_inner][INFO] - {"epoch": 26, "update": 25.848, "loss": "3.855", "ppl": "14.47", "wps": "44590.4", "ups": "0.42", "wpb": "107177", "bsz": "256", "num_updates": "28200", "lr": "0.000589217", "gnorm": "0.686", "train_wall": "418", "gb_free": "6.8", "wall": "63032"}
[2023-03-30 16:16:38,594][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 16:16:38,595][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 16:16:40,516][valid][INFO] - {"epoch": 26, "valid_loss": "4.601", "valid_ppl": "24.26", "valid_wps": "128434", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "28366", "valid_best_loss": "4.515"}
[2023-03-30 16:16:40,517][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 26 @ 28366 updates
[2023-03-30 16:16:40,517][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 16:16:41,629][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 16:16:41,666][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 26 @ 28366 updates, score 4.601) (writing took 1.1492549999966286 seconds)
[2023-03-30 16:16:41,666][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2023-03-30 16:16:41,667][train][INFO] - {"epoch": 26, "train_loss": "3.785", "train_ppl": "13.79", "train_wps": "45613.3", "train_ups": "0.43", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "28366", "train_lr": "0.000588207", "train_gnorm": "0.686", "train_train_wall": "2280", "train_gb_free": "6.8", "train_wall": "63423"}
[2023-03-30 16:16:41,669][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 16:16:41,714][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 16:16:41,716][fairseq.trainer][INFO] - begin training epoch 27
[2023-03-30 16:16:41,716][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 16:18:00,734][train_inner][INFO] - {"epoch": 27, "update": 26.031, "loss": "3.83", "ppl": "14.22", "wps": "45460.1", "ups": "0.43", "wpb": "106778", "bsz": "255.8", "num_updates": "28400", "lr": "0.000588", "gnorm": "0.69", "train_wall": "418", "gb_free": "6.8", "wall": "63502"}
[2023-03-30 16:25:54,439][train_inner][INFO] - {"epoch": 27, "update": 26.214, "loss": "3.657", "ppl": "12.62", "wps": "45275.1", "ups": "0.42", "wpb": "107235", "bsz": "256", "num_updates": "28600", "lr": "0.000586783", "gnorm": "0.691", "train_wall": "417", "gb_free": "6.8", "wall": "63975"}
[2023-03-30 16:33:39,519][train_inner][INFO] - {"epoch": 27, "update": 26.398, "loss": "3.724", "ppl": "13.22", "wps": "46112.9", "ups": "0.43", "wpb": "107231", "bsz": "256", "num_updates": "28800", "lr": "0.000585565", "gnorm": "0.696", "train_wall": "417", "gb_free": "6.8", "wall": "64441"}
[2023-03-30 16:41:23,489][train_inner][INFO] - {"epoch": 27, "update": 26.581, "loss": "3.774", "ppl": "13.68", "wps": "46072.1", "ups": "0.43", "wpb": "106880", "bsz": "256", "num_updates": "29000", "lr": "0.000584348", "gnorm": "0.689", "train_wall": "416", "gb_free": "6.8", "wall": "64905"}
[2023-03-30 16:49:10,474][train_inner][INFO] - {"epoch": 27, "update": 26.764, "loss": "3.813", "ppl": "14.06", "wps": "46052.6", "ups": "0.43", "wpb": "107530", "bsz": "256", "num_updates": "29200", "lr": "0.00058313", "gnorm": "0.688", "train_wall": "418", "gb_free": "6.8", "wall": "65372"}
[2023-03-30 16:57:03,456][train_inner][INFO] - {"epoch": 27, "update": 26.948, "loss": "3.845", "ppl": "14.37", "wps": "45268.3", "ups": "0.42", "wpb": "107056", "bsz": "256", "num_updates": "29400", "lr": "0.000581913", "gnorm": "0.691", "train_wall": "418", "gb_free": "6.8", "wall": "65845"}
[2023-03-30 16:59:18,678][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 16:59:18,678][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 16:59:20,493][valid][INFO] - {"epoch": 27, "valid_loss": "4.602", "valid_ppl": "24.28", "valid_wps": "136570", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "29457", "valid_best_loss": "4.515"}
[2023-03-30 16:59:20,494][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 27 @ 29457 updates
[2023-03-30 16:59:20,495][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 16:59:21,761][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 16:59:21,795][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 27 @ 29457 updates, score 4.602) (writing took 1.3006155640032375 seconds)
[2023-03-30 16:59:21,795][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2023-03-30 16:59:21,796][train][INFO] - {"epoch": 27, "train_loss": "3.764", "train_ppl": "13.59", "train_wps": "45686", "train_ups": "0.43", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "29457", "train_lr": "0.000581566", "train_gnorm": "0.692", "train_train_wall": "2277", "train_gb_free": "6.8", "train_wall": "65983"}
[2023-03-30 16:59:21,797][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 16:59:21,830][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 16:59:21,832][fairseq.trainer][INFO] - begin training epoch 28
[2023-03-30 16:59:21,832][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 17:04:54,882][train_inner][INFO] - {"epoch": 28, "update": 27.131, "loss": "3.685", "ppl": "12.86", "wps": "45504.8", "ups": "0.42", "wpb": "107261", "bsz": "255.8", "num_updates": "29600", "lr": "0.000580696", "gnorm": "0.689", "train_wall": "419", "gb_free": "6.8", "wall": "66316"}
[2023-03-30 17:12:43,959][train_inner][INFO] - {"epoch": 28, "update": 27.314, "loss": "3.674", "ppl": "12.76", "wps": "45706.9", "ups": "0.43", "wpb": "107199", "bsz": "256", "num_updates": "29800", "lr": "0.000579478", "gnorm": "0.696", "train_wall": "421", "gb_free": "6.8", "wall": "66785"}
[2023-03-30 17:20:24,788][train_inner][INFO] - {"epoch": 28, "update": 27.498, "loss": "3.737", "ppl": "13.33", "wps": "46544.2", "ups": "0.43", "wpb": "107245", "bsz": "256", "num_updates": "30000", "lr": "0.000578261", "gnorm": "0.692", "train_wall": "414", "gb_free": "6.8", "wall": "67246"}
[2023-03-30 17:28:02,933][train_inner][INFO] - {"epoch": 28, "update": 27.681, "loss": "3.78", "ppl": "13.74", "wps": "46775.5", "ups": "0.44", "wpb": "107148", "bsz": "256", "num_updates": "30200", "lr": "0.000577043", "gnorm": "0.69", "train_wall": "412", "gb_free": "6.8", "wall": "67704"}
[2023-03-30 17:35:37,887][train_inner][INFO] - {"epoch": 28, "update": 27.864, "loss": "3.816", "ppl": "14.08", "wps": "47120.3", "ups": "0.44", "wpb": "107188", "bsz": "256", "num_updates": "30400", "lr": "0.000575826", "gnorm": "0.688", "train_wall": "409", "gb_free": "6.8", "wall": "68159"}
[2023-03-30 17:41:09,458][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 17:41:09,459][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 17:41:11,182][valid][INFO] - {"epoch": 28, "valid_loss": "4.618", "valid_ppl": "24.56", "valid_wps": "143596", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "30548", "valid_best_loss": "4.515"}
[2023-03-30 17:41:11,183][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 28 @ 30548 updates
[2023-03-30 17:41:11,184][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 17:41:12,860][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 17:41:12,891][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 28 @ 30548 updates, score 4.618) (writing took 1.7075668499892345 seconds)
[2023-03-30 17:41:12,891][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2023-03-30 17:41:12,891][train][INFO] - {"epoch": 28, "train_loss": "3.744", "train_ppl": "13.4", "train_wps": "46578.1", "train_ups": "0.43", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "30548", "train_lr": "0.000574925", "train_gnorm": "0.691", "train_train_wall": "2252", "train_gb_free": "6.8", "train_wall": "68494"}
[2023-03-30 17:41:12,893][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 17:41:12,923][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 17:41:12,925][fairseq.trainer][INFO] - begin training epoch 29
[2023-03-30 17:41:12,926][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 17:43:14,782][train_inner][INFO] - {"epoch": 29, "update": 28.048, "loss": "3.771", "ppl": "13.65", "wps": "46909.2", "ups": "0.44", "wpb": "107163", "bsz": "255.8", "num_updates": "30600", "lr": "0.000574609", "gnorm": "0.694", "train_wall": "407", "gb_free": "6.8", "wall": "68616"}
[2023-03-30 17:51:58,174][train_inner][INFO] - {"epoch": 29, "update": 28.231, "loss": "3.624", "ppl": "12.33", "wps": "40947.6", "ups": "0.38", "wpb": "107158", "bsz": "256", "num_updates": "30800", "lr": "0.000573391", "gnorm": "0.692", "train_wall": "461", "gb_free": "6.8", "wall": "69139"}
[2023-03-30 18:00:52,340][train_inner][INFO] - {"epoch": 29, "update": 28.414, "loss": "3.689", "ppl": "12.9", "wps": "40243", "ups": "0.37", "wpb": "107482", "bsz": "256", "num_updates": "31000", "lr": "0.000572174", "gnorm": "0.698", "train_wall": "480", "gb_free": "6.8", "wall": "69673"}
[2023-03-30 18:09:54,339][train_inner][INFO] - {"epoch": 29, "update": 28.598, "loss": "3.742", "ppl": "13.38", "wps": "39557.3", "ups": "0.37", "wpb": "107199", "bsz": "256", "num_updates": "31200", "lr": "0.000570957", "gnorm": "0.695", "train_wall": "486", "gb_free": "6.8", "wall": "70215"}
[2023-03-30 18:19:02,473][train_inner][INFO] - {"epoch": 29, "update": 28.781, "loss": "3.776", "ppl": "13.7", "wps": "39143.6", "ups": "0.36", "wpb": "107278", "bsz": "256", "num_updates": "31400", "lr": "0.000569739", "gnorm": "0.692", "train_wall": "488", "gb_free": "6.8", "wall": "70764"}
[2023-03-30 18:28:05,005][train_inner][INFO] - {"epoch": 29, "update": 28.964, "loss": "3.81", "ppl": "14.02", "wps": "39516.1", "ups": "0.37", "wpb": "107192", "bsz": "256", "num_updates": "31600", "lr": "0.000568522", "gnorm": "0.697", "train_wall": "482", "gb_free": "6.8", "wall": "71306"}
[2023-03-30 18:29:52,516][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 18:29:52,524][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 18:29:54,565][valid][INFO] - {"epoch": 29, "valid_loss": "4.63", "valid_ppl": "24.75", "valid_wps": "121999", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "31639", "valid_best_loss": "4.515"}
[2023-03-30 18:29:54,573][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 29 @ 31639 updates
[2023-03-30 18:29:54,575][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 18:29:55,670][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 18:29:55,698][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 29 @ 31639 updates, score 4.63) (writing took 1.1247921439935453 seconds)
[2023-03-30 18:29:55,698][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2023-03-30 18:29:55,699][train][INFO] - {"epoch": 29, "train_loss": "3.724", "train_ppl": "13.22", "train_wps": "40017", "train_ups": "0.37", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "31639", "train_lr": "0.000568284", "train_gnorm": "0.696", "train_train_wall": "2602", "train_gb_free": "6.8", "train_wall": "71417"}
[2023-03-30 18:29:55,700][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 18:29:55,733][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 18:29:55,735][fairseq.trainer][INFO] - begin training epoch 30
[2023-03-30 18:29:55,735][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 18:37:04,863][train_inner][INFO] - {"epoch": 30, "update": 29.148, "loss": "3.617", "ppl": "12.27", "wps": "39674", "ups": "0.37", "wpb": "107090", "bsz": "255.8", "num_updates": "31800", "lr": "0.000567304", "gnorm": "0.698", "train_wall": "481", "gb_free": "6.8", "wall": "71846"}
[2023-03-30 18:45:07,292][train_inner][INFO] - {"epoch": 30, "update": 29.331, "loss": "3.642", "ppl": "12.48", "wps": "44467.4", "ups": "0.41", "wpb": "107262", "bsz": "256", "num_updates": "32000", "lr": "0.000566087", "gnorm": "0.699", "train_wall": "435", "gb_free": "6.8", "wall": "72328"}
[2023-03-30 18:52:32,769][train_inner][INFO] - {"epoch": 30, "update": 29.514, "loss": "3.698", "ppl": "12.98", "wps": "48134.2", "ups": "0.45", "wpb": "107213", "bsz": "256", "num_updates": "32200", "lr": "0.00056487", "gnorm": "0.702", "train_wall": "400", "gb_free": "6.8", "wall": "72774"}
[2023-03-30 18:59:58,598][train_inner][INFO] - {"epoch": 30, "update": 29.698, "loss": "3.745", "ppl": "13.41", "wps": "48140.4", "ups": "0.45", "wpb": "107310", "bsz": "256", "num_updates": "32400", "lr": "0.000563652", "gnorm": "0.692", "train_wall": "400", "gb_free": "6.8", "wall": "73220"}
[2023-03-30 19:07:24,527][train_inner][INFO] - {"epoch": 30, "update": 29.881, "loss": "3.777", "ppl": "13.71", "wps": "48125.1", "ups": "0.45", "wpb": "107300", "bsz": "256", "num_updates": "32600", "lr": "0.000562435", "gnorm": "0.696", "train_wall": "400", "gb_free": "6.8", "wall": "73666"}
[2023-03-30 19:13:02,222][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 19:13:02,230][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 19:13:04,379][valid][INFO] - {"epoch": 30, "valid_loss": "4.628", "valid_ppl": "24.73", "valid_wps": "115047", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "32730", "valid_best_loss": "4.515"}
[2023-03-30 19:13:04,380][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 32730 updates
[2023-03-30 19:13:04,380][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 19:13:07,573][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 19:13:07,599][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 30 @ 32730 updates, score 4.628) (writing took 3.2196147149952594 seconds)
[2023-03-30 19:13:07,600][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2023-03-30 19:13:07,600][train][INFO] - {"epoch": 30, "train_loss": "3.705", "train_ppl": "13.04", "train_wps": "45125.9", "train_ups": "0.42", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "32730", "train_lr": "0.000561643", "train_gnorm": "0.697", "train_train_wall": "2326", "train_gb_free": "6.8", "train_wall": "74009"}
[2023-03-30 19:13:07,602][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 19:13:07,635][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 19:13:07,637][fairseq.trainer][INFO] - begin training epoch 31
[2023-03-30 19:13:07,637][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 19:16:23,720][train_inner][INFO] - {"epoch": 31, "update": 30.064, "loss": "3.707", "ppl": "13.06", "wps": "39649.8", "ups": "0.37", "wpb": "106893", "bsz": "255.8", "num_updates": "32800", "lr": "0.000561217", "gnorm": "0.693", "train_wall": "480", "gb_free": "6.8", "wall": "74205"}
[2023-03-30 19:25:18,170][train_inner][INFO] - {"epoch": 31, "update": 30.247, "loss": "3.597", "ppl": "12.1", "wps": "40091.5", "ups": "0.37", "wpb": "107134", "bsz": "256", "num_updates": "33000", "lr": "0.00056", "gnorm": "0.696", "train_wall": "481", "gb_free": "6.8", "wall": "74739"}
[2023-03-30 19:34:20,372][train_inner][INFO] - {"epoch": 31, "update": 30.431, "loss": "3.657", "ppl": "12.61", "wps": "39545.7", "ups": "0.37", "wpb": "107209", "bsz": "256", "num_updates": "33200", "lr": "0.000558783", "gnorm": "0.701", "train_wall": "487", "gb_free": "6.8", "wall": "75281"}
[2023-03-30 19:43:13,683][train_inner][INFO] - {"epoch": 31, "update": 30.614, "loss": "3.699", "ppl": "12.99", "wps": "40281.6", "ups": "0.38", "wpb": "107412", "bsz": "256", "num_updates": "33400", "lr": "0.000557565", "gnorm": "0.699", "train_wall": "479", "gb_free": "6.8", "wall": "75815"}
[2023-03-30 19:52:16,098][train_inner][INFO] - {"epoch": 31, "update": 30.797, "loss": "3.751", "ppl": "13.46", "wps": "39555", "ups": "0.37", "wpb": "107276", "bsz": "256", "num_updates": "33600", "lr": "0.000556348", "gnorm": "0.694", "train_wall": "488", "gb_free": "6.8", "wall": "76357"}
[2023-03-30 20:01:22,213][train_inner][INFO] - {"epoch": 31, "update": 30.981, "loss": "3.779", "ppl": "13.72", "wps": "39243.3", "ups": "0.37", "wpb": "107155", "bsz": "256", "num_updates": "33800", "lr": "0.00055513", "gnorm": "0.692", "train_wall": "492", "gb_free": "6.8", "wall": "76903"}
[2023-03-30 20:02:21,366][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 20:02:21,373][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 20:02:23,531][valid][INFO] - {"epoch": 31, "valid_loss": "4.641", "valid_ppl": "24.95", "valid_wps": "116791", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "33821", "valid_best_loss": "4.515"}
[2023-03-30 20:02:23,533][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 31 @ 33821 updates
[2023-03-30 20:02:23,534][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 20:02:25,425][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 20:02:25,446][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 31 @ 33821 updates, score 4.641) (writing took 1.9130415659892606 seconds)
[2023-03-30 20:02:25,447][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2023-03-30 20:02:25,447][train][INFO] - {"epoch": 31, "train_loss": "3.687", "train_ppl": "12.88", "train_wps": "39543", "train_ups": "0.37", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "33821", "train_lr": "0.000555003", "train_gnorm": "0.696", "train_train_wall": "2656", "train_gb_free": "6.8", "train_wall": "76966"}
[2023-03-30 20:02:25,449][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 20:02:25,482][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 20:02:25,485][fairseq.trainer][INFO] - begin training epoch 32
[2023-03-30 20:02:25,486][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 20:09:53,949][train_inner][INFO] - {"epoch": 32, "update": 31.164, "loss": "3.568", "ppl": "11.86", "wps": "41834", "ups": "0.39", "wpb": "107040", "bsz": "255.8", "num_updates": "34000", "lr": "0.000553913", "gnorm": "0.7", "train_wall": "457", "gb_free": "6.8", "wall": "77415"}
[2023-03-30 20:17:19,871][train_inner][INFO] - {"epoch": 32, "update": 31.347, "loss": "3.614", "ppl": "12.25", "wps": "48046.6", "ups": "0.45", "wpb": "107123", "bsz": "256", "num_updates": "34200", "lr": "0.000552696", "gnorm": "0.7", "train_wall": "400", "gb_free": "6.8", "wall": "77861"}
[2023-03-30 20:24:46,193][train_inner][INFO] - {"epoch": 32, "update": 31.531, "loss": "3.669", "ppl": "12.72", "wps": "48096.3", "ups": "0.45", "wpb": "107332", "bsz": "256", "num_updates": "34400", "lr": "0.000551478", "gnorm": "0.698", "train_wall": "401", "gb_free": "6.8", "wall": "78307"}
[2023-03-30 20:32:12,452][train_inner][INFO] - {"epoch": 32, "update": 31.714, "loss": "3.709", "ppl": "13.08", "wps": "48097.3", "ups": "0.45", "wpb": "107319", "bsz": "256", "num_updates": "34600", "lr": "0.000550261", "gnorm": "0.7", "train_wall": "401", "gb_free": "6.8", "wall": "78753"}
[2023-03-30 20:41:08,831][train_inner][INFO] - {"epoch": 32, "update": 31.897, "loss": "3.746", "ppl": "13.42", "wps": "39883.1", "ups": "0.37", "wpb": "106962", "bsz": "256", "num_updates": "34800", "lr": "0.000549043", "gnorm": "0.702", "train_wall": "484", "gb_free": "6.8", "wall": "79290"}
[2023-03-30 20:46:17,071][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 20:46:17,079][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 20:46:19,326][valid][INFO] - {"epoch": 32, "valid_loss": "4.652", "valid_ppl": "25.15", "valid_wps": "110034", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "34912", "valid_best_loss": "4.515"}
[2023-03-30 20:46:19,327][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 32 @ 34912 updates
[2023-03-30 20:46:19,328][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 20:46:20,435][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 20:46:20,468][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 32 @ 34912 updates, score 4.652) (writing took 1.1404586209973786 seconds)
[2023-03-30 20:46:20,468][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2023-03-30 20:46:20,469][train][INFO] - {"epoch": 32, "train_loss": "3.67", "train_ppl": "12.73", "train_wps": "44387.5", "train_ups": "0.41", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "34912", "train_lr": "0.000548362", "train_gnorm": "0.7", "train_train_wall": "2366", "train_gb_free": "6.8", "train_wall": "79602"}
[2023-03-30 20:46:20,471][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 20:46:20,508][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 20:46:20,510][fairseq.trainer][INFO] - begin training epoch 33
[2023-03-30 20:46:20,511][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 20:50:28,800][train_inner][INFO] - {"epoch": 33, "update": 32.081, "loss": "3.653", "ppl": "12.58", "wps": "38330.5", "ups": "0.36", "wpb": "107318", "bsz": "255.8", "num_updates": "35000", "lr": "0.000547826", "gnorm": "0.7", "train_wall": "499", "gb_free": "6.8", "wall": "79850"}
[2023-03-30 20:59:38,844][train_inner][INFO] - {"epoch": 33, "update": 32.264, "loss": "3.568", "ppl": "11.86", "wps": "39059", "ups": "0.36", "wpb": "107421", "bsz": "256", "num_updates": "35200", "lr": "0.000546609", "gnorm": "0.701", "train_wall": "494", "gb_free": "6.8", "wall": "80400"}
[2023-03-30 21:08:46,359][train_inner][INFO] - {"epoch": 33, "update": 32.447, "loss": "3.631", "ppl": "12.39", "wps": "39072.6", "ups": "0.37", "wpb": "106964", "bsz": "256", "num_updates": "35400", "lr": "0.000545391", "gnorm": "0.705", "train_wall": "492", "gb_free": "6.8", "wall": "80947"}
[2023-03-30 21:17:57,336][train_inner][INFO] - {"epoch": 33, "update": 32.631, "loss": "3.676", "ppl": "12.78", "wps": "38948.8", "ups": "0.36", "wpb": "107300", "bsz": "256", "num_updates": "35600", "lr": "0.000544174", "gnorm": "0.703", "train_wall": "495", "gb_free": "6.8", "wall": "81498"}
[2023-03-30 21:27:03,380][train_inner][INFO] - {"epoch": 33, "update": 32.814, "loss": "3.715", "ppl": "13.13", "wps": "39267.1", "ups": "0.37", "wpb": "107208", "bsz": "256", "num_updates": "35800", "lr": "0.000542957", "gnorm": "0.701", "train_wall": "491", "gb_free": "6.8", "wall": "82044"}
[2023-03-30 21:35:55,839][train_inner][INFO] - {"epoch": 33, "update": 32.997, "loss": "3.747", "ppl": "13.43", "wps": "40250.2", "ups": "0.38", "wpb": "107157", "bsz": "256", "num_updates": "36000", "lr": "0.000541739", "gnorm": "0.699", "train_wall": "478", "gb_free": "6.8", "wall": "82577"}
[2023-03-30 21:36:03,608][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 21:36:03,609][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 21:36:05,651][valid][INFO] - {"epoch": 33, "valid_loss": "4.679", "valid_ppl": "25.61", "valid_wps": "124058", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "36003", "valid_best_loss": "4.515"}
[2023-03-30 21:36:05,654][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 33 @ 36003 updates
[2023-03-30 21:36:05,655][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 21:36:07,555][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 21:36:07,584][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 33 @ 36003 updates, score 4.679) (writing took 1.9305090970010497 seconds)
[2023-03-30 21:36:07,585][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2023-03-30 21:36:07,586][train][INFO] - {"epoch": 33, "train_loss": "3.654", "train_ppl": "12.59", "train_wps": "39155.5", "train_ups": "0.37", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "36003", "train_lr": "0.000541721", "train_gnorm": "0.702", "train_train_wall": "2680", "train_gb_free": "6.8", "train_wall": "82589"}
[2023-03-30 21:36:07,588][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 21:36:07,622][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 21:36:07,625][fairseq.trainer][INFO] - begin training epoch 34
[2023-03-30 21:36:07,626][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 21:45:00,538][train_inner][INFO] - {"epoch": 34, "update": 33.181, "loss": "3.517", "ppl": "11.45", "wps": "39423.3", "ups": "0.37", "wpb": "107369", "bsz": "255.8", "num_updates": "36200", "lr": "0.000540522", "gnorm": "0.705", "train_wall": "484", "gb_free": "6.8", "wall": "83122"}
[2023-03-30 21:54:11,303][train_inner][INFO] - {"epoch": 34, "update": 33.364, "loss": "3.588", "ppl": "12.02", "wps": "38870.3", "ups": "0.36", "wpb": "107042", "bsz": "256", "num_updates": "36400", "lr": "0.000539304", "gnorm": "0.705", "train_wall": "492", "gb_free": "6.8", "wall": "83672"}
[2023-03-30 22:03:29,856][train_inner][INFO] - {"epoch": 34, "update": 33.547, "loss": "3.639", "ppl": "12.46", "wps": "38282.5", "ups": "0.36", "wpb": "106914", "bsz": "256", "num_updates": "36600", "lr": "0.000538087", "gnorm": "0.71", "train_wall": "501", "gb_free": "6.8", "wall": "84231"}
[2023-03-30 22:12:45,345][train_inner][INFO] - {"epoch": 34, "update": 33.731, "loss": "3.682", "ppl": "12.84", "wps": "38646.1", "ups": "0.36", "wpb": "107337", "bsz": "256", "num_updates": "36800", "lr": "0.00053687", "gnorm": "0.703", "train_wall": "496", "gb_free": "6.8", "wall": "84786"}
[2023-03-30 22:21:26,679][train_inner][INFO] - {"epoch": 34, "update": 33.914, "loss": "3.721", "ppl": "13.19", "wps": "41263", "ups": "0.38", "wpb": "107558", "bsz": "256", "num_updates": "37000", "lr": "0.000535652", "gnorm": "0.704", "train_wall": "467", "gb_free": "6.8", "wall": "85308"}
[2023-03-30 22:25:34,427][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 22:25:34,434][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 22:25:36,738][valid][INFO] - {"epoch": 34, "valid_loss": "4.68", "valid_ppl": "25.64", "valid_wps": "107537", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "37094", "valid_best_loss": "4.515"}
[2023-03-30 22:25:36,740][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 34 @ 37094 updates
[2023-03-30 22:25:36,741][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 22:25:37,925][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 22:25:37,956][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 34 @ 37094 updates, score 4.68) (writing took 1.2161366299988003 seconds)
[2023-03-30 22:25:37,956][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2023-03-30 22:25:37,957][train][INFO] - {"epoch": 34, "train_loss": "3.638", "train_ppl": "12.45", "train_wps": "39376.2", "train_ups": "0.37", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "37094", "train_lr": "0.00053508", "train_gnorm": "0.706", "train_train_wall": "2655", "train_gb_free": "6.8", "train_wall": "85559"}
[2023-03-30 22:25:37,959][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 22:25:37,992][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 22:25:37,994][fairseq.trainer][INFO] - begin training epoch 35
[2023-03-30 22:25:37,995][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 22:30:25,093][train_inner][INFO] - {"epoch": 35, "update": 34.097, "loss": "3.595", "ppl": "12.08", "wps": "39816", "ups": "0.37", "wpb": "107186", "bsz": "255.8", "num_updates": "37200", "lr": "0.000534435", "gnorm": "0.709", "train_wall": "479", "gb_free": "6.8", "wall": "85846"}
[2023-03-30 22:39:35,255][train_inner][INFO] - {"epoch": 35, "update": 34.28, "loss": "3.549", "ppl": "11.71", "wps": "38931.4", "ups": "0.36", "wpb": "107093", "bsz": "256", "num_updates": "37400", "lr": "0.000533217", "gnorm": "0.706", "train_wall": "493", "gb_free": "6.8", "wall": "86396"}
[2023-03-30 22:48:56,780][train_inner][INFO] - {"epoch": 35, "update": 34.464, "loss": "3.6", "ppl": "12.12", "wps": "38179.3", "ups": "0.36", "wpb": "107193", "bsz": "256", "num_updates": "37600", "lr": "0.000532", "gnorm": "0.717", "train_wall": "501", "gb_free": "6.8", "wall": "86958"}
[2023-03-30 22:58:03,741][train_inner][INFO] - {"epoch": 35, "update": 34.647, "loss": "3.653", "ppl": "12.58", "wps": "39241", "ups": "0.37", "wpb": "107316", "bsz": "256", "num_updates": "37800", "lr": "0.000530783", "gnorm": "0.708", "train_wall": "490", "gb_free": "6.8", "wall": "87505"}
[2023-03-30 23:07:02,467][train_inner][INFO] - {"epoch": 35, "update": 34.83, "loss": "3.687", "ppl": "12.88", "wps": "39672.6", "ups": "0.37", "wpb": "106863", "bsz": "256", "num_updates": "38000", "lr": "0.000529565", "gnorm": "0.706", "train_wall": "483", "gb_free": "6.8", "wall": "88044"}
[2023-03-30 23:15:29,163][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 23:15:29,171][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 23:15:31,329][valid][INFO] - {"epoch": 35, "valid_loss": "4.683", "valid_ppl": "25.68", "valid_wps": "114888", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "38185", "valid_best_loss": "4.515"}
[2023-03-30 23:15:31,332][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 35 @ 38185 updates
[2023-03-30 23:15:31,333][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 23:15:33,069][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 23:15:33,115][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 35 @ 38185 updates, score 4.683) (writing took 1.7833000579994405 seconds)
[2023-03-30 23:15:33,117][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2023-03-30 23:15:33,117][train][INFO] - {"epoch": 35, "train_loss": "3.623", "train_ppl": "12.32", "train_wps": "39050.3", "train_ups": "0.36", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "38185", "train_lr": "0.000528439", "train_gnorm": "0.709", "train_train_wall": "2679", "train_gb_free": "6.8", "train_wall": "88554"}
[2023-03-30 23:15:33,122][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 23:15:33,155][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 23:15:33,158][fairseq.trainer][INFO] - begin training epoch 36
[2023-03-30 23:15:33,158][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-30 23:16:14,411][train_inner][INFO] - {"epoch": 36, "update": 35.014, "loss": "3.691", "ppl": "12.91", "wps": "38914.6", "ups": "0.36", "wpb": "107392", "bsz": "255.8", "num_updates": "38200", "lr": "0.000528348", "gnorm": "0.71", "train_wall": "491", "gb_free": "6.8", "wall": "88595"}
[2023-03-30 23:24:03,010][train_inner][INFO] - {"epoch": 36, "update": 35.197, "loss": "3.493", "ppl": "11.26", "wps": "45736.5", "ups": "0.43", "wpb": "107160", "bsz": "256", "num_updates": "38400", "lr": "0.00052713", "gnorm": "0.709", "train_wall": "421", "gb_free": "6.8", "wall": "89064"}
[2023-03-30 23:31:25,957][train_inner][INFO] - {"epoch": 36, "update": 35.38, "loss": "3.567", "ppl": "11.85", "wps": "48272.5", "ups": "0.45", "wpb": "106911", "bsz": "256", "num_updates": "38600", "lr": "0.000525913", "gnorm": "0.712", "train_wall": "398", "gb_free": "6.8", "wall": "89507"}
[2023-03-30 23:38:53,972][train_inner][INFO] - {"epoch": 36, "update": 35.564, "loss": "3.615", "ppl": "12.25", "wps": "47845.1", "ups": "0.45", "wpb": "107177", "bsz": "256", "num_updates": "38800", "lr": "0.000524696", "gnorm": "0.708", "train_wall": "403", "gb_free": "6.8", "wall": "89955"}
[2023-03-30 23:46:22,484][train_inner][INFO] - {"epoch": 36, "update": 35.747, "loss": "3.66", "ppl": "12.64", "wps": "47890.2", "ups": "0.45", "wpb": "107396", "bsz": "256", "num_updates": "39000", "lr": "0.000523478", "gnorm": "0.713", "train_wall": "403", "gb_free": "6.8", "wall": "90404"}
[2023-03-30 23:53:50,697][train_inner][INFO] - {"epoch": 36, "update": 35.93, "loss": "3.681", "ppl": "12.82", "wps": "47836.9", "ups": "0.45", "wpb": "107206", "bsz": "256", "num_updates": "39200", "lr": "0.000522261", "gnorm": "0.702", "train_wall": "403", "gb_free": "6.8", "wall": "90852"}
[2023-03-30 23:56:41,350][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-30 23:56:41,350][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 23:56:43,085][valid][INFO] - {"epoch": 36, "valid_loss": "4.695", "valid_ppl": "25.9", "valid_wps": "142516", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "39276", "valid_best_loss": "4.515"}
[2023-03-30 23:56:43,086][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 36 @ 39276 updates
[2023-03-30 23:56:43,086][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 23:56:44,013][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-30 23:56:44,036][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 36 @ 39276 updates, score 4.695) (writing took 0.9500760659866501 seconds)
[2023-03-30 23:56:44,036][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2023-03-30 23:56:44,036][train][INFO] - {"epoch": 36, "train_loss": "3.608", "train_ppl": "12.2", "train_wps": "47335.5", "train_ups": "0.44", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "39276", "train_lr": "0.000521798", "train_gnorm": "0.709", "train_train_wall": "2218", "train_gb_free": "6.8", "train_wall": "91025"}
[2023-03-30 23:56:44,038][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-30 23:56:44,071][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-30 23:56:44,073][fairseq.trainer][INFO] - begin training epoch 37
[2023-03-30 23:56:44,074][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 00:01:21,880][train_inner][INFO] - {"epoch": 37, "update": 36.114, "loss": "3.554", "ppl": "11.74", "wps": "47558.3", "ups": "0.44", "wpb": "107288", "bsz": "255.8", "num_updates": "39400", "lr": "0.000521043", "gnorm": "0.711", "train_wall": "403", "gb_free": "6.8", "wall": "91303"}
[2023-03-31 00:08:49,876][train_inner][INFO] - {"epoch": 37, "update": 36.297, "loss": "3.522", "ppl": "11.49", "wps": "47861.1", "ups": "0.45", "wpb": "107208", "bsz": "256", "num_updates": "39600", "lr": "0.000519826", "gnorm": "0.709", "train_wall": "403", "gb_free": "6.8", "wall": "91751"}
[2023-03-31 00:16:17,494][train_inner][INFO] - {"epoch": 37, "update": 36.48, "loss": "3.583", "ppl": "11.99", "wps": "47839.4", "ups": "0.45", "wpb": "107069", "bsz": "256", "num_updates": "39800", "lr": "0.000518609", "gnorm": "0.715", "train_wall": "402", "gb_free": "6.8", "wall": "92199"}
[2023-03-31 00:23:45,321][train_inner][INFO] - {"epoch": 37, "update": 36.664, "loss": "3.62", "ppl": "12.3", "wps": "47851.7", "ups": "0.45", "wpb": "107146", "bsz": "256", "num_updates": "40000", "lr": "0.000517391", "gnorm": "0.706", "train_wall": "403", "gb_free": "6.8", "wall": "92646"}
[2023-03-31 00:31:14,312][train_inner][INFO] - {"epoch": 37, "update": 36.847, "loss": "3.663", "ppl": "12.67", "wps": "47905.8", "ups": "0.45", "wpb": "107546", "bsz": "256", "num_updates": "40200", "lr": "0.000516174", "gnorm": "0.709", "train_wall": "404", "gb_free": "6.8", "wall": "93095"}
[2023-03-31 00:37:28,136][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 00:37:28,137][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 00:37:29,897][valid][INFO] - {"epoch": 37, "valid_loss": "4.705", "valid_ppl": "26.09", "valid_wps": "141691", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "40367", "valid_best_loss": "4.515"}
[2023-03-31 00:37:29,898][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 37 @ 40367 updates
[2023-03-31 00:37:29,899][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 00:37:30,836][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 00:37:30,860][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 37 @ 40367 updates, score 4.705) (writing took 0.9614544100040803 seconds)
[2023-03-31 00:37:30,860][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2023-03-31 00:37:30,860][train][INFO] - {"epoch": 37, "train_loss": "3.595", "train_ppl": "12.08", "train_wps": "47801.6", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "40367", "train_lr": "0.000515157", "train_gnorm": "0.71", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "93472"}
[2023-03-31 00:37:30,862][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 00:37:30,894][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 00:37:30,896][fairseq.trainer][INFO] - begin training epoch 38
[2023-03-31 00:37:30,896][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 00:38:45,519][train_inner][INFO] - {"epoch": 38, "update": 37.03, "loss": "3.641", "ppl": "12.48", "wps": "47559.2", "ups": "0.44", "wpb": "107295", "bsz": "255.8", "num_updates": "40400", "lr": "0.000514957", "gnorm": "0.708", "train_wall": "403", "gb_free": "6.8", "wall": "93547"}
[2023-03-31 00:46:13,642][train_inner][INFO] - {"epoch": 38, "update": 37.214, "loss": "3.477", "ppl": "11.13", "wps": "47888", "ups": "0.45", "wpb": "107298", "bsz": "256", "num_updates": "40600", "lr": "0.000513739", "gnorm": "0.712", "train_wall": "403", "gb_free": "6.8", "wall": "93995"}
[2023-03-31 00:53:41,314][train_inner][INFO] - {"epoch": 38, "update": 37.397, "loss": "3.54", "ppl": "11.63", "wps": "47856", "ups": "0.45", "wpb": "107119", "bsz": "256", "num_updates": "40800", "lr": "0.000512522", "gnorm": "0.708", "train_wall": "402", "gb_free": "6.8", "wall": "94442"}
[2023-03-31 01:01:09,367][train_inner][INFO] - {"epoch": 38, "update": 37.58, "loss": "3.593", "ppl": "12.06", "wps": "47854.8", "ups": "0.45", "wpb": "107207", "bsz": "256", "num_updates": "41000", "lr": "0.000511304", "gnorm": "0.721", "train_wall": "403", "gb_free": "6.8", "wall": "94890"}
[2023-03-31 01:08:36,833][train_inner][INFO] - {"epoch": 38, "update": 37.764, "loss": "3.629", "ppl": "12.37", "wps": "47843.2", "ups": "0.45", "wpb": "107039", "bsz": "256", "num_updates": "41200", "lr": "0.000510087", "gnorm": "0.715", "train_wall": "402", "gb_free": "6.8", "wall": "95338"}
[2023-03-31 01:16:05,067][train_inner][INFO] - {"epoch": 38, "update": 37.947, "loss": "3.666", "ppl": "12.7", "wps": "47863.4", "ups": "0.45", "wpb": "107270", "bsz": "256", "num_updates": "41400", "lr": "0.00050887", "gnorm": "0.717", "train_wall": "403", "gb_free": "6.8", "wall": "95786"}
[2023-03-31 01:18:14,739][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 01:18:14,740][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 01:18:16,490][valid][INFO] - {"epoch": 38, "valid_loss": "4.713", "valid_ppl": "26.22", "valid_wps": "141344", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "41458", "valid_best_loss": "4.515"}
[2023-03-31 01:18:16,491][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 38 @ 41458 updates
[2023-03-31 01:18:16,492][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 01:18:18,422][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 01:18:18,455][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 38 @ 41458 updates, score 4.713) (writing took 1.9637465229898226 seconds)
[2023-03-31 01:18:18,455][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2023-03-31 01:18:18,456][train][INFO] - {"epoch": 38, "train_loss": "3.581", "train_ppl": "11.97", "train_wps": "47786.5", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "41458", "train_lr": "0.000508517", "train_gnorm": "0.714", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "95920"}
[2023-03-31 01:18:18,457][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 01:18:18,492][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 01:18:18,494][fairseq.trainer][INFO] - begin training epoch 39
[2023-03-31 01:18:18,495][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 01:23:37,784][train_inner][INFO] - {"epoch": 39, "update": 38.13, "loss": "3.503", "ppl": "11.34", "wps": "47480.8", "ups": "0.44", "wpb": "107477", "bsz": "255.8", "num_updates": "41600", "lr": "0.000507652", "gnorm": "0.718", "train_wall": "404", "gb_free": "6.8", "wall": "96239"}
[2023-03-31 01:31:06,161][train_inner][INFO] - {"epoch": 39, "update": 38.313, "loss": "3.501", "ppl": "11.32", "wps": "47876.8", "ups": "0.45", "wpb": "107334", "bsz": "256", "num_updates": "41800", "lr": "0.000506435", "gnorm": "0.721", "train_wall": "403", "gb_free": "6.8", "wall": "96687"}
[2023-03-31 01:38:33,004][train_inner][INFO] - {"epoch": 39, "update": 38.497, "loss": "3.566", "ppl": "11.84", "wps": "47821.6", "ups": "0.45", "wpb": "106844", "bsz": "256", "num_updates": "42000", "lr": "0.000505217", "gnorm": "0.712", "train_wall": "402", "gb_free": "6.8", "wall": "97134"}
[2023-03-31 01:46:00,912][train_inner][INFO] - {"epoch": 39, "update": 38.68, "loss": "3.6", "ppl": "12.13", "wps": "47850.6", "ups": "0.45", "wpb": "107163", "bsz": "256", "num_updates": "42200", "lr": "0.000504", "gnorm": "0.716", "train_wall": "403", "gb_free": "6.8", "wall": "97582"}
[2023-03-31 01:53:29,149][train_inner][INFO] - {"epoch": 39, "update": 38.863, "loss": "3.633", "ppl": "12.4", "wps": "47890.6", "ups": "0.45", "wpb": "107332", "bsz": "256", "num_updates": "42400", "lr": "0.000502783", "gnorm": "0.716", "train_wall": "403", "gb_free": "6.8", "wall": "98030"}
[2023-03-31 01:59:02,378][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 01:59:02,379][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 01:59:04,140][valid][INFO] - {"epoch": 39, "valid_loss": "4.715", "valid_ppl": "26.26", "valid_wps": "140692", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "42549", "valid_best_loss": "4.515"}
[2023-03-31 01:59:04,141][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 39 @ 42549 updates
[2023-03-31 01:59:04,142][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 01:59:05,462][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 01:59:05,486][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 39 @ 42549 updates, score 4.715) (writing took 1.344667818993912 seconds)
[2023-03-31 01:59:05,486][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2023-03-31 01:59:05,487][train][INFO] - {"epoch": 39, "train_loss": "3.567", "train_ppl": "11.86", "train_wps": "47797.5", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "42549", "train_lr": "0.000501876", "train_gnorm": "0.717", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "98367"}
[2023-03-31 01:59:05,488][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 01:59:05,519][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 01:59:05,521][fairseq.trainer][INFO] - begin training epoch 40
[2023-03-31 01:59:05,522][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 02:01:00,362][train_inner][INFO] - {"epoch": 40, "update": 39.047, "loss": "3.588", "ppl": "12.03", "wps": "47506", "ups": "0.44", "wpb": "107177", "bsz": "255.8", "num_updates": "42600", "lr": "0.000501565", "gnorm": "0.722", "train_wall": "403", "gb_free": "6.8", "wall": "98481"}
[2023-03-31 02:08:28,267][train_inner][INFO] - {"epoch": 40, "update": 39.23, "loss": "3.458", "ppl": "10.99", "wps": "47863.8", "ups": "0.45", "wpb": "107192", "bsz": "256", "num_updates": "42800", "lr": "0.000500348", "gnorm": "0.722", "train_wall": "403", "gb_free": "6.8", "wall": "98929"}
[2023-03-31 02:15:56,120][train_inner][INFO] - {"epoch": 40, "update": 39.413, "loss": "3.521", "ppl": "11.48", "wps": "47844.8", "ups": "0.45", "wpb": "107136", "bsz": "256", "num_updates": "43000", "lr": "0.00049913", "gnorm": "0.72", "train_wall": "403", "gb_free": "6.8", "wall": "99377"}
[2023-03-31 02:23:23,729][train_inner][INFO] - {"epoch": 40, "update": 39.597, "loss": "3.569", "ppl": "11.87", "wps": "47849.9", "ups": "0.45", "wpb": "107090", "bsz": "256", "num_updates": "43200", "lr": "0.000497913", "gnorm": "0.716", "train_wall": "402", "gb_free": "6.8", "wall": "99825"}
[2023-03-31 02:30:51,645][train_inner][INFO] - {"epoch": 40, "update": 39.78, "loss": "3.612", "ppl": "12.23", "wps": "47855.5", "ups": "0.45", "wpb": "107176", "bsz": "256", "num_updates": "43400", "lr": "0.000496696", "gnorm": "0.723", "train_wall": "403", "gb_free": "6.8", "wall": "100273"}
[2023-03-31 02:38:20,002][train_inner][INFO] - {"epoch": 40, "update": 39.963, "loss": "3.634", "ppl": "12.42", "wps": "47887.2", "ups": "0.45", "wpb": "107353", "bsz": "256", "num_updates": "43600", "lr": "0.000495478", "gnorm": "0.722", "train_wall": "403", "gb_free": "6.8", "wall": "100721"}
[2023-03-31 02:39:49,415][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 02:39:49,416][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 02:39:51,105][valid][INFO] - {"epoch": 40, "valid_loss": "4.717", "valid_ppl": "26.3", "valid_wps": "146457", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "43640", "valid_best_loss": "4.515"}
[2023-03-31 02:39:51,106][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 43640 updates
[2023-03-31 02:39:51,107][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 02:39:52,550][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 02:39:52,574][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 40 @ 43640 updates, score 4.717) (writing took 1.4674768509867135 seconds)
[2023-03-31 02:39:52,574][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2023-03-31 02:39:52,574][train][INFO] - {"epoch": 40, "train_loss": "3.555", "train_ppl": "11.75", "train_wps": "47796.4", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "43640", "train_lr": "0.000495235", "train_gnorm": "0.721", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "100814"}
[2023-03-31 02:39:52,576][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 02:39:52,606][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 02:39:52,608][fairseq.trainer][INFO] - begin training epoch 41
[2023-03-31 02:39:52,608][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 02:45:51,262][train_inner][INFO] - {"epoch": 41, "update": 40.147, "loss": "3.462", "ppl": "11.02", "wps": "47494", "ups": "0.44", "wpb": "107161", "bsz": "255.8", "num_updates": "43800", "lr": "0.000494261", "gnorm": "0.722", "train_wall": "403", "gb_free": "6.8", "wall": "101172"}
[2023-03-31 02:53:19,741][train_inner][INFO] - {"epoch": 41, "update": 40.33, "loss": "3.489", "ppl": "11.22", "wps": "47893.7", "ups": "0.45", "wpb": "107396", "bsz": "256", "num_updates": "44000", "lr": "0.000493043", "gnorm": "0.721", "train_wall": "403", "gb_free": "6.8", "wall": "101621"}
[2023-03-31 03:00:46,965][train_inner][INFO] - {"epoch": 41, "update": 40.513, "loss": "3.53", "ppl": "11.55", "wps": "47836.6", "ups": "0.45", "wpb": "106968", "bsz": "256", "num_updates": "44200", "lr": "0.000491826", "gnorm": "0.719", "train_wall": "402", "gb_free": "6.8", "wall": "102068"}
[2023-03-31 03:08:15,914][train_inner][INFO] - {"epoch": 41, "update": 40.697, "loss": "3.575", "ppl": "11.91", "wps": "47904", "ups": "0.45", "wpb": "107532", "bsz": "256", "num_updates": "44400", "lr": "0.000490609", "gnorm": "0.722", "train_wall": "404", "gb_free": "6.8", "wall": "102517"}
[2023-03-31 03:15:44,042][train_inner][INFO] - {"epoch": 41, "update": 40.88, "loss": "3.615", "ppl": "12.25", "wps": "47879.3", "ups": "0.45", "wpb": "107280", "bsz": "256", "num_updates": "44600", "lr": "0.000489391", "gnorm": "0.722", "train_wall": "403", "gb_free": "6.8", "wall": "102965"}
[2023-03-31 03:20:36,291][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 03:20:36,292][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 03:20:38,032][valid][INFO] - {"epoch": 41, "valid_loss": "4.732", "valid_ppl": "26.58", "valid_wps": "143068", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "44731", "valid_best_loss": "4.515"}
[2023-03-31 03:20:38,033][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 41 @ 44731 updates
[2023-03-31 03:20:38,033][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 03:20:38,935][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 03:20:38,959][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 41 @ 44731 updates, score 4.732) (writing took 0.9261363349942258 seconds)
[2023-03-31 03:20:38,959][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2023-03-31 03:20:38,959][train][INFO] - {"epoch": 41, "train_loss": "3.542", "train_ppl": "11.65", "train_wps": "47810.1", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "44731", "train_lr": "0.000488594", "train_gnorm": "0.722", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "103260"}
[2023-03-31 03:20:38,961][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 03:20:38,991][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 03:20:38,993][fairseq.trainer][INFO] - begin training epoch 42
[2023-03-31 03:20:38,994][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 03:23:13,988][train_inner][INFO] - {"epoch": 42, "update": 41.063, "loss": "3.552", "ppl": "11.73", "wps": "47517.8", "ups": "0.44", "wpb": "106902", "bsz": "255.8", "num_updates": "44800", "lr": "0.000488174", "gnorm": "0.722", "train_wall": "402", "gb_free": "6.8", "wall": "103415"}
[2023-03-31 03:30:41,720][train_inner][INFO] - {"epoch": 42, "update": 41.247, "loss": "3.443", "ppl": "10.88", "wps": "47850.6", "ups": "0.45", "wpb": "107121", "bsz": "256", "num_updates": "45000", "lr": "0.000486957", "gnorm": "0.723", "train_wall": "403", "gb_free": "6.8", "wall": "103863"}
[2023-03-31 03:38:09,863][train_inner][INFO] - {"epoch": 42, "update": 41.43, "loss": "3.5", "ppl": "11.31", "wps": "47866.1", "ups": "0.45", "wpb": "107254", "bsz": "256", "num_updates": "45200", "lr": "0.000485739", "gnorm": "0.725", "train_wall": "403", "gb_free": "6.8", "wall": "104311"}
[2023-03-31 03:45:38,081][train_inner][INFO] - {"epoch": 42, "update": 41.613, "loss": "3.548", "ppl": "11.7", "wps": "47872.8", "ups": "0.45", "wpb": "107287", "bsz": "256", "num_updates": "45400", "lr": "0.000484522", "gnorm": "0.717", "train_wall": "403", "gb_free": "6.8", "wall": "104759"}
[2023-03-31 03:53:06,395][train_inner][INFO] - {"epoch": 42, "update": 41.797, "loss": "3.588", "ppl": "12.03", "wps": "47881", "ups": "0.45", "wpb": "107328", "bsz": "256", "num_updates": "45600", "lr": "0.000483304", "gnorm": "0.733", "train_wall": "403", "gb_free": "6.8", "wall": "105207"}
[2023-03-31 04:00:33,779][train_inner][INFO] - {"epoch": 42, "update": 41.98, "loss": "3.613", "ppl": "12.23", "wps": "47845.1", "ups": "0.45", "wpb": "107026", "bsz": "256", "num_updates": "45800", "lr": "0.000482087", "gnorm": "0.726", "train_wall": "402", "gb_free": "6.8", "wall": "105655"}
[2023-03-31 04:01:22,927][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 04:01:22,928][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 04:01:24,613][valid][INFO] - {"epoch": 42, "valid_loss": "4.742", "valid_ppl": "26.75", "valid_wps": "146751", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "45822", "valid_best_loss": "4.515"}
[2023-03-31 04:01:24,614][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 42 @ 45822 updates
[2023-03-31 04:01:24,615][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 04:01:25,994][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 04:01:26,019][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 42 @ 45822 updates, score 4.742) (writing took 1.4049162150040502 seconds)
[2023-03-31 04:01:26,019][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2023-03-31 04:01:26,019][train][INFO] - {"epoch": 42, "train_loss": "3.531", "train_ppl": "11.56", "train_wps": "47797", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "45822", "train_lr": "0.000481953", "train_gnorm": "0.725", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "105707"}
[2023-03-31 04:01:26,021][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 04:01:26,051][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 04:01:26,053][fairseq.trainer][INFO] - begin training epoch 43
[2023-03-31 04:01:26,054][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 04:08:05,142][train_inner][INFO] - {"epoch": 43, "update": 42.163, "loss": "3.424", "ppl": "10.74", "wps": "47510.5", "ups": "0.44", "wpb": "107222", "bsz": "255.8", "num_updates": "46000", "lr": "0.00048087", "gnorm": "0.72", "train_wall": "403", "gb_free": "6.8", "wall": "106106"}
[2023-03-31 04:15:33,866][train_inner][INFO] - {"epoch": 43, "update": 42.346, "loss": "3.465", "ppl": "11.04", "wps": "47904", "ups": "0.45", "wpb": "107478", "bsz": "256", "num_updates": "46200", "lr": "0.000479652", "gnorm": "0.723", "train_wall": "404", "gb_free": "6.8", "wall": "106555"}
[2023-03-31 04:23:02,209][train_inner][INFO] - {"epoch": 43, "update": 42.53, "loss": "3.519", "ppl": "11.46", "wps": "47882.4", "ups": "0.45", "wpb": "107339", "bsz": "256", "num_updates": "46400", "lr": "0.000478435", "gnorm": "0.725", "train_wall": "403", "gb_free": "6.8", "wall": "107003"}
[2023-03-31 04:30:30,285][train_inner][INFO] - {"epoch": 43, "update": 42.713, "loss": "3.555", "ppl": "11.75", "wps": "47887.1", "ups": "0.45", "wpb": "107285", "bsz": "256", "num_updates": "46600", "lr": "0.000477217", "gnorm": "0.722", "train_wall": "403", "gb_free": "6.8", "wall": "107451"}
[2023-03-31 04:37:57,704][train_inner][INFO] - {"epoch": 43, "update": 42.896, "loss": "3.586", "ppl": "12.01", "wps": "47845.6", "ups": "0.45", "wpb": "107035", "bsz": "256", "num_updates": "46800", "lr": "0.000476", "gnorm": "0.719", "train_wall": "402", "gb_free": "6.8", "wall": "107899"}
[2023-03-31 04:42:09,586][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 04:42:09,587][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 04:42:11,307][valid][INFO] - {"epoch": 43, "valid_loss": "4.737", "valid_ppl": "26.67", "valid_wps": "143848", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "46913", "valid_best_loss": "4.515"}
[2023-03-31 04:42:11,308][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 43 @ 46913 updates
[2023-03-31 04:42:11,309][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 04:42:12,972][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 04:42:12,997][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 43 @ 46913 updates, score 4.737) (writing took 1.6882350469968515 seconds)
[2023-03-31 04:42:12,997][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2023-03-31 04:42:12,997][train][INFO] - {"epoch": 43, "train_loss": "3.519", "train_ppl": "11.46", "train_wps": "47798.6", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "46913", "train_lr": "0.000475312", "train_gnorm": "0.721", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "108154"}
[2023-03-31 04:42:12,999][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 04:42:13,030][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 04:42:13,032][fairseq.trainer][INFO] - begin training epoch 44
[2023-03-31 04:42:13,033][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 04:45:27,881][train_inner][INFO] - {"epoch": 44, "update": 43.08, "loss": "3.51", "ppl": "11.39", "wps": "47438.9", "ups": "0.44", "wpb": "106779", "bsz": "255.8", "num_updates": "47000", "lr": "0.000474783", "gnorm": "0.727", "train_wall": "401", "gb_free": "6.8", "wall": "108349"}
[2023-03-31 04:52:56,104][train_inner][INFO] - {"epoch": 44, "update": 43.263, "loss": "3.428", "ppl": "10.76", "wps": "47880.8", "ups": "0.45", "wpb": "107306", "bsz": "256", "num_updates": "47200", "lr": "0.000473565", "gnorm": "0.727", "train_wall": "403", "gb_free": "6.8", "wall": "108797"}
[2023-03-31 05:00:23,797][train_inner][INFO] - {"epoch": 44, "update": 43.446, "loss": "3.483", "ppl": "11.18", "wps": "47859.3", "ups": "0.45", "wpb": "107131", "bsz": "256", "num_updates": "47400", "lr": "0.000472348", "gnorm": "0.724", "train_wall": "403", "gb_free": "6.8", "wall": "109245"}
[2023-03-31 05:07:51,632][train_inner][INFO] - {"epoch": 44, "update": 43.63, "loss": "3.526", "ppl": "11.52", "wps": "47837.6", "ups": "0.45", "wpb": "107117", "bsz": "256", "num_updates": "47600", "lr": "0.00047113", "gnorm": "0.727", "train_wall": "403", "gb_free": "6.8", "wall": "109693"}
[2023-03-31 05:15:19,293][train_inner][INFO] - {"epoch": 44, "update": 43.813, "loss": "3.562", "ppl": "11.81", "wps": "47856.1", "ups": "0.45", "wpb": "107116", "bsz": "256", "num_updates": "47800", "lr": "0.000469913", "gnorm": "0.73", "train_wall": "403", "gb_free": "6.8", "wall": "110140"}
[2023-03-31 05:22:47,909][train_inner][INFO] - {"epoch": 44, "update": 43.996, "loss": "3.595", "ppl": "12.08", "wps": "47905", "ups": "0.45", "wpb": "107455", "bsz": "256", "num_updates": "48000", "lr": "0.000468696", "gnorm": "0.724", "train_wall": "403", "gb_free": "6.8", "wall": "110589"}
[2023-03-31 05:22:56,732][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 05:22:56,733][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 05:22:58,423][valid][INFO] - {"epoch": 44, "valid_loss": "4.754", "valid_ppl": "26.98", "valid_wps": "146756", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "48004", "valid_best_loss": "4.515"}
[2023-03-31 05:22:58,424][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 44 @ 48004 updates
[2023-03-31 05:22:58,425][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 05:23:00,033][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 05:23:00,057][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 44 @ 48004 updates, score 4.754) (writing took 1.632122088005417 seconds)
[2023-03-31 05:23:00,057][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2023-03-31 05:23:00,057][train][INFO] - {"epoch": 44, "train_loss": "3.507", "train_ppl": "11.37", "train_wps": "47796.9", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "48004", "train_lr": "0.000468671", "train_gnorm": "0.727", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "110601"}
[2023-03-31 05:23:00,059][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 05:23:00,088][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 05:23:00,091][fairseq.trainer][INFO] - begin training epoch 45
[2023-03-31 05:23:00,091][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 05:30:19,674][train_inner][INFO] - {"epoch": 45, "update": 44.18, "loss": "3.383", "ppl": "10.44", "wps": "47512.7", "ups": "0.44", "wpb": "107323", "bsz": "255.8", "num_updates": "48200", "lr": "0.000467478", "gnorm": "0.73", "train_wall": "403", "gb_free": "6.8", "wall": "111041"}
[2023-03-31 05:37:47,651][train_inner][INFO] - {"epoch": 45, "update": 44.363, "loss": "3.447", "ppl": "10.9", "wps": "47855.3", "ups": "0.45", "wpb": "107190", "bsz": "256", "num_updates": "48400", "lr": "0.000466261", "gnorm": "0.727", "train_wall": "403", "gb_free": "6.8", "wall": "111489"}
[2023-03-31 05:45:16,433][train_inner][INFO] - {"epoch": 45, "update": 44.546, "loss": "3.499", "ppl": "11.3", "wps": "47903.2", "ups": "0.45", "wpb": "107490", "bsz": "256", "num_updates": "48600", "lr": "0.000465043", "gnorm": "0.727", "train_wall": "404", "gb_free": "6.8", "wall": "111937"}
[2023-03-31 05:52:43,999][train_inner][INFO] - {"epoch": 45, "update": 44.73, "loss": "3.538", "ppl": "11.62", "wps": "47858.8", "ups": "0.45", "wpb": "107100", "bsz": "256", "num_updates": "48800", "lr": "0.000463826", "gnorm": "0.732", "train_wall": "402", "gb_free": "6.8", "wall": "112385"}
[2023-03-31 06:00:11,060][train_inner][INFO] - {"epoch": 45, "update": 44.913, "loss": "3.572", "ppl": "11.89", "wps": "47839.3", "ups": "0.45", "wpb": "106936", "bsz": "256", "num_updates": "49000", "lr": "0.000462609", "gnorm": "0.726", "train_wall": "402", "gb_free": "6.8", "wall": "112832"}
[2023-03-31 06:03:43,637][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 06:03:43,638][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 06:03:45,393][valid][INFO] - {"epoch": 45, "valid_loss": "4.754", "valid_ppl": "26.99", "valid_wps": "141278", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "49095", "valid_best_loss": "4.515"}
[2023-03-31 06:03:45,394][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 45 @ 49095 updates
[2023-03-31 06:03:45,395][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 06:03:46,726][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 06:03:46,751][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 45 @ 49095 updates, score 4.754) (writing took 1.3577362229989376 seconds)
[2023-03-31 06:03:46,752][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2023-03-31 06:03:46,752][train][INFO] - {"epoch": 45, "train_loss": "3.496", "train_ppl": "11.28", "train_wps": "47804.1", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "49095", "train_lr": "0.00046203", "train_gnorm": "0.728", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "113048"}
[2023-03-31 06:03:46,754][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 06:03:46,785][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 06:03:46,787][fairseq.trainer][INFO] - begin training epoch 46
[2023-03-31 06:03:46,787][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 06:07:42,289][train_inner][INFO] - {"epoch": 46, "update": 45.096, "loss": "3.467", "ppl": "11.05", "wps": "47513.1", "ups": "0.44", "wpb": "107196", "bsz": "255.8", "num_updates": "49200", "lr": "0.000461391", "gnorm": "0.729", "train_wall": "403", "gb_free": "6.8", "wall": "113283"}
[2023-03-31 06:15:10,945][train_inner][INFO] - {"epoch": 46, "update": 45.28, "loss": "3.41", "ppl": "10.63", "wps": "47915.4", "ups": "0.45", "wpb": "107488", "bsz": "256", "num_updates": "49400", "lr": "0.000460174", "gnorm": "0.73", "train_wall": "403", "gb_free": "6.8", "wall": "113732"}
[2023-03-31 06:22:38,408][train_inner][INFO] - {"epoch": 46, "update": 45.463, "loss": "3.462", "ppl": "11.02", "wps": "47849.9", "ups": "0.45", "wpb": "107055", "bsz": "256", "num_updates": "49600", "lr": "0.000458957", "gnorm": "0.735", "train_wall": "402", "gb_free": "6.8", "wall": "114179"}
[2023-03-31 06:30:06,038][train_inner][INFO] - {"epoch": 46, "update": 45.646, "loss": "3.513", "ppl": "11.42", "wps": "47856.3", "ups": "0.45", "wpb": "107110", "bsz": "256", "num_updates": "49800", "lr": "0.000457739", "gnorm": "0.733", "train_wall": "402", "gb_free": "6.8", "wall": "114627"}
[2023-03-31 06:37:34,402][train_inner][INFO] - {"epoch": 46, "update": 45.83, "loss": "3.543", "ppl": "11.66", "wps": "47859.5", "ups": "0.45", "wpb": "107292", "bsz": "256", "num_updates": "50000", "lr": "0.000456522", "gnorm": "0.733", "train_wall": "403", "gb_free": "6.8", "wall": "115075"}
[2023-03-31 06:44:30,480][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 06:44:30,481][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 06:44:32,212][valid][INFO] - {"epoch": 46, "valid_loss": "4.76", "valid_ppl": "27.09", "valid_wps": "142804", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "50186", "valid_best_loss": "4.515"}
[2023-03-31 06:44:32,213][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 46 @ 50186 updates
[2023-03-31 06:44:32,214][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 06:44:33,563][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 06:44:33,587][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 46 @ 50186 updates, score 4.76) (writing took 1.3740201569889905 seconds)
[2023-03-31 06:44:33,588][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2023-03-31 06:44:33,588][train][INFO] - {"epoch": 46, "train_loss": "3.486", "train_ppl": "11.2", "train_wps": "47801.3", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "50186", "train_lr": "0.00045539", "train_gnorm": "0.731", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "115495"}
[2023-03-31 06:44:33,590][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 06:44:33,619][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 06:44:33,621][fairseq.trainer][INFO] - begin training epoch 47
[2023-03-31 06:44:33,622][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 06:45:05,090][train_inner][INFO] - {"epoch": 47, "update": 46.013, "loss": "3.557", "ppl": "11.77", "wps": "47482.1", "ups": "0.44", "wpb": "106998", "bsz": "255.8", "num_updates": "50200", "lr": "0.000455304", "gnorm": "0.726", "train_wall": "402", "gb_free": "6.8", "wall": "115526"}
[2023-03-31 06:52:31,717][train_inner][INFO] - {"epoch": 47, "update": 46.196, "loss": "3.374", "ppl": "10.37", "wps": "47817.4", "ups": "0.45", "wpb": "106783", "bsz": "256", "num_updates": "50400", "lr": "0.000454087", "gnorm": "0.732", "train_wall": "401", "gb_free": "6.8", "wall": "115973"}
[2023-03-31 07:00:01,135][train_inner][INFO] - {"epoch": 47, "update": 46.379, "loss": "3.431", "ppl": "10.79", "wps": "47928", "ups": "0.45", "wpb": "107698", "bsz": "256", "num_updates": "50600", "lr": "0.00045287", "gnorm": "0.734", "train_wall": "404", "gb_free": "6.8", "wall": "116422"}
[2023-03-31 07:07:28,930][train_inner][INFO] - {"epoch": 47, "update": 46.563, "loss": "3.486", "ppl": "11.21", "wps": "47827.9", "ups": "0.45", "wpb": "107086", "bsz": "256", "num_updates": "50800", "lr": "0.000451652", "gnorm": "0.732", "train_wall": "403", "gb_free": "6.8", "wall": "116870"}
[2023-03-31 07:14:57,539][train_inner][INFO] - {"epoch": 47, "update": 46.746, "loss": "3.51", "ppl": "11.4", "wps": "47877.6", "ups": "0.45", "wpb": "107392", "bsz": "256", "num_updates": "51000", "lr": "0.000450435", "gnorm": "0.729", "train_wall": "403", "gb_free": "6.8", "wall": "117319"}
[2023-03-31 07:22:25,333][train_inner][INFO] - {"epoch": 47, "update": 46.929, "loss": "3.551", "ppl": "11.72", "wps": "47851.2", "ups": "0.45", "wpb": "107137", "bsz": "256", "num_updates": "51200", "lr": "0.000449217", "gnorm": "0.733", "train_wall": "403", "gb_free": "6.8", "wall": "117766"}
[2023-03-31 07:25:17,609][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 07:25:17,610][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 07:25:19,378][valid][INFO] - {"epoch": 47, "valid_loss": "4.778", "valid_ppl": "27.44", "valid_wps": "140114", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "51277", "valid_best_loss": "4.515"}
[2023-03-31 07:25:19,379][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 47 @ 51277 updates
[2023-03-31 07:25:19,386][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 07:25:20,314][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 07:25:20,340][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 47 @ 51277 updates, score 4.778) (writing took 0.9609263970050961 seconds)
[2023-03-31 07:25:20,340][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2023-03-31 07:25:20,341][train][INFO] - {"epoch": 47, "train_loss": "3.475", "train_ppl": "11.12", "train_wps": "47803", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "51277", "train_lr": "0.000448749", "train_gnorm": "0.733", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "117941"}
[2023-03-31 07:25:20,342][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 07:25:20,373][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 07:25:20,375][fairseq.trainer][INFO] - begin training epoch 48
[2023-03-31 07:25:20,376][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 07:29:55,988][train_inner][INFO] - {"epoch": 48, "update": 47.113, "loss": "3.425", "ppl": "10.74", "wps": "47552.3", "ups": "0.44", "wpb": "107148", "bsz": "255.8", "num_updates": "51400", "lr": "0.000448", "gnorm": "0.739", "train_wall": "403", "gb_free": "6.8", "wall": "118217"}
[2023-03-31 07:37:23,615][train_inner][INFO] - {"epoch": 48, "update": 47.296, "loss": "3.401", "ppl": "10.56", "wps": "47817.7", "ups": "0.45", "wpb": "107022", "bsz": "256", "num_updates": "51600", "lr": "0.000446783", "gnorm": "0.734", "train_wall": "402", "gb_free": "6.8", "wall": "118665"}
[2023-03-31 07:44:51,942][train_inner][INFO] - {"epoch": 48, "update": 47.479, "loss": "3.45", "ppl": "10.93", "wps": "47886.8", "ups": "0.45", "wpb": "107345", "bsz": "256", "num_updates": "51800", "lr": "0.000445565", "gnorm": "0.734", "train_wall": "403", "gb_free": "6.8", "wall": "119113"}
[2023-03-31 07:52:20,652][train_inner][INFO] - {"epoch": 48, "update": 47.663, "loss": "3.493", "ppl": "11.26", "wps": "47892.1", "ups": "0.45", "wpb": "107448", "bsz": "256", "num_updates": "52000", "lr": "0.000444348", "gnorm": "0.738", "train_wall": "404", "gb_free": "6.8", "wall": "119562"}
[2023-03-31 07:59:48,424][train_inner][INFO] - {"epoch": 48, "update": 47.846, "loss": "3.518", "ppl": "11.45", "wps": "47855.8", "ups": "0.45", "wpb": "107142", "bsz": "256", "num_updates": "52200", "lr": "0.00044313", "gnorm": "0.734", "train_wall": "403", "gb_free": "6.8", "wall": "120009"}
[2023-03-31 08:06:04,311][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 08:06:04,312][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 08:06:06,051][valid][INFO] - {"epoch": 48, "valid_loss": "4.789", "valid_ppl": "27.64", "valid_wps": "142363", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "52368", "valid_best_loss": "4.515"}
[2023-03-31 08:06:06,052][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 48 @ 52368 updates
[2023-03-31 08:06:06,053][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 08:06:06,971][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 08:06:06,995][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 48 @ 52368 updates, score 4.789) (writing took 0.9428984330006642 seconds)
[2023-03-31 08:06:06,995][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2023-03-31 08:06:06,996][train][INFO] - {"epoch": 48, "train_loss": "3.463", "train_ppl": "11.03", "train_wps": "47804.9", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "52368", "train_lr": "0.000442108", "train_gnorm": "0.734", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "120388"}
[2023-03-31 08:06:06,997][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 08:06:07,028][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 08:06:07,030][fairseq.trainer][INFO] - begin training epoch 49
[2023-03-31 08:06:07,030][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 08:07:19,084][train_inner][INFO] - {"epoch": 49, "update": 48.029, "loss": "3.51", "ppl": "11.39", "wps": "47548.8", "ups": "0.44", "wpb": "107142", "bsz": "255.8", "num_updates": "52400", "lr": "0.000441913", "gnorm": "0.732", "train_wall": "403", "gb_free": "6.8", "wall": "120460"}
[2023-03-31 08:14:46,419][train_inner][INFO] - {"epoch": 49, "update": 48.213, "loss": "3.358", "ppl": "10.25", "wps": "47836.9", "ups": "0.45", "wpb": "106995", "bsz": "256", "num_updates": "52600", "lr": "0.000440696", "gnorm": "0.74", "train_wall": "402", "gb_free": "6.8", "wall": "120907"}
[2023-03-31 08:22:14,749][train_inner][INFO] - {"epoch": 49, "update": 48.396, "loss": "3.42", "ppl": "10.7", "wps": "47890.7", "ups": "0.45", "wpb": "107354", "bsz": "256", "num_updates": "52800", "lr": "0.000439478", "gnorm": "0.735", "train_wall": "403", "gb_free": "6.8", "wall": "121356"}
[2023-03-31 08:29:42,613][train_inner][INFO] - {"epoch": 49, "update": 48.579, "loss": "3.46", "ppl": "11.01", "wps": "47853.6", "ups": "0.45", "wpb": "107159", "bsz": "256", "num_updates": "53000", "lr": "0.000438261", "gnorm": "0.741", "train_wall": "403", "gb_free": "6.8", "wall": "121804"}
[2023-03-31 08:37:10,339][train_inner][INFO] - {"epoch": 49, "update": 48.763, "loss": "3.493", "ppl": "11.26", "wps": "47846.8", "ups": "0.45", "wpb": "107112", "bsz": "256", "num_updates": "53200", "lr": "0.000437043", "gnorm": "0.74", "train_wall": "402", "gb_free": "6.8", "wall": "122251"}
[2023-03-31 08:44:39,401][train_inner][INFO] - {"epoch": 49, "update": 48.946, "loss": "3.536", "ppl": "11.6", "wps": "47894.6", "ups": "0.45", "wpb": "107538", "bsz": "256", "num_updates": "53400", "lr": "0.000435826", "gnorm": "0.734", "train_wall": "404", "gb_free": "6.8", "wall": "122700"}
[2023-03-31 08:46:51,055][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 08:46:51,055][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 08:46:52,787][valid][INFO] - {"epoch": 49, "valid_loss": "4.776", "valid_ppl": "27.4", "valid_wps": "142939", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "53459", "valid_best_loss": "4.515"}
[2023-03-31 08:46:52,787][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 49 @ 53459 updates
[2023-03-31 08:46:52,788][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 08:46:54,349][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 08:46:54,373][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 49 @ 53459 updates, score 4.776) (writing took 1.5857088140037376 seconds)
[2023-03-31 08:46:54,373][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2023-03-31 08:46:54,374][train][INFO] - {"epoch": 49, "train_loss": "3.454", "train_ppl": "10.96", "train_wps": "47790.7", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "53459", "train_lr": "0.000435467", "train_gnorm": "0.737", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "122835"}
[2023-03-31 08:46:54,376][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 08:46:54,405][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 08:46:54,407][fairseq.trainer][INFO] - begin training epoch 50
[2023-03-31 08:46:54,408][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 08:52:10,876][train_inner][INFO] - {"epoch": 50, "update": 49.129, "loss": "3.387", "ppl": "10.46", "wps": "47484.9", "ups": "0.44", "wpb": "107191", "bsz": "255.8", "num_updates": "53600", "lr": "0.000434609", "gnorm": "0.731", "train_wall": "403", "gb_free": "6.8", "wall": "123152"}
[2023-03-31 08:59:38,096][train_inner][INFO] - {"epoch": 50, "update": 49.313, "loss": "3.381", "ppl": "10.42", "wps": "47837.2", "ups": "0.45", "wpb": "106969", "bsz": "256", "num_updates": "53800", "lr": "0.000433391", "gnorm": "0.737", "train_wall": "402", "gb_free": "6.8", "wall": "123599"}
[2023-03-31 09:07:06,991][train_inner][INFO] - {"epoch": 50, "update": 49.496, "loss": "3.432", "ppl": "10.79", "wps": "47894.5", "ups": "0.45", "wpb": "107498", "bsz": "256", "num_updates": "54000", "lr": "0.000432174", "gnorm": "0.739", "train_wall": "404", "gb_free": "6.8", "wall": "124048"}
[2023-03-31 09:14:35,123][train_inner][INFO] - {"epoch": 50, "update": 49.679, "loss": "3.476", "ppl": "11.13", "wps": "47855.8", "ups": "0.45", "wpb": "107228", "bsz": "256", "num_updates": "54200", "lr": "0.000430957", "gnorm": "0.742", "train_wall": "403", "gb_free": "6.8", "wall": "124496"}
[2023-03-31 09:22:02,774][train_inner][INFO] - {"epoch": 50, "update": 49.863, "loss": "3.511", "ppl": "11.4", "wps": "47873.7", "ups": "0.45", "wpb": "107153", "bsz": "256", "num_updates": "54400", "lr": "0.000429739", "gnorm": "0.734", "train_wall": "402", "gb_free": "6.8", "wall": "124944"}
[2023-03-31 09:27:38,236][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 09:27:38,237][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 09:27:39,963][valid][INFO] - {"epoch": 50, "valid_loss": "4.784", "valid_ppl": "27.56", "valid_wps": "143413", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "54550", "valid_best_loss": "4.515"}
[2023-03-31 09:27:39,963][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 54550 updates
[2023-03-31 09:27:39,964][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 09:27:41,814][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 09:27:41,838][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 50 @ 54550 updates, score 4.784) (writing took 1.8746770800207742 seconds)
[2023-03-31 09:27:41,838][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2023-03-31 09:27:41,839][train][INFO] - {"epoch": 50, "train_loss": "3.445", "train_ppl": "10.89", "train_wps": "47789", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "54550", "train_lr": "0.000428826", "train_gnorm": "0.738", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "125283"}
[2023-03-31 09:27:41,841][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 09:27:41,872][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 09:27:41,874][fairseq.trainer][INFO] - begin training epoch 51
[2023-03-31 09:27:41,874][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 09:29:33,747][train_inner][INFO] - {"epoch": 51, "update": 50.046, "loss": "3.474", "ppl": "11.11", "wps": "47414.5", "ups": "0.44", "wpb": "106913", "bsz": "255.8", "num_updates": "54600", "lr": "0.000428522", "gnorm": "0.743", "train_wall": "402", "gb_free": "6.8", "wall": "125395"}
[2023-03-31 09:37:01,553][train_inner][INFO] - {"epoch": 51, "update": 50.229, "loss": "3.34", "ppl": "10.13", "wps": "47850.8", "ups": "0.45", "wpb": "107139", "bsz": "256", "num_updates": "54800", "lr": "0.000427304", "gnorm": "0.744", "train_wall": "403", "gb_free": "6.8", "wall": "125843"}
[2023-03-31 09:44:30,156][train_inner][INFO] - {"epoch": 51, "update": 50.412, "loss": "3.406", "ppl": "10.6", "wps": "47873.7", "ups": "0.45", "wpb": "107380", "bsz": "256", "num_updates": "55000", "lr": "0.000426087", "gnorm": "0.736", "train_wall": "403", "gb_free": "6.8", "wall": "126291"}
[2023-03-31 09:51:58,780][train_inner][INFO] - {"epoch": 51, "update": 50.596, "loss": "3.448", "ppl": "10.91", "wps": "47904.5", "ups": "0.45", "wpb": "107456", "bsz": "256", "num_updates": "55200", "lr": "0.00042487", "gnorm": "0.746", "train_wall": "403", "gb_free": "6.8", "wall": "126740"}
[2023-03-31 09:59:27,031][train_inner][INFO] - {"epoch": 51, "update": 50.779, "loss": "3.486", "ppl": "11.2", "wps": "47862.6", "ups": "0.45", "wpb": "107272", "bsz": "256", "num_updates": "55400", "lr": "0.000423652", "gnorm": "0.745", "train_wall": "403", "gb_free": "6.8", "wall": "127188"}
[2023-03-31 10:06:54,519][train_inner][INFO] - {"epoch": 51, "update": 50.962, "loss": "3.512", "ppl": "11.41", "wps": "47828.9", "ups": "0.45", "wpb": "107014", "bsz": "256", "num_updates": "55600", "lr": "0.000422435", "gnorm": "0.749", "train_wall": "402", "gb_free": "6.8", "wall": "127636"}
[2023-03-31 10:08:26,002][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 10:08:26,003][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 10:08:27,693][valid][INFO] - {"epoch": 51, "valid_loss": "4.783", "valid_ppl": "27.54", "valid_wps": "146389", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "55641", "valid_best_loss": "4.515"}
[2023-03-31 10:08:27,694][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 51 @ 55641 updates
[2023-03-31 10:08:27,695][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 10:08:28,622][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 10:08:28,646][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 51 @ 55641 updates, score 4.783) (writing took 0.9519641700026114 seconds)
[2023-03-31 10:08:28,646][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2023-03-31 10:08:28,647][train][INFO] - {"epoch": 51, "train_loss": "3.435", "train_ppl": "10.81", "train_wps": "47801.9", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "55641", "train_lr": "0.000422185", "train_gnorm": "0.745", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "127730"}
[2023-03-31 10:08:28,648][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 10:08:28,678][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 10:08:28,680][fairseq.trainer][INFO] - begin training epoch 52
[2023-03-31 10:08:28,680][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 10:14:24,993][train_inner][INFO] - {"epoch": 52, "update": 51.146, "loss": "3.353", "ppl": "10.22", "wps": "47542.1", "ups": "0.44", "wpb": "107082", "bsz": "255.8", "num_updates": "55800", "lr": "0.000421217", "gnorm": "0.739", "train_wall": "402", "gb_free": "6.8", "wall": "128086"}
[2023-03-31 10:21:52,304][train_inner][INFO] - {"epoch": 52, "update": 51.329, "loss": "3.367", "ppl": "10.32", "wps": "47840.2", "ups": "0.45", "wpb": "106997", "bsz": "256", "num_updates": "56000", "lr": "0.00042", "gnorm": "0.741", "train_wall": "402", "gb_free": "6.8", "wall": "128533"}
[2023-03-31 10:29:20,196][train_inner][INFO] - {"epoch": 52, "update": 51.512, "loss": "3.421", "ppl": "10.71", "wps": "47841.6", "ups": "0.45", "wpb": "107139", "bsz": "256", "num_updates": "56200", "lr": "0.000418783", "gnorm": "0.747", "train_wall": "403", "gb_free": "6.8", "wall": "128981"}
[2023-03-31 10:36:48,529][train_inner][INFO] - {"epoch": 52, "update": 51.696, "loss": "3.458", "ppl": "10.99", "wps": "47874.1", "ups": "0.45", "wpb": "107317", "bsz": "256", "num_updates": "56400", "lr": "0.000417565", "gnorm": "0.742", "train_wall": "403", "gb_free": "6.8", "wall": "129430"}
[2023-03-31 10:44:16,314][train_inner][INFO] - {"epoch": 52, "update": 51.879, "loss": "3.483", "ppl": "11.19", "wps": "47855", "ups": "0.45", "wpb": "107144", "bsz": "256", "num_updates": "56600", "lr": "0.000416348", "gnorm": "0.748", "train_wall": "403", "gb_free": "6.8", "wall": "129877"}
[2023-03-31 10:49:12,640][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 10:49:12,640][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 10:49:14,366][valid][INFO] - {"epoch": 52, "valid_loss": "4.803", "valid_ppl": "27.91", "valid_wps": "143392", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "56732", "valid_best_loss": "4.515"}
[2023-03-31 10:49:14,367][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 52 @ 56732 updates
[2023-03-31 10:49:14,368][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 10:49:15,857][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 10:49:15,881][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 52 @ 56732 updates, score 4.803) (writing took 1.5139674819947686 seconds)
[2023-03-31 10:49:15,881][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2023-03-31 10:49:15,882][train][INFO] - {"epoch": 52, "train_loss": "3.425", "train_ppl": "10.74", "train_wps": "47793.5", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "56732", "train_lr": "0.000415544", "train_gnorm": "0.743", "train_train_wall": "2197", "train_gb_free": "6.8", "train_wall": "130177"}
[2023-03-31 10:49:15,883][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 10:49:15,914][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 10:49:15,916][fairseq.trainer][INFO] - begin training epoch 53
[2023-03-31 10:49:15,917][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 10:51:48,202][train_inner][INFO] - {"epoch": 53, "update": 52.062, "loss": "3.44", "ppl": "10.85", "wps": "47518.6", "ups": "0.44", "wpb": "107365", "bsz": "255.8", "num_updates": "56800", "lr": "0.00041513", "gnorm": "0.744", "train_wall": "403", "gb_free": "6.8", "wall": "130329"}
[2023-03-31 10:59:16,016][train_inner][INFO] - {"epoch": 53, "update": 52.246, "loss": "3.332", "ppl": "10.07", "wps": "47853.9", "ups": "0.45", "wpb": "107148", "bsz": "256", "num_updates": "57000", "lr": "0.000413913", "gnorm": "0.739", "train_wall": "403", "gb_free": "6.8", "wall": "130777"}
[2023-03-31 11:07:15,096][train_inner][INFO] - {"epoch": 53, "update": 52.429, "loss": "3.388", "ppl": "10.47", "wps": "44766.8", "ups": "0.42", "wpb": "107234", "bsz": "256", "num_updates": "57200", "lr": "0.000412696", "gnorm": "0.751", "train_wall": "429", "gb_free": "6.8", "wall": "131256"}
[2023-03-31 11:15:29,341][train_inner][INFO] - {"epoch": 53, "update": 52.612, "loss": "3.431", "ppl": "10.78", "wps": "43405.7", "ups": "0.4", "wpb": "107265", "bsz": "256", "num_updates": "57400", "lr": "0.000411478", "gnorm": "0.742", "train_wall": "442", "gb_free": "6.8", "wall": "131750"}
[2023-03-31 11:23:08,095][train_inner][INFO] - {"epoch": 53, "update": 52.796, "loss": "3.464", "ppl": "11.04", "wps": "46736.8", "ups": "0.44", "wpb": "107203", "bsz": "256", "num_updates": "57600", "lr": "0.000410261", "gnorm": "0.748", "train_wall": "412", "gb_free": "6.8", "wall": "132209"}
[2023-03-31 11:30:47,831][train_inner][INFO] - {"epoch": 53, "update": 52.979, "loss": "3.498", "ppl": "11.3", "wps": "46707", "ups": "0.44", "wpb": "107364", "bsz": "256", "num_updates": "57800", "lr": "0.000409043", "gnorm": "0.74", "train_wall": "413", "gb_free": "6.8", "wall": "132669"}
[2023-03-31 11:31:39,871][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 11:31:39,874][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 11:31:41,563][valid][INFO] - {"epoch": 53, "valid_loss": "4.815", "valid_ppl": "28.15", "valid_wps": "146422", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "57823", "valid_best_loss": "4.515"}
[2023-03-31 11:31:41,564][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 53 @ 57823 updates
[2023-03-31 11:31:41,573][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 11:31:42,993][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 11:31:43,021][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 53 @ 57823 updates, score 4.815) (writing took 1.4567608580109663 seconds)
[2023-03-31 11:31:43,022][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2023-03-31 11:31:43,022][train][INFO] - {"epoch": 53, "train_loss": "3.416", "train_ppl": "10.67", "train_wps": "45918.9", "train_ups": "0.43", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "57823", "train_lr": "0.000408903", "train_gnorm": "0.744", "train_train_wall": "2283", "train_gb_free": "6.8", "train_wall": "132724"}
[2023-03-31 11:31:43,024][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 11:31:43,053][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 11:31:43,055][fairseq.trainer][INFO] - begin training epoch 54
[2023-03-31 11:31:43,056][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 11:38:33,375][train_inner][INFO] - {"epoch": 54, "update": 53.162, "loss": "3.315", "ppl": "9.95", "wps": "46027.1", "ups": "0.43", "wpb": "107137", "bsz": "255.8", "num_updates": "58000", "lr": "0.000407826", "gnorm": "0.74", "train_wall": "415", "gb_free": "6.8", "wall": "133134"}
[2023-03-31 11:46:20,018][train_inner][INFO] - {"epoch": 54, "update": 53.346, "loss": "3.362", "ppl": "10.28", "wps": "45882.9", "ups": "0.43", "wpb": "107055", "bsz": "256", "num_updates": "58200", "lr": "0.000406609", "gnorm": "0.751", "train_wall": "419", "gb_free": "6.8", "wall": "133601"}
[2023-03-31 11:54:13,124][train_inner][INFO] - {"epoch": 54, "update": 53.529, "loss": "3.399", "ppl": "10.55", "wps": "45277.2", "ups": "0.42", "wpb": "107104", "bsz": "256", "num_updates": "58400", "lr": "0.000405391", "gnorm": "0.751", "train_wall": "425", "gb_free": "6.8", "wall": "134074"}
[2023-03-31 12:02:02,227][train_inner][INFO] - {"epoch": 54, "update": 53.712, "loss": "3.444", "ppl": "10.88", "wps": "45786.4", "ups": "0.43", "wpb": "107393", "bsz": "256", "num_updates": "58600", "lr": "0.000404174", "gnorm": "0.749", "train_wall": "421", "gb_free": "6.8", "wall": "134543"}
[2023-03-31 12:09:47,937][train_inner][INFO] - {"epoch": 54, "update": 53.896, "loss": "3.471", "ppl": "11.09", "wps": "46097.9", "ups": "0.43", "wpb": "107341", "bsz": "256", "num_updates": "58800", "lr": "0.000402957", "gnorm": "0.755", "train_wall": "418", "gb_free": "6.8", "wall": "135009"}
[2023-03-31 12:14:07,952][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 12:14:07,953][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 12:14:09,674][valid][INFO] - {"epoch": 54, "valid_loss": "4.812", "valid_ppl": "28.09", "valid_wps": "143922", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "58914", "valid_best_loss": "4.515"}
[2023-03-31 12:14:09,675][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 54 @ 58914 updates
[2023-03-31 12:14:09,676][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 12:14:11,193][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 12:14:11,219][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 54 @ 58914 updates, score 4.812) (writing took 1.5436573970073368 seconds)
[2023-03-31 12:14:11,219][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2023-03-31 12:14:11,220][train][INFO] - {"epoch": 54, "train_loss": "3.407", "train_ppl": "10.6", "train_wps": "45899.9", "train_ups": "0.43", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "58914", "train_lr": "0.000402263", "train_gnorm": "0.749", "train_train_wall": "2285", "train_gb_free": "6.8", "train_wall": "135272"}
[2023-03-31 12:14:11,221][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 12:14:11,251][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 12:14:11,253][fairseq.trainer][INFO] - begin training epoch 55
[2023-03-31 12:14:11,254][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 12:17:23,072][train_inner][INFO] - {"epoch": 55, "update": 54.079, "loss": "3.401", "ppl": "10.56", "wps": "47017.5", "ups": "0.44", "wpb": "106996", "bsz": "255.8", "num_updates": "59000", "lr": "0.000401739", "gnorm": "0.75", "train_wall": "406", "gb_free": "6.8", "wall": "135464"}
[2023-03-31 12:25:02,493][train_inner][INFO] - {"epoch": 55, "update": 54.262, "loss": "3.326", "ppl": "10.03", "wps": "46717.5", "ups": "0.44", "wpb": "107313", "bsz": "256", "num_updates": "59200", "lr": "0.000400522", "gnorm": "0.75", "train_wall": "412", "gb_free": "6.8", "wall": "135924"}
[2023-03-31 12:32:58,425][train_inner][INFO] - {"epoch": 55, "update": 54.445, "loss": "3.371", "ppl": "10.35", "wps": "45041.4", "ups": "0.42", "wpb": "107183", "bsz": "256", "num_updates": "59400", "lr": "0.000399304", "gnorm": "0.748", "train_wall": "417", "gb_free": "6.8", "wall": "136399"}
[2023-03-31 12:40:57,973][train_inner][INFO] - {"epoch": 55, "update": 54.629, "loss": "3.417", "ppl": "10.68", "wps": "44710.7", "ups": "0.42", "wpb": "107204", "bsz": "256", "num_updates": "59600", "lr": "0.000398087", "gnorm": "0.746", "train_wall": "421", "gb_free": "6.8", "wall": "136879"}
[2023-03-31 12:48:47,474][train_inner][INFO] - {"epoch": 55, "update": 54.812, "loss": "3.451", "ppl": "10.93", "wps": "45682.9", "ups": "0.43", "wpb": "107240", "bsz": "256", "num_updates": "59800", "lr": "0.00039687", "gnorm": "0.746", "train_wall": "420", "gb_free": "6.8", "wall": "137349"}
[2023-03-31 12:56:13,094][train_inner][INFO] - {"epoch": 55, "update": 54.995, "loss": "3.475", "ppl": "11.12", "wps": "48128.3", "ups": "0.45", "wpb": "107234", "bsz": "256", "num_updates": "60000", "lr": "0.000395652", "gnorm": "0.752", "train_wall": "400", "gb_free": "6.8", "wall": "137794"}
[2023-03-31 12:56:24,070][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 12:56:24,070][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 12:56:25,740][valid][INFO] - {"epoch": 55, "valid_loss": "4.84", "valid_ppl": "28.65", "valid_wps": "148706", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "60005", "valid_best_loss": "4.515"}
[2023-03-31 12:56:25,741][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 55 @ 60005 updates
[2023-03-31 12:56:25,742][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 12:56:27,518][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 12:56:27,544][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 55 @ 60005 updates, score 4.84) (writing took 1.8030098750023171 seconds)
[2023-03-31 12:56:27,545][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2023-03-31 12:56:27,545][train][INFO] - {"epoch": 55, "train_loss": "3.397", "train_ppl": "10.54", "train_wps": "46114.7", "train_ups": "0.43", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "60005", "train_lr": "0.000395622", "train_gnorm": "0.748", "train_train_wall": "2252", "train_gb_free": "6.8", "train_wall": "137809"}
[2023-03-31 12:56:27,547][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 12:56:27,576][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 12:56:27,578][fairseq.trainer][INFO] - begin training epoch 56
[2023-03-31 12:56:27,579][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 13:03:40,444][train_inner][INFO] - {"epoch": 56, "update": 55.179, "loss": "3.291", "ppl": "9.79", "wps": "47922.1", "ups": "0.45", "wpb": "107190", "bsz": "255.8", "num_updates": "60200", "lr": "0.000394435", "gnorm": "0.748", "train_wall": "398", "gb_free": "6.8", "wall": "138241"}
[2023-03-31 13:11:03,612][train_inner][INFO] - {"epoch": 56, "update": 55.362, "loss": "3.344", "ppl": "10.15", "wps": "48504.4", "ups": "0.45", "wpb": "107478", "bsz": "256", "num_updates": "60400", "lr": "0.000393217", "gnorm": "0.753", "train_wall": "398", "gb_free": "6.8", "wall": "138685"}
[2023-03-31 13:18:24,737][train_inner][INFO] - {"epoch": 56, "update": 55.545, "loss": "3.392", "ppl": "10.5", "wps": "48397", "ups": "0.45", "wpb": "106746", "bsz": "256", "num_updates": "60600", "lr": "0.000392", "gnorm": "0.754", "train_wall": "396", "gb_free": "6.8", "wall": "139126"}
[2023-03-31 13:25:47,248][train_inner][INFO] - {"epoch": 56, "update": 55.729, "loss": "3.427", "ppl": "10.75", "wps": "48497.3", "ups": "0.45", "wpb": "107303", "bsz": "256", "num_updates": "60800", "lr": "0.000390783", "gnorm": "0.759", "train_wall": "398", "gb_free": "6.8", "wall": "139568"}
[2023-03-31 13:33:09,642][train_inner][INFO] - {"epoch": 56, "update": 55.912, "loss": "3.449", "ppl": "10.92", "wps": "48492.7", "ups": "0.45", "wpb": "107264", "bsz": "256", "num_updates": "61000", "lr": "0.000389565", "gnorm": "0.747", "train_wall": "398", "gb_free": "6.8", "wall": "140011"}
[2023-03-31 13:36:41,796][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 13:36:41,797][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 13:36:43,532][valid][INFO] - {"epoch": 56, "valid_loss": "4.834", "valid_ppl": "28.52", "valid_wps": "142467", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "61096", "valid_best_loss": "4.515"}
[2023-03-31 13:36:43,533][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 56 @ 61096 updates
[2023-03-31 13:36:43,534][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 13:36:44,793][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 13:36:44,818][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 56 @ 61096 updates, score 4.834) (writing took 1.2844388220109977 seconds)
[2023-03-31 13:36:44,818][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2023-03-31 13:36:44,818][train][INFO] - {"epoch": 56, "train_loss": "3.389", "train_ppl": "10.47", "train_wps": "48385.9", "train_ups": "0.45", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "61096", "train_lr": "0.000388981", "train_gnorm": "0.752", "train_train_wall": "2170", "train_gb_free": "6.8", "train_wall": "140226"}
[2023-03-31 13:36:44,820][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 13:36:44,852][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 13:36:44,854][fairseq.trainer][INFO] - begin training epoch 57
[2023-03-31 13:36:44,854][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 13:40:35,640][train_inner][INFO] - {"epoch": 57, "update": 56.095, "loss": "3.361", "ppl": "10.28", "wps": "48190.8", "ups": "0.45", "wpb": "107465", "bsz": "255.8", "num_updates": "61200", "lr": "0.000388348", "gnorm": "0.747", "train_wall": "398", "gb_free": "6.8", "wall": "140457"}
[2023-03-31 13:48:16,584][train_inner][INFO] - {"epoch": 57, "update": 56.279, "loss": "3.312", "ppl": "9.93", "wps": "46475.3", "ups": "0.43", "wpb": "107112", "bsz": "256", "num_updates": "61400", "lr": "0.00038713", "gnorm": "0.758", "train_wall": "413", "gb_free": "6.8", "wall": "140918"}
[2023-03-31 13:55:54,830][train_inner][INFO] - {"epoch": 57, "update": 56.462, "loss": "3.359", "ppl": "10.26", "wps": "46818.2", "ups": "0.44", "wpb": "107271", "bsz": "256", "num_updates": "61600", "lr": "0.000385913", "gnorm": "0.749", "train_wall": "411", "gb_free": "6.8", "wall": "141376"}
[2023-03-31 14:03:56,940][train_inner][INFO] - {"epoch": 57, "update": 56.645, "loss": "3.404", "ppl": "10.58", "wps": "44501.9", "ups": "0.41", "wpb": "107274", "bsz": "256", "num_updates": "61800", "lr": "0.000384696", "gnorm": "0.762", "train_wall": "416", "gb_free": "6.8", "wall": "141858"}
[2023-03-31 14:12:02,102][train_inner][INFO] - {"epoch": 57, "update": 56.829, "loss": "3.437", "ppl": "10.83", "wps": "44146.5", "ups": "0.41", "wpb": "107091", "bsz": "256", "num_updates": "62000", "lr": "0.000383478", "gnorm": "0.755", "train_wall": "419", "gb_free": "6.8", "wall": "142343"}
[2023-03-31 14:19:36,167][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 14:19:36,175][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 14:19:38,034][valid][INFO] - {"epoch": 57, "valid_loss": "4.839", "valid_ppl": "28.61", "valid_wps": "137935", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "62187", "valid_best_loss": "4.515"}
[2023-03-31 14:19:38,035][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 57 @ 62187 updates
[2023-03-31 14:19:38,036][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 14:19:39,086][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 14:19:39,107][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 57 @ 62187 updates, score 4.839) (writing took 1.0718140850076452 seconds)
[2023-03-31 14:19:39,107][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2023-03-31 14:19:39,107][train][INFO] - {"epoch": 57, "train_loss": "3.38", "train_ppl": "10.41", "train_wps": "45434.7", "train_ups": "0.42", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "62187", "train_lr": "0.00038234", "train_gnorm": "0.755", "train_train_wall": "2259", "train_gb_free": "6.8", "train_wall": "142800"}
[2023-03-31 14:19:39,109][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 14:19:39,140][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 14:19:39,142][fairseq.trainer][INFO] - begin training epoch 58
[2023-03-31 14:19:39,143][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 14:20:10,433][train_inner][INFO] - {"epoch": 58, "update": 57.012, "loss": "3.442", "ppl": "10.87", "wps": "43815.7", "ups": "0.41", "wpb": "106983", "bsz": "255.8", "num_updates": "62200", "lr": "0.000382261", "gnorm": "0.754", "train_wall": "419", "gb_free": "6.8", "wall": "142831"}
[2023-03-31 14:28:00,170][train_inner][INFO] - {"epoch": 58, "update": 57.195, "loss": "3.277", "ppl": "9.69", "wps": "45703.5", "ups": "0.43", "wpb": "107343", "bsz": "256", "num_updates": "62400", "lr": "0.000381043", "gnorm": "0.754", "train_wall": "420", "gb_free": "6.8", "wall": "143301"}
[2023-03-31 14:35:57,329][train_inner][INFO] - {"epoch": 58, "update": 57.379, "loss": "3.334", "ppl": "10.08", "wps": "45018.1", "ups": "0.42", "wpb": "107402", "bsz": "256", "num_updates": "62600", "lr": "0.000379826", "gnorm": "0.76", "train_wall": "425", "gb_free": "6.8", "wall": "143778"}
[2023-03-31 14:44:02,559][train_inner][INFO] - {"epoch": 58, "update": 57.562, "loss": "3.37", "ppl": "10.34", "wps": "44201.8", "ups": "0.41", "wpb": "107239", "bsz": "256", "num_updates": "62800", "lr": "0.000378609", "gnorm": "0.756", "train_wall": "418", "gb_free": "6.8", "wall": "144264"}
[2023-03-31 14:51:55,303][train_inner][INFO] - {"epoch": 58, "update": 57.745, "loss": "3.41", "ppl": "10.63", "wps": "45426", "ups": "0.42", "wpb": "107373", "bsz": "256", "num_updates": "63000", "lr": "0.000377391", "gnorm": "0.757", "train_wall": "424", "gb_free": "6.8", "wall": "144736"}
[2023-03-31 14:59:51,801][train_inner][INFO] - {"epoch": 58, "update": 57.929, "loss": "3.444", "ppl": "10.88", "wps": "44862.7", "ups": "0.42", "wpb": "106885", "bsz": "256", "num_updates": "63200", "lr": "0.000376174", "gnorm": "0.758", "train_wall": "414", "gb_free": "6.8", "wall": "145213"}
[2023-03-31 15:02:53,285][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 15:02:53,286][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 15:02:55,077][valid][INFO] - {"epoch": 58, "valid_loss": "4.841", "valid_ppl": "28.66", "valid_wps": "138828", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "63278", "valid_best_loss": "4.515"}
[2023-03-31 15:02:55,078][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 58 @ 63278 updates
[2023-03-31 15:02:55,079][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 15:02:56,172][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 15:02:56,193][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 58 @ 63278 updates, score 4.841) (writing took 1.1149443349859212 seconds)
[2023-03-31 15:02:56,193][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2023-03-31 15:02:56,194][train][INFO] - {"epoch": 58, "train_loss": "3.372", "train_ppl": "10.35", "train_wps": "45035.9", "train_ups": "0.42", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "63278", "train_lr": "0.000375699", "train_gnorm": "0.758", "train_train_wall": "2291", "train_gb_free": "6.8", "train_wall": "145397"}
[2023-03-31 15:02:56,196][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 15:02:56,227][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 15:02:56,229][fairseq.trainer][INFO] - begin training epoch 59
[2023-03-31 15:02:56,230][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 15:07:31,211][train_inner][INFO] - {"epoch": 59, "update": 58.112, "loss": "3.331", "ppl": "10.07", "wps": "46576.3", "ups": "0.44", "wpb": "106986", "bsz": "255.8", "num_updates": "63400", "lr": "0.000374957", "gnorm": "0.764", "train_wall": "409", "gb_free": "6.8", "wall": "145672"}
[2023-03-31 15:14:58,273][train_inner][INFO] - {"epoch": 59, "update": 58.295, "loss": "3.299", "ppl": "9.84", "wps": "47980.6", "ups": "0.45", "wpb": "107252", "bsz": "256", "num_updates": "63600", "lr": "0.000373739", "gnorm": "0.761", "train_wall": "402", "gb_free": "6.8", "wall": "146119"}
[2023-03-31 15:22:38,899][train_inner][INFO] - {"epoch": 59, "update": 58.478, "loss": "3.348", "ppl": "10.18", "wps": "46506.5", "ups": "0.43", "wpb": "107110", "bsz": "256", "num_updates": "63800", "lr": "0.000372522", "gnorm": "0.759", "train_wall": "408", "gb_free": "6.8", "wall": "146580"}
[2023-03-31 15:30:41,151][train_inner][INFO] - {"epoch": 59, "update": 58.662, "loss": "3.386", "ppl": "10.46", "wps": "44627", "ups": "0.41", "wpb": "107607", "bsz": "256", "num_updates": "64000", "lr": "0.000371304", "gnorm": "0.76", "train_wall": "418", "gb_free": "6.8", "wall": "147062"}
[2023-03-31 15:38:40,280][train_inner][INFO] - {"epoch": 59, "update": 58.845, "loss": "3.418", "ppl": "10.69", "wps": "44684.9", "ups": "0.42", "wpb": "107049", "bsz": "256", "num_updates": "64200", "lr": "0.000370087", "gnorm": "0.768", "train_wall": "417", "gb_free": "6.8", "wall": "147541"}
[2023-03-31 15:45:10,929][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-03-31 15:45:10,937][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 15:45:13,350][valid][INFO] - {"epoch": 59, "valid_loss": "4.839", "valid_ppl": "28.62", "valid_wps": "102967", "valid_wpb": "1700.9", "valid_bsz": "4", "valid_num_updates": "64369", "valid_best_loss": "4.515"}
[2023-03-31 15:45:13,352][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 59 @ 64369 updates
[2023-03-31 15:45:13,354][fairseq.trainer][INFO] - Saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 15:45:16,464][fairseq.trainer][INFO] - Finished saving checkpoint to /home/alexey/Desktop/fairseq/multirun/2023-03-29/22-39-34/0/checkpoints/checkpoint_last.pt
[2023-03-31 15:45:16,497][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 59 @ 64369 updates, score 4.839) (writing took 3.145500501006609 seconds)
[2023-03-31 15:45:16,499][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2023-03-31 15:45:16,500][train][INFO] - {"epoch": 59, "train_loss": "3.363", "train_ppl": "10.29", "train_wps": "46042.5", "train_ups": "0.43", "train_wpb": "107206", "train_bsz": "256", "train_num_updates": "64369", "train_lr": "0.000369058", "train_gnorm": "0.761", "train_train_wall": "2242", "train_gb_free": "6.8", "train_wall": "147938"}
[2023-03-31 15:45:16,503][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-03-31 15:45:16,538][fairseq.data.iterators][INFO] - grouped total_num_itrs = 1091
[2023-03-31 15:45:16,541][fairseq.trainer][INFO] - begin training epoch 60
[2023-03-31 15:45:16,543][fairseq_cli.train][INFO] - Start iterating over samples
[2023-03-31 15:46:35,705][train_inner][INFO] - {"epoch": 60, "update": 59.028, "loss": "3.411", "ppl": "10.64", "wps": "45089.9", "ups": "0.42", "wpb": "107184", "bsz": "255.8", "num_updates": "64400", "lr": "0.00036887", "gnorm": "0.755", "train_wall": "415", "gb_free": "6.8", "wall": "148017"}
[2023-03-31 15:54:41,564][train_inner][INFO] - {"epoch": 60, "update": 59.212, "loss": "3.266", "ppl": "9.62", "wps": "44043.7", "ups": "0.41", "wpb": "106995", "bsz": "256", "num_updates": "64600", "lr": "0.000367652", "gnorm": "0.755", "train_wall": "416", "gb_free": "6.8", "wall": "148503"}
[2023-03-31 16:02:37,549][train_inner][INFO] - {"epoch": 60, "update": 59.395, "loss": "3.324", "ppl": "10.01", "wps": "44992.9", "ups": "0.42", "wpb": "107079", "bsz": "256", "num_updates": "64800", "lr": "0.000366435", "gnorm": "0.764", "train_wall": "414", "gb_free": "6.8", "wall": "148979"}
[2023-03-31 16:10:23,680][train_inner][INFO] - {"epoch": 60, "update": 59.578, "loss": "3.358", "ppl": "10.25", "wps": "46053", "ups": "0.43", "wpb": "107334", "bsz": "256", "num_updates": "65000", "lr": "0.000365217", "gnorm": "0.757", "train_wall": "418", "gb_free": "6.8", "wall": "149445"}
[2023-03-31 16:18:39,629][train_inner][INFO] - {"epoch": 60, "update": 59.762, "loss": "3.397", "ppl": "10.53", "wps": "43322.6", "ups": "0.4", "wpb": "107429", "bsz": "256", "num_updates": "65200", "lr": "0.000364", "gnorm": "0.769", "train_wall": "438", "gb_free": "6.8", "wall": "149941"}
